#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
P0 ç¼ºé™·ä¿®å¾©é©—è­‰æ¸¬è©¦è…³æœ¬

ã€æ¨™æº–åšæ³•ã€‘æŒ‰ç…§ Core æ¨¡çµ„ README çš„è¦ç¯„ï¼š
- ä½¿ç”¨æ­£ç¢ºçš„åŒ…å°å…¥æ–¹å¼
- ä¸ä¿®æ”¹ sys.path
- éµå¾ªå°ˆæ¡ˆæ¶æ§‹æ¨™æº–

æ­¤è…³æœ¬è‡ªå‹•é©—è­‰ä»¥ä¸‹ P0 ä¿®å¾©æˆæœï¼š
1. IDOR å¤šå¸³æˆ¶æ¸¬è©¦åŠŸèƒ½
2. AI Commander æ ¸å¿ƒåŠŸèƒ½
3. BioNeuron Master é‚è¼¯
4. ModelTrainer åŠŸèƒ½

ç›®æ¨™é¶å ´: http://localhost:3000

åŸ·è¡Œæ–¹å¼: å¾å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œ
    python -m testing.p0_fixes_validation_test
"""

import asyncio
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
import json

# ä¸å†ä¿®æ”¹ sys.pathï¼Œä½¿ç”¨æ¨™æº–å°å…¥
PROJECT_ROOT = Path(__file__).resolve().parent.parent

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(PROJECT_ROOT / "logs" / f"p0_validation_{datetime.now():%Y%m%d_%H%M%S}.log")
    ]
)
logger = logging.getLogger("P0_Validation")


class P0FixesValidator:
    """P0 ç¼ºé™·ä¿®å¾©é©—è­‰å™¨"""
    
    def __init__(self, target_url: str = "http://localhost:3000"):
        self.target_url = target_url
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "target": target_url,
            "tests": []
        }
        
    async def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰é©—è­‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹ P0 ç¼ºé™·ä¿®å¾©é©—è­‰æ¸¬è©¦")
        logger.info(f"ğŸ“ ç›®æ¨™é¶å ´: {self.target_url}")
        logger.info("=" * 80)
        
        # æ¸¬è©¦ 1: IDOR å¤šå¸³æˆ¶æ¸¬è©¦
        await self.test_idor_multi_user()
        
        # æ¸¬è©¦ 2: AI Commander æ ¸å¿ƒåŠŸèƒ½
        await self.test_ai_commander()
        
        # æ¸¬è©¦ 3: BioNeuron Master é‚è¼¯
        await self.test_bioneuron_master()
        
        # æ¸¬è©¦ 4: ModelTrainer åŠŸèƒ½
        await self.test_model_trainer()
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        self.generate_report()
        
    async def test_idor_multi_user(self):
        """æ¸¬è©¦ 1: é©—è­‰ IDOR å¤šå¸³æˆ¶æ¸¬è©¦åŠŸèƒ½"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ§ª æ¸¬è©¦ 1: IDOR å¤šå¸³æˆ¶æ¸¬è©¦åŠŸèƒ½")
        logger.info("=" * 80)
        
        test_result = {
            "test_name": "IDOR å¤šå¸³æˆ¶æ¸¬è©¦",
            "status": "PENDING",
            "details": [],
            "errors": []
        }
        
        try:
            # å°å…¥ IDOR Worker
            from services.features.function_idor.worker import IdorWorker
            from services.aiva_common.schemas import FunctionTaskPayload
            
            logger.info("âœ… æˆåŠŸå°å…¥ IdorWorker")
            test_result["details"].append("æ¨¡çµ„å°å…¥æˆåŠŸ")
            
            # å‰µå»º Worker å¯¦ä¾‹
            worker = IdorWorker()
            logger.info("âœ… æˆåŠŸå‰µå»º IdorWorker å¯¦ä¾‹")
            
            # æ¸¬è©¦å¤šå¸³æˆ¶æ†‘è­‰é…ç½®
            test_configs = [
                {
                    "name": "Bearer Token èªè­‰",
                    "config": {
                        "second_user_auth": {
                            "type": "bearer",
                            "token": "test_token_user2"
                        }
                    },
                    "expected_header": "Authorization"
                },
                {
                    "name": "Cookie èªè­‰",
                    "config": {
                        "second_user_auth": {
                            "type": "cookie",
                            "cookie": "session=user2_session"
                        }
                    },
                    "expected_header": "Cookie"
                },
                {
                    "name": "API Key èªè­‰",
                    "config": {
                        "second_user_auth": {
                            "type": "api_key",
                            "api_key": "test_api_key_user2",
                            "key_name": "X-API-Key"
                        }
                    },
                    "expected_header": "X-API-Key"
                },
                {
                    "name": "Basic Auth èªè­‰",
                    "config": {
                        "second_user_auth": {
                            "type": "basic",
                            "username": "user2",
                            "password": "pass2"
                        }
                    },
                    "expected_header": "Authorization"
                }
            ]
            
            passed_tests = 0
            for test_config in test_configs:
                try:
                    # å‰µå»ºæ¸¬è©¦ä»»å‹™
                    task = type('Task', (), {'config': test_config["config"]})()
                    
                    # èª¿ç”¨ _get_test_user_auth
                    auth_headers = worker._get_test_user_auth(task)
                    
                    if auth_headers and test_config["expected_header"] in auth_headers:
                        logger.info(f"  âœ… {test_config['name']}: é€šé")
                        logger.info(f"     è¿”å›: {auth_headers}")
                        passed_tests += 1
                        test_result["details"].append(f"{test_config['name']}: é€šé")
                    else:
                        logger.warning(f"  âš ï¸ {test_config['name']}: å¤±æ•—")
                        test_result["details"].append(f"{test_config['name']}: å¤±æ•—")
                        
                except Exception as e:
                    logger.error(f"  âŒ {test_config['name']}: éŒ¯èª¤ - {e}")
                    test_result["errors"].append(f"{test_config['name']}: {str(e)}")
            
            # æ¸¬è©¦ç„¡é…ç½®æƒ…æ³ï¼ˆæ‡‰è¿”å› Noneï¼‰
            task_no_config = type('Task', (), {'config': None})()
            auth_no_config = worker._get_test_user_auth(task_no_config)
            if auth_no_config is None:
                logger.info("  âœ… ç„¡é…ç½®æ¸¬è©¦: é€šé (æ­£ç¢ºè¿”å› None)")
                passed_tests += 1
                test_result["details"].append("ç„¡é…ç½®æ¸¬è©¦: é€šé")
            
            # è©•ä¼°æ¸¬è©¦çµæœ
            if passed_tests >= 4:
                test_result["status"] = "PASSED"
                logger.info(f"âœ… IDOR å¤šå¸³æˆ¶æ¸¬è©¦: é€šé ({passed_tests}/5)")
            else:
                test_result["status"] = "FAILED"
                logger.warning(f"âš ï¸ IDOR å¤šå¸³æˆ¶æ¸¬è©¦: éƒ¨åˆ†é€šé ({passed_tests}/5)")
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["errors"].append(str(e))
            logger.error(f"âŒ IDOR æ¸¬è©¦éŒ¯èª¤: {e}", exc_info=True)
            
        self.results["tests"].append(test_result)
        
    async def test_ai_commander(self):
        """æ¸¬è©¦ 2: é©—è­‰ AI Commander æ ¸å¿ƒåŠŸèƒ½"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ§ª æ¸¬è©¦ 2: AI Commander æ ¸å¿ƒåŠŸèƒ½")
        logger.info("=" * 80)
        
        test_result = {
            "test_name": "AI Commander æ ¸å¿ƒåŠŸèƒ½",
            "status": "PENDING",
            "details": [],
            "errors": []
        }
        
        try:
            # å°å…¥ AI Commander
            from services.core.aiva_core.ai_commander import AICommander
            
            logger.info("âœ… æˆåŠŸå°å…¥ AICommander")
            test_result["details"].append("æ¨¡çµ„å°å…¥æˆåŠŸ")
            
            # å‰µå»º AICommander å¯¦ä¾‹
            commander = AICommander()
            logger.info("âœ… æˆåŠŸå‰µå»º AICommander å¯¦ä¾‹")
            
            # æª¢æŸ¥é—œéµçµ„ä»¶
            checks = []
            
            # 1. æª¢æŸ¥ç¶“é©—è³‡æ–™åº«æ•´åˆ
            if hasattr(commander, 'experience_manager'):
                logger.info("  âœ… ç¶“é©—è³‡æ–™åº« (ExperienceManager): å·²æ•´åˆ")
                checks.append(True)
                test_result["details"].append("ExperienceManager å·²æ•´åˆ")
                
                # æª¢æŸ¥ storage_backend
                if hasattr(commander.experience_manager, 'storage'):
                    logger.info("  âœ… å„²å­˜å¾Œç«¯ (StorageBackend): å·²é…ç½®")
                    checks.append(True)
                    test_result["details"].append("StorageBackend å·²é…ç½®")
                else:
                    logger.warning("  âš ï¸ å„²å­˜å¾Œç«¯æœªé…ç½®")
                    checks.append(False)
            else:
                logger.warning("  âš ï¸ ExperienceManager æœªæ•´åˆ")
                checks.append(False)
            
            # 2. æª¢æŸ¥ BioNeuronRAGAgent
            if hasattr(commander, 'bio_neuron_agent'):
                logger.info("  âœ… BioNeuronRAGAgent: å·²æ¥å…¥")
                checks.append(True)
                test_result["details"].append("BioNeuronRAGAgent å·²æ¥å…¥")
            else:
                logger.warning("  âš ï¸ BioNeuronRAGAgent æœªæ¥å…¥")
                checks.append(False)
            
            # 3. æª¢æŸ¥æ”»æ“Šè¨ˆç•«ç”Ÿæˆå‡½å¼
            if hasattr(commander, '_plan_attack'):
                logger.info("  âœ… æ”»æ“Šè¨ˆç•«ç”Ÿæˆ (_plan_attack): å·²å¯¦ç¾")
                checks.append(True)
                test_result["details"].append("_plan_attack å·²å¯¦ç¾")
                
                # æ¸¬è©¦å‡½å¼ç°½å
                import inspect
                sig = inspect.signature(commander._plan_attack)
                logger.info(f"     å‡½å¼ç°½å: {sig}")
            else:
                logger.warning("  âš ï¸ _plan_attack æœªå¯¦ç¾")
                checks.append(False)
            
            # 4. æª¢æŸ¥ç­–ç•¥æ±ºç­–å‡½å¼
            if hasattr(commander, '_make_strategy_decision'):
                logger.info("  âœ… ç­–ç•¥æ±ºç­– (_make_strategy_decision): å·²å¯¦ç¾")
                checks.append(True)
                test_result["details"].append("_make_strategy_decision å·²å¯¦ç¾")
            else:
                logger.warning("  âš ï¸ _make_strategy_decision æœªå¯¦ç¾")
                checks.append(False)
            
            # è©•ä¼°æ¸¬è©¦çµæœ
            passed_checks = sum(checks)
            total_checks = len(checks)
            
            if passed_checks == total_checks:
                test_result["status"] = "PASSED"
                logger.info(f"âœ… AI Commander æ¸¬è©¦: å®Œå…¨é€šé ({passed_checks}/{total_checks})")
            elif passed_checks >= total_checks * 0.7:
                test_result["status"] = "PARTIAL"
                logger.info(f"âš ï¸ AI Commander æ¸¬è©¦: éƒ¨åˆ†é€šé ({passed_checks}/{total_checks})")
            else:
                test_result["status"] = "FAILED"
                logger.warning(f"âŒ AI Commander æ¸¬è©¦: æœªé€šé ({passed_checks}/{total_checks})")
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["errors"].append(str(e))
            logger.error(f"âŒ AI Commander æ¸¬è©¦éŒ¯èª¤: {e}", exc_info=True)
            
        self.results["tests"].append(test_result)
        
    async def test_bioneuron_master(self):
        """æ¸¬è©¦ 3: é©—è­‰ BioNeuron Master é‚è¼¯"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ§ª æ¸¬è©¦ 3: BioNeuron Master é‚è¼¯")
        logger.info("=" * 80)
        
        test_result = {
            "test_name": "BioNeuron Master é‚è¼¯",
            "status": "PENDING",
            "details": [],
            "errors": []
        }
        
        try:
            # å°å…¥ BioNeuron Master
            from services.core.aiva_core.bio_neuron_master import BioNeuronMasterController
            
            logger.info("âœ… æˆåŠŸå°å…¥ BioNeuronMasterController")
            test_result["details"].append("æ¨¡çµ„å°å…¥æˆåŠŸ")
            
            # å‰µå»ºå¯¦ä¾‹ï¼ˆä½¿ç”¨è‡¨æ™‚è·¯å¾‘ï¼‰
            controller = BioNeuronMasterController(
                codebase_path=str(PROJECT_ROOT),
                default_mode="hybrid"  # å‚³éå­—ä¸²ï¼Œç¨‹å¼æœƒè‡ªå‹•è½‰æ›
            )
            logger.info("âœ… æˆåŠŸå‰µå»º BioNeuronMasterController å¯¦ä¾‹")
            
            # æª¢æŸ¥é—œéµçµ„ä»¶
            checks = []
            
            # 1. æª¢æŸ¥ NLU åŠŸèƒ½
            if hasattr(controller, '_parse_ui_command'):
                logger.info("  âœ… NLU åŠŸèƒ½ (_parse_ui_command): å·²å¯¦ç¾")
                checks.append(True)
                test_result["details"].append("NLU åŠŸèƒ½å·²å¯¦ç¾")
                
                # æ¸¬è©¦ NLUï¼ˆç°¡å–®æ¸¬è©¦ï¼‰
                try:
                    test_input = "æƒæ http://localhost:3000"
                    result = await controller._parse_ui_command(test_input)
                    logger.info(f"     NLU æ¸¬è©¦çµæœ: {result}")
                    test_result["details"].append(f"NLU æ¸¬è©¦: {result.get('intent', 'unknown')}")
                except Exception as e:
                    logger.warning(f"     NLU æ¸¬è©¦è­¦å‘Š: {e}")
            else:
                logger.warning("  âš ï¸ _parse_ui_command æœªå¯¦ç¾")
                checks.append(False)
            
            # 2. æª¢æŸ¥ AI æ±ºç­–åŠŸèƒ½
            if hasattr(controller, '_bio_neuron_decide'):
                logger.info("  âœ… AI æ±ºç­– (_bio_neuron_decide): å·²å¯¦ç¾")
                checks.append(True)
                test_result["details"].append("AI æ±ºç­–åŠŸèƒ½å·²å¯¦ç¾")
            else:
                logger.warning("  âš ï¸ _bio_neuron_decide æœªå¯¦ç¾")
                checks.append(False)
            
            # 3. æª¢æŸ¥ç¶“é©—å­¸ç¿’æ•´åˆ
            if hasattr(controller, '_learn_from_execution'):
                logger.info("  âœ… ç¶“é©—å­¸ç¿’ (_learn_from_execution): å·²å¯¦ç¾")
                checks.append(True)
                test_result["details"].append("ç¶“é©—å­¸ç¿’å·²å¯¦ç¾")
            else:
                logger.warning("  âš ï¸ _learn_from_execution æœªå¯¦ç¾")
                checks.append(False)
            
            # 4. æª¢æŸ¥ä»»å‹™å•Ÿå‹•åŠŸèƒ½
            task_start_methods = ['_start_scan_task', '_start_attack_task', '_start_training_task']
            task_checks = []
            for method in task_start_methods:
                if hasattr(controller, method):
                    logger.info(f"  âœ… {method}: å·²å¯¦ç¾")
                    task_checks.append(True)
                else:
                    logger.warning(f"  âš ï¸ {method}: æœªå¯¦ç¾")
                    task_checks.append(False)
            
            if all(task_checks):
                checks.append(True)
                test_result["details"].append("æ‰€æœ‰ä»»å‹™å•Ÿå‹•åŠŸèƒ½å·²å¯¦ç¾")
            else:
                checks.append(False)
                test_result["details"].append(f"ä»»å‹™å•Ÿå‹•åŠŸèƒ½: {sum(task_checks)}/3 å¯¦ç¾")
            
            # 5. æª¢æŸ¥ RAG Engine
            if hasattr(controller, 'rag_engine'):
                logger.info("  âœ… RAG Engine: å·²æ•´åˆ")
                checks.append(True)
                test_result["details"].append("RAG Engine å·²æ•´åˆ")
            else:
                logger.warning("  âš ï¸ RAG Engine æœªæ•´åˆ")
                checks.append(False)
            
            # è©•ä¼°æ¸¬è©¦çµæœ
            passed_checks = sum(checks)
            total_checks = len(checks)
            
            if passed_checks == total_checks:
                test_result["status"] = "PASSED"
                logger.info(f"âœ… BioNeuron Master æ¸¬è©¦: å®Œå…¨é€šé ({passed_checks}/{total_checks})")
            elif passed_checks >= total_checks * 0.7:
                test_result["status"] = "PARTIAL"
                logger.info(f"âš ï¸ BioNeuron Master æ¸¬è©¦: éƒ¨åˆ†é€šé ({passed_checks}/{total_checks})")
            else:
                test_result["status"] = "FAILED"
                logger.warning(f"âŒ BioNeuron Master æ¸¬è©¦: æœªé€šé ({passed_checks}/{total_checks})")
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["errors"].append(str(e))
            logger.error(f"âŒ BioNeuron Master æ¸¬è©¦éŒ¯èª¤: {e}", exc_info=True)
            
        self.results["tests"].append(test_result)
        
    async def test_model_trainer(self):
        """æ¸¬è©¦ 4: é©—è­‰ ModelTrainer åŠŸèƒ½"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ§ª æ¸¬è©¦ 4: ModelTrainer åŠŸèƒ½")
        logger.info("=" * 80)
        
        test_result = {
            "test_name": "ModelTrainer åŠŸèƒ½",
            "status": "PENDING",
            "details": [],
            "errors": []
        }
        
        try:
            # å°å…¥ ModelTrainer
            from services.core.aiva_core.learning.model_trainer import ModelTrainer
            
            logger.info("âœ… æˆåŠŸå°å…¥ ModelTrainer")
            test_result["details"].append("æ¨¡çµ„å°å…¥æˆåŠŸ")
            
            # å‰µå»ºå¯¦ä¾‹
            trainer = ModelTrainer()
            logger.info("âœ… æˆåŠŸå‰µå»º ModelTrainer å¯¦ä¾‹")
            
            # æª¢æŸ¥é—œéµå‡½å¼
            checks = []
            methods_to_check = [
                ('_train_model_supervised', 'ç›£ç£å­¸ç¿’è¨“ç·´'),
                ('_train_model_rl', 'å¼·åŒ–å­¸ç¿’è¨“ç·´'),
                ('_evaluate_model', 'æ¨¡å‹è©•ä¼°'),
                ('_save_model', 'æ¨¡å‹ä¿å­˜'),
                ('load_model', 'æ¨¡å‹è¼‰å…¥')
            ]
            
            for method_name, description in methods_to_check:
                if hasattr(trainer, method_name):
                    logger.info(f"  âœ… {description} ({method_name}): å·²å¯¦ç¾")
                    checks.append(True)
                    test_result["details"].append(f"{description}: å·²å¯¦ç¾")
                    
                    # æª¢æŸ¥å‡½å¼æ˜¯å¦ç‚ºå¯¦éš›å¯¦ç¾ï¼ˆä¸æ˜¯ç©ºå¯¦ä½œï¼‰
                    import inspect
                    method = getattr(trainer, method_name)
                    source = inspect.getsource(method)
                    
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«å¯¦éš›é‚è¼¯ï¼ˆé TODO æˆ–ç°¡å–® returnï¼‰
                    if 'TODO' not in source and 'pass' not in source[:100]:
                        logger.info(f"     âœ“ åŒ…å«å¯¦éš›å¯¦ç¾é‚è¼¯")
                    else:
                        logger.warning(f"     âš ï¸ å¯èƒ½ç‚ºç©ºå¯¦ä½œ")
                else:
                    logger.warning(f"  âš ï¸ {description} ({method_name}): æœªå¯¦ç¾")
                    checks.append(False)
            
            # æ¸¬è©¦ç›£ç£å­¸ç¿’åŠŸèƒ½ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            try:
                import numpy as np
                from services.aiva_common.schemas import ModelTrainingConfig
                
                # å‰µå»ºç°¡å–®æ¸¬è©¦æ•¸æ“š
                X_train = np.random.rand(100, 10)
                y_train = np.random.randint(0, 2, 100)
                X_val = np.random.rand(20, 10)
                y_val = np.random.randint(0, 2, 20)
                
                config = ModelTrainingConfig(
                    model_type="random_forest",
                    max_epochs=5,
                    batch_size=32
                )
                
                logger.info("  ğŸ”¬ åŸ·è¡Œç›£ç£å­¸ç¿’æ¸¬è©¦...")
                result = await trainer._train_model_supervised(
                    X_train, y_train, X_val, y_val, config
                )
                
                if result and 'error' not in result:
                    logger.info(f"  âœ… ç›£ç£å­¸ç¿’æ¸¬è©¦: æˆåŠŸ")
                    logger.info(f"     è¨“ç·´çµæœ: {result}")
                    test_result["details"].append("ç›£ç£å­¸ç¿’å¯¦éš›æ¸¬è©¦: æˆåŠŸ")
                else:
                    logger.warning(f"  âš ï¸ ç›£ç£å­¸ç¿’æ¸¬è©¦: è¿”å›éŒ¯èª¤")
                    test_result["details"].append(f"ç›£ç£å­¸ç¿’æ¸¬è©¦: {result.get('error', 'unknown')}")
                    
            except Exception as e:
                logger.warning(f"  âš ï¸ ç›£ç£å­¸ç¿’æ¸¬è©¦è·³é: {e}")
                test_result["details"].append(f"ç›£ç£å­¸ç¿’æ¸¬è©¦: è·³é ({str(e)[:50]})")
            
            # è©•ä¼°æ¸¬è©¦çµæœ
            passed_checks = sum(checks)
            total_checks = len(checks)
            
            if passed_checks == total_checks:
                test_result["status"] = "PASSED"
                logger.info(f"âœ… ModelTrainer æ¸¬è©¦: å®Œå…¨é€šé ({passed_checks}/{total_checks})")
            elif passed_checks >= total_checks * 0.8:
                test_result["status"] = "PARTIAL"
                logger.info(f"âš ï¸ ModelTrainer æ¸¬è©¦: éƒ¨åˆ†é€šé ({passed_checks}/{total_checks})")
            else:
                test_result["status"] = "FAILED"
                logger.warning(f"âŒ ModelTrainer æ¸¬è©¦: æœªé€šé ({passed_checks}/{total_checks})")
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["errors"].append(str(e))
            logger.error(f"âŒ ModelTrainer æ¸¬è©¦éŒ¯èª¤: {e}", exc_info=True)
            
        self.results["tests"].append(test_result)
        
    def generate_report(self):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š æ¸¬è©¦å ±å‘Š")
        logger.info("=" * 80)
        
        # çµ±è¨ˆçµæœ
        total = len(self.results["tests"])
        passed = sum(1 for t in self.results["tests"] if t["status"] == "PASSED")
        partial = sum(1 for t in self.results["tests"] if t["status"] == "PARTIAL")
        failed = sum(1 for t in self.results["tests"] if t["status"] == "FAILED")
        errors = sum(1 for t in self.results["tests"] if t["status"] == "ERROR")
        
        logger.info(f"\nç¸½æ¸¬è©¦æ•¸: {total}")
        logger.info(f"âœ… å®Œå…¨é€šé: {passed}")
        logger.info(f"âš ï¸ éƒ¨åˆ†é€šé: {partial}")
        logger.info(f"âŒ æœªé€šé: {failed}")
        logger.info(f"ğŸ”¥ éŒ¯èª¤: {errors}")
        
        # è©³ç´°çµæœ
        logger.info("\n" + "-" * 80)
        for test in self.results["tests"]:
            status_icon = {
                "PASSED": "âœ…",
                "PARTIAL": "âš ï¸",
                "FAILED": "âŒ",
                "ERROR": "ğŸ”¥",
                "PENDING": "â¸ï¸"
            }.get(test["status"], "â“")
            
            logger.info(f"\n{status_icon} {test['test_name']}: {test['status']}")
            for detail in test["details"]:
                logger.info(f"  - {detail}")
            if test["errors"]:
                logger.info("  éŒ¯èª¤:")
                for error in test["errors"]:
                    logger.info(f"    - {error}")
        
        # ä¿å­˜ JSON å ±å‘Š
        report_path = PROJECT_ROOT / "_out" / f"p0_validation_report_{datetime.now():%Y%m%d_%H%M%S}.json"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
        
        # æœ€çµ‚è©•ä¼°
        logger.info("\n" + "=" * 80)
        if passed == total:
            logger.info("ğŸ‰ æ‰€æœ‰ P0 ä¿®å¾©é©—è­‰æ¸¬è©¦å…¨éƒ¨é€šéï¼")
        elif passed + partial >= total * 0.8:
            logger.info("âœ… å¤§éƒ¨åˆ† P0 ä¿®å¾©é©—è­‰æ¸¬è©¦é€šé")
        else:
            logger.warning("âš ï¸ éƒ¨åˆ† P0 ä¿®å¾©éœ€è¦é€²ä¸€æ­¥æª¢æŸ¥")
        logger.info("=" * 80)


async def main():
    """ä¸»å‡½å¼"""
    # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
    (PROJECT_ROOT / "logs").mkdir(exist_ok=True)
    (PROJECT_ROOT / "_out").mkdir(exist_ok=True)
    
    # å‰µå»ºé©—è­‰å™¨
    validator = P0FixesValidator(target_url="http://localhost:3000")
    
    # åŸ·è¡Œæ¸¬è©¦
    await validator.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())
