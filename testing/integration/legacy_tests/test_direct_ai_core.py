#!/usr/bin/env python3
"""ç›´æ¥æ¸¬è©¦æ›¿æ›çš„ScalableBioNetæ ¸å¿ƒ"""

import numpy as np
import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

# ç›´æ¥åŸ·è¡Œbio_neuron_core.pyä¸­çš„ScalableBioNetéƒ¨åˆ†
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    has_torch = True
    print("âœ… PyTorchå¯ç”¨")
except ImportError:
    has_torch = False
    print("âŒ PyTorchä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨å‡AI")

# æ¨¡æ“¬BiologicalSpikingLayer
class BiologicalSpikingLayer:
    def __init__(self, input_size: int, output_size: int):
        self.input_size = input_size
        self.output_size = output_size
        self.params = input_size * output_size
        self.weights = np.random.randn(input_size, output_size) * 0.1
    
    def forward(self, x):
        return np.tanh(x @ self.weights)

# ç°¡åŒ–çš„ScalableBioNetæ¸¬è©¦ç‰ˆæœ¬
class TestScalableBioNet:
    def __init__(self, input_size: int, num_tools: int):
        self.input_size = input_size
        self.num_tools = num_tools
        
        if has_torch:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            self.has_real_torch = True
            
            # çœŸå¯¦çš„PyTorchç¥ç¶“ç¶²è·¯
            self.hidden_size_1 = 2048
            self.hidden_size_2 = 1024
            
            self.network = nn.Sequential(
                nn.Linear(input_size, self.hidden_size_1),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(self.hidden_size_1, self.hidden_size_2),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(self.hidden_size_2, num_tools)
            ).to(self.device)
            
            self.total_params = sum(p.numel() for p in self.network.parameters())
            print(f"ğŸ§  çœŸå¯¦AIæ ¸å¿ƒ: {self.total_params:,} åƒæ•¸ ({self.total_params/1_000_000:.1f}M)")
            
        else:
            self.has_real_torch = False
            # é™ç´šåˆ°å‡AI
            self.hidden_size_1 = 2048
            self.hidden_size_2 = 1024
            
            self.fc1 = np.random.randn(input_size, self.hidden_size_1)
            self.spiking1 = BiologicalSpikingLayer(self.hidden_size_1, self.hidden_size_2)
            self.fc2 = np.random.randn(self.hidden_size_2, num_tools)
            
            self.total_params = (input_size * self.hidden_size_1 + 
                               self.spiking1.params + 
                               self.hidden_size_2 * num_tools)
            print(f"ğŸ¤– å‡AIæ ¸å¿ƒ: {self.total_params:,} åƒæ•¸")
    
    def forward(self, x):
        if self.has_real_torch:
            # çœŸå¯¦AIå‰å‘å‚³æ’­
            self.network.eval()
            if isinstance(x, np.ndarray):
                x_tensor = torch.from_numpy(x.astype(np.float32)).to(self.device)
            else:
                x_tensor = torch.tensor(x, dtype=torch.float32).to(self.device)
            
            if x_tensor.dim() == 1:
                x_tensor = x_tensor.unsqueeze(0)
            
            with torch.no_grad():
                logits = self.network(x_tensor)
                probabilities = F.softmax(logits, dim=1)
                return probabilities.cpu().numpy()
        else:
            # å‡AIå‰å‘å‚³æ’­
            x = np.tanh(x @ self.fc1)
            x = self.spiking1.forward(x)
            decision_potential = x @ self.fc2
            e_x = np.exp(decision_potential - np.max(decision_potential))
            return e_x / e_x.sum(axis=0)

def test_ai_core():
    print("ğŸš€ AIVA AIæ ¸å¿ƒå°æ¯”æ¸¬è©¦")
    print("=" * 50)
    
    # å‰µå»ºæ¸¬è©¦å¯¦ä¾‹
    net = TestScalableBioNet(input_size=512, num_tools=10)
    
    # æ¸¬è©¦è¼¸å…¥
    rng = np.random.default_rng(42)
    test_input = rng.random((1, 512))
    
    print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
    print(f"AIé¡å‹: {'çœŸå¯¦AI (PyTorch)' if net.has_real_torch else 'å‡AI (NumPy)'}")
    print(f"åƒæ•¸æ•¸é‡: {net.total_params:,}")
    print(f"è¨­å‚™: {getattr(net, 'device', 'CPU/NumPy')}")
    
    # åŸ·è¡Œå‰å‘å‚³æ’­
    output = net.forward(test_input)
    print(f"è¼¸å‡ºå½¢ç‹€: {output.shape}")
    print(f"è¼¸å‡ºæ©Ÿç‡å’Œ: {np.sum(output):.6f}")
    print(f"æœ€å¤§æ©Ÿç‡: {np.max(output):.6f}")
    print(f"æœ€å°æ©Ÿç‡: {np.min(output):.6f}")
    
    # æ€§èƒ½æ¸¬è©¦
    import time
    start_time = time.time()
    for _ in range(100):
        _ = net.forward(test_input)
    inference_time = (time.time() - start_time) / 100
    
    print(f"å¹³å‡æ¨ç†æ™‚é–“: {inference_time*1000:.2f} ms")
    
    print("\nğŸ¯ å°æ¯”åˆ†æ:")
    if net.has_real_torch:
        print("âœ… ä½¿ç”¨çœŸå¯¦PyTorchç¥ç¶“ç¶²è·¯")
        print("âœ… å…·å‚™çœŸæ­£çš„å­¸ç¿’èƒ½åŠ›")
        print("âœ… GPUåŠ é€Ÿæ”¯æŒ")
        print("âœ… å¯å„²å­˜/è¼‰å…¥æ¬Šé‡")
        
        # æª¢æŸ¥æ¬Šé‡æª”æ¡ˆ
        weights_file = "aiva_real_ai_core.pth"
        if os.path.exists(weights_file):
            file_size = os.path.getsize(weights_file)
            print(f"âœ… æ¬Šé‡æª”æ¡ˆ: {file_size/1024/1024:.1f} MB")
        
    else:
        print("âŒ ä½¿ç”¨å‡AI (éš¨æ©Ÿæ¬Šé‡)")
        print("âŒ ç„¡æ³•å­¸ç¿’æˆ–è¨“ç·´")
        print("âŒ æ²’æœ‰GPUåŠ é€Ÿ")
        print("âŒ ç„¡æ³•æŒä¹…åŒ–")
    
    return net.has_real_torch

if __name__ == "__main__":
    success = test_ai_core()
    print("\n" + "="*50)
    if success:
        print("ğŸ‰ AIVAæˆåŠŸå‡ç´šåˆ°çœŸå¯¦AI!")
    else:
        print("âš ï¸  AIVAä»åœ¨ä½¿ç”¨å‡AI")
    print("="*50)