#!/usr/bin/env python3
"""
æ¸¬è©¦5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ•´åˆ
"""

import torch
import numpy as np
from pathlib import Path
import sys
import os

# æ·»åŠ æœå‹™è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir / 'services' / 'core'))

try:
    from aiva_core.ai_engine.real_neural_core import RealAICore, RealDecisionEngine
    print("âœ… æˆåŠŸå°å…¥5M AIæ ¸å¿ƒæ¨¡çµ„")
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    
    # å˜—è©¦ç›´æ¥å°å…¥
    try:
        sys.path.insert(0, str(current_dir / 'services' / 'core' / 'aiva_core' / 'ai_engine'))
        from real_neural_core import RealAICore, RealDecisionEngine
        print("âœ… ç›´æ¥å°å…¥5M AIæ ¸å¿ƒæ¨¡çµ„æˆåŠŸ")
    except ImportError as e2:
        print(f"âŒ ç›´æ¥å°å…¥ä¹Ÿå¤±æ•—: {e2}")
        sys.exit(1)

def test_5m_model():
    """æ¸¬è©¦5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯"""
    print("\nğŸ”¬ æ¸¬è©¦5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯...")
    
    # æª¢æŸ¥æ¬Šé‡æª”æ¡ˆ
    weights_path = "services/core/aiva_core/ai_engine/aiva_5M_weights.pth"
    if not Path(weights_path).exists():
        print(f"âŒ æ¬Šé‡æª”æ¡ˆä¸å­˜åœ¨: {weights_path}")
        return False
    
    # å‰µå»º5Mæ¨¡å‹å¯¦ä¾‹
    try:
        ai_core = RealAICore(
            input_size=512,
            output_size=100,
            aux_output_size=531,
            use_5m_model=True,
            weights_path=weights_path
        )
        print("âœ… 5M AIæ ¸å¿ƒå‰µå»ºæˆåŠŸ")
        
        # è¼‰å…¥æ¬Šé‡
        ai_core.load_weights()
        print("âœ… 5Mæ¨¡å‹æ¬Šé‡è¼‰å…¥æˆåŠŸ")
        
        # æ¸¬è©¦å‰å‘æ¨ç†
        test_input = torch.randn(1, 512)  # æ‰¹æ¬¡å¤§å°1, 512ç¶­è¼¸å…¥
        
        with torch.no_grad():
            # æ¸¬è©¦ä¸»è¼¸å‡º
            main_output = ai_core.forward(test_input)
            print(f"âœ… ä¸»è¼¸å‡ºå½¢ç‹€: {main_output.shape} (é æœŸ: [1, 100])")
            
            # æ¸¬è©¦é›™è¼¸å‡º
            main_out, aux_out = ai_core.forward_with_aux(test_input)
            print(f"âœ… é›™è¼¸å‡ºå½¢ç‹€: ä¸»{main_out.shape}, è¼”{aux_out.shape}")
            
            # æ±ºç­–æ¸¬è©¦
            decision = torch.argmax(main_output, dim=1).item()
            confidence = torch.max(torch.softmax(main_output, dim=1)).item()
            
            print(f"ğŸ¯ æ±ºç­–çµæœ: {decision} (ä¿¡å¿ƒåº¦: {confidence:.3f})")
            
        return True
        
    except Exception as e:
        print(f"âŒ 5Mæ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_decision_engine():
    """æ¸¬è©¦5Mæ±ºç­–å¼•æ“"""
    print("\nğŸ§  æ¸¬è©¦5Mæ±ºç­–å¼•æ“...")
    
    try:
        # å‰µå»º5Mæ±ºç­–å¼•æ“
        engine = RealDecisionEngine(
            weights_path="services/core/aiva_core/ai_engine/aiva_5M_weights.pth",
            use_5m_model=True
        )
        print("âœ… 5Mæ±ºç­–å¼•æ“å‰µå»ºæˆåŠŸ")
        
        # è¼‰å…¥æ¬Šé‡
        engine.ai_core.load_weights()
        print("âœ… æ±ºç­–å¼•æ“æ¬Šé‡è¼‰å…¥æˆåŠŸ")
        
        # æ¸¬è©¦æ±ºç­–ç”Ÿæˆ
        test_context = {
            "target_info": "test_target",
            "tools_available": ["nmap", "nikto", "sqlmap"],
            "scan_results": {"ports": [80, 443], "services": ["http", "https"]}
        }
        
        decision = engine.generate_decision("é¸æ“‡æœ€ä½³æ”»æ“Šå·¥å…·", test_context)
        print(f"âœ… æ±ºç­–ç”ŸæˆæˆåŠŸ: {decision['decision']}")
        print(f"   ä¿¡å¿ƒåº¦: {decision['confidence']:.3f}")
        print(f"   æ¨ç†: {decision['reasoning'][:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ±ºç­–å¼•æ“æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_compatibility():
    """æ¸¬è©¦å‘å¾Œå…¼å®¹æ€§"""
    print("\nğŸ”„ æ¸¬è©¦å‘å¾Œå…¼å®¹æ€§...")
    
    try:
        # æ¸¬è©¦åŸå§‹æ¶æ§‹
        legacy_core = RealAICore(
            input_size=512,
            output_size=128,
            use_5m_model=False
        )
        print("âœ… åŸå§‹æ¶æ§‹æ ¸å¿ƒå‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦å‰å‘æ¨ç†
        test_input = torch.randn(1, 512)
        with torch.no_grad():
            output = legacy_core.forward(test_input)
            print(f"âœ… åŸå§‹æ¶æ§‹è¼¸å‡ºå½¢ç‹€: {output.shape} (é æœŸ: [1, 128])")
        
        # æ¸¬è©¦5Mæ¶æ§‹ä¸æ”¯æ´é›™è¼¸å‡º
        try:
            legacy_core.forward_with_aux(test_input)
            print("âŒ åŸå§‹æ¶æ§‹ä¸æ‡‰æ”¯æ´é›™è¼¸å‡º")
            return False
        except ValueError:
            print("âœ… åŸå§‹æ¶æ§‹æ­£ç¢ºæ‹’çµ•é›™è¼¸å‡º")
        
        return True
        
    except Exception as e:
        print(f"âŒ å…¼å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("ğŸš€ é–‹å§‹5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ•´åˆæ¸¬è©¦")
    print("=" * 50)
    
    # æª¢æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"ğŸ® CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        print("ğŸ’» ä½¿ç”¨CPUé‹ç®—")
    
    # åŸ·è¡Œæ¸¬è©¦
    tests = [
        ("5Mæ¨¡å‹æ ¸å¿ƒ", test_5m_model),
        ("5Mæ±ºç­–å¼•æ“", test_decision_engine),
        ("å‘å¾Œå…¼å®¹æ€§", test_compatibility)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        if test_func():
            passed += 1
            print(f"âœ… {test_name} é€šé")
        else:
            print(f"âŒ {test_name} å¤±æ•—")
    
    print(f"\n{'='*50}")
    print(f"ğŸ† æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ•´åˆæˆåŠŸ!")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥å•é¡Œ")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)