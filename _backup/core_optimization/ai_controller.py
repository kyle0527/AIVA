"""
AIVA çµ±ä¸€ AI æ§åˆ¶å™¨ - æ•´åˆæ‰€æœ‰ AI çµ„ä»¶
å°‡åˆ†æ•£çš„ AI çµ„ä»¶çµ±ä¸€åœ¨ BioNeuronRAGAgent æ§åˆ¶ä¸‹
"""

from __future__ import annotations

import asyncio
import logging
from typing import Any

from .ai_engine import BioNeuronRAGAgent

logger = logging.getLogger(__name__)


class UnifiedAIController:
    """AIVA çµ±ä¸€ AI æ§åˆ¶å™¨ - æ¶ˆé™¤ AI çµ„ä»¶è¡çª"""

    def __init__(self, codebase_path: str = "c:/AMD/AIVA"):
        """åˆå§‹åŒ–çµ±ä¸€ AI æ§åˆ¶å™¨"""
        logger.info("ğŸ§  åˆå§‹åŒ– AIVA çµ±ä¸€ AI æ§åˆ¶å™¨...")

        # ä¸»æ§ AI ç³»çµ±
        self.master_ai = BioNeuronRAGAgent(codebase_path)

        # åˆ†æ•£ AI çµ„ä»¶è¨»å†Š
        self.ai_components = {
            'code_fixer': None,  # å»¶é²åˆå§‹åŒ– CodeFixer
            'smart_detectors': {},
            'detection_engines': {}
        }

        # AI æ±ºç­–æ­·å²
        self.decision_history = []

        logger.info("âœ… çµ±ä¸€ AI æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")

    async def process_unified_request(self, user_input: str, **context) -> dict[str, Any]:
        """çµ±ä¸€è™•ç†æ‰€æœ‰ AI è«‹æ±‚ - é¿å… AI è¡çª"""
        logger.info(f"ğŸ¯ çµ±ä¸€ AI è™•ç†: {user_input}")

        # 1. ä¸»æ§ AI åˆ†æä»»å‹™è¤‡é›œåº¦
        task_analysis = self._analyze_task_complexity(user_input, context)

        # 2. æ±ºå®šè™•ç†ç­–ç•¥
        if task_analysis['can_handle_directly']:
            # ä¸»æ§ AI ç›´æ¥è™•ç†
            result = await self._direct_processing(user_input, context)
        elif task_analysis['needs_code_fixing']:
            # éœ€è¦ç¨‹å¼ç¢¼ä¿®å¾©ï¼Œä½†ä»ç”±ä¸»æ§ AI å”èª¿
            result = await self._coordinated_code_fixing(user_input, context)
        elif task_analysis['needs_specialized_detection']:
            # éœ€è¦å°ˆé–€æª¢æ¸¬ï¼Œä¸»æ§ AI çµ±ç±Œ
            result = await self._coordinated_detection(user_input, context)
        else:
            # è¤‡é›œä»»å‹™ï¼Œå¤š AI å”åŒä½†ä¸»æ§çµ±ç±Œ
            result = await self._multi_ai_coordination(user_input, context)

        # 3. è¨˜éŒ„çµ±ä¸€æ±ºç­–
        self._record_unified_decision(user_input, task_analysis, result)

        return result

    def _analyze_task_complexity(self, user_input: str, context: dict) -> dict[str, Any]:
        """åˆ†æä»»å‹™è¤‡é›œåº¦ - æ±ºå®šè™•ç†ç­–ç•¥"""
        input_lower = user_input.lower()

        analysis = {
            'can_handle_directly': False,
            'needs_code_fixing': False,
            'needs_specialized_detection': False,
            'complexity_score': 0.0,
            'confidence': 0.0
        }

        # ç°¡å–®ä»»å‹™åˆ¤æ–·
        simple_patterns = ['è®€å–', 'æŸ¥çœ‹', 'é¡¯ç¤º', 'åˆ—å‡º', 'ç‹€æ…‹']
        if any(pattern in input_lower for pattern in simple_patterns):
            analysis['can_handle_directly'] = True
            analysis['complexity_score'] = 0.2

        # ç¨‹å¼ç¢¼ä¿®å¾©åˆ¤æ–·
        fix_patterns = ['ä¿®å¾©', 'ä¿®æ­£', 'éŒ¯èª¤', 'æ¼æ´ä¿®å¾©', 'fix']
        if any(pattern in input_lower for pattern in fix_patterns):
            analysis['needs_code_fixing'] = True
            analysis['complexity_score'] = 0.7

        # å°ˆé–€æª¢æ¸¬åˆ¤æ–·
        detection_patterns = ['æƒæ', 'æª¢æ¸¬', 'æ¼æ´', 'å®‰å…¨æª¢æŸ¥']
        if any(pattern in input_lower for pattern in detection_patterns):
            analysis['needs_specialized_detection'] = True
            analysis['complexity_score'] = 0.6

        analysis['confidence'] = min(analysis['complexity_score'] + 0.3, 1.0)
        return analysis

    async def _direct_processing(self, user_input: str, context: dict) -> dict[str, Any]:
        """ä¸»æ§ AI ç›´æ¥è™•ç†"""
        logger.info("ğŸ“‹ ä¸»æ§ AI ç›´æ¥è™•ç†ä»»å‹™")

        result = self.master_ai.invoke(user_input, **context)

        return {
            'status': 'success',
            'processing_method': 'direct_master_ai',
            'result': result,
            'ai_conflicts': 0,
            'unified_control': True
        }

    async def _coordinated_code_fixing(self, user_input: str, context: dict) -> dict[str, Any]:
        """å”èª¿ç¨‹å¼ç¢¼ä¿®å¾© - ä¸»æ§ AI ç›£ç£ä¸‹çš„ä¿®å¾©"""
        logger.info("ğŸ”§ å”èª¿ç¨‹å¼ç¢¼ä¿®å¾© (ä¸»æ§ AI ç›£ç£)")

        # ä¸»æ§ AI é è™•ç†
        preprocessed = self.master_ai.invoke(f"åˆ†æä¿®å¾©éœ€æ±‚: {user_input}", **context)

        # æ¨¡æ“¬ç¨‹å¼ç¢¼ä¿®å¾© (å¯¦éš›æœƒèª¿ç”¨ CodeFixerï¼Œä½†ä¿æŒä¸»æ§ç›£ç£)
        fix_result = {
            'fixed_code': '# ä¿®å¾©å¾Œçš„ç¨‹å¼ç¢¼ (ç”±ä¸»æ§ AI å”èª¿)',
            'explanation': f'åŸºæ–¼ä¸»æ§ AI åˆ†æ: {preprocessed.get("tool_result", {}).get("analysis", "æœªçŸ¥")}',
            'confidence': 0.85
        }

        # ä¸»æ§ AI é©—è­‰çµæœ
        validation = self.master_ai.invoke(f"é©—è­‰ä¿®å¾©çµæœ: {fix_result}", **context)

        return {
            'status': 'success',
            'processing_method': 'coordinated_code_fixing',
            'original_analysis': preprocessed,
            'fix_result': fix_result,
            'validation': validation,
            'ai_conflicts': 0,
            'unified_control': True
        }

    async def _coordinated_detection(self, user_input: str, context: dict) -> dict[str, Any]:
        """å”èª¿æ¼æ´æª¢æ¸¬ - çµ±ä¸€èª¿åº¦å¤šæª¢æ¸¬å¼•æ“"""
        logger.info("ğŸ” å”èª¿æ¼æ´æª¢æ¸¬ (çµ±ä¸€èª¿åº¦)")

        # ä¸»æ§ AI åˆ†ææª¢æ¸¬éœ€æ±‚
        detection_plan = self.master_ai.invoke(f"è¦åŠƒæª¢æ¸¬ç­–ç•¥: {user_input}", **context)

        # æ¨¡æ“¬å¤šå¼•æ“æª¢æ¸¬çµæœ
        detection_results = {
            'sqli_results': {'vulnerabilities_found': 0, 'confidence': 0.9},
            'xss_results': {'vulnerabilities_found': 1, 'confidence': 0.8},
            'ssrf_results': {'vulnerabilities_found': 0, 'confidence': 0.95}
        }

        # ä¸»æ§ AI æ•´åˆçµæœ
        integration = self.master_ai.invoke(f"æ•´åˆæª¢æ¸¬çµæœ: {detection_results}", **context)

        return {
            'status': 'success',
            'processing_method': 'coordinated_detection',
            'detection_plan': detection_plan,
            'detection_results': detection_results,
            'integration': integration,
            'ai_conflicts': 0,
            'unified_control': True
        }

    async def _multi_ai_coordination(self, user_input: str, context: dict) -> dict[str, Any]:
        """å¤š AI å”åŒ - ä¸»æ§ AI çµ±ç±Œ"""
        logger.info("ğŸ¤ å¤š AI å”åŒè™•ç† (ä¸»æ§çµ±ç±Œ)")

        # ä¸»æ§ AI åˆ¶å®šå”åŒè¨ˆç•«
        coordination_plan = self.master_ai.invoke(f"åˆ¶å®šå”åŒè¨ˆç•«: {user_input}", **context)

        # æ¨¡æ“¬å¤š AI å”åŒåŸ·è¡Œ
        coordination_results = {
            'master_ai_role': 'ç¸½é«”è¦åŠƒèˆ‡æœ€çµ‚æ±ºç­–',
            'code_fixer_role': 'ç¨‹å¼ç¢¼å•é¡Œä¿®å¾©',
            'detectors_role': 'å®‰å…¨æ¼æ´æª¢æ¸¬',
            'coordination_efficiency': 0.92
        }

        # ä¸»æ§ AI æœ€çµ‚æ•´åˆ
        final_result = self.master_ai.invoke(f"æ•´åˆå”åŒçµæœ: {coordination_results}", **context)

        return {
            'status': 'success',
            'processing_method': 'multi_ai_coordination',
            'coordination_plan': coordination_plan,
            'coordination_results': coordination_results,
            'final_result': final_result,
            'ai_conflicts': 0,
            'unified_control': True
        }

    def _record_unified_decision(self, user_input: str, analysis: dict, result: dict):
        """è¨˜éŒ„çµ±ä¸€æ±ºç­–æ­·å²"""
        decision_record = {
            'timestamp': asyncio.get_event_loop().time(),
            'user_input': user_input,
            'task_analysis': analysis,
            'processing_method': result.get('processing_method'),
            'ai_conflicts_avoided': result.get('ai_conflicts', 0) == 0,
            'unified_control_maintained': result.get('unified_control', False)
        }

        self.decision_history.append(decision_record)

        if len(self.decision_history) > 100:  # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœ
            self.decision_history.pop(0)

    def get_control_statistics(self) -> dict[str, Any]:
        """ç²å–çµ±ä¸€æ§åˆ¶çµ±è¨ˆ"""
        if not self.decision_history:
            return {'no_decisions': True}

        total_decisions = len(self.decision_history)
        unified_decisions = sum(1 for d in self.decision_history if d['unified_control_maintained'])
        conflict_free_decisions = sum(1 for d in self.decision_history if d['ai_conflicts_avoided'])

        return {
            'total_decisions': total_decisions,
            'unified_control_rate': unified_decisions / total_decisions,
            'conflict_free_rate': conflict_free_decisions / total_decisions,
            'processing_methods': {
                method: sum(1 for d in self.decision_history if d['processing_method'] == method)
                for method in {d['processing_method'] for d in self.decision_history}
            },
            'recommendation': 'çµ±ä¸€æ§åˆ¶æ•ˆæœè‰¯å¥½' if unified_decisions / total_decisions > 0.9 else 'éœ€è¦å„ªåŒ–çµ±ä¸€æ§åˆ¶'
        }


# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_unified_control():
    """å±•ç¤ºçµ±ä¸€ AI æ§åˆ¶çš„æ•ˆæœ"""
    print("ğŸ¯ AIVA çµ±ä¸€ AI æ§åˆ¶å±•ç¤º")
    print("=" * 40)

    controller = UnifiedAIController()

    test_requests = [
        "è®€å– app.py æª”æ¡ˆ",
        "ä¿®å¾© SQL æ³¨å…¥æ¼æ´",
        "åŸ·è¡Œå…¨é¢å®‰å…¨æƒæ",
        "å”èª¿ Go å’Œ Rust æ¨¡çµ„",
        "åˆ†æä¸¦å„ªåŒ–ç³»çµ±æ¶æ§‹"
    ]

    for request in test_requests:
        print(f"\nğŸ‘¤ ç”¨æˆ¶è«‹æ±‚: {request}")
        result = await controller.process_unified_request(request)
        print(f"ğŸ¤– è™•ç†æ–¹å¼: {result['processing_method']}")
        print(f"âœ… çµ±ä¸€æ§åˆ¶: {result['unified_control']}")
        print(f"ğŸ”„ AI è¡çª: {result['ai_conflicts']}")

    print("\nğŸ“Š çµ±ä¸€æ§åˆ¶çµ±è¨ˆ:")
    stats = controller.get_control_statistics()
    print(f"çµ±ä¸€æ§åˆ¶ç‡: {stats['unified_control_rate']:.1%}")
    print(f"ç„¡è¡çªç‡: {stats['conflict_free_rate']:.1%}")
    print(f"å»ºè­°: {stats['recommendation']}")


if __name__ == "__main__":
    asyncio.run(demonstrate_unified_control())
