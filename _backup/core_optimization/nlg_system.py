"""
AIVA è‡ªç„¶èªè¨€ç”Ÿæˆå¢å¼·ç³»çµ±
åŸºæ–¼è¦å‰‡å’Œæ¨¡æ¿çš„é«˜å“è³ªä¸­æ–‡å›æ‡‰ç”Ÿæˆï¼Œç„¡éœ€å¤–éƒ¨ LLM
"""

from __future__ import annotations

import random
import re
from typing import Any


class AIVANaturalLanguageGenerator:
    """AIVA å°ˆç”¨è‡ªç„¶èªè¨€ç”Ÿæˆå™¨ - æ›¿ä»£ GPT-4"""

    def __init__(self):
        """åˆå§‹åŒ–è‡ªç„¶èªè¨€ç”Ÿæˆå™¨"""
        self.response_templates = self._init_response_templates()
        self.context_analyzers = self._init_context_analyzers()
        self.personality_traits = {
            "professional": True,
            "helpful": True,
            "concise": True,
            "technical": True,
        }

    def _init_response_templates(self) -> dict[str, dict]:
        """åˆå§‹åŒ–å›æ‡‰æ¨¡æ¿"""
        return {
            "task_completion": {
                "success": [
                    "âœ… ä»»å‹™å®Œæˆï¼{action}å·²æˆåŠŸåŸ·è¡Œï¼Œ{result_detail}ã€‚",
                    "ğŸ¯ æ“ä½œæˆåŠŸï¼ä½¿ç”¨{tool_name}å®Œæˆäº†{action}ï¼Œçµæœï¼š{result_detail}ã€‚",
                    "âœ¨ è™•ç†å®Œç•¢ï¼{action}åŸ·è¡Œé †åˆ©ï¼Œ{result_detail}ã€‚ä¿¡å¿ƒåº¦ï¼š{confidence}%",
                    "ğŸ’¯ å·²å®Œæˆæ‚¨çš„è«‹æ±‚ã€Œ{action}ã€ï¼Œ{result_detail}ã€‚AIVA è‡ªä¸»åŸ·è¡ŒæˆåŠŸï¼",
                ],
                "partial": [
                    "âš ï¸ éƒ¨åˆ†å®Œæˆï¼š{action}å·²åŸ·è¡Œï¼Œä½†{issue}ã€‚å»ºè­°ï¼š{suggestion}",
                    "ğŸ”„ è™•ç†ä¸­ï¼š{action}é€²è¡Œé †åˆ©ï¼Œ{progress}ã€‚é è¨ˆ{eta}å®Œæˆ",
                    "ğŸ“‹ éšæ®µæ€§æˆæœï¼š{action}å®Œæˆ {percentage}%ï¼Œ{result_detail}",
                ],
                "failed": [
                    "âŒ åŸ·è¡Œé‡åˆ°å•é¡Œï¼š{action}å¤±æ•—ï¼ŒåŸå› ï¼š{error_reason}ã€‚å»ºè­°ï¼š{solution}",
                    "âš¡ éœ€è¦å”åŠ©ï¼š{action}ç„¡æ³•å®Œæˆï¼Œ{error_detail}ã€‚è«‹{next_step}",
                    "ğŸ”§ æŠ€è¡“å•é¡Œï¼š{error_type}å°è‡´{action}ä¸­æ–·ï¼Œæ­£åœ¨{recovery_action}",
                ],
            },
            "code_operations": {
                "reading": [
                    "ğŸ“– ç¨‹å¼ç¢¼è®€å–å®Œæˆï¼å…±{lines}è¡Œï¼Œä¸»è¦åŒ…å«{content_summary}",
                    "ğŸ” å·²åˆ†æ{file_name}ï¼Œç™¼ç¾{key_components}ï¼Œç¨‹å¼ç¢¼å“è³ª{quality_rating}",
                    "ğŸ“‹ æª”æ¡ˆå…§å®¹ï¼š{lines}è¡Œç¨‹å¼ç¢¼ï¼Œ{functions}å€‹å‡½æ•¸ï¼Œ{classes}å€‹é¡åˆ¥",
                ],
                "writing": [
                    "âœï¸ ç¨‹å¼ç¢¼å¯«å…¥æˆåŠŸï¼æ–°å¢{bytes_written}ä½å…ƒçµ„è‡³{file_name}",
                    "ğŸ’¾ æª”æ¡ˆæ›´æ–°å®Œæˆï¼Œ{modification_type}ï¼Œå½±éŸ¿{scope}",
                    "ğŸš€ ç¨‹å¼ç¢¼éƒ¨ç½²å°±ç·’ï¼Œ{file_name}å·²{action_type}ï¼Œå¯ç«‹å³ä½¿ç”¨",
                ],
                "analysis": [
                    "ğŸ§® ç¨‹å¼åˆ†æå®Œæˆï¼æ¶æ§‹{architecture_rating}ï¼Œè¤‡é›œåº¦{complexity_level}",
                    "ğŸ“Š ç¨‹å¼ç¢¼å“è³ªå ±å‘Šï¼š{metrics}ï¼Œå»ºè­°{recommendations}",
                    "ğŸ¯ åˆ†æçµæœï¼š{findings}ï¼Œå„ªåŒ–å»ºè­°ï¼š{optimizations}",
                ],
            },
            "security_operations": {
                "scanning": [
                    "ğŸ›¡ï¸ å®‰å…¨æƒæå®Œæˆï¼æª¢æ¸¬{scan_coverage}ï¼Œç™¼ç¾{findings_count}é …å•é¡Œ",
                    "ğŸ”’ æ¼æ´æª¢æ¸¬å ±å‘Šï¼š{vuln_summary}ï¼Œé¢¨éšªç­‰ç´š{risk_level}",
                    "âš”ï¸ å®‰å…¨åˆ†æï¼š{threat_analysis}ï¼Œé˜²è­·å»ºè­°{security_recommendations}",
                ],
                "detection": [
                    "ğŸš¨ æª¢æ¸¬åˆ°{vuln_type}æ¼æ´ï¼ä½ç½®ï¼š{location}ï¼Œåš´é‡åº¦ï¼š{severity}",
                    "âš ï¸ å®‰å…¨è­¦å‘Šï¼š{security_issue}ï¼Œå»ºè­°ç«‹å³{action_required}",
                    "ğŸ¯ æ¼æ´ç¢ºèªï¼š{vulnerability_details}ï¼Œä¿®å¾©æ–¹æ¡ˆï¼š{fix_suggestion}",
                ],
            },
            "system_control": {
                "coordination": [
                    "ğŸ® ç³»çµ±å”èª¿å®Œæˆï¼{language_modules}æ¨¡çµ„å·²åŒæ­¥ï¼Œç‹€æ…‹æ­£å¸¸",
                    "ğŸ”„ å¤šèªè¨€å”èª¿ï¼šPythonä¸»æ§âœ…ï¼ŒGoæ¨¡çµ„âœ…ï¼ŒRustå¼•æ“âœ…ï¼ŒTSå‰ç«¯âœ…",
                    "ğŸŒ è·¨èªè¨€æ“ä½œæˆåŠŸï¼Œ{operation_summary}ï¼Œæ•ˆèƒ½æå‡{performance_gain}%",
                ],
                "execution": [
                    "âš¡ ç³»çµ±æŒ‡ä»¤åŸ·è¡Œå®Œæˆï¼{command_summary}ï¼Œè¼¸å‡ºï¼š{output_summary}",
                    "ğŸ–¥ï¸ åŸ·è¡Œçµæœï¼š{execution_details}ï¼Œç‹€æ…‹ç¢¼ï¼š{status_code}",
                    "ğŸ”§ æ“ä½œå®Œæˆï¼š{system_operation}ï¼Œç³»çµ±å›æ‡‰ï¼š{system_response}",
                ],
            },
            "communication": {
                "greeting": [
                    "ğŸ¤– AIVA è‡ªä¸» AI ç‚ºæ‚¨æœå‹™ï¼æˆ‘å…·å‚™å®Œæ•´çš„ç¨‹å¼æ§åˆ¶å’Œåˆ†æèƒ½åŠ›",
                    "ğŸ‘‹ æ‚¨å¥½ï¼æˆ‘æ˜¯ AIVA æ™ºèƒ½åŠ©æ‰‹ï¼Œæº–å‚™å”åŠ©æ‚¨é€²è¡Œç¨‹å¼ç®¡ç†å’Œåˆ†æ",
                    "ğŸ¯ AIVA å·²å°±ç·’ï¼Œ500è¬åƒæ•¸ç”Ÿç‰©ç¥ç¶“ç¶²è·¯éš¨æ™‚ç‚ºæ‚¨æä¾›å°ˆæ¥­å”åŠ©",
                ],
                "clarification": [
                    "ğŸ¤” æ‚¨æ˜¯å¸Œæœ›æˆ‘{possible_action_1}é‚„æ˜¯{possible_action_2}ï¼Ÿè«‹æä¾›æ›´å¤šç´°ç¯€",
                    "ğŸ“‹ éœ€è¦æ¾„æ¸…ï¼šé—œæ–¼ã€Œ{user_input}ã€ï¼Œæˆ‘å¯ä»¥{available_options}",
                    "ğŸ’¡ å»ºè­°ï¼šæ‚¨å¯ä»¥èªªã€Œ{suggestion_1}ã€æˆ–ã€Œ{suggestion_2}ã€ä¾†ç²å¾—æ›´ç²¾ç¢ºçš„å”åŠ©",
                ],
                "status": [
                    "ğŸ“Š AIVA ç‹€æ…‹ï¼šç³»çµ±é‹ä½œæ­£å¸¸ï¼ŒAI å¼•æ“æ´»èºï¼ŒçŸ¥è­˜åº«å·²è¼‰å…¥{kb_stats}",
                    "ğŸš€ ç•¶å‰ç‹€æ…‹ï¼šæ‰€æœ‰æ¨¡çµ„å”èª¿è‰¯å¥½ï¼Œè™•ç†æ•ˆèƒ½{performance_level}",
                    "âš¡ ç³»çµ±å¥åº·åº¦ï¼š{health_percentage}%ï¼Œè¨˜æ†¶é«”ä½¿ç”¨{memory_usage}ï¼Œæ±ºç­–æº–ç¢ºç‡{accuracy}%",
                ],
            },
        }

    def _init_context_analyzers(self) -> dict[str, Any]:
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡åˆ†æå™¨"""
        return {
            "intent_patterns": {
                "read_request": [r"è®€å–", r"æŸ¥çœ‹", r"é¡¯ç¤º", r"show", r"read", r"view"],
                "write_request": [
                    r"å¯«å…¥",
                    r"å»ºç«‹",
                    r"å‰µå»º",
                    r"write",
                    r"create",
                    r"generate",
                ],
                "analyze_request": [
                    r"åˆ†æ",
                    r"æª¢æŸ¥",
                    r"evaluate",
                    r"analyze",
                    r"check",
                ],
                "scan_request": [r"æƒæ", r"æª¢æ¸¬", r"scan", r"detect", r"test"],
                "fix_request": [r"ä¿®å¾©", r"ä¿®æ­£", r"fix", r"repair", r"resolve"],
                "status_request": [r"ç‹€æ…‹", r"status", r"health", r"info"],
                "coordinate_request": [r"å”èª¿", r"coordinate", r"sync", r"ç®¡ç†"],
            },
            "technical_entities": {
                "file_types": [
                    r"\.py$",
                    r"\.go$",
                    r"\.rs$",
                    r"\.ts$",
                    r"\.js$",
                    r"\.json$",
                ],
                "vulnerability_types": [r"SQLæ³¨å…¥", r"XSS", r"SSRF", r"IDOR", r"SQLi"],
                "system_components": [
                    r"æ¨¡çµ„",
                    r"module",
                    r"service",
                    r"engine",
                    r"controller",
                ],
            },
            "sentiment_indicators": {
                "urgent": [r"ç«‹å³", r"ç·Šæ€¥", r"urgent", r"immediately"],
                "polite": [r"è«‹", r"è¬è¬", r"please", r"thank"],
                "confused": [r"ä¸çŸ¥é“", r"confused", r"ä¸ç¢ºå®š", r"æ€éº¼"],
            },
        }

    def generate_response(
        self, context: dict[str, Any], response_type: str = "auto"
    ) -> str:
        """ç”Ÿæˆè‡ªç„¶èªè¨€å›æ‡‰"""

        # 1. åˆ†æä¸Šä¸‹æ–‡
        analyzed_context = self._analyze_context(context)

        # 2. ç¢ºå®šå›æ‡‰é¡å‹
        if response_type == "auto":
            response_type = self._determine_response_type(analyzed_context)

        # 3. é¸æ“‡åˆé©çš„æ¨¡æ¿
        template = self._select_template(response_type, analyzed_context)

        # 4. å¡«å……æ¨¡æ¿è®Šæ•¸
        response = self._fill_template(template, analyzed_context)

        # 5. å¾Œè™•ç†å„ªåŒ–
        final_response = self._post_process_response(response, analyzed_context)

        return final_response

    def _analyze_context(self, context: dict[str, Any]) -> dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡"""
        user_input = context.get("user_input", "")
        tool_result = context.get("tool_result", {})
        bio_result = context.get("bio_result", {})

        analyzed = {
            "user_input": user_input,
            "intent": self._detect_intent(user_input),
            "entities": self._extract_entities(user_input),
            "sentiment": self._analyze_sentiment(user_input),
            "tool_used": bio_result.get("tool_used", "unknown"),
            "success_status": tool_result.get("status") == "success",
            "confidence": bio_result.get("confidence", 0.0),
            "technical_details": self._extract_technical_details(tool_result),
        }

        return analyzed

    def _detect_intent(self, user_input: str) -> str:
        """æª¢æ¸¬ç”¨æˆ¶æ„åœ–"""
        input_lower = user_input.lower()

        for intent, patterns in self.context_analyzers["intent_patterns"].items():
            if any(re.search(pattern, input_lower) for pattern in patterns):
                return intent.replace("_request", "")

        return "general"

    def _extract_entities(self, user_input: str) -> dict[str, list]:
        """æå–å¯¦é«”"""
        entities = {"files": [], "vulnerabilities": [], "components": []}

        # æå–æª”æ¡ˆå
        file_matches = re.findall(r"\b\w+\.(py|go|rs|ts|js|json)\b", user_input)
        entities["files"] = [match[0] for match in file_matches]

        # æå–æ¼æ´é¡å‹
        vuln_patterns = self.context_analyzers["technical_entities"][
            "vulnerability_types"
        ]
        for pattern in vuln_patterns:
            if re.search(pattern, user_input, re.IGNORECASE):
                entities["vulnerabilities"].append(pattern.strip("r"))

        return entities

    def _analyze_sentiment(self, user_input: str) -> dict[str, bool]:
        """åˆ†ææƒ…æ„Ÿå‚¾å‘"""
        sentiment = {"urgent": False, "polite": False, "confused": False}

        for emotion, patterns in self.context_analyzers["sentiment_indicators"].items():
            sentiment[emotion] = any(
                re.search(pattern, user_input, re.IGNORECASE) for pattern in patterns
            )

        return sentiment

    def _extract_technical_details(self, tool_result: dict) -> dict[str, Any]:
        """æå–æŠ€è¡“ç´°ç¯€"""
        details = {}

        if "lines" in tool_result:
            details["lines"] = tool_result["lines"]
        if "bytes_written" in tool_result:
            details["bytes_written"] = tool_result["bytes_written"]
        if "analysis" in tool_result:
            details["analysis"] = tool_result["analysis"]
        if "vulnerabilities_found" in tool_result:
            details["vulnerabilities_found"] = tool_result["vulnerabilities_found"]

        return details

    def _determine_response_type(self, analyzed_context: dict) -> str:
        """ç¢ºå®šå›æ‡‰é¡å‹"""
        intent = analyzed_context["intent"]
        success = analyzed_context["success_status"]
        tool = analyzed_context["tool_used"]

        # æ ¹æ“šå·¥å…·å’Œæ„åœ–ç¢ºå®šé¡å‹
        if "Reader" in tool:
            return "code_operations.reading"
        elif "Writer" in tool:
            return "code_operations.writing"
        elif "Analyzer" in tool:
            return "code_operations.analysis"
        elif "Detector" in tool or intent == "scan":
            return "security_operations.scanning"
        elif intent == "coordinate":
            return "system_control.coordination"
        elif intent == "status":
            return "communication.status"
        else:
            status = "success" if success else "failed"
            return f"task_completion.{status}"

    def _select_template(self, response_type: str, context: dict) -> str:
        """é¸æ“‡åˆé©çš„æ¨¡æ¿"""
        type_parts = response_type.split(".")
        category = type_parts[0]
        subcategory = type_parts[1] if len(type_parts) > 1 else "success"

        templates = self.response_templates.get(category, {}).get(subcategory, [])

        if not templates:
            return "âœ… ä»»å‹™å·²å®Œæˆï¼Œçµæœï¼š{result_summary}"

        # åŸºæ–¼ä¸Šä¸‹æ–‡ç‰¹å¾µé¸æ“‡æ¨¡æ¿
        if context.get("sentiment", {}).get("urgent"):
            # å„ªå…ˆé¸æ“‡ç°¡æ½”çš„æ¨¡æ¿
            return min(templates, key=len)
        elif context.get("sentiment", {}).get("polite"):
            # é¸æ“‡è¼ƒæ­£å¼çš„æ¨¡æ¿
            return templates[-1] if templates else templates[0]
        else:
            # éš¨æ©Ÿé¸æ“‡ä»¥å¢åŠ è®ŠåŒ–
            return random.choice(templates)

    def _fill_template(self, template: str, context: dict) -> str:
        """å¡«å……æ¨¡æ¿è®Šæ•¸"""
        variables = {
            "action": context.get("user_input", "æœªçŸ¥æ“ä½œ"),
            "tool_name": context.get("tool_used", "AIVAå·¥å…·"),
            "confidence": int(context.get("confidence", 0.0) * 100),
            "result_detail": self._generate_result_detail(context),
            "lines": context.get("technical_details", {}).get("lines", 0),
            "bytes_written": context.get("technical_details", {}).get(
                "bytes_written", 0
            ),
            "file_name": self._extract_filename(context),
            "performance_level": "å„ªç•°",
            "health_percentage": 98,
            "memory_usage": "æ­£å¸¸",
            "accuracy": 95,
            # æ–°å¢æ›´å¤šé è¨­è®Šæ•¸
            "error_type": "ç³»çµ±éŒ¯èª¤",
            "vulnerability_type": "SQLæ³¨å…¥",
            "severity": "é«˜",
            "affected_files": ", ".join(context.get("affected_files", ["test.py"])),
            "content_summary": "ä¸»è¦åŠŸèƒ½ä»£ç¢¼",
            "key_components": "æ ¸å¿ƒçµ„ä»¶",
            "quality_rating": "è‰¯å¥½",
            "functions": 5,
            "classes": 2,
            "modification_type": "ç¨‹å¼ç¢¼æ›´æ–°",
            "scope": "å±€éƒ¨ä¿®æ”¹",
            "action_type": "æ›´æ–°å®Œæˆ",
            "result_summary": "æ“ä½œæˆåŠŸ",
            # ä¿®å¾©éºå¤±çš„è®Šæ•¸
            "solution": "è«‹æª¢æŸ¥ç›¸é—œé…ç½®",
            "error_reason": "æœªçŸ¥éŒ¯èª¤",
            "suggestion": "å»ºè­°é‡è©¦æ“ä½œ",
            "issue": "éƒ¨åˆ†çµ„ä»¶æœªéŸ¿æ‡‰",
            "progress": "é€²åº¦è‰¯å¥½",
            "eta": "1åˆ†é˜",
            "percentage": 75,
            "error_detail": "è©³ç´°éŒ¯èª¤ä¿¡æ¯",
            "next_step": "è¯ç¹«æŠ€è¡“æ”¯æ´",
            "recovery_action": "è‡ªå‹•æ¢å¾©ä¸­",
        }

        # å¡«å……æ‰€æœ‰å¯ç”¨è®Šæ•¸
        try:
            return template.format(**variables)
        except KeyError as e:
            # å¦‚æœæœ‰ç¼ºå¤±çš„è®Šæ•¸ï¼Œæä¾›é è¨­å€¼
            missing_var = str(e).strip("'")
            variables[missing_var] = f"[{missing_var}]"
            return template.format(**variables)

    def _generate_result_detail(self, context: dict) -> str:
        """ç”Ÿæˆçµæœè©³æƒ…"""
        tool_result = context.get("tool_result", {})
        tech_details = context.get("technical_details", {})

        if "lines" in tech_details:
            return f"è®€å–äº† {tech_details['lines']} è¡Œç¨‹å¼ç¢¼"
        elif "bytes_written" in tech_details:
            return f"æˆåŠŸå¯«å…¥ {tech_details['bytes_written']} ä½å…ƒçµ„"
        elif "analysis" in tech_details:
            return f"åˆ†æçµæœï¼š{tech_details['analysis']}"
        elif tool_result.get("status") == "success":
            return "æ“ä½œæˆåŠŸå®Œæˆ"
        else:
            return "è™•ç†å®Œæˆ"

    def _extract_filename(self, context: dict) -> str:
        """æå–æª”æ¡ˆåç¨±"""
        user_input = context.get("user_input", "")
        files = context.get("entities", {}).get("files", [])

        if files:
            return files[0]

        # å¾ç”¨æˆ¶è¼¸å…¥ä¸­æå–æª”æ¡ˆå
        file_match = re.search(r"\b(\w+\.\w+)\b", user_input)
        if file_match:
            return file_match.group(1)

        return "ç›®æ¨™æª”æ¡ˆ"

    def _post_process_response(self, response: str, context: dict) -> str:
        """å¾Œè™•ç†å„ªåŒ–å›æ‡‰"""

        # æ·»åŠ  AIVA ç‰¹è‰²
        if not any(marker in response for marker in ["AIVA", "ç”Ÿç‰©ç¥ç¶“ç¶²è·¯", "è‡ªä¸»"]) and random.random() < 0.3:
            aiva_signatures = [
                "(AIVA è‡ªä¸»åŸ·è¡Œ)",
                "(åŸºæ–¼ç”Ÿç‰©ç¥ç¶“ç¶²è·¯æ±ºç­–)",
                "(AIVA æ™ºèƒ½åˆ†æ)",
                "(500è¬åƒæ•¸ AI è™•ç†)",
            ]
            response += f" {random.choice(aiva_signatures)}"

        # æ ¹æ“šä¿¡å¿ƒåº¦èª¿æ•´èªæ°£
        confidence = context.get("confidence", 0.0)
        if confidence < 0.5:
            response = response.replace("âœ…", "âš ï¸").replace("æˆåŠŸ", "å˜—è©¦")
        elif confidence > 0.9:
            response = response.replace("å®Œæˆ", "å®Œç¾å®Œæˆ")

        return response


# ä½¿ç”¨ç¤ºä¾‹å’Œæ¸¬è©¦
def test_nlg_system():
    """æ¸¬è©¦è‡ªç„¶èªè¨€ç”Ÿæˆç³»çµ±"""
    print("ğŸ§  AIVA è‡ªç„¶èªè¨€ç”Ÿæˆç³»çµ±æ¸¬è©¦")
    print("=" * 40)

    nlg = AIVANaturalLanguageGenerator()

    test_contexts = [
        {
            "user_input": "è®€å– app.py æª”æ¡ˆ",
            "bio_result": {"tool_used": "CodeReader", "confidence": 0.95},
            "tool_result": {"status": "success", "lines": 256},
        },
        {
            "user_input": "æª¢æŸ¥ SQL æ³¨å…¥æ¼æ´",
            "bio_result": {"tool_used": "SQLiDetector", "confidence": 0.88},
            "tool_result": {"status": "success", "vulnerabilities_found": 2},
        },
        {
            "user_input": "å”èª¿ Go æ¨¡çµ„",
            "bio_result": {"tool_used": "CommandExecutor", "confidence": 0.92},
            "tool_result": {"status": "success", "output": "Module synchronized"},
        },
    ]

    for i, context in enumerate(test_contexts, 1):
        print(f"\næ¸¬è©¦ {i}: {context['user_input']}")
        response = nlg.generate_response(context)
        print(f"AIVA: {response}")

    print("\nâœ… è‡ªç„¶èªè¨€ç”Ÿæˆæ¸¬è©¦å®Œæˆï¼")
    print("ğŸ’¡ AIVA ç„¡éœ€ GPT-4 ä¹Ÿèƒ½ç”Ÿæˆé«˜å“è³ªä¸­æ–‡å›æ‡‰")


if __name__ == "__main__":
    test_nlg_system()
