# å¢å¼·ç‰ˆå¤šèªè¨€èƒ½åŠ›åˆ†æä½¿ç”¨æŒ‡å—

**ç‰ˆæœ¬**: v2.0 Enhanced  
**æ›´æ–°æ—¥æœŸ**: 2025-11-16

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from services.core.aiva_core.internal_exploration import ModuleExplorer, CapabilityAnalyzer

async def analyze_capabilities():
    # 1. åˆå§‹åŒ–æ¢ç´¢å™¨å’Œåˆ†æå™¨
    explorer = ModuleExplorer()
    analyzer = CapabilityAnalyzer()
    
    # 2. æ¢ç´¢æ‰€æœ‰æ¨¡çµ„
    modules = await explorer.explore_all_modules()
    print(f"ğŸ“š Found {len(modules)} modules")
    
    # 3. åˆ†æèƒ½åŠ›
    capabilities = await analyzer.analyze_capabilities(modules)
    print(f"âœ… Extracted {len(capabilities)} capabilities")
    
    # 4. æŸ¥çœ‹èªè¨€åˆ†å¸ƒ
    from collections import Counter
    lang_counts = Counter(cap["language"] for cap in capabilities)
    
    print("\nğŸ“Š Language Distribution:")
    for lang, count in lang_counts.most_common():
        percentage = (count / len(capabilities)) * 100
        print(f"  {lang:12} : {count:4} ({percentage:5.1f}%)")
    
    # 5. æŸ¥çœ‹éŒ¯èª¤å ±å‘Š
    analyzer.print_extraction_report()
    
    return capabilities

# é‹è¡Œ
capabilities = asyncio.run(analyze_capabilities())
```

**è¼¸å‡ºç¯„ä¾‹**:
```
ğŸ“š Found 4 modules
ğŸ” Starting capability analysis for 4 modules...
âœ… Extracted 692 capabilities

ğŸ“Š Language Distribution:
  python       :  411 ( 59.4%)
  rust         :  115 ( 16.6%)
  go           :   88 ( 12.7%)
  typescript   :   78 ( 11.3%)

ğŸ“Š Capability Extraction Report
==============================================================
ğŸ“ Files Processed:
  Total:      382
  âœ… Success:  382
  âŒ Failed:   0
  âš ï¸  Skipped:  0
  Success Rate: 100.0%
==============================================================
```

---

## ğŸ“ èƒ½åŠ›æ•¸æ“šçµæ§‹

### Python èƒ½åŠ›
```python
{
    "name": "sql_injection_scan",
    "language": "python",
    "module": "core/aiva_core",
    "description": "åŸ·è¡Œ SQL æ³¨å…¥æ¼æ´æƒæ",
    "parameters": [
        {"name": "target_url", "annotation": "str"},
        {"name": "payload_type", "annotation": "str | None"}
    ],
    "file_path": "C:/D/fold7/AIVA-git/services/core/...",
    "return_type": "ScanResult",
    "is_async": True,
    "decorators": ["@register_capability"],
    "docstring": "åŸ·è¡Œ SQL æ³¨å…¥æ¼æ´æƒæ...",
    "line_number": 45
}
```

### Rust èƒ½åŠ› (æ–¹æ³•)
```python
{
    "name": "SensitiveInfoScanner::scan",
    "language": "rust",
    "module": "scan",
    "struct": "SensitiveInfoScanner",  # âœ¨ æ–°å¢
    "method": "scan",                   # âœ¨ æ–°å¢
    "description": "Scan content for sensitive information",
    "parameters": [
        {"name": "content", "type": "&str"},
        {"name": "source_url", "type": "&str"}
    ],
    "file_path": "C:/D/fold7/AIVA-git/services/scan/...",
    "return_type": "Vec<Finding>",
    "is_async": False,
    "is_method": True,                  # âœ¨ æ–°å¢
    "line_number": 123
}
```

### Go èƒ½åŠ›
```python
{
    "name": "DetectSSRF",
    "language": "go",
    "module": "scanner",
    "description": "Go function: DetectSSRF",
    "parameters": [
        {"name": "target", "type": "string"},
        {"name": "options", "type": "*DetectorOptions"}
    ],
    "file_path": "C:/D/fold7/AIVA-git/services/scan/...",
    "return_type": "(*Finding, error)",
    "is_exported": True,
    "line_number": 67
}
```

### TypeScript èƒ½åŠ›
```python
{
    "name": "scanWebApplication",
    "language": "typescript",
    "module": "scan",
    "description": "Scan web application for vulnerabilities",
    "parameters": [
        {"name": "url", "type": "string", "description": "Target URL"},
        {"name": "options", "type": "ScanOptions", "description": "Scan options"}
    ],
    "file_path": "C:/D/fold7/AIVA-git/services/scan/...",
    "return_type": "Promise<ScanResult>",
    "is_async": True,
    "is_exported": True,
    "line_number": 89
}
```

---

## ğŸ” é€²éšä½¿ç”¨

### 1. éæ¿¾ç‰¹å®šèªè¨€èƒ½åŠ›

```python
# åªæŸ¥çœ‹ Rust æ–¹æ³•
rust_methods = [
    cap for cap in capabilities 
    if cap["language"] == "rust" and cap.get("is_method")
]

print(f"ğŸ¦€ Found {len(rust_methods)} Rust methods")
for cap in rust_methods[:10]:
    print(f"  - {cap['name']}")
```

### 2. æŒ‰æ¨¡çµ„åˆ†çµ„

```python
analyzer = CapabilityAnalyzer()
grouped = analyzer.get_capabilities_by_module(capabilities)

for module, caps in grouped.items():
    print(f"\nğŸ“¦ Module: {module}")
    print(f"   Capabilities: {len(caps)}")
    
    # çµ±è¨ˆèªè¨€åˆ†å¸ƒ
    langs = Counter(cap["language"] for cap in caps)
    for lang, count in langs.items():
        print(f"     - {lang}: {count}")
```

### 3. æŸ¥æ‰¾ç•°æ­¥èƒ½åŠ›

```python
async_capabilities = [
    cap for cap in capabilities 
    if cap.get("is_async")
]

print(f"âš¡ Found {len(async_capabilities)} async capabilities")

# æŒ‰èªè¨€åˆ†çµ„
by_lang = {}
for cap in async_capabilities:
    lang = cap["language"]
    by_lang.setdefault(lang, []).append(cap)

for lang, caps in by_lang.items():
    print(f"  {lang}: {len(caps)} async capabilities")
```

### 4. æå–éŒ¯èª¤å ±å‘Š

```python
analyzer = CapabilityAnalyzer()
# ... åŸ·è¡Œåˆ†æ ...

# ç²å–è©³ç´°å ±å‘Š
report = analyzer.get_extraction_report()

print(f"ğŸ“Š Statistics:")
print(f"  Total Files:    {report['statistics']['total_files']}")
print(f"  Success Rate:   {report['success_rate']:.1f}%")
print(f"  Total Errors:   {report['total_errors']}")

if report['total_errors'] > 0:
    print(f"\nâš ï¸  Errors by Type:")
    for err_type, count in report['errors_by_type'].items():
        print(f"    {err_type}: {count}")
    
    print(f"\nğŸ“‹ Recent Errors:")
    for err in report['recent_errors']:
        print(f"    - {err['file']}")
        print(f"      Type: {err['type']}")
        print(f"      Message: {err['message']}")
```

---

## ğŸ§ª æ¸¬è©¦å’Œé©—è­‰

### é‹è¡Œå®Œæ•´æ¸¬è©¦

```bash
# åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„
cd C:\D\fold7\AIVA-git

# é‹è¡Œæ¸¬è©¦è…³æœ¬
python -m services.core.aiva_core.internal_exploration.test_enhanced_extraction
```

### é‹è¡Œç‰¹å®šæ¸¬è©¦

```python
import asyncio
from services.core.aiva_core.internal_exploration.test_enhanced_extraction import (
    test_rust_extraction,
    test_error_handling,
    test_full_analysis
)

# åªæ¸¬è©¦ Rust æå–
asyncio.run(test_rust_extraction())

# åªæ¸¬è©¦éŒ¯èª¤è™•ç†
asyncio.run(test_error_handling())

# å®Œæ•´åˆ†æ
asyncio.run(test_full_analysis())
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1: ModuleNotFoundError

**ç—‡ç‹€**: `ModuleNotFoundError: No module named 'services'`

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# ç¢ºä¿åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„
cd C:\D\fold7\AIVA-git

# ä½¿ç”¨ -m æ¨™èªŒé‹è¡Œ
python -m services.core.aiva_core.internal_exploration.test_enhanced_extraction
```

### å•é¡Œ 2: æ²’æœ‰æå–åˆ° Rust èƒ½åŠ›

**æª¢æŸ¥æ¸…å–®**:
1. âœ… ç¢ºèª Rust æ–‡ä»¶å­˜åœ¨
   ```bash
   Get-ChildItem -Path "services" -Recurse -Filter "*.rs" | Measure-Object
   ```

2. âœ… æª¢æŸ¥ Rust ä»£ç¢¼æ ¼å¼
   ```rust
   // âœ… æ­£ç¢º: impl å€å¡Š + pub fn
   impl Scanner {
       pub fn scan(&self) -> Result<()> { }
   }
   
   // âŒ éŒ¯èª¤: ç§æœ‰æ–¹æ³•ä¸æœƒè¢«æå–
   impl Scanner {
       fn internal_method(&self) { }
   }
   ```

3. âœ… æŸ¥çœ‹æ—¥èªŒè¼¸å‡º
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

### å•é¡Œ 3: æˆåŠŸç‡ä½æ–¼ 100%

**è¨ºæ–·æ­¥é©Ÿ**:
```python
analyzer = CapabilityAnalyzer()
# ... åŸ·è¡Œåˆ†æ ...

# æŸ¥çœ‹éŒ¯èª¤è©³æƒ…
report = analyzer.get_extraction_report()

print("âŒ Failed Files:")
for err in report['recent_errors']:
    print(f"  File: {err['file']}")
    print(f"  Type: {err['type']}")
    print(f"  Message: {err['message']}\n")
```

---

## ğŸ“Š æ€§èƒ½å„ªåŒ–å»ºè­°

### 1. è·³éä¸å¿…è¦çš„ç›®éŒ„

```python
explorer = ModuleExplorer()

# è‡ªå®šç¾©æ’é™¤æ¨¡å¼
explorer.exclude_patterns.extend([
    "**/node_modules/**",
    "**/target/**",        # Rust ç·¨è­¯è¼¸å‡º
    "**/__pycache__/**",
    "**/venv/**"
])
```

### 2. ä¸¦è¡Œè™•ç† (æœªä¾†ç‰ˆæœ¬)

```python
# ç•¶å‰ç‰ˆæœ¬: åŒæ­¥è™•ç†
capabilities = await analyzer.analyze_capabilities(modules)

# æœªä¾†ç‰ˆæœ¬ (P2): ä¸¦è¡Œè™•ç†
analyzer = CapabilityAnalyzer(max_workers=4)
capabilities = await analyzer.analyze_capabilities_parallel(modules)
```

### 3. ä½¿ç”¨å¿«å– (æœªä¾†ç‰ˆæœ¬)

```python
# æœªä¾†ç‰ˆæœ¬ (P2): æ™ºèƒ½å¿«å–
analyzer = CapabilityAnalyzer(enable_cache=True)

# é¦–æ¬¡é‹è¡Œ: å®Œæ•´æƒæ
capabilities1 = await analyzer.analyze_capabilities(modules)

# äºŒæ¬¡é‹è¡Œ: ä½¿ç”¨å¿«å– (åƒ…æƒæè®Šæ›´æ–‡ä»¶)
capabilities2 = await analyzer.analyze_capabilities(modules)
```

---

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. å®šæœŸåŸ·è¡Œå®Œæ•´æƒæ

```python
# åœ¨ CI/CD æµç¨‹ä¸­
async def ci_capability_check():
    explorer = ModuleExplorer()
    analyzer = CapabilityAnalyzer()
    
    modules = await explorer.explore_all_modules()
    capabilities = await analyzer.analyze_capabilities(modules)
    
    # é©—è­‰æœ€å°èƒ½åŠ›æ•¸
    MIN_CAPABILITIES = 650
    if len(capabilities) < MIN_CAPABILITIES:
        raise ValueError(f"Capability count dropped: {len(capabilities)} < {MIN_CAPABILITIES}")
    
    # é©—è­‰æˆåŠŸç‡
    report = analyzer.get_extraction_report()
    if report['success_rate'] < 95.0:
        raise ValueError(f"Success rate too low: {report['success_rate']:.1f}%")
    
    print(f"âœ… CI Check Passed: {len(capabilities)} capabilities")
```

### 2. ç›£æ§èƒ½åŠ›è®ŠåŒ–

```python
# ä¿å­˜åŸºç·š
import json

baseline_path = "capabilities_baseline.json"

# é¦–æ¬¡é‹è¡Œ: ä¿å­˜åŸºç·š
with open(baseline_path, 'w') as f:
    json.dump(capabilities, f, indent=2)

# å¾ŒçºŒé‹è¡Œ: æ¯”è¼ƒè®ŠåŒ–
with open(baseline_path) as f:
    baseline = json.load(f)

# æ¯”è¼ƒå·®ç•°
new_caps = {cap['name'] for cap in capabilities}
old_caps = {cap['name'] for cap in baseline}

added = new_caps - old_caps
removed = old_caps - new_caps

if added:
    print(f"âœ… Added capabilities: {len(added)}")
    for name in list(added)[:10]:
        print(f"  + {name}")

if removed:
    print(f"âš ï¸  Removed capabilities: {len(removed)}")
    for name in list(removed)[:10]:
        print(f"  - {name}")
```

### 3. ç”Ÿæˆèƒ½åŠ›æ–‡æª”

```python
def generate_capability_docs(capabilities: list[dict], output_path: str):
    """ç”Ÿæˆèƒ½åŠ›æ¸…å–® Markdown æ–‡æª”"""
    
    lines = [
        "# AIVA èƒ½åŠ›æ¸…å–®",
        f"\n**ç”Ÿæˆæ™‚é–“**: {datetime.now().isoformat()}",
        f"**ç¸½è¨ˆ**: {len(capabilities)} å€‹èƒ½åŠ›\n",
    ]
    
    # æŒ‰èªè¨€åˆ†çµ„
    by_lang = {}
    for cap in capabilities:
        lang = cap["language"]
        by_lang.setdefault(lang, []).append(cap)
    
    for lang, caps in sorted(by_lang.items()):
        lines.append(f"\n## {lang.title()} ({len(caps)} å€‹èƒ½åŠ›)\n")
        
        # æŒ‰æ¨¡çµ„åˆ†çµ„
        by_module = {}
        for cap in caps:
            module = cap.get("module", "unknown")
            by_module.setdefault(module, []).append(cap)
        
        for module, module_caps in sorted(by_module.items()):
            lines.append(f"\n### æ¨¡çµ„: {module}\n")
            
            for cap in sorted(module_caps, key=lambda x: x['name']):
                lines.append(f"- **`{cap['name']}`**")
                if cap.get("description"):
                    lines.append(f"  - {cap['description']}")
                if cap.get("parameters"):
                    params = ", ".join(p["name"] for p in cap["parameters"])
                    lines.append(f"  - åƒæ•¸: `{params}`")
                lines.append("")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"âœ… Documentation generated: {output_path}")

# ä½¿ç”¨
generate_capability_docs(capabilities, "CAPABILITIES.md")
```

---

## ğŸ“š ç›¸é—œè³‡æº

### å…§éƒ¨æ–‡æª”
- [MULTI_LANGUAGE_INTEGRATION_IMPROVEMENT_PLAN.md](./MULTI_LANGUAGE_INTEGRATION_IMPROVEMENT_PLAN.md) - æ”¹å–„è¨ˆåŠƒ
- [P0_IMPLEMENTATION_COMPLETION_REPORT.md](./P0_IMPLEMENTATION_COMPLETION_REPORT.md) - å®Œæˆå ±å‘Š
- [MULTI_LANGUAGE_ANALYSIS_INTEGRATION_REPORT.md](./MULTI_LANGUAGE_ANALYSIS_INTEGRATION_REPORT.md) - åŸå§‹åˆ†æ

### API æ–‡æª”
- `ModuleExplorer` - æ¨¡çµ„æ¢ç´¢å™¨
- `CapabilityAnalyzer` - èƒ½åŠ›åˆ†æå™¨
- `LanguageExtractor` - èªè¨€æå–å™¨åŸºé¡
  - `GoExtractor`
  - `RustExtractor` âœ¨ å¢å¼·ç‰ˆ
  - `TypeScriptExtractor`

### æ¸¬è©¦æ–‡ä»¶
- `test_enhanced_extraction.py` - å¢å¼·ç‰ˆæ¸¬è©¦è…³æœ¬

---

## ğŸ¤ è²¢ç»æŒ‡å—

### æ·»åŠ æ–°èªè¨€æ”¯æ´

1. åœ¨ `language_extractors.py` å‰µå»ºæ–°çš„æå–å™¨é¡
   ```python
   class KotlinExtractor(LanguageExtractor):
       def extract_capabilities(self, content: str, file_path: str) -> list[dict[str, Any]]:
           # å¯¦ç¾æå–é‚è¼¯
           pass
   ```

2. åœ¨ `get_extractor()` è¨»å†Šèªè¨€
   ```python
   extractors = {
       "go": GoExtractor(),
       "rust": RustExtractor(),
       "typescript": TypeScriptExtractor(),
       "javascript": TypeScriptExtractor(),
       "kotlin": KotlinExtractor(),  # æ–°å¢
   }
   ```

3. åœ¨ `capability_analyzer.py` æ·»åŠ èªè¨€æª¢æ¸¬
   ```python
   language_map = {
       ".py": "python",
       ".go": "go",
       ".rs": "rust",
       ".ts": "typescript",
       ".js": "javascript",
       ".kt": "kotlin",  # æ–°å¢
   }
   ```

4. æ·»åŠ æ¸¬è©¦ç”¨ä¾‹
   ```python
   def test_kotlin_extraction():
       # æ¸¬è©¦é‚è¼¯
       pass
   ```

---

**æŒ‡å—ç‰ˆæœ¬**: v2.0  
**æœ€å¾Œæ›´æ–°**: 2025-11-16  
**ç¶­è­·è€…**: AIVA æ¶æ§‹åœ˜éšŠ
