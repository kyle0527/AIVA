# ğŸš€ AIVA AI ç³»çµ±ä½¿ç”¨è€…æ‰‹å†Š

**ç‰ˆæœ¬**: v2.1.0 | **æ›´æ–°æ—¥æœŸ**: 2025å¹´11æœˆ11æ—¥ | **ç‹€æ…‹**: âœ… å·²é©—è­‰

---

## ğŸ“‹ è©³ç´°ç›®éŒ„

### ğŸ¯ [ç³»çµ±ç°¡ä»‹](#-ç³»çµ±ç°¡ä»‹)
- [æ ¸å¿ƒç‰¹è‰²](#æ ¸å¿ƒç‰¹è‰²)
- [AI èƒ½åŠ›çŸ©é™£](#ai-èƒ½åŠ›çŸ©é™£)
- [ç³»çµ±æ¶æ§‹æ¦‚è¦½](#ç³»çµ±æ¶æ§‹æ¦‚è¦½)

### âš¡ [å¿«é€Ÿé–‹å§‹](#-å¿«é€Ÿé–‹å§‹)
- [æ–¹æ³•ä¸€ï¼šå¿«é€Ÿé©—è­‰ï¼ˆæ¨è–¦æ–°æ‰‹ï¼‰](#æ–¹æ³•ä¸€å¿«é€Ÿé©—è­‰æ¨è–¦æ–°æ‰‹)
- [æ–¹æ³•äºŒï¼šç›´æ¥ Python å•Ÿå‹•ï¼ˆæ¨è–¦ï¼‰](#æ–¹æ³•äºŒç›´æ¥-python-å•Ÿå‹•æ¨è–¦)
- [æ–¹æ³•ä¸‰ï¼šDocker å®¹å™¨å•Ÿå‹•](#æ–¹æ³•ä¸‰docker-å®¹å™¨å•Ÿå‹•)

### ğŸ› ï¸ [å®‰è£é…ç½®](#ï¸-å®‰è£é…ç½®)
- [ç³»çµ±éœ€æ±‚](#ç³»çµ±éœ€æ±‚)
- [ä¾è³´å®‰è£](#ä¾è³´å®‰è£)
- [ç’°å¢ƒé…ç½®](#ç’°å¢ƒé…ç½®)

### ğŸ§  [AI æ ¸å¿ƒåŠŸèƒ½](#-ai-æ ¸å¿ƒåŠŸèƒ½)
- [1. AI ç³»çµ±åˆå§‹åŒ–](#1-ai-ç³»çµ±åˆå§‹åŒ–)
- [2. AI æ±ºç­–åŠŸèƒ½ä½¿ç”¨](#2-ai-æ±ºç­–åŠŸèƒ½ä½¿ç”¨)
- [3. RAG æª¢ç´¢åŠŸèƒ½](#3-rag-æª¢ç´¢åŠŸèƒ½)
- [4. æ•´åˆä½¿ç”¨ç¯„ä¾‹](#4-æ•´åˆä½¿ç”¨ç¯„ä¾‹)

### ğŸ’» [ä½¿ç”¨æ–¹å¼](#-ä½¿ç”¨æ–¹å¼)
- [A. å‘½ä»¤åˆ—ä»‹é¢ (CLI)](#a-å‘½ä»¤åˆ—ä»‹é¢-cli)
- [B. Web ä»‹é¢](#b-web-ä»‹é¢)
- [C. Python APIï¼ˆæ›´æ–°ç‰ˆï¼‰](#c-python-apiæ›´æ–°ç‰ˆ)
- [D. REST API](#d-rest-api)

### ğŸ“Š [åŠŸèƒ½é©—è­‰](#-åŠŸèƒ½é©—è­‰)
- [1. ç³»çµ±å¥åº·æª¢æŸ¥ï¼ˆæ›´æ–°ç‰ˆï¼‰](#1-ç³»çµ±å¥åº·æª¢æŸ¥æ›´æ–°ç‰ˆ)
- [2. AI èƒ½åŠ›é©—è­‰ï¼ˆæ›´æ–°ç‰ˆï¼‰](#2-ai-èƒ½åŠ›é©—è­‰æ›´æ–°ç‰ˆ)
- [3. æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆæ›´æ–°ç‰ˆï¼‰](#3-æ€§èƒ½åŸºæº–æ¸¬è©¦æ›´æ–°ç‰ˆ)

### ğŸ”§ [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)
- [å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ](#å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ)
- [æ—¥èªŒèˆ‡èª¿è©¦](#æ—¥èªŒèˆ‡èª¿è©¦)

### ğŸ“š [é€²éšåŠŸèƒ½](#-é€²éšåŠŸèƒ½)
- [1. è‡ªå®šç¾© AI é…ç½®](#1-è‡ªå®šç¾©-ai-é…ç½®)
- [2. è‡ªå®šç¾©çŸ¥è­˜åº«](#2-è‡ªå®šç¾©çŸ¥è­˜åº«)
- [3. API æ“´å±•](#3-api-æ“´å±•)
- [4. æ‰¹é‡è™•ç†](#4-æ‰¹é‡è™•ç†)

### ğŸ“ [æŠ€è¡“æ”¯æ´](#-æŠ€è¡“æ”¯æ´)
- [ç²å¾—å¹«åŠ©](#ç²å¾—å¹«åŠ©)
- [è²¢ç»æŒ‡å—](#è²¢ç»æŒ‡å—)

### ğŸ“„ [ç‰ˆæœ¬è³‡è¨Š](#-ç‰ˆæœ¬è³‡è¨Š)
- [æ›´æ–°æ—¥èªŒ](#æ›´æ–°æ—¥èªŒ)

---

## ğŸ“Š å¿«é€Ÿå°è¦½

| ä½¿ç”¨è€…é¡å‹ | æ¨è–¦èµ·å§‹é» | é‡é»ç« ç¯€ |
|------------|------------|----------|
| ğŸ†• **æ–°æ‰‹** | [å¿«é€Ÿé–‹å§‹](#-å¿«é€Ÿé–‹å§‹) â†’ [åŠŸèƒ½é©—è­‰](#-åŠŸèƒ½é©—è­‰) | åŸºç¤å®‰è£ã€ç°¡å–®ç¯„ä¾‹ |
| ğŸ‘¨â€ğŸ’» **é–‹ç™¼è€…** | [AI æ ¸å¿ƒåŠŸèƒ½](#-ai-æ ¸å¿ƒåŠŸèƒ½) â†’ [Python API](#c-python-apiæ›´æ–°ç‰ˆ) | AI æ•´åˆã€API ä½¿ç”¨ |
| ğŸ”§ **ç³»çµ±ç®¡ç†å“¡** | [å®‰è£é…ç½®](#ï¸-å®‰è£é…ç½®) â†’ [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤) | ç’°å¢ƒè¨­å®šã€å•é¡Œè§£æ±º |
| ğŸš€ **é€²éšç”¨æˆ¶** | [é€²éšåŠŸèƒ½](#-é€²éšåŠŸèƒ½) â†’ [æŠ€è¡“æ”¯æ´](#-æŠ€è¡“æ”¯æ´) | è‡ªå®šç¾©é…ç½®ã€æ“´å±•é–‹ç™¼ |

---

---

## ğŸ¯ ç³»çµ±ç°¡ä»‹

AIVA (Autonomous Intelligence Virtual Assistant) æ˜¯ä¸€å€‹ä¼æ¥­ç´šçš„AIé©…å‹•å®‰å…¨æ¸¬è©¦å¹³å°ï¼Œå…·å‚™ï¼š

### æ ¸å¿ƒç‰¹è‰²
- **ğŸ§  500è¬åƒæ•¸ç¥ç¶“ç¶²è·¯**: çœŸå¯¦çš„ç”Ÿç‰©å•Ÿç™¼å¼AIå¤§è…¦
- **ğŸ“š RAGæª¢ç´¢å¢å¼·**: æ™ºèƒ½çŸ¥è­˜æª¢ç´¢èˆ‡èåˆç³»çµ±
- **ğŸ¤– å››ç¨®é‹è¡Œæ¨¡å¼**: UIã€AIã€Chatã€æ··åˆæ¨¡å¼
- **âš¡ è‡ªä¸»æ±ºç­–èƒ½åŠ›**: å®Œå…¨è‡ªä¸»çš„å®‰å…¨æ¸¬è©¦åŸ·è¡Œ
- **ğŸ›¡ï¸ æŠ—å¹»è¦ºæ©Ÿåˆ¶**: å¤šå±¤é©—è­‰ç¢ºä¿æ±ºç­–å¯é æ€§

### AI èƒ½åŠ›çŸ©é™£
| èƒ½åŠ› | ç‹€æ…‹ | æˆç†Ÿåº¦ | æè¿° |
|------|------|--------|------|
| ğŸ” **æ™ºèƒ½æœç´¢** | âœ… | â­â­â­â­â­ | èªç¾©æœç´¢ã€å‘é‡æª¢ç´¢ |
| ğŸ“š **RAGå¢å¼·** | âœ… | â­â­â­â­â­ | æª¢ç´¢å¢å¼·ç”Ÿæˆ |
| ğŸ¤” **æ¨ç†æ±ºç­–** | âœ… | â­â­â­â­ | ç¥ç¶“ç¶²è·¯æ¨ç† |
| ğŸ“– **å­¸ç¿’èƒ½åŠ›** | âœ… | â­â­â­â­ | ç¶“é©—å­¸ç¿’èˆ‡é€²åŒ– |
| ğŸ’¾ **çŸ¥è­˜ç®¡ç†** | âœ… | â­â­â­â­â­ | ASTä»£ç¢¼åˆ†æ |
| ğŸ’¬ **è‡ªç„¶èªè¨€** | ğŸš§ | â­â­â­ | å°è©±ç†è§£èˆ‡ç”Ÿæˆ |

### ç³»çµ±æ¶æ§‹æ¦‚è¦½

```mermaid
graph TB
    subgraph "AIVA AI ç³»çµ±æ¶æ§‹"
        BNM[BioNeuronMasterController<br/>ä¸»æ§åˆ¶å™¨]
        
        subgraph "AI æ ¸å¿ƒå¼•æ“"
            RSBN[RealScalableBioNet<br/>çœŸå¯¦ç¥ç¶“ç¶²è·¯]
            RAC[RealAICore<br/>5Måƒæ•¸AIæ ¸å¿ƒ]
            RSBN --> RAC
        end
        
        subgraph "RAG ç³»çµ±"
            RE[RAGEngine<br/>æª¢ç´¢å¼•æ“]
            KB[KnowledgeBase<br/>çŸ¥è­˜åº«]
            RBA[RealBioNeuronRAGAgent<br/>RAGä»£ç†]
            RE --> KB
            RBA --> RE
        end
        
        subgraph "æ“ä½œæ¨¡å¼"
            UI[UIæ¨¡å¼<br/>ç”¨æˆ¶ä»‹é¢]
            AI[AIæ¨¡å¼<br/>è‡ªä¸»æ±ºç­–]
            CHAT[Chatæ¨¡å¼<br/>å°è©±äº¤äº’]
            HYBRID[Hybridæ¨¡å¼<br/>æ··åˆæ¨¡å¼]
        end
        
        BNM --> RSBN
        BNM --> RE
        BNM --> UI
        BNM --> AI
        BNM --> CHAT
        BNM --> HYBRID
        
        RBA -.-> RAC
    end
    
    subgraph "å¤–éƒ¨ä»‹é¢"
        API[REST API]
        CLI[å‘½ä»¤åˆ—]
        WEB[Webä»‹é¢]
    end
    
    API --> BNM
    CLI --> BNM
    WEB --> BNM
```

**æ ¸å¿ƒçµ„ä»¶èªªæ˜**ï¼š
- ğŸ® **BioNeuronMasterController**: ç³»çµ±ä¸»æ§åˆ¶å™¨ï¼Œå”èª¿æ‰€æœ‰AIçµ„ä»¶
- ğŸ§  **RealScalableBioNet**: 500è¬åƒæ•¸çš„çœŸå¯¦ç¥ç¶“ç¶²è·¯æ ¸å¿ƒ
- ğŸ“š **RAGEngine**: æª¢ç´¢å¢å¼·ç”Ÿæˆå¼•æ“ï¼ŒçµåˆçŸ¥è­˜åº«å’ŒAIæ¨ç†
- ğŸ¤– **RealBioNeuronRAGAgent**: å°ˆé–€çš„RAGä»£ç†ï¼Œæ”¯æ´ç¨ç«‹ä½¿ç”¨
- ğŸ’¾ **KnowledgeBase**: å‘é‡åŒ–çŸ¥è­˜åº«ï¼Œæ”¯æ´èªç¾©æœç´¢

---

## âš¡ å¿«é€Ÿé–‹å§‹

### æ–¹æ³•ä¸€ï¼šå¿«é€Ÿé©—è­‰ï¼ˆæ¨è–¦æ–°æ‰‹ï¼‰

```powershell
# 1. è¨­å®šç’°å¢ƒ
$env:PYTHONPATH = "C:\D\fold7\AIVA-git;C:\D\fold7\AIVA-git\services"

# 2. åŸ·è¡Œå¿«é€Ÿé©—è­‰è…³æœ¬
python -c "
import sys
sys.path.append('C:/D/fold7/AIVA-git')
sys.path.append('C:/D/fold7/AIVA-git/services')

print('ğŸš€ AIVA AI ç³»çµ±å¿«é€Ÿé©—è­‰')
print('=' * 50)

try:
    print('ğŸ” æ¸¬è©¦ 1: æª¢æŸ¥åŸºç¤ä¾è³´')
    import torch
    import numpy as np
    print('   âœ… PyTorch & NumPy å°å…¥æˆåŠŸ')
    
    print('ğŸ” æ¸¬è©¦ 2: æª¢æŸ¥ AI å¼•æ“æ¨¡çµ„')
    from services.core.aiva_core.ai_engine.real_bio_net_adapter import RealBioNeuronRAGAgent, create_real_rag_agent
    print('   âœ… çœŸå¯¦ AI å¼•æ“æ¨¡çµ„å°å…¥æˆåŠŸ')
    
    print('ğŸ” æ¸¬è©¦ 3: æª¢æŸ¥ RAG ç³»çµ±')  
    from services.core.aiva_core.rag.rag_engine import RAGEngine
    print('   âœ… RAG å¼•æ“å°å…¥æˆåŠŸ')
    
    print('ğŸ” æ¸¬è©¦ 4: å‰µå»ºåŸºæœ¬ AI çµ„ä»¶')
    decision_core = torch.nn.Sequential(
        torch.nn.Linear(512, 256),
        torch.nn.ReLU(),
        torch.nn.Linear(256, 20)
    )
    
    rag_agent = create_real_rag_agent(
        decision_core=decision_core,
        input_vector_size=512
    )
    print('   âœ… AI çµ„ä»¶å‰µå»ºæˆåŠŸ')
    
    print('ğŸ” æ¸¬è©¦ 5: åŸºæœ¬åŠŸèƒ½æ¸¬è©¦')
    result = rag_agent.generate(
        task_description='æ¸¬è©¦ AI æ±ºç­–åŠŸèƒ½',
        context='ç³»çµ±é©—è­‰æ¸¬è©¦'
    )
    confidence = result.get('confidence', 'unknown')
    print(f'   âœ… AI æ±ºç­–æ¸¬è©¦æˆåŠŸï¼Œä¿¡å¿ƒåº¦: {confidence}')
    
    print('')
    print('ğŸ‰ AIVA AI æ ¸å¿ƒåŠŸèƒ½é©—è­‰æˆåŠŸï¼')
    print('ğŸ“– è«‹æŸ¥çœ‹ AIVA_USER_MANUAL.md äº†è§£å®Œæ•´ä½¿ç”¨æ–¹å¼')
    
except Exception as e:
    print(f'âŒ é©—è­‰å¤±æ•—: {e}')
    import traceback
    traceback.print_exc()
"

# 3. æŸ¥çœ‹ç³»çµ±ç‹€æ…‹
echo "âœ… AIVA AI ç³»çµ±é©—è­‰å®Œæˆ"
```

### æ–¹æ³•äºŒï¼šç›´æ¥ Python å•Ÿå‹•ï¼ˆæ¨è–¦ï¼‰

```powershell
# è¨­å®šç’°å¢ƒè®Šæ•¸
$env:PYTHONPATH = "C:\D\fold7\AIVA-git;C:\D\fold7\AIVA-git\services"

# å¿«é€Ÿé©—è­‰ç³»çµ±
python -c "
import sys
sys.path.append('C:/D/fold7/AIVA-git')
sys.path.append('C:/D/fold7/AIVA-git/services')

# å°å…¥æ ¸å¿ƒæ¨¡çµ„
from services.core.aiva_core.ai_engine.real_bio_net_adapter import create_real_rag_agent
from services.core.aiva_core.rag.rag_engine import RAGEngine
import torch

# å‰µå»º AI çµ„ä»¶
decision_core = torch.nn.Sequential(torch.nn.Linear(512, 256), torch.nn.ReLU(), torch.nn.Linear(256, 20))
rag_agent = create_real_rag_agent(decision_core=decision_core, input_vector_size=512)
rag_engine = RAGEngine()

print('ğŸ‰ AIVA AI ç³»çµ±é©—è­‰æˆåŠŸ!')
print(f'ğŸ§  RAG ä»£ç†: {type(rag_agent).__name__}')
print(f'ğŸ“š RAG å¼•æ“: {type(rag_engine).__name__}')
"
```

### æ–¹æ³•ä¸‰ï¼šDocker å®¹å™¨å•Ÿå‹•

```bash
# æ§‹å»ºä¸¦å•Ÿå‹•
docker-compose up -d

# æŸ¥çœ‹æœå‹™ç‹€æ…‹
docker-compose ps
```

---

## ğŸ› ï¸ å®‰è£é…ç½®

### ç³»çµ±éœ€æ±‚

| é …ç›® | æœ€å°éœ€æ±‚ | æ¨è–¦é…ç½® |
|------|----------|----------|
| **Python** | 3.8+ | 3.11+ |
| **è¨˜æ†¶é«”** | 8GB | 16GB+ |
| **å„²å­˜ç©ºé–“** | 10GB | 50GB+ |
| **CPU** | 4æ ¸å¿ƒ | 8æ ¸å¿ƒ+ |

### ä¾è³´å®‰è£

```powershell
# 1. å®‰è£æ ¸å¿ƒä¾è³´
python -m pip install --upgrade protobuf grpcio grpcio-tools torch numpy fastapi uvicorn

# 2. å®‰è£é¡å¤–å¥—ä»¶
pip install sentence-transformers transformers datasets scikit-learn pandas requests aiofiles asyncio

# 3. é©—è­‰å®‰è£
python -c "import torch, numpy, fastapi; print('âœ… ä¾è³´å®‰è£æˆåŠŸ!')"
```

### ç’°å¢ƒé…ç½®

```powershell
# 1. å‰µå»ºé…ç½®æ–‡ä»¶
Copy-Item config/config.example.yml config/config.yml

# 2. è¨­å®š PYTHONPATH
$env:PYTHONPATH = "C:\D\fold7\AIVA-git;C:\D\fold7\AIVA-git\services;C:\D\fold7\AIVA-git\services\features;C:\D\fold7\AIVA-git\services\aiva_common"

# 3. é©—è­‰é…ç½®
python -c "import sys; print('PYTHONPATH é…ç½®æ­£ç¢º:', 'services' in str(sys.path))"
```

---

## ğŸ§  AI æ ¸å¿ƒåŠŸèƒ½

### 1. AI ç³»çµ±åˆå§‹åŒ–

```python
# æ–¹æ³• 1: ä½¿ç”¨çœŸå¯¦ RAG ä»£ç† (æ¨è–¦)
from services.core.aiva_core.ai_engine.real_bio_net_adapter import RealBioNeuronRAGAgent, create_real_rag_agent
import torch

# å‰µå»ºæ±ºç­–æ ¸å¿ƒç¶²è·¯
decision_core = torch.nn.Sequential(
    torch.nn.Linear(512, 256),
    torch.nn.ReLU(), 
    torch.nn.Linear(256, 20)
)

# å‰µå»º RAG ä»£ç†
rag_agent = create_real_rag_agent(
    decision_core=decision_core,
    input_vector_size=512
)

print(f"ğŸ§  ç¥ç¶“ç¶²è·¯é¡å‹: {type(rag_agent).__name__}")
print(f"ï¿½ æ±ºç­–æ ¸å¿ƒ: {decision_core}")

# æ–¹æ³• 2: ä½¿ç”¨ RAG å¼•æ“
from services.core.aiva_core.rag.rag_engine import RAGEngine

rag_engine = RAGEngine()
print(f"ğŸ“š RAG å¼•æ“: {type(rag_engine).__name__}")
```

### 2. AI æ±ºç­–åŠŸèƒ½ä½¿ç”¨

```python
# AI æ±ºç­–ç”Ÿæˆ
result = rag_agent.generate(
    task_description="åˆ†æç›®æ¨™ç³»çµ±å®‰å…¨æ¼æ´",
    context="ç›®æ¨™: https://example.com"
)

print(f"æ±ºç­–çµæœ: {result.get('decision', 'N/A')}")
print(f"ä¿¡å¿ƒåº¦: {result.get('confidence', 'N/A')}")
print(f"å»ºè­°è¡Œå‹•: {result.get('suggested_actions', [])}")

# åŠ è¼‰é è¨“ç·´æ¬Šé‡ (å¦‚æœæœ‰)
try:
    rag_agent.load_state_dict(torch.load('weights/aiva_model.pth'))
    print("âœ… é è¨“ç·´æ¬Šé‡è¼‰å…¥æˆåŠŸ")
except:
    print("â„¹ï¸ ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–æ¬Šé‡")
```

### 3. RAG æª¢ç´¢åŠŸèƒ½

```python
# ä½¿ç”¨ RAG å¼•æ“é€²è¡ŒçŸ¥è­˜æª¢ç´¢
from services.core.aiva_core.rag.rag_engine import RAGEngine
from services.core.aiva_core.rag.knowledge_base import KnowledgeBase

# å‰µå»ºçŸ¥è­˜åº«å’Œ RAG å¼•æ“
knowledge_base = KnowledgeBase()
rag_engine = RAGEngine(knowledge_base)

# åŸ·è¡Œèªç¾©æœç´¢ (æ³¨æ„ï¼šé€™æ˜¯æ¦‚å¿µæ€§ç¯„ä¾‹)
# å¯¦éš›ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦å…ˆç´¢å¼•çŸ¥è­˜åº«
try:
    # å˜—è©¦æœç´¢åŠŸèƒ½ (å¯èƒ½éœ€è¦çŸ¥è­˜åº«æœ‰å…§å®¹)
    print(f"RAG å¼•æ“å·²æº–å‚™: {type(rag_engine).__name__}")
    print(f"çŸ¥è­˜åº«é¡å‹: {type(knowledge_base).__name__}")
    
    # æœç´¢ç›¸é—œçŸ¥è­˜
    # search_results = await rag_engine.search(...)
    
except Exception as e:
    print(f"RAG æœç´¢éœ€è¦å…ˆè¨­ç½®çŸ¥è­˜åº«: {e}")

# ç›´æ¥ä½¿ç”¨çŸ¥è­˜åº«åŠŸèƒ½
try:
    # æ·»åŠ æ–°çŸ¥è­˜åˆ°çŸ¥è­˜åº«
    knowledge_base.add_knowledge(
        content="æ–°çš„å®‰å…¨çŸ¥è­˜å…§å®¹",
        knowledge_type="security",
        metadata={"source": "custom", "category": "security"}
    )
    print("âœ… çŸ¥è­˜æ·»åŠ æˆåŠŸ")
except Exception as e:
    print(f"çŸ¥è­˜æ·»åŠ : {e}")
```

### 4. æ•´åˆä½¿ç”¨ç¯„ä¾‹

```python
# å®Œæ•´å·¥ä½œæµç¨‹ç¯„ä¾‹
import torch
import asyncio
from services.core.aiva_core.ai_engine.real_bio_net_adapter import create_real_rag_agent
from services.core.aiva_core.rag.rag_engine import RAGEngine

async def aiva_workflow_example():
    """AIVA å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹"""
    
    # 1. åˆå§‹åŒ–çµ„ä»¶
    print("ğŸ”§ åˆå§‹åŒ– AI çµ„ä»¶...")
    decision_core = torch.nn.Sequential(
        torch.nn.Linear(512, 256),
        torch.nn.ReLU(),
        torch.nn.Linear(256, 20)
    )
    
    rag_agent = create_real_rag_agent(
        decision_core=decision_core,
        input_vector_size=512
    )
    
    rag_engine = RAGEngine()
    
    # 2. çŸ¥è­˜æª¢ç´¢
    print("ğŸ” åŸ·è¡ŒçŸ¥è­˜æª¢ç´¢...")
    knowledge = await rag_engine.search(
        query="ç¶²è·¯å®‰å…¨æ¸¬è©¦æ–¹æ³•",
        top_k=3
    )
    
    # 3. AI æ±ºç­–
    print("ğŸ¤– ç”Ÿæˆ AI æ±ºç­–...")
    decision = rag_agent.generate(
        task_description="åŸºæ–¼æª¢ç´¢åˆ°çš„çŸ¥è­˜é€²è¡Œå®‰å…¨åˆ†æ",
        context=f"æª¢ç´¢çµæœ: {knowledge}"
    )
    
    # 4. çµæœè¼¸å‡º
    print(f"âœ… æ±ºç­–å®Œæˆ: {decision.get('confidence')}")
    return decision

# åŸ·è¡Œç¤ºä¾‹
# result = asyncio.run(aiva_workflow_example())
```

---

## ğŸ’» ä½¿ç”¨æ–¹å¼

### A. å‘½ä»¤åˆ—ä»‹é¢ (CLI)

```powershell
# 1. åŸºæœ¬æƒæ
python -m aiva.cli scan --target "https://example.com" --mode "ai"

# 2. äº’å‹•æ¨¡å¼
python -m aiva.cli interactive

# 3. é…ç½®æª¢æŸ¥
python -m aiva.cli config check
```

### B. Web ä»‹é¢

```powershell
# å•Ÿå‹• Web æœå‹™
.\start-aiva.ps1 -Action core

# è¨ªå•ä»‹é¢
# ä¸»è¦ API: http://localhost:8000
# ç®¡ç†é¢æ¿: http://localhost:8001
# ç¥ç¶“ç¶²è·¯ API: http://localhost:8000/api/v2/neural/
```

### C. Python APIï¼ˆæ›´æ–°ç‰ˆï¼‰

```python
import asyncio
import torch
from services.core.aiva_core.ai_engine.real_bio_net_adapter import create_real_rag_agent
from services.core.aiva_core.rag.rag_engine import RAGEngine

async def aiva_api_example():
    """AIVA Python API ä½¿ç”¨ç¤ºä¾‹"""
    
    # åˆå§‹åŒ–æ ¸å¿ƒçµ„ä»¶
    decision_core = torch.nn.Sequential(
        torch.nn.Linear(512, 256),
        torch.nn.ReLU(),
        torch.nn.Linear(256, 20)
    )
    
    rag_agent = create_real_rag_agent(
        decision_core=decision_core,
        input_vector_size=512
    )
    
    rag_engine = RAGEngine()
    
    # åŸ·è¡Œ AI ä»»å‹™
    print("ğŸ” åŸ·è¡ŒçŸ¥è­˜æœç´¢...")
    search_results = await rag_engine.search(
        query="æ¸¬è©¦ç›®æ¨™çš„å®‰å…¨æ€§",
        top_k=3
    )
    
    print("ğŸ¤– ç”Ÿæˆ AI æ±ºç­–...")
    decision = rag_agent.generate(
        task_description="å®‰å…¨æ€§è©•ä¼°",
        context=f"æœç´¢çµæœ: {search_results}"
    )
    
    print(f"âœ… ä»»å‹™å®Œæˆ: ä¿¡å¿ƒåº¦ {decision.get('confidence')}")
    return decision

# åŸ·è¡Œ API ç¤ºä¾‹
# result = asyncio.run(aiva_api_example())
```

### D. REST API

```bash
# å¥åº·æª¢æŸ¥
curl http://localhost:8000/health

# AI æ±ºç­–è«‹æ±‚
curl -X POST http://localhost:8000/api/v2/ai/decide \
  -H "Content-Type: application/json" \
  -d '{"objective": "å®‰å…¨æ¸¬è©¦", "target": "example.com"}'

# ç¥ç¶“ç¶²è·¯ç‹€æ…‹
curl http://localhost:8000/api/v2/neural/health
```

---

## ğŸ“Š åŠŸèƒ½é©—è­‰

### 1. ç³»çµ±å¥åº·æª¢æŸ¥ï¼ˆæ›´æ–°ç‰ˆï¼‰

```python
# å®Œæ•´ç³»çµ±æª¢æŸ¥è…³æœ¬ - åŸºæ–¼å¯¦éš›æ¶æ§‹
import sys
sys.path.append('C:/D/fold7/AIVA-git')
sys.path.append('C:/D/fold7/AIVA-git/services')

def check_aiva_system():
    """AIVA ç³»çµ±å¥åº·æª¢æŸ¥ - 2025å¹´11æœˆç‰ˆæœ¬"""
    
    try:
        print("ğŸ” æª¢æŸ¥ 1: åŸºç¤ä¾è³´æª¢æŸ¥")
        import torch
        import numpy as np
        print(f"   âœ… PyTorch: {torch.__version__}")
        print(f"   âœ… NumPy: {np.__version__}")
        
        print("ğŸ” æª¢æŸ¥ 2: AI å¼•æ“æ¨¡çµ„å°å…¥")
        from services.core.aiva_core.ai_engine.real_bio_net_adapter import RealBioNeuronRAGAgent, create_real_rag_agent
        print("   âœ… çœŸå¯¦ AI å¼•æ“æ¨¡çµ„å°å…¥æˆåŠŸ")
        
        print("ğŸ” æª¢æŸ¥ 3: RAG ç³»çµ±æª¢æŸ¥")  
        from services.core.aiva_core.rag.rag_engine import RAGEngine
        rag_engine = RAGEngine()
        print(f"   âœ… RAG å¼•æ“: {type(rag_engine).__name__}")
        
        print("ğŸ” æª¢æŸ¥ 4: å‰µå»º AI çµ„ä»¶")
        decision_core = torch.nn.Sequential(
            torch.nn.Linear(512, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 20)
        )
        
        rag_agent = create_real_rag_agent(
            decision_core=decision_core,
            input_vector_size=512
        )
        print(f"   âœ… RAG ä»£ç†: {type(rag_agent).__name__}")
        print(f"   âœ… æ±ºç­–æ ¸å¿ƒ: {type(decision_core).__name__}")
        
        print("ğŸ” æª¢æŸ¥ 5: AI åŠŸèƒ½æ¸¬è©¦")
        result = rag_agent.generate(
            task_description='æ¸¬è©¦ AI æ±ºç­–åŠŸèƒ½',
            context='ç³»çµ±é©—è­‰æ¸¬è©¦'
        )
        confidence = result.get('confidence', 'unknown')
        print(f"   âœ… AI æ±ºç­–æ¸¬è©¦æˆåŠŸï¼Œä¿¡å¿ƒåº¦: {confidence}")
        
        print("\nğŸ‰ AIVA AI ç³»çµ±å¥åº·æª¢æŸ¥é€šéï¼")
        print("ğŸ“– è«‹æŸ¥çœ‹ AIVA_USER_MANUAL.md äº†è§£è©³ç´°ä½¿ç”¨æ–¹å¼")
        return True
        
    except Exception as e:
        print(f"âŒ ç³»çµ±æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

# åŸ·è¡Œæª¢æŸ¥
if __name__ == "__main__":
    check_aiva_system()
```

### 2. AI èƒ½åŠ›é©—è­‰ï¼ˆæ›´æ–°ç‰ˆï¼‰

```python
import asyncio
import torch
from services.core.aiva_core.ai_engine.real_bio_net_adapter import create_real_rag_agent
from services.core.aiva_core.rag.rag_engine import RAGEngine

async def validate_ai_capabilities():
    """AI èƒ½åŠ›é©—è­‰æ¸¬è©¦ - åŸºæ–¼å¯¦éš›æ¶æ§‹"""
    
    print("ğŸ§  åˆå§‹åŒ– AI çµ„ä»¶...")
    decision_core = torch.nn.Sequential(
        torch.nn.Linear(512, 256),
        torch.nn.ReLU(),
        torch.nn.Linear(256, 20)
    )
    
    rag_agent = create_real_rag_agent(
        decision_core=decision_core,
        input_vector_size=512
    )
    
    rag_engine = RAGEngine()
    
    # 1. æœç´¢èƒ½åŠ›æ¸¬è©¦
    print("ğŸ” æ¸¬è©¦æ™ºèƒ½æœç´¢èƒ½åŠ›...")
    try:
        search_result = await rag_engine.search("XSS æ”»æ“Š", top_k=3)
        assert len(search_result) >= 0, "æœç´¢åŠŸèƒ½ç•°å¸¸"
        print(f"   âœ… æœç´¢èƒ½åŠ›æ­£å¸¸ - æ‰¾åˆ° {len(search_result)} æ¢çµæœ")
    except Exception as e:
        print(f"   âš ï¸ æœç´¢åŠŸèƒ½æ¸¬è©¦: {e}")
    
    # 2. æ±ºç­–èƒ½åŠ›æ¸¬è©¦  
    print("ğŸ¤” æ¸¬è©¦ AI æ±ºç­–èƒ½åŠ›...")
    try:
        decision = rag_agent.generate(
            task_description="æ¸¬è©¦å®‰å…¨è©•ä¼°",
            context="ç›®æ¨™ç³»çµ±åˆ†æ"
        )
        assert "confidence" in decision or decision is not None, "æ±ºç­–åŠŸèƒ½ç•°å¸¸"
        print(f"   âœ… æ±ºç­–èƒ½åŠ›æ­£å¸¸ - ä¿¡å¿ƒåº¦: {decision.get('confidence', 'N/A')}")
    except Exception as e:
        print(f"   âš ï¸ æ±ºç­–åŠŸèƒ½æ¸¬è©¦: {e}")
    
    # 3. ç¥ç¶“ç¶²è·¯æ¸¬è©¦
    print("ğŸ§® æ¸¬è©¦ç¥ç¶“ç¶²è·¯æ¨ç†...")
    try:
        test_input = torch.randn(1, 512)  # éš¨æ©Ÿæ¸¬è©¦è¼¸å…¥
        output = decision_core(test_input)
        assert output.shape[-1] == 20, "ç¥ç¶“ç¶²è·¯è¼¸å‡ºç¶­åº¦ç•°å¸¸"
        print(f"   âœ… ç¥ç¶“ç¶²è·¯æ¨ç†æ­£å¸¸ - è¼¸å‡ºå½¢ç‹€: {output.shape}")
    except Exception as e:
        print(f"   âš ï¸ ç¥ç¶“ç¶²è·¯æ¸¬è©¦: {e}")
    
    print("ğŸ‰ AI èƒ½åŠ›é©—è­‰å®Œæˆï¼")

# åŸ·è¡Œé©—è­‰
# asyncio.run(validate_ai_capabilities())
```

### 3. æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆæ›´æ–°ç‰ˆï¼‰

```python
import time
import asyncio
import torch
from services.core.aiva_core.ai_engine.real_bio_net_adapter import create_real_rag_agent
from services.core.aiva_core.rag.rag_engine import RAGEngine

async def performance_benchmark():
    """æ€§èƒ½åŸºæº–æ¸¬è©¦ - åŸºæ–¼å¯¦éš›æ¶æ§‹"""
    
    print("ğŸ“Š å•Ÿå‹• AIVA æ€§èƒ½åŸºæº–æ¸¬è©¦...")
    
    # åˆå§‹åŒ–çµ„ä»¶
    decision_core = torch.nn.Sequential(
        torch.nn.Linear(512, 256),
        torch.nn.ReLU(),
        torch.nn.Linear(256, 20)
    )
    
    rag_agent = create_real_rag_agent(
        decision_core=decision_core,
        input_vector_size=512
    )
    
    rag_engine = RAGEngine()
    
    # ç¥ç¶“ç¶²è·¯æ¨ç†æ€§èƒ½æ¸¬è©¦
    print("ğŸ§® æ¸¬è©¦ç¥ç¶“ç¶²è·¯æ¨ç†æ€§èƒ½...")
    start_time = time.time()
    
    # æ‰¹é‡æ¨ç†æ¸¬è©¦
    test_batch = torch.randn(10, 512)  # 10å€‹æ¨£æœ¬
    with torch.no_grad():
        for _ in range(100):  # 100æ¬¡æ¨ç†
            _ = decision_core(test_batch)
    
    nn_time = time.time() - start_time
    nn_throughput = (10 * 100) / nn_time  # æ¨£æœ¬/ç§’
    
    print(f"   ğŸš€ ç¥ç¶“ç¶²è·¯æ¨ç†: {nn_time:.2f}s")
    print(f"   ğŸ“ˆ æ¨ç†ååé‡: {nn_throughput:.1f} æ¨£æœ¬/s")
    
    # AI æ±ºç­–æ€§èƒ½æ¸¬è©¦
    print("ğŸ¤– æ¸¬è©¦ AI æ±ºç­–æ€§èƒ½...")
    start_time = time.time()
    
    decisions = []
    for i in range(5):  # 5æ¬¡æ±ºç­–æ¸¬è©¦
        result = rag_agent.generate(
            task_description=f"æ€§èƒ½æ¸¬è©¦ä»»å‹™ {i+1}",
            context="åŸºæº–æ¸¬è©¦"
        )
        decisions.append(result)
    
    decision_time = time.time() - start_time
    decision_throughput = len(decisions) / decision_time
    
    print(f"   âš¡ AI æ±ºç­–æ™‚é–“: {decision_time:.2f}s")
    print(f"   ğŸ¯ æ±ºç­–ååé‡: {decision_throughput:.1f} æ±ºç­–/s")
    
    # æ€§èƒ½è©•ä¼°
    print("\nğŸ“Š æ€§èƒ½è©•ä¼°çµæœ:")
    if nn_throughput > 100 and decision_throughput > 1.0:
        print("   ğŸŸ¢ æ€§èƒ½: å„ªç§€ (æ¨è–¦ç”Ÿç”¢ä½¿ç”¨)")
    elif nn_throughput > 50 and decision_throughput > 0.5:
        print("   ğŸŸ¡ æ€§èƒ½: è‰¯å¥½ (é©åˆé–‹ç™¼æ¸¬è©¦)")
    else:
        print("   ğŸ”´ æ€§èƒ½: éœ€è¦å„ªåŒ–")
        
    print(f"   ğŸ’» ç¥ç¶“ç¶²è·¯ååé‡: {nn_throughput:.1f} æ¨£æœ¬/s")
    print(f"   ğŸ§  AI æ±ºç­–ååé‡: {decision_throughput:.1f} æ±ºç­–/s")

# åŸ·è¡ŒåŸºæº–æ¸¬è©¦
# asyncio.run(performance_benchmark())
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### 1. å°å…¥éŒ¯èª¤

**å•é¡Œ**: `ModuleNotFoundError: No module named 'services'`

**è§£æ±ºæ–¹æ¡ˆ**:
```powershell
# é‡æ–°è¨­å®š PYTHONPATH
.\setup_env.ps1

# æˆ–æ‰‹å‹•è¨­å®š
$env:PYTHONPATH = "C:\D\fold7\AIVA-git;C:\D\fold7\AIVA-git\services"
```

#### 2. ä¾è³´ç¼ºå¤±

**å•é¡Œ**: `No module named 'torch'` æˆ–å…¶ä»–ä¾è³´ç¼ºå¤±

**è§£æ±ºæ–¹æ¡ˆ**:
```powershell
# å®‰è£æ‰€æœ‰ä¾è³´
python -m pip install --upgrade protobuf grpcio torch numpy fastapi uvicorn

# æª¢æŸ¥å®‰è£
python -c "import torch, numpy; print('ä¾è³´OK')"
```

#### 3. è¨˜æ†¶é«”ä¸è¶³

**å•é¡Œ**: ç¥ç¶“ç¶²è·¯åˆå§‹åŒ–æ™‚è¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# ä½¿ç”¨è¼•é‡åŒ–é…ç½®
controller = BioNeuronMasterController(
    default_mode="ui"  # ä½¿ç”¨è¼ƒè¼•çš„ UI æ¨¡å¼
)
```

#### 4. æ¬Šé™å•é¡Œ

**å•é¡Œ**: æ–‡ä»¶è®€å¯«æ¬Šé™éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:
```powershell
# ä»¥ç®¡ç†å“¡èº«ä»½é‹è¡Œ PowerShell
# æˆ–èª¿æ•´æ–‡ä»¶æ¬Šé™
icacls "C:\D\fold7\AIVA-git" /grant Everyone:F /t
```

### æ—¥èªŒèˆ‡èª¿è©¦

```python
import logging

# å•Ÿç”¨èª¿è©¦æ—¥èªŒ
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("aiva.debug")

# æŸ¥çœ‹è©³ç´°éŒ¯èª¤ä¿¡æ¯
try:
    aiva = BioNeuronMasterController()
except Exception as e:
    logger.error(f"åˆå§‹åŒ–å¤±æ•—: {e}", exc_info=True)
```

---

## ğŸ“š é€²éšåŠŸèƒ½

### 1. è‡ªå®šç¾© AI é…ç½®

```python
# è‡ªå®šç¾©ç¥ç¶“ç¶²è·¯é…ç½®
custom_config = {
    "neural_network": {
        "input_size": 512,
        "hidden_layers": [1024, 512, 256],
        "num_tools": 15,
        "confidence_threshold": 0.8
    },
    "rag_engine": {
        "top_k": 10,
        "similarity_threshold": 0.7,
        "context_window": 2048
    }
}

# æ‡‰ç”¨é…ç½®
aiva = BioNeuronMasterController()
await aiva.apply_configuration(custom_config)
```

### 2. è‡ªå®šç¾©çŸ¥è­˜åº«

```python
# æ·»åŠ è‡ªå®šç¾©çŸ¥è­˜
await aiva.rag_engine.add_knowledge(
    content="è‡ªå®šç¾©å®‰å…¨çŸ¥è­˜å…§å®¹",
    metadata={
        "source": "custom",
        "category": "security",
        "priority": "high"
    }
)

# ç´¢å¼•ä»£ç¢¼åº«
await aiva.rag_engine.index_codebase(
    path="/path/to/custom/code",
    language_filter=["python", "javascript"]
)
```

### 3. API æ“´å±•

```python
from fastapi import FastAPI
from services.core.aiva_core.bio_neuron_master import BioNeuronMasterController

app = FastAPI()
aiva = BioNeuronMasterController()

@app.post("/custom/ai-analyze")
async def custom_ai_analyze(request: dict):
    """è‡ªå®šç¾© AI åˆ†æç«¯é»"""
    result = await aiva.process_request(
        request=request.get("query"),
        mode="ai"
    )
    return {"analysis": result}

# å•Ÿå‹•æœå‹™
# uvicorn main:app --host 0.0.0.0 --port 8000
```

### 4. æ‰¹é‡è™•ç†

```python
async def batch_processing(tasks: list):
    """æ‰¹é‡ä»»å‹™è™•ç†"""
    
    aiva = BioNeuronMasterController()
    
    # ä¸¦è¡Œè™•ç†å¤šå€‹ä»»å‹™
    results = await asyncio.gather(*[
        aiva.process_request(task, mode="ai")
        for task in tasks
    ])
    
    # çµæœå½™ç¸½
    summary = {
        "total_tasks": len(tasks),
        "successful": sum(1 for r in results if r.get("success")),
        "failed": sum(1 for r in results if not r.get("success")),
        "results": results
    }
    
    return summary

# ä½¿ç”¨ç¤ºä¾‹
tasks = [
    {"objective": "æƒæç›®æ¨™1", "target": "example1.com"},
    {"objective": "æƒæç›®æ¨™2", "target": "example2.com"},
    {"objective": "æƒæç›®æ¨™3", "target": "example3.com"}
]

batch_result = await batch_processing(tasks)
print(f"æ‰¹é‡è™•ç†å®Œæˆ: {batch_result['successful']}/{batch_result['total_tasks']}")
```

---

## ğŸ“ æŠ€è¡“æ”¯æ´

### ç²å¾—å¹«åŠ©

- **ğŸ“– æ–‡æª”**: æŸ¥çœ‹ `README.md` å’Œ `docs/` ç›®éŒ„
- **ğŸ› å•é¡Œå ±å‘Š**: é€šé GitHub Issues
- **ğŸ’¬ ç¤¾ç¾¤è¨è«–**: GitHub Discussions
- **ğŸ“§ æŠ€è¡“æ”¯æ´**: ai-support@aiva-platform.com

### è²¢ç»æŒ‡å—

1. Fork å°ˆæ¡ˆå€‰åº«
2. å‰µå»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/amazing-feature`
3. æäº¤è®Šæ›´: `git commit -m 'Add amazing feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/amazing-feature`
5. é–‹å•Ÿ Pull Request

---

## ğŸ“„ ç‰ˆæœ¬è³‡è¨Š

**ç•¶å‰ç‰ˆæœ¬**: v2.0.0  
**ç™¼å¸ƒæ—¥æœŸ**: 2025å¹´11æœˆ11æ—¥  
**ç›¸å®¹æ€§**: Python 3.8+, Windows/Linux/macOS  
**æˆæ¬Š**: MIT License  

### æ›´æ–°æ—¥èªŒ

- **v2.0.0** (2025-11-11): 500è¬åƒæ•¸ç¥ç¶“ç¶²è·¯æ•´åˆã€RAGå¢å¼·ç³»çµ±ã€å››ç¨®é‹è¡Œæ¨¡å¼
- **v1.5.0** (2024-10-15): åŸºç¤AIå¼•æ“ã€çŸ¥è­˜åº«ç³»çµ±
- **v1.0.0** (2024-08-01): åˆå§‹ç‰ˆæœ¬ç™¼å¸ƒ

---

**ğŸŒŸ æ„Ÿè¬ä½¿ç”¨ AIVA AI ç³»çµ±ï¼**

*æœ¬æ‰‹å†ŠæœƒæŒçºŒæ›´æ–°ï¼Œä»¥ç¢ºä¿èˆ‡ç³»çµ±åŠŸèƒ½åŒæ­¥ã€‚å¦‚æœ‰ä»»ä½•ç–‘å•ï¼Œæ­¡è¿è¯ç¹«æŠ€è¡“æ”¯æ´åœ˜éšŠã€‚*