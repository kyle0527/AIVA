#!/usr/bin/env python3
"""
ä½¿ç”¨å¯¦éš›æ•¸æ“šæ¸¬è©¦ BioNeuronCore AI
- çœŸå¯¦ä»£ç¢¼åº«è·¯å¾‘
- å¯¦éš›æ–‡ä»¶æ“ä½œ
- å®Œæ•´è¨˜æ†¶æ¸¬è©¦
- æŒä¹…åŒ–é©—è­‰
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

def test_with_real_data():
    """ä½¿ç”¨å¯¦éš›æ•¸æ“šæ¸¬è©¦ AI"""
    print("="*70)
    print("BioNeuronCore AI - å¯¦éš›æ•¸æ“šæ¸¬è©¦")
    print("="*70)
    
    try:
        from services.core.aiva_core.ai_engine.bio_neuron_core import BioNeuronRAGAgent
        import json
        from datetime import datetime
        
        # ä½¿ç”¨å¯¦éš›çš„ AIVA ä»£ç¢¼åº«
        codebase_path = str(Path(__file__).parent)
        
        print(f"\n[é…ç½®] ä»£ç¢¼åº«è·¯å¾‘: {codebase_path}")
        
        # ====== æ¸¬è©¦ 1: å‰µå»º AI ä¸¦æª¢æŸ¥åƒæ•¸ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 1] å‰µå»º AI ä¸¦æª¢æŸ¥ç¥ç¶“ç¶²è·¯åƒæ•¸")
        print("="*70)
        
        agent = BioNeuronRAGAgent(
            codebase_path=codebase_path,
            enable_planner=False,
            enable_tracer=False,
            enable_experience=False
        )
        
        print(f"âœ“ AI å‰µå»ºæˆåŠŸ")
        print(f"\n[ç¥ç¶“ç¶²è·¯åƒæ•¸]")
        print(f"  - è¼¸å…¥å‘é‡ç¶­åº¦: {agent.input_vector_size}")
        print(f"  - å·¥å…·æ•¸é‡: {len(agent.tools)}")
        print(f"  - æ±ºç­–æ ¸å¿ƒåƒæ•¸: {agent.decision_core.total_params:,}")
        print(f"    â€¢ FC1 å±¤: {agent.decision_core.params_fc1:,}")
        print(f"    â€¢ Spiking å±¤: {agent.decision_core.params_spiking1:,}")
        print(f"    â€¢ FC2 å±¤: {agent.decision_core.params_fc2:,}")
        
        # ====== æ¸¬è©¦ 2: å¯¦éš›æ–‡ä»¶æ“ä½œ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 2] å¯¦éš›æ–‡ä»¶æ“ä½œæ¸¬è©¦")
        print("="*70)
        
        # è®€å–çœŸå¯¦æ–‡ä»¶
        test_file = "README.md"
        print(f"\n[ä»»å‹™] è®€å–æ–‡ä»¶: {test_file}")
        result1 = agent.invoke(
            f"è®€å– {test_file} æ–‡ä»¶",
        )
        
        print(f"âœ“ ä»»å‹™å®Œæˆ")
        print(f"  - ç‹€æ…‹: {result1.get('status')}")
        print(f"  - é¸æ“‡å·¥å…·: {result1.get('tool_used')}")
        print(f"  - ä¿¡å¿ƒåº¦: {result1.get('confidence'):.2%}")
        print(f"  - åŸ·è¡Œçµæœ: {result1.get('result', 'N/A')}")
        
        # ====== æ¸¬è©¦ 3: å¤šä»»å‹™åŸ·è¡Œèˆ‡è¨˜æ†¶ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 3] å¤šä»»å‹™åŸ·è¡Œèˆ‡è¨˜æ†¶æ¸¬è©¦")
        print("="*70)
        
        tasks = [
            "åˆ†æ pyproject.toml é…ç½®",
            "æª¢æŸ¥ services ç›®éŒ„çµæ§‹",
            "è®€å– AI æ ¸å¿ƒæ¨¡çµ„ä»£ç¢¼",
            "åˆ†æç¥ç¶“ç¶²è·¯æ¶æ§‹",
            "æª¢æŸ¥è¨“ç·´è…³æœ¬",
        ]
        
        print(f"\nåŸ·è¡Œå‰è¨˜éŒ„æ•¸: {len(agent.history)}")
        
        for i, task in enumerate(tasks, 1):
            print(f"\n[ä»»å‹™ {i}/5] {task}")
            result = agent.invoke(task)
            print(f"  âœ“ å®Œæˆ - å·¥å…·: {result.get('tool_used')}, "
                  f"ä¿¡å¿ƒ: {result.get('confidence', 0):.1%}")
        
        print(f"\nåŸ·è¡Œå¾Œè¨˜éŒ„æ•¸: {len(agent.history)}")
        print(f"âœ“ è¨˜æ†¶äº† {len(agent.history)} æ¢åŸ·è¡Œè¨˜éŒ„")
        
        # ====== æ¸¬è©¦ 4: æª¢æŸ¥è¨˜æ†¶å…§å®¹ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 4] è¨˜æ†¶å…§å®¹è©³ç´°æª¢æŸ¥")
        print("="*70)
        
        print(f"\n[å®Œæ•´åŸ·è¡Œæ­·å²] å…± {len(agent.history)} æ¢:")
        for i, record in enumerate(agent.history, 1):
            print(f"\n  è¨˜éŒ„ #{i}:")
            print(f"    å·¥å…·: {record.get('tool_used')}")
            print(f"    ç‹€æ…‹: {record.get('status')}")
            print(f"    ä¿¡å¿ƒåº¦: {record.get('confidence', 0):.2%}")
            if 'result' in record:
                result_str = str(record['result'])[:50]
                print(f"    çµæœ: {result_str}...")
        
        # ====== æ¸¬è©¦ 5: çŸ¥è­˜åº«å¯¦éš›çµ±è¨ˆ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 5] çŸ¥è­˜åº«å¯¦éš›æ•¸æ“šçµ±è¨ˆ")
        print("="*70)
        
        stats = agent.get_knowledge_stats()
        print(f"\n[çŸ¥è­˜åº«çµ±è¨ˆ]")
        for key, value in stats.items():
            print(f"  - {key}: {value:,}")
        
        # ====== æ¸¬è©¦ 6: ä¿å­˜è¨˜æ†¶åˆ°æ–‡ä»¶ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 6] æŒä¹…åŒ–æ¸¬è©¦ - ä¿å­˜è¨˜æ†¶")
        print("="*70)
        
        memory_file = Path("data/ai_memory_test.json")
        memory_file.parent.mkdir(parents=True, exist_ok=True)
        
        memory_data = {
            "timestamp": datetime.now().isoformat(),
            "codebase": codebase_path,
            "total_executions": len(agent.history),
            "neural_params": agent.decision_core.total_params,
            "tools_available": len(agent.tools),
            "execution_history": [
                {
                    "tool": r.get("tool_used"),
                    "status": r.get("status"),
                    "confidence": r.get("confidence", 0),
                }
                for r in agent.history
            ],
            "knowledge_stats": stats,
        }
        
        with open(memory_file, 'w', encoding='utf-8') as f:
            json.dump(memory_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ è¨˜æ†¶å·²ä¿å­˜åˆ°: {memory_file}")
        print(f"  - æ–‡ä»¶å¤§å°: {memory_file.stat().st_size} bytes")
        
        # ====== æ¸¬è©¦ 7: é©—è­‰å¯ä»¥è®€å–è¨˜æ†¶ ======
        print("\n" + "="*70)
        print("[æ¸¬è©¦ 7] é©—è­‰è¨˜æ†¶å¯ä»¥é‡æ–°è¼‰å…¥")
        print("="*70)
        
        with open(memory_file, 'r', encoding='utf-8') as f:
            loaded_memory = json.load(f)
        
        print(f"âœ“ æˆåŠŸè¼‰å…¥è¨˜æ†¶æ–‡ä»¶")
        print(f"  - æ™‚é–“æˆ³: {loaded_memory['timestamp']}")
        print(f"  - åŸ·è¡Œæ¬¡æ•¸: {loaded_memory['total_executions']}")
        print(f"  - ç¥ç¶“ç¶²è·¯åƒæ•¸: {loaded_memory['neural_params']:,}")
        print(f"  - æ­·å²è¨˜éŒ„æ•¸: {len(loaded_memory['execution_history'])}")
        
        # ====== æœ€çµ‚ç¸½çµ ======
        print("\n" + "="*70)
        print("æœ€çµ‚æ¸¬è©¦çµæœç¸½çµ")
        print("="*70)
        
        results = {
            "âœ“ AI å‰µå»º": "æˆåŠŸ",
            "âœ“ ç¥ç¶“ç¶²è·¯": f"{agent.decision_core.total_params:,} åƒæ•¸",
            "âœ“ å¯¦éš›åŸ·è¡Œ": f"{len(agent.history)} æ¬¡ä»»å‹™",
            "âœ“ è¨˜æ†¶åŠŸèƒ½": f"{len(agent.history)} æ¢è¨˜éŒ„",
            "âœ“ çŸ¥è­˜åº«": f"{stats.get('total_chunks', 0):,} ç¨‹å¼ç¢¼ç‰‡æ®µ",
            "âœ“ æŒä¹…åŒ–": f"{memory_file} å·²ä¿å­˜",
            "âœ“ å¯é‡è¼‰": "é©—è­‰æˆåŠŸ",
        }
        
        print()
        for key, value in results.items():
            print(f"  {key}: {value}")
        
        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼AI å®Œå…¨å¯ç”¨æ–¼å¯¦éš›ä»»å‹™ï¼")
        print("="*70)
        print()
        print("ğŸ“Š é—œéµæ•¸æ“š:")
        print(f"  â€¢ 500è¬åƒæ•¸ç¥ç¶“ç¶²è·¯: âœ“ é‹ä½œæ­£å¸¸")
        print(f"  â€¢ åŸ·è¡Œèƒ½åŠ›: âœ“ {len(agent.history)} æ¬¡æˆåŠŸåŸ·è¡Œ")
        print(f"  â€¢ è¨˜æ†¶èƒ½åŠ›: âœ“ æ‰€æœ‰åŸ·è¡Œéƒ½è¢«è¨˜éŒ„")
        print(f"  â€¢ æŒä¹…åŒ–: âœ“ å¯ä»¥ä¿å­˜å’Œè¼‰å…¥")
        print(f"  â€¢ çŸ¥è­˜åº«: âœ“ {stats.get('total_chunks', 0)} å€‹ç¨‹å¼ç¢¼ç‰‡æ®µ")
        print()
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè­°:")
        print("  1. å•Ÿç”¨ç¶“é©—å­¸ç¿’ (enable_experience=True)")
        print("  2. é€£æ¥è³‡æ–™åº«æŒä¹…åŒ–")
        print("  3. é–‹å§‹è¨“ç·´å¾ªç’°")
        print("  4. åŸ·è¡Œå¯¦éš›çš„ CLI å‘½ä»¤")
        print("="*70)
        
        return True
        
    except Exception as e:
        print(f"\nâœ— æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_with_real_data()
    sys.exit(0 if success else 1)
