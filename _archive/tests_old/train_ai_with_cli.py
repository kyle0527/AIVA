#!/usr/bin/env python3
"""
BioNeuronCore AI - å®Œæ•´è¨“ç·´å’Œ CLI é…å°ç³»çµ±

åŠŸèƒ½ï¼š
1. å•Ÿç”¨ç¶“é©—å­¸ç¿’
2. åŸ·è¡Œ CLI å‘½ä»¤ä¸¦å­¸ç¿’
3. æŒçºŒå„ªåŒ–ç¥ç¶“ç¶²è·¯
4. è¨˜æ†¶å’ŒæŒä¹…åŒ–
"""
import sys
from pathlib import Path
import asyncio
import json
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

class AITrainingSystem:
    """AI è¨“ç·´ç³»çµ± - é…å° CLI å‘½ä»¤åŸ·è¡Œ"""
    
    def __init__(self, codebase_path: str):
        """åˆå§‹åŒ–è¨“ç·´ç³»çµ±"""
        self.codebase_path = codebase_path
        self.agent = None
        self.training_data = {
            "start_time": datetime.now().isoformat(),
            "sessions": [],
            "total_executions": 0,
            "total_experiences": 0,
        }
        
    def initialize_ai(self):
        """åˆå§‹åŒ– AI ä»£ç†ï¼ˆå•Ÿç”¨æ‰€æœ‰åŠŸèƒ½ï¼‰"""
        print("="*70)
        print("åˆå§‹åŒ– BioNeuronCore AIï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰")
        print("="*70)
        
        from services.core.aiva_core.ai_engine.bio_neuron_core import BioNeuronRAGAgent
        from services.core.aiva_core.ai_engine.cli_tools import get_all_tools
        
        # å‰µå»ºæ•¸æ“šç›®éŒ„
        data_dir = Path("data/ai_training")
        data_dir.mkdir(parents=True, exist_ok=True)
        
        db_path = data_dir / "aiva_experience.db"
        
        print(f"\n[é…ç½®]")
        print(f"  ä»£ç¢¼åº«: {self.codebase_path}")
        print(f"  æ•¸æ“šåº«: {db_path}")
        
        try:
            # å•Ÿç”¨å®Œæ•´åŠŸèƒ½
            self.agent = BioNeuronRAGAgent(
                codebase_path=self.codebase_path,
                enable_planner=True,      # å•Ÿç”¨è¨ˆç•«åŸ·è¡Œ
                enable_tracer=True,       # å•Ÿç”¨åŸ·è¡Œè¿½è¹¤
                enable_experience=True,   # å•Ÿç”¨ç¶“é©—å­¸ç¿’
                database_url=f"sqlite:///{db_path}"
            )
            
            # åŠ è¼‰å®Œæ•´ CLI å·¥å…·é›†ä¸¦æ›¿æ›é»˜èªå·¥å…·
            cli_tools_dict = get_all_tools()
            self.agent.tools = [
                {"name": tool_name, "instance": tool_obj}
                for tool_name, tool_obj in cli_tools_dict.items()
            ]
            self.agent.tool_map = {tool["name"]: tool for tool in self.agent.tools}
            
            # é‡æ–°å‰µå»ºæ±ºç­–æ ¸å¿ƒä»¥åŒ¹é…æ–°å·¥å…·æ•¸é‡
            from services.core.aiva_core.ai_engine.bio_neuron_core import ScalableBioNet
            self.agent.decision_core = ScalableBioNet(
                self.agent.input_vector_size, 
                len(self.agent.tools)
            )
            
            print("\nâœ“ AI å®Œæ•´åˆå§‹åŒ–æˆåŠŸ")
            print(f"  - è¨ˆç•«åŸ·è¡Œå™¨: {'âœ“' if self.agent.orchestrator else 'âœ—'}")
            print(f"  - åŸ·è¡Œè¿½è¹¤: {'âœ“' if self.agent.execution_monitor else 'âœ—'}")
            print(f"  - ç¶“é©—å­¸ç¿’: {'âœ“' if self.agent.experience_repo else 'âœ—'}")
            print(f"  - CLI å·¥å…·é›†: {len(self.agent.tools)} å€‹å·¥å…·")
            for i, tool in enumerate(self.agent.tools, 1):
                print(f"    {i}. {tool['name']}")
            
        except Exception as e:
            print(f"\nâš  éƒ¨åˆ†åŠŸèƒ½åˆå§‹åŒ–å¤±æ•—: {e}")
            print("  é™ç´šç‚ºåŸºç¤æ¨¡å¼...")
            import traceback
            traceback.print_exc()
            
            # é™ç´šï¼šå‰µå»ºåŸºç¤ AI
            self.agent = BioNeuronRAGAgent(
                codebase_path=self.codebase_path,
                enable_planner=False,
                enable_tracer=False,
                enable_experience=False
            )
            
            # ä»ç„¶å˜—è©¦åŠ è¼‰ CLI å·¥å…·
            try:
                cli_tools_dict = get_all_tools()
                self.agent.tools = [
                    {"name": tool_name, "instance": tool_obj}
                    for tool_name, tool_obj in cli_tools_dict.items()
                ]
                self.agent.tool_map = {tool["name"]: tool for tool in self.agent.tools}
                
                from services.core.aiva_core.ai_engine.bio_neuron_core import ScalableBioNet
                self.agent.decision_core = ScalableBioNet(
                    self.agent.input_vector_size, 
                    len(self.agent.tools)
                )
                print("âœ“ åŸºç¤æ¨¡å¼ AI å‰µå»ºæˆåŠŸï¼ˆåŒ…å« CLI å·¥å…·é›†ï¼‰")
                print(f"  - å·¥å…·é›†: {len(self.agent.tools)} å€‹å·¥å…·")
            except Exception as tool_err:
                print(f"âš  å·¥å…·åŠ è¼‰å¤±æ•—: {tool_err}")
        
        return self.agent
    
    def simulate_cli_commands(self):
        """æ¨¡æ“¬ CLI å‘½ä»¤åŸ·è¡Œï¼ˆé…å°ï¼‰"""
        print("\n" + "="*70)
        print("CLI å‘½ä»¤é…å°åŸ·è¡Œ")
        print("="*70)
        
        # å®šç¾© CLI å‘½ä»¤å’Œå°æ‡‰çš„ AI ä»»å‹™
        cli_tasks = [
            {
                "cli": "aiva scan start https://example.com",
                "task": "æƒæç›®æ¨™ç¶²ç«™ example.com",
                "tool_expected": "ScanTrigger"
            },
            {
                "cli": "aiva detect sqli https://example.com/login --param username",
                "task": "æª¢æ¸¬ SQL æ³¨å…¥æ¼æ´åœ¨ login é é¢çš„ username åƒæ•¸",
                "tool_expected": "SQLiDetector"
            },
            {
                "cli": "aiva analyze code services/core/",
                "task": "åˆ†æ services/core ç›®éŒ„çš„ä»£ç¢¼çµæ§‹",
                "tool_expected": "CodeAnalyzer"
            },
            {
                "cli": "aiva read config pyproject.toml",
                "task": "è®€å– pyproject.toml é…ç½®æ–‡ä»¶",
                "tool_expected": "CodeReader"
            },
            {
                "cli": "aiva detect xss https://example.com/search --param q",
                "task": "æª¢æ¸¬ XSS æ¼æ´åœ¨ search é é¢çš„ q åƒæ•¸",
                "tool_expected": "XSSDetector"
            },
        ]
        
        session = {
            "session_id": f"train_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "executions": []
        }
        
        print(f"\nè¨“ç·´æœƒè©±: {session['session_id']}")
        print(f"ä»»å‹™æ•¸é‡: {len(cli_tasks)}\n")
        
        for i, task_info in enumerate(cli_tasks, 1):
            print(f"\n[ä»»å‹™ {i}/{len(cli_tasks)}]")
            print(f"CLI å‘½ä»¤: {task_info['cli']}")
            print(f"AI ä»»å‹™: {task_info['task']}")
            
            # AI åŸ·è¡Œä»»å‹™
            result = self.agent.invoke(task_info['task'])
            
            # è¨˜éŒ„åŸ·è¡Œ
            execution = {
                "cli_command": task_info['cli'],
                "ai_task": task_info['task'],
                "tool_used": result.get('tool_used'),
                "tool_expected": task_info['tool_expected'],
                "status": result.get('status'),
                "confidence": result.get('confidence', 0),
                "matched": result.get('tool_used') == task_info['tool_expected'],
                "timestamp": datetime.now().isoformat()
            }
            
            session['executions'].append(execution)
            self.training_data['total_executions'] += 1
            
            # é¡¯ç¤ºçµæœ
            match_icon = "âœ“" if execution['matched'] else "âœ—"
            print(f"  çµæœ: {result.get('status')}")
            print(f"  å·¥å…·: {result.get('tool_used')} {match_icon}")
            print(f"  ä¿¡å¿ƒåº¦: {result.get('confidence', 0):.1%}")
            print(f"  é…å°: {'æˆåŠŸ' if execution['matched'] else 'å¤±æ•—'}")
        
        self.training_data['sessions'].append(session)
        return session
    
    def train_from_experience(self):
        """å¾ç¶“é©—è¨“ç·´æ¨¡å‹"""
        print("\n" + "="*70)
        print("å¾ç¶“é©—è¨“ç·´ AI æ¨¡å‹")
        print("="*70)
        
        if not hasattr(self.agent, 'train_from_experiences'):
            print("\nâš  ç¶“é©—å­¸ç¿’æœªå•Ÿç”¨ï¼Œè·³éè¨“ç·´")
            return None
        
        try:
            print("\næ­£åœ¨å¾ç¶“é©—åº«è¨“ç·´...")
            result = self.agent.train_from_experiences(
                min_score=0.5,
                max_samples=1000
            )
            
            print(f"âœ“ è¨“ç·´å®Œæˆ")
            print(f"  ç‹€æ…‹: {result.get('status')}")
            
            if result.get('status') == 'success':
                self.training_data['total_experiences'] = result.get('samples_used', 0)
            
            return result
            
        except Exception as e:
            print(f"âš  è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def save_training_report(self):
        """ä¿å­˜è¨“ç·´å ±å‘Š"""
        print("\n" + "="*70)
        print("ä¿å­˜è¨“ç·´å ±å‘Š")
        print("="*70)
        
        report_file = Path("data/ai_training/training_report.json")
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        # è¨ˆç®—çµ±è¨ˆ
        total_tasks = self.training_data['total_executions']
        matched_count = sum(
            1 for session in self.training_data['sessions']
            for exec in session['executions']
            if exec.get('matched', False)
        )
        
        success_rate = (matched_count / total_tasks * 100) if total_tasks > 0 else 0
        
        report = {
            **self.training_data,
            "end_time": datetime.now().isoformat(),
            "statistics": {
                "total_tasks": total_tasks,
                "matched_tasks": matched_count,
                "success_rate": f"{success_rate:.1f}%",
                "total_sessions": len(self.training_data['sessions']),
            },
            "neural_network": {
                "total_params": self.agent.decision_core.total_params,
                "input_size": self.agent.input_vector_size,
                "tools_count": len(self.agent.tools),
            },
            "memory": {
                "history_count": len(self.agent.history),
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ å ±å‘Šå·²ä¿å­˜: {report_file}")
        print(f"  æ–‡ä»¶å¤§å°: {report_file.stat().st_size} bytes")
        
        return report
    
    def display_summary(self, report):
        """é¡¯ç¤ºè¨“ç·´ç¸½çµ"""
        print("\n" + "="*70)
        print("è¨“ç·´ç¸½çµ")
        print("="*70)
        
        stats = report['statistics']
        
        print(f"\n[åŸ·è¡Œçµ±è¨ˆ]")
        print(f"  ç¸½ä»»å‹™æ•¸: {stats['total_tasks']}")
        print(f"  é…å°æˆåŠŸ: {stats['matched_tasks']}")
        print(f"  æˆåŠŸç‡: {stats['success_rate']}")
        print(f"  è¨“ç·´æœƒè©±: {stats['total_sessions']}")
        
        print(f"\n[ç¥ç¶“ç¶²è·¯]")
        nn_info = report['neural_network']
        print(f"  ç¸½åƒæ•¸: {nn_info['total_params']:,}")
        print(f"  è¼¸å…¥ç¶­åº¦: {nn_info['input_size']}")
        print(f"  å·¥å…·æ•¸é‡: {nn_info['tools_count']}")
        
        print(f"\n[è¨˜æ†¶ç³»çµ±]")
        print(f"  æ­·å²è¨˜éŒ„: {report['memory']['history_count']}")
        print(f"  ç¶“é©—æ•¸æ“š: {self.training_data['total_experiences']}")
        
        print(f"\n[æ™‚é–“]")
        print(f"  é–‹å§‹: {report['start_time']}")
        print(f"  çµæŸ: {report['end_time']}")
        
        # é¡¯ç¤ºæ¯å€‹æœƒè©±çš„è©³æƒ…
        print(f"\n[æœƒè©±è©³æƒ…]")
        for i, session in enumerate(self.training_data['sessions'], 1):
            matched = sum(1 for e in session['executions'] if e.get('matched', False))
            total = len(session['executions'])
            print(f"  æœƒè©± {i}: {matched}/{total} é…å°æˆåŠŸ ({matched/total*100:.0f}%)")


async def main():
    """ä¸»è¨“ç·´æµç¨‹"""
    print("\n" + "="*70)
    print("BioNeuronCore AI - å®Œæ•´è¨“ç·´ç³»çµ±")
    print("é…å° CLI å‘½ä»¤åŸ·è¡Œå’ŒæŒçºŒå­¸ç¿’")
    print("="*70)
    
    # åˆå§‹åŒ–è¨“ç·´ç³»çµ±
    codebase = str(Path(__file__).parent)
    trainer = AITrainingSystem(codebase)
    
    # æ­¥é©Ÿ 1: åˆå§‹åŒ– AI
    trainer.initialize_ai()
    
    # æ­¥é©Ÿ 2: CLI å‘½ä»¤é…å°åŸ·è¡Œ
    session = trainer.simulate_cli_commands()
    
    # æ­¥é©Ÿ 3: å¾ç¶“é©—è¨“ç·´
    trainer.train_from_experience()
    
    # æ­¥é©Ÿ 4: ä¿å­˜å ±å‘Š
    report = trainer.save_training_report()
    
    # æ­¥é©Ÿ 5: é¡¯ç¤ºç¸½çµ
    trainer.display_summary(report)
    
    # æœ€çµ‚æç¤º
    print("\n" + "="*70)
    print("ğŸ‰ è¨“ç·´å®Œæˆï¼")
    print("="*70)
    print("\nğŸ“Š é—œéµæˆæœ:")
    print(f"  âœ“ AI å¯åŸ·è¡Œ CLI å‘½ä»¤")
    print(f"  âœ“ é…å°æˆåŠŸç‡: {report['statistics']['success_rate']}")
    print(f"  âœ“ è¨˜æ†¶äº† {report['memory']['history_count']} æ¬¡åŸ·è¡Œ")
    print(f"  âœ“ ç¥ç¶“ç¶²è·¯: {report['neural_network']['total_params']:,} åƒæ•¸")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. åŸ·è¡Œæ›´å¤š CLI å‘½ä»¤å¢åŠ è¨“ç·´æ•¸æ“š")
    print("  2. èª¿æ•´ç¥ç¶“ç¶²è·¯åƒæ•¸æé«˜é…å°æº–ç¢ºåº¦")
    print("  3. å•Ÿç”¨è‡ªå‹•è¨“ç·´å¾ªç’°")
    print("  4. éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ")
    print("="*70 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
