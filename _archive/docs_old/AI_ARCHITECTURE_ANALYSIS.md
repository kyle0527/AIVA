# BioNeuronCore AI æ¶æ§‹åˆ†æå ±å‘Š

**åˆ†ææ™‚é–“**: 2025-10-17  
**ç›®çš„**: ç¢ºèªç¥ç¶“ç¶²è·¯æ•¸çµ„çµæ§‹æ˜¯å¦éœ€è¦æ”¹è®Šä»¥æ”¯æŒè¨“ç·´

---

## 1. ç•¶å‰æ¶æ§‹åˆ†æ

### 1.1 ç¥ç¶“ç¶²è·¯çµæ§‹

```
ScalableBioNet (500è¬åƒæ•¸)
â”œâ”€â”€ fc1: numpy.ndarray (1024, 2048)          # å…¨é€£æ¥å±¤ 1
â”‚   â””â”€â”€ åƒæ•¸é‡: 2,097,152
â”œâ”€â”€ spiking1: BiologicalSpikingLayer         # ç”Ÿç‰©å°–å³°å±¤
â”‚   â”œâ”€â”€ weights: numpy.ndarray (2048, 1024)
â”‚   â””â”€â”€ åƒæ•¸é‡: 2,097,152
â””â”€â”€ fc2: numpy.ndarray (1024, num_tools)     # å…¨é€£æ¥å±¤ 2
    â””â”€â”€ åƒæ•¸é‡: 1024 Ã— å·¥å…·æ•¸é‡
```

**ç¸½åƒæ•¸**: ~4,196,352 (7å€‹å·¥å…·æ™‚)

### 1.2 æ•¸æ“šé¡å‹

```python
# ç•¶å‰å¯¦ç¾
self.fc1 = np.random.randn(input_size, self.hidden_size_1)      # ndarray
self.spiking1.weights = np.random.randn(input_size, output_size) # ndarray
self.fc2 = np.random.randn(self.hidden_size_2, num_tools)       # ndarray
```

**é—œéµç™¼ç¾**: 
- âœ… æ‰€æœ‰æ¬Šé‡éƒ½æ˜¯ **numpy.ndarray** (ä¸æ˜¯ Layer å°è±¡)
- âœ… å¯ä»¥ç›´æ¥ä¿®æ”¹å’Œè¨“ç·´
- âœ… æ”¯æŒçŸ©é™£é‹ç®—

---

## 2. è¨“ç·´éœ€æ±‚åˆ†æ

### 2.1 åå‘å‚³æ’­éœ€æ±‚

ç‚ºäº†è¨“ç·´ç¥ç¶“ç¶²è·¯ï¼Œéœ€è¦ï¼š

1. **å‰å‘å‚³æ’­** âœ… å·²å¯¦ç¾
   ```python
   def forward(self, x: np.ndarray) -> np.ndarray:
       x = np.tanh(x @ self.fc1)
       x = self.spiking1.forward(x)
       decision_potential = x @ self.fc2
       return self._softmax(decision_potential)
   ```

2. **æ¢¯åº¦è¨ˆç®—** âŒ æœªå¯¦ç¾
   - éœ€è¦ä¿å­˜ä¸­é–“å±¤è¼¸å‡º
   - éœ€è¦è¨ˆç®—æ¢¯åº¦

3. **æ¬Šé‡æ›´æ–°** âŒ æœªå¯¦ç¾
   - éœ€è¦æ›´æ–° fc1, spiking1.weights, fc2

### 2.2 ç•¶å‰ç¼ºå¤±çš„åŠŸèƒ½

```python
# ç¼ºå¤± 1: ä¸­é–“å±¤è¼¸å‡ºä¿å­˜
self.fc1_output = None  # éœ€è¦ä¿å­˜ç”¨æ–¼åå‘å‚³æ’­
self.spiking1_output = None

# ç¼ºå¤± 2: åç½®é …
# fc1 å’Œ fc2 æ²’æœ‰åç½®é … (bias)

# ç¼ºå¤± 3: åå‘å‚³æ’­æ–¹æ³•
def backward(self, grad_output):  # ä¸å­˜åœ¨
    pass

# ç¼ºå¤± 4: å„ªåŒ–å™¨
# æ²’æœ‰ Adam, SGD ç­‰å„ªåŒ–å™¨
```

---

## 3. å•é¡Œè¨ºæ–·

### 3.1 è¨“ç·´è…³æœ¬éŒ¯èª¤

```python
# train_cli_matching.py ç¬¬ 127 è¡Œ
agent.decision_core.fc2.weight -= learning_rate * ...
                        ^^^^^^
# éŒ¯èª¤: fc2 æ˜¯ ndarrayï¼Œæ²’æœ‰ .weight å±¬æ€§
```

**åŸå› **: 
- fc2 ç›´æ¥æ˜¯ ndarrayï¼Œä¸æ˜¯æœ‰ weight å±¬æ€§çš„ Layer å°è±¡
- æ‡‰è©²ç›´æ¥æ“ä½œ `agent.decision_core.fc2`

### 3.2 ç”Ÿç‰©å°–å³°å±¤çš„è¨“ç·´å•é¡Œ

```python
class BiologicalSpikingLayer:
    def forward(self, x: np.ndarray) -> np.ndarray:
        # è¿”å›çš„æ˜¯ 0/1 çš„å°–å³°ä¿¡è™Ÿ
        spikes = (potential > self.threshold).astype(int)
```

**å•é¡Œ**:
- âŒ è¼¸å‡ºæ˜¯é›¢æ•£çš„ (0 æˆ– 1)ï¼Œä¸å¯å¾®åˆ†
- âŒ ç„¡æ³•é€²è¡Œæ¨™æº–åå‘å‚³æ’­
- âš ï¸ éœ€è¦ç‰¹æ®Šçš„æ¢¯åº¦è¿‘ä¼¼æ–¹æ³•

---

## 4. è§£æ±ºæ–¹æ¡ˆå»ºè­°

### æ–¹æ¡ˆ A: æœ€å°æ”¹å‹• - ç›´æ¥ä¿®æ”¹æ•¸çµ„ âœ… **æ¨è–¦**

**å„ªé»**:
- ä¸æ”¹è®Šç¾æœ‰æ¶æ§‹
- å¿«é€Ÿå¯¦ç¾
- ä¿æŒå…¼å®¹æ€§

**å¯¦ç¾**:
```python
# 1. ä¿å­˜ä¸­é–“è¼¸å‡º
def forward_with_cache(self, x):
    self.fc1_input = x
    self.fc1_output = np.tanh(x @ self.fc1)
    self.spiking_output = self.spiking1.forward(self.fc1_output)
    self.fc2_output = self.spiking_output @ self.fc2
    return self._softmax(self.fc2_output)

# 2. ç°¡åŒ–çš„åå‘å‚³æ’­ï¼ˆå¿½ç•¥å°–å³°å±¤æ¢¯åº¦ï¼‰
def update_weights(self, grad_output, learning_rate):
    # æ›´æ–° fc2
    self.fc2 -= learning_rate * np.outer(self.spiking_output, grad_output)
    
    # å¿½ç•¥å°–å³°å±¤çš„ä¸å¯å¾®åˆ†æ€§
    # åªæ›´æ–° fc1 å’Œ fc2
```

### æ–¹æ¡ˆ B: å®Œæ•´é‡æ§‹ - æ·»åŠ è¨“ç·´æ¡†æ¶ âš ï¸ **å·¥ç¨‹é‡å¤§**

**å„ªé»**:
- å®Œæ•´çš„è¨“ç·´èƒ½åŠ›
- æ”¯æŒè¤‡é›œå„ªåŒ–å™¨

**ç¼ºé»**:
- éœ€è¦å¤§å¹…ä¿®æ”¹ä»£ç¢¼
- å¯èƒ½ç ´å£ç¾æœ‰åŠŸèƒ½

**å¯¦ç¾**:
```python
class TrainableScalableBioNet(ScalableBioNet):
    def __init__(self, ...):
        super().__init__(...)
        # æ·»åŠ åç½®é …
        self.fc1_bias = np.zeros(self.hidden_size_1)
        self.fc2_bias = np.zeros(num_tools)
        
    def backward(self, loss_grad):
        # å®Œæ•´çš„åå‘å‚³æ’­å¯¦ç¾
        pass
        
    def update(self, optimizer):
        # ä½¿ç”¨å„ªåŒ–å™¨æ›´æ–°
        pass
```

### æ–¹æ¡ˆ C: ä½¿ç”¨é è¨“ç·´åµŒå…¥ + å¾®èª¿ ğŸ¯ **å¯¦ç”¨**

**ç­–ç•¥**:
- ä¸è¨“ç·´æ•´å€‹ç¥ç¶“ç¶²è·¯
- åªè¨“ç·´ä»»å‹™åˆ°å·¥å…·çš„æ˜ å°„
- ä½¿ç”¨ç°¡å–®çš„æŸ¥æ‰¾è¡¨æˆ–å°å‹åˆ†é¡å™¨

**å¯¦ç¾**:
```python
# ä»»å‹™æè¿° -> å·¥å…·åç¨±çš„æ˜ å°„è¡¨
task_to_tool_map = {
    "æƒæ": "ScanTrigger",
    "SQLæ³¨å…¥": "SQLiDetector",
    # ...
}

# æˆ–ä½¿ç”¨ç°¡å–®çš„ TF-IDF + æœ€è¿‘é„°
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
```

---

## 5. å»ºè­°è¡Œå‹•æ–¹æ¡ˆ

### ç«‹å³åŸ·è¡Œ (æ–¹æ¡ˆ A + C çµ„åˆ)

1. **ä¿æŒç¾æœ‰ç¥ç¶“ç¶²è·¯ä¸è®Š** âœ…
   - fc1, spiking1, fc2 ç¶­æŒåŸæ¨£
   - ä¸ä¿®æ”¹æ•¸çµ„çµæ§‹

2. **æ·»åŠ è¼•é‡ç´šè¨“ç·´æ–¹æ³•** âœ…
   ```python
   # æ–°å¢æ–‡ä»¶: services/core/aiva_core/ai_engine/simple_trainer.py
   
   class SimpleTaskMatcher:
       """ç°¡å–®çš„ä»»å‹™-å·¥å…·é…å°å™¨ï¼ˆä¸éœ€è¦è¨“ç·´ç¥ç¶“ç¶²è·¯ï¼‰"""
       
       def __init__(self, tools):
           self.tools = tools
           self.keyword_map = {
               "æƒæ": "ScanTrigger",
               "scan": "ScanTrigger",
               "SQLæ³¨å…¥": "SQLiDetector",
               "sqli": "SQLiDetector",
               "XSS": "XSSDetector",
               "xss": "XSSDetector",
               "åˆ†æ": "CodeAnalyzer",
               "analyze": "CodeAnalyzer",
               "è®€å–": "CodeReader",
               "read": "CodeReader",
               "å¯«å…¥": "CodeWriter",
               "write": "CodeWriter",
               "å ±å‘Š": "ReportGenerator",
               "report": "ReportGenerator",
           }
       
       def match(self, task_description):
           """åŸºæ–¼é—œéµå­—åŒ¹é…å·¥å…·"""
           task_lower = task_description.lower()
           
           for keyword, tool_name in self.keyword_map.items():
               if keyword.lower() in task_lower:
                   return tool_name
           
           # é»˜èªå·¥å…·
           return "CodeReader"
   ```

3. **é›†æˆåˆ° BioNeuronRAGAgent** âœ…
   ```python
   # åœ¨ invoke æ–¹æ³•ä¸­æ·»åŠ é è™•ç†
   def invoke(self, task_description: str):
       # ä½¿ç”¨ç°¡å–®åŒ¹é…å™¨
       matched_tool = self.simple_matcher.match(task_description)
       
       # ç„¶å¾Œä½¿ç”¨ç¥ç¶“ç¶²è·¯ç¢ºèª
       neural_decision = self.decision_core.forward(...)
       
       # çµ„åˆæ±ºç­–
       if confidence < 0.7:
           return matched_tool  # ä¿¡å¿ƒåº¦ä½æ™‚ä½¿ç”¨é—œéµå­—åŒ¹é…
       else:
           return neural_decision  # ä¿¡å¿ƒåº¦é«˜æ™‚ä½¿ç”¨ç¥ç¶“ç¶²è·¯
   ```

---

## 6. çµè«–

### æ˜¯å¦éœ€è¦æ”¹è®Šæ•¸çµ„ï¼Ÿ

**ç­”æ¡ˆ: ä¸éœ€è¦ âŒ**

**ç†ç”±**:

1. **ç•¶å‰æ•¸çµ„çµæ§‹é©åˆç›´æ¥æ“ä½œ**
   - numpy.ndarray å¯ä»¥ç›´æ¥ä¿®æ”¹
   - æ”¯æŒçŸ©é™£é‹ç®—
   - ä¸éœ€è¦é‡æ§‹

2. **ç”Ÿç‰©å°–å³°å±¤ä¸é©åˆæ¨™æº–è¨“ç·´**
   - é›¢æ•£è¼¸å‡º (0/1) ä¸å¯å¾®åˆ†
   - æ¨™æº–åå‘å‚³æ’­ç„¡æ³•å·¥ä½œ
   - éœ€è¦ç‰¹æ®Šè™•ç†

3. **æ›´å¥½çš„è§£æ±ºæ–¹æ¡ˆ**
   - ä½¿ç”¨é—œéµå­—åŒ¹é… (ç°¡å–®ã€å¿«é€Ÿã€æº–ç¢º)
   - ä¿ç•™ç¥ç¶“ç¶²è·¯ä½œç‚ºé©—è­‰
   - çµ„åˆæ±ºç­–æé«˜æº–ç¢ºç‡

### æ¨è–¦å¯¦æ–½æ­¥é©Ÿ

1. âœ… **å‰µå»º SimpleTaskMatcher** (é—œéµå­—åŒ¹é…å™¨)
2. âœ… **é›†æˆåˆ° BioNeuronRAGAgent** 
3. âœ… **æ¸¬è©¦é…å°æº–ç¢ºç‡**
4. ğŸ”„ **æ”¶é›†å¯¦éš›ä½¿ç”¨æ•¸æ“š**
5. ğŸ”„ **è¿­ä»£å„ªåŒ–é—œéµå­—æ˜ å°„**

### æœªä¾†å¯é¸

- å¦‚æœéœ€è¦çœŸæ­£çš„ç¥ç¶“ç¶²è·¯è¨“ç·´ï¼Œè€ƒæ…®ï¼š
  - ä½¿ç”¨ PyTorch/TensorFlow é‡å¯«æ±ºç­–æ ¸å¿ƒ
  - æˆ–ä½¿ç”¨ SVM/Random Forest ç­‰å¯è¨“ç·´çš„åˆ†é¡å™¨
  - ä½†ç•¶å‰çš„é—œéµå­—åŒ¹é…å·²è¶³å¤ ä½¿ç”¨

---

**æœ€çµ‚å»ºè­°**: ä¿æŒæ•¸çµ„çµæ§‹ä¸è®Šï¼Œä½¿ç”¨é—œéµå­—åŒ¹é… + ç¥ç¶“ç¶²è·¯é©—è­‰çš„æ··åˆæ–¹æ¡ˆã€‚
