#!/usr/bin/env python3
"""
AIVA CLI - ä¸»å‘½ä»¤è¡Œä»‹é¢

æä¾›å®Œæ•´çš„ AIVA å¹³å°å‘½ä»¤è¡Œæ“ä½œä»‹é¢ï¼ŒåŒ…æ‹¬ï¼š
- æƒæç®¡ç† (scan)
- æ¼æ´æª¢æ¸¬ (detect)
- å ±å‘Šç”Ÿæˆ (report)
- AI è¨“ç·´ (ai)
- ç³»çµ±ç®¡ç† (system)
"""

import argparse
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from services.aiva_common.utils import get_logger, new_id
from services.aiva_common.enums import ModuleName, Topic
from services.aiva_common.schemas import (
    AivaMessage,
    MessageHeader,
    ScanStartPayload,
)
from services.aiva_common.mq import get_broker

logger = get_logger(__name__)


# ============================================================================
# æƒæå‘½ä»¤
# ============================================================================

async def cmd_scan_start(args):
    """å•Ÿå‹•ç¶²ç«™æƒæ"""
    scan_id = new_id("scan")
    task_id = new_id("task")
    
    logger.info(f"ğŸš€ å•Ÿå‹•æƒæä»»å‹™")
    logger.info(f"   æƒæ ID: {scan_id}")
    logger.info(f"   ä»»å‹™ ID: {task_id}")
    logger.info(f"   ç›®æ¨™ URL: {args.url}")
    logger.info(f"   æœ€å¤§æ·±åº¦: {args.max_depth}")
    
    # æ§‹å»ºæƒæè«‹æ±‚
    header = MessageHeader(
        message_id=new_id("msg"),
        source_module=ModuleName.CLI,
        target_module=ModuleName.SCAN,
        correlation_id=scan_id,
    )
    
    payload = ScanStartPayload(
        scan_id=scan_id,
        task_id=task_id,
        target_url=args.url,
        max_depth=args.max_depth,
        max_pages=args.max_pages,
        scope_domains=[args.url],
    )
    
    message = AivaMessage(
        header=header,
        payload=payload.model_dump(),
    )
    
    # ç™¼é€åˆ° RabbitMQ
    broker = await get_broker()
    await broker.publish(
        topic=Topic.TASK_SCAN_START,
        message=message.model_dump_json(),
    )
    
    logger.info("âœ… æƒæä»»å‹™å·²æäº¤åˆ°æ¶ˆæ¯éšŠåˆ—")
    logger.info(f"   è¨‚é–±ä¸»é¡Œ: {Topic.TASK_SCAN_START}")
    
    # å¦‚æœé–‹å•Ÿç­‰å¾…æ¨¡å¼ï¼Œç›£è½çµæœ
    if args.wait:
        logger.info("â³ ç­‰å¾…æƒæçµæœ...")
        await wait_for_scan_result(scan_id)


async def wait_for_scan_result(scan_id: str):
    """ç­‰å¾…æƒæçµæœ"""
    broker = await get_broker()
    
    async for mqmsg in broker.subscribe(Topic.RESULTS_SCAN_COMPLETED):
        msg = AivaMessage.model_validate_json(mqmsg.body)
        
        if msg.header.correlation_id == scan_id:
            logger.info("âœ… æƒæå®Œæˆï¼")
            logger.info(f"   è³‡ç”¢æ•¸é‡: {len(msg.payload.get('assets', []))}")
            logger.info(f"   æŒ‡ç´‹æ•¸é‡: {len(msg.payload.get('fingerprints', {}))}")
            
            # é¡¯ç¤ºè©³ç´°è³‡è¨Š
            if msg.payload.get('assets'):
                logger.info("\nğŸ“¦ ç™¼ç¾çš„è³‡ç”¢:")
                for asset in msg.payload['assets'][:5]:  # é¡¯ç¤ºå‰5å€‹
                    logger.info(f"   - {asset.get('url', 'N/A')}")
            
            break


# ============================================================================
# æª¢æ¸¬å‘½ä»¤
# ============================================================================

async def cmd_detect_sqli(args):
    """å•Ÿå‹• SQL æ³¨å…¥æª¢æ¸¬"""
    task_id = new_id("task")
    
    logger.info(f"ğŸ” å•Ÿå‹• SQL æ³¨å…¥æª¢æ¸¬")
    logger.info(f"   ä»»å‹™ ID: {task_id}")
    logger.info(f"   ç›®æ¨™ URL: {args.url}")
    logger.info(f"   åƒæ•¸: {args.param}")
    
    # æ§‹å»ºæª¢æ¸¬è«‹æ±‚
    header = MessageHeader(
        message_id=new_id("msg"),
        source_module=ModuleName.CLI,
        target_module=ModuleName.FUNCTION_SQLI,
        correlation_id=task_id,
    )
    
    payload_data = {
        "task_id": task_id,
        "target_url": args.url,
        "param_name": args.param,
        "method": args.method or "GET",
        "engines": args.engines.split(",") if args.engines else None,
    }
    
    message = AivaMessage(
        header=header,
        payload=payload_data,
    )
    
    broker = await get_broker()
    await broker.publish(
        topic=Topic.TASK_FUNCTION_SQLI,
        message=message.model_dump_json(),
    )
    
    logger.info("âœ… SQL æ³¨å…¥æª¢æ¸¬ä»»å‹™å·²æäº¤")
    
    if args.wait:
        await wait_for_detection_result(task_id, "sqli")


async def cmd_detect_xss(args):
    """å•Ÿå‹• XSS æª¢æ¸¬"""
    task_id = new_id("task")
    
    logger.info(f"ğŸ” å•Ÿå‹• XSS æª¢æ¸¬")
    logger.info(f"   ä»»å‹™ ID: {task_id}")
    logger.info(f"   ç›®æ¨™ URL: {args.url}")
    
    header = MessageHeader(
        message_id=new_id("msg"),
        source_module=ModuleName.CLI,
        target_module=ModuleName.FUNCTION_XSS,
        correlation_id=task_id,
    )
    
    payload_data = {
        "task_id": task_id,
        "target_url": args.url,
        "param_name": args.param,
        "xss_type": args.type or "reflected",
    }
    
    message = AivaMessage(header=header, payload=payload_data)
    
    broker = await get_broker()
    await broker.publish(
        topic=Topic.TASK_FUNCTION_XSS,
        message=message.model_dump_json(),
    )
    
    logger.info("âœ… XSS æª¢æ¸¬ä»»å‹™å·²æäº¤")
    
    if args.wait:
        await wait_for_detection_result(task_id, "xss")


async def wait_for_detection_result(task_id: str, vuln_type: str):
    """ç­‰å¾…æª¢æ¸¬çµæœ"""
    broker = await get_broker()
    
    # æ ¹æ“šæ¼æ´é¡å‹è¨‚é–±ä¸åŒçš„çµæœä¸»é¡Œ
    topic_map = {
        "sqli": Topic.RESULTS_FUNCTION_SQLI,
        "xss": Topic.RESULTS_FUNCTION_XSS,
        "ssrf": Topic.RESULTS_FUNCTION_SSRF,
        "idor": Topic.RESULTS_FUNCTION_IDOR,
    }
    
    result_topic = topic_map.get(vuln_type, Topic.RESULTS_FUNCTION_SQLI)
    
    logger.info(f"â³ ç­‰å¾… {vuln_type.upper()} æª¢æ¸¬çµæœ...")
    
    async for mqmsg in broker.subscribe(result_topic):
        msg = AivaMessage.model_validate_json(mqmsg.body)
        
        if msg.header.correlation_id == task_id:
            findings = msg.payload.get('findings', [])
            
            if findings:
                logger.info(f"ğŸš¨ ç™¼ç¾ {len(findings)} å€‹æ¼æ´ï¼")
                for i, finding in enumerate(findings, 1):
                    logger.info(f"\næ¼æ´ #{i}:")
                    logger.info(f"   åš´é‡ç¨‹åº¦: {finding.get('vulnerability', {}).get('severity', 'N/A')}")
                    logger.info(f"   ç½®ä¿¡åº¦: {finding.get('vulnerability', {}).get('confidence', 'N/A')}")
                    logger.info(f"   æè¿°: {finding.get('vulnerability', {}).get('description', 'N/A')}")
            else:
                logger.info("âœ… æœªç™¼ç¾æ¼æ´")
            
            break


# ============================================================================
# AI è¨“ç·´å‘½ä»¤
# ============================================================================

async def cmd_ai_train(args):
    """å•Ÿå‹• AI è¨“ç·´"""
    from services.core.aiva_core.ai_engine.bio_neuron_core import ScalableBioNet
    from services.core.aiva_core.learning.experience_manager import ExperienceManager
    from services.core.aiva_core.training.training_orchestrator import TrainingOrchestrator
    
    logger.info("ğŸ¤– å•Ÿå‹• AI è¨“ç·´ç³»çµ±")
    logger.info(f"   è¨“ç·´æ¨¡å¼: {args.mode}")
    logger.info(f"   è¨“ç·´è¼ªæ•¸: {args.epochs}")
    
    # åˆå§‹åŒ–çµ„ä»¶
    bio_net = ScalableBioNet(
        input_dim=512,
        hidden_dims=[1024, 2048, 1024],
        output_dim=256,
    )
    
    logger.info(f"   ç¥ç¶“ç¶²è·¯åƒæ•¸é‡: {bio_net.count_params():,}")
    
    exp_manager = ExperienceManager(storage_path=args.storage_path)
    
    orchestrator = TrainingOrchestrator(
        bio_net=bio_net,
        experience_manager=exp_manager,
    )
    
    # åŸ·è¡Œè¨“ç·´
    if args.mode == "realtime":
        logger.info("ğŸ“¡ å¯¦æ™‚è¨“ç·´æ¨¡å¼ï¼šç›£è½å¯¦éš›ä»»å‹™åŸ·è¡Œ...")
        await orchestrator.train_from_live_tasks(epochs=args.epochs)
    
    elif args.mode == "replay":
        logger.info("ğŸ“¼ å›æ”¾è¨“ç·´æ¨¡å¼ï¼šå¾æ­·å²ç¶“é©—å­¸ç¿’...")
        await orchestrator.train_from_history(epochs=args.epochs)
    
    elif args.mode == "simulation":
        logger.info("ğŸ® æ¨¡æ“¬è¨“ç·´æ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ“¬å ´æ™¯...")
        await orchestrator.train_from_simulation(
            num_scenarios=args.scenarios,
            epochs=args.epochs,
        )
    
    logger.info("âœ… AI è¨“ç·´å®Œæˆ")


async def cmd_ai_status(args):
    """æŸ¥çœ‹ AI ç‹€æ…‹"""
    from services.core.aiva_core.ai_engine.bio_neuron_core import ScalableBioNet
    from services.core.aiva_core.ai_engine.knowledge_base import KnowledgeBase
    
    logger.info("ğŸ¤– AI ç³»çµ±ç‹€æ…‹")
    
    # è¼‰å…¥æ¨¡å‹
    bio_net = ScalableBioNet(
        input_dim=512,
        hidden_dims=[1024, 2048, 1024],
        output_dim=256,
    )
    
    logger.info(f"   æ¨¡å‹åƒæ•¸é‡: {bio_net.count_params():,}")
    
    # çŸ¥è­˜åº«ç‹€æ…‹
    kb = KnowledgeBase(storage_path=args.storage_path)
    stats = await kb.get_stats()
    
    logger.info(f"   çŸ¥è­˜åº«æ¢ç›®: {stats.get('total_entries', 0)}")
    logger.info(f"   å‘é‡ç¶­åº¦: {stats.get('vector_dim', 0)}")
    logger.info(f"   æœ€å¾Œæ›´æ–°: {stats.get('last_update', 'N/A')}")


# ============================================================================
# å ±å‘Šå‘½ä»¤
# ============================================================================

async def cmd_report_generate(args):
    """ç”Ÿæˆå ±å‘Š"""
    logger.info(f"ğŸ“Š ç”Ÿæˆå ±å‘Š")
    logger.info(f"   æƒæ ID: {args.scan_id}")
    logger.info(f"   æ ¼å¼: {args.format}")
    logger.info(f"   è¼¸å‡º: {args.output}")
    
    # èª¿ç”¨ Integration æ¨¡çµ„çš„å ±å‘Šç”Ÿæˆå™¨
    from services.integration.aiva_integration.reporting.report_content_generator import (
        ReportContentGenerator,
    )
    from services.integration.aiva_integration.reporting.formatter_exporter import (
        FormatterExporter,
    )
    
    generator = ReportContentGenerator()
    exporter = FormatterExporter()
    
    # ç”Ÿæˆå ±å‘Šå…§å®¹
    content = await generator.generate_report(
        scan_id=args.scan_id,
        include_findings=not args.no_findings,
        include_stats=True,
    )
    
    # å°å‡ºå ±å‘Š
    await exporter.export(
        content=content,
        format=args.format,
        output_path=args.output,
    )
    
    logger.info(f"âœ… å ±å‘Šå·²ç”Ÿæˆ: {args.output}")


# ============================================================================
# ç³»çµ±å‘½ä»¤
# ============================================================================

async def cmd_system_status(args):
    """æŸ¥çœ‹ç³»çµ±ç‹€æ…‹"""
    logger.info("âš™ï¸ AIVA ç³»çµ±ç‹€æ…‹")
    
    broker = await get_broker()
    
    # æª¢æŸ¥å„æ¨¡çµ„ç‹€æ…‹
    modules = [
        ModuleName.CORE,
        ModuleName.SCAN,
        ModuleName.FUNCTION_SQLI,
        ModuleName.FUNCTION_XSS,
        ModuleName.INTEGRATION,
    ]
    
    logger.info("\nğŸ“¡ æ¨¡çµ„ç‹€æ…‹:")
    for module in modules:
        # ç™¼é€å¿ƒè·³æª¢æŸ¥
        status = "ğŸŸ¢ é‹è¡Œä¸­" if await check_module_alive(module) else "ğŸ”´ é›¢ç·š"
        logger.info(f"   {module.value}: {status}")


async def check_module_alive(module: ModuleName) -> bool:
    """æª¢æŸ¥æ¨¡çµ„æ˜¯å¦å­˜æ´»"""
    # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰è©²æª¢æŸ¥å¿ƒè·³
    return True


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def create_parser():
    """å‰µå»ºå‘½ä»¤è¡Œè§£æå™¨"""
    parser = argparse.ArgumentParser(
        prog="aiva",
        description="AIVA - AI-powered Vulnerability Analysis Platform",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æƒæç¶²ç«™
  aiva scan start https://example.com --max-depth 3
  
  # SQL æ³¨å…¥æª¢æ¸¬
  aiva detect sqli https://example.com/login --param username
  
  # XSS æª¢æ¸¬
  aiva detect xss https://example.com/search --param q
  
  # ç”Ÿæˆå ±å‘Š
  aiva report generate scan_xxx --format pdf --output report.pdf
  
  # AI è¨“ç·´
  aiva ai train --mode realtime --epochs 10
  
  # æŸ¥çœ‹ç³»çµ±ç‹€æ…‹
  aiva system status
        """,
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # ========== æƒæå‘½ä»¤ ==========
    scan_parser = subparsers.add_parser("scan", help="æƒæç®¡ç†")
    scan_sub = scan_parser.add_subparsers(dest="scan_action")
    
    # scan start
    scan_start = scan_sub.add_parser("start", help="å•Ÿå‹•æƒæ")
    scan_start.add_argument("url", help="ç›®æ¨™ URL")
    scan_start.add_argument("--max-depth", type=int, default=3, help="æœ€å¤§çˆ¬å–æ·±åº¦")
    scan_start.add_argument("--max-pages", type=int, default=100, help="æœ€å¤§é é¢æ•¸")
    scan_start.add_argument("--wait", action="store_true", help="ç­‰å¾…æƒæå®Œæˆ")
    scan_start.set_defaults(func=cmd_scan_start)
    
    # ========== æª¢æ¸¬å‘½ä»¤ ==========
    detect_parser = subparsers.add_parser("detect", help="æ¼æ´æª¢æ¸¬")
    detect_sub = detect_parser.add_subparsers(dest="detect_type")
    
    # detect sqli
    sqli_parser = detect_sub.add_parser("sqli", help="SQL æ³¨å…¥æª¢æ¸¬")
    sqli_parser.add_argument("url", help="ç›®æ¨™ URL")
    sqli_parser.add_argument("--param", required=True, help="æ¸¬è©¦åƒæ•¸å")
    sqli_parser.add_argument("--method", choices=["GET", "POST"], help="HTTP æ–¹æ³•")
    sqli_parser.add_argument("--engines", help="æª¢æ¸¬å¼•æ“ (é€—è™Ÿåˆ†éš”)")
    sqli_parser.add_argument("--wait", action="store_true", help="ç­‰å¾…æª¢æ¸¬å®Œæˆ")
    sqli_parser.set_defaults(func=cmd_detect_sqli)
    
    # detect xss
    xss_parser = detect_sub.add_parser("xss", help="XSS æª¢æ¸¬")
    xss_parser.add_argument("url", help="ç›®æ¨™ URL")
    xss_parser.add_argument("--param", required=True, help="æ¸¬è©¦åƒæ•¸å")
    xss_parser.add_argument("--type", choices=["reflected", "stored", "dom"], help="XSS é¡å‹")
    xss_parser.add_argument("--wait", action="store_true", help="ç­‰å¾…æª¢æ¸¬å®Œæˆ")
    xss_parser.set_defaults(func=cmd_detect_xss)
    
    # ========== AI å‘½ä»¤ ==========
    ai_parser = subparsers.add_parser("ai", help="AI è¨“ç·´å’Œç®¡ç†")
    ai_sub = ai_parser.add_subparsers(dest="ai_action")
    
    # ai train
    ai_train = ai_sub.add_parser("train", help="è¨“ç·´ AI æ¨¡å‹")
    ai_train.add_argument(
        "--mode",
        choices=["realtime", "replay", "simulation"],
        default="realtime",
        help="è¨“ç·´æ¨¡å¼",
    )
    ai_train.add_argument("--epochs", type=int, default=10, help="è¨“ç·´è¼ªæ•¸")
    ai_train.add_argument("--scenarios", type=int, default=100, help="æ¨¡æ“¬å ´æ™¯æ•¸é‡")
    ai_train.add_argument("--storage-path", default="./data/ai", help="å­˜å„²è·¯å¾‘")
    ai_train.set_defaults(func=cmd_ai_train)
    
    # ai status
    ai_status = ai_sub.add_parser("status", help="æŸ¥çœ‹ AI ç‹€æ…‹")
    ai_status.add_argument("--storage-path", default="./data/ai", help="å­˜å„²è·¯å¾‘")
    ai_status.set_defaults(func=cmd_ai_status)
    
    # ========== å ±å‘Šå‘½ä»¤ ==========
    report_parser = subparsers.add_parser("report", help="å ±å‘Šç”Ÿæˆ")
    report_sub = report_parser.add_subparsers(dest="report_action")
    
    # report generate
    report_gen = report_sub.add_parser("generate", help="ç”Ÿæˆå ±å‘Š")
    report_gen.add_argument("scan_id", help="æƒæ ID")
    report_gen.add_argument("--format", choices=["pdf", "html", "json"], default="html", help="å ±å‘Šæ ¼å¼")
    report_gen.add_argument("--output", default="report.html", help="è¼¸å‡ºæª”æ¡ˆ")
    report_gen.add_argument("--no-findings", action="store_true", help="ä¸åŒ…å«æ¼æ´è©³æƒ…")
    report_gen.set_defaults(func=cmd_report_generate)
    
    # ========== ç³»çµ±å‘½ä»¤ ==========
    system_parser = subparsers.add_parser("system", help="ç³»çµ±ç®¡ç†")
    system_sub = system_parser.add_subparsers(dest="system_action")
    
    # system status
    system_status = system_sub.add_parser("status", help="æŸ¥çœ‹ç³»çµ±ç‹€æ…‹")
    system_status.set_defaults(func=cmd_system_status)
    
    return parser


async def async_main():
    """ç•°æ­¥ä¸»å‡½æ•¸"""
    parser = create_parser()
    args = parser.parse_args()
    
    if not hasattr(args, "func"):
        parser.print_help()
        return
    
    try:
        await args.func(args)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ¶ä¸­æ–·æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ éŒ¯èª¤: {e}", exc_info=True)
        sys.exit(1)


def main():
    """ä¸»å…¥å£é»"""
    asyncio.run(async_main())


if __name__ == "__main__":
    main()
