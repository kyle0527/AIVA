"""
AI è¨“ç·´æ•´åˆç³»çµ± - åŸºæ–¼çœŸå¯¦ CLI æŒ‡ä»¤æµç¨‹

æ­¤æ¨¡çµ„æ•´åˆäº†ï¼š
1. çœŸå¯¦çš„ CLI å‘½ä»¤æµç¨‹ (aiva scan, aiva detect)
2. 500è¬åƒæ•¸çš„ ScalableBioNet (BioNeuronCore)
3. å®Œæ•´çš„è¨Šæ¯æµè¿½è¹¤å’Œå­¸ç¿’
4. ç¶“é©—å›æ”¾å’Œæ¨¡å‹æ›´æ–°

è¨“ç·´æµç¨‹ï¼š
CLI â†’ Core.TaskDispatcher â†’ Worker â†’ Core.ResultCollector â†’ Integration â†’ AI Learning
"""

import asyncio
import json
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

from services.aiva_common.enums import ModuleName, Severity, Topic
from services.aiva_common.mq import get_broker
from services.aiva_common.schemas import (
    AivaMessage,
    MessageHeader,
    ScanStartPayload,
)
from services.aiva_common.utils import get_logger, new_id

# Core AI çµ„ä»¶
from services.core.aiva_core.ai_engine.bio_neuron_core import ScalableBioNet
from services.core.aiva_core.ai_engine.knowledge_base import KnowledgeBase
from services.core.aiva_core.learning.experience_manager import ExperienceManager
from services.core.aiva_core.storage.storage_manager import StorageManager

logger = get_logger(__name__)


# ============================================================================
# è¨“ç·´å ´æ™¯æ¨¡æ“¬å™¨
# ============================================================================


class TrainingScenarioSimulator:
    """è¨“ç·´å ´æ™¯æ¨¡æ“¬å™¨ - æ¨¡æ“¬å®Œæ•´çš„ CLI â†’ Core â†’ Worker â†’ Integration æµç¨‹"""

    def __init__(
        self,
        bio_net: ScalableBioNet,
        experience_manager: ExperienceManager,
        knowledge_base: KnowledgeBase,
    ):
        self.bio_net = bio_net
        self.exp_manager = experience_manager
        self.kb = knowledge_base
        self.broker = None

    async def initialize(self):
        """åˆå§‹åŒ–é€£æ¥"""
        self.broker = await get_broker()
        logger.info("âœ… è¨“ç·´å ´æ™¯æ¨¡æ“¬å™¨å·²åˆå§‹åŒ–")

    # ========== å ´æ™¯ 1: æƒææµç¨‹ ==========

    async def simulate_scan_flow(self, target_url: str) -> dict[str, Any]:
        """
        æ¨¡æ“¬å®Œæ•´çš„æƒææµç¨‹ä¸¦è¨˜éŒ„ç¶“é©—

        CLI å‘½ä»¤æ¨¡æ“¬:
            aiva scan start https://example.com --max-depth 3

        æµç¨‹:
            1. CLI ç™¼é€ TASK_SCAN_START
            2. Scan Worker æ¥æ”¶ä¸¦åŸ·è¡Œ
            3. Worker ç™¼é€ RESULTS_SCAN_COMPLETED
            4. Core.ResultCollector æ¥æ”¶çµæœ
            5. Integration å­˜å„²å’Œåˆ†æ
            6. AI å­¸ç¿’æ•´å€‹æµç¨‹
        """
        scenario_id = new_id("scenario")
        scan_id = new_id("scan")
        task_id = new_id("task")

        logger.info(f"ğŸ¬ å ´æ™¯ 1: æƒææµç¨‹æ¨¡æ“¬")
        logger.info(f"   å ´æ™¯ ID: {scenario_id}")
        logger.info(f"   ç›®æ¨™ URL: {target_url}")

        # æ­¥é©Ÿ 1: CLI ç™¼é€æƒæè«‹æ±‚
        logger.info("   æ­¥é©Ÿ 1/5: CLI ç™¼é€æƒæè«‹æ±‚...")
        scan_request = await self._cli_send_scan_request(scan_id, task_id, target_url)

        # AI æ±ºç­–: æ‡‰è©²å¦‚ä½•è™•ç†é€™å€‹æƒæè«‹æ±‚?
        decision_context = {
            "action": "scan_start",
            "target_url": target_url,
            "scan_id": scan_id,
        }
        ai_decision = await self._ai_make_decision(decision_context)

        # æ­¥é©Ÿ 2: Scan Worker æ¥æ”¶ä¸¦è™•ç†
        logger.info("   æ­¥é©Ÿ 2/5: Scan Worker è™•ç†è«‹æ±‚...")
        scan_result = await self._scan_worker_execute(scan_request)

        # æ­¥é©Ÿ 3: Worker ç™¼é€çµæœ
        logger.info("   æ­¥é©Ÿ 3/5: Worker ç™¼é€çµæœåˆ° ResultCollector...")
        await self._worker_send_result(scan_id, scan_result)

        # æ­¥é©Ÿ 4: ResultCollector æ¥æ”¶ä¸¦è½‰ç™¼
        logger.info("   æ­¥é©Ÿ 4/5: ResultCollector è½‰ç™¼åˆ° Integration...")
        await self._result_collector_forward(scan_result)

        # æ­¥é©Ÿ 5: Integration åˆ†æå’Œå­˜å„²
        logger.info("   æ­¥é©Ÿ 5/5: Integration åˆ†æçµæœ...")
        analysis = await self._integration_analyze(scan_result)

        # AI å­¸ç¿’: è¨˜éŒ„æ•´å€‹æµç¨‹çš„ç¶“é©—
        logger.info("   ğŸ§  AI å­¸ç¿’æµç¨‹...")
        experience = {
            "scenario_id": scenario_id,
            "flow_type": "scan",
            "initial_decision": ai_decision,
            "scan_request": scan_request,
            "scan_result": scan_result,
            "analysis": analysis,
            "timestamp": datetime.now(UTC).isoformat(),
        }

        await self.exp_manager.store_experience(
            experience_id=new_id("exp"),
            experience_data=experience,
            tags=["scan_flow", "complete"],
        )

        # æ›´æ–°çŸ¥è­˜åº«
        await self.kb.add_entry(
            entry_id=new_id("kb"),
            content=f"æƒææµç¨‹: {target_url} -> {len(scan_result.get('assets', []))} è³‡ç”¢",
            metadata={"type": "scan_flow", "assets_count": len(scan_result.get("assets", []))},
        )

        logger.info(f"âœ… å ´æ™¯ 1 å®Œæˆ: ç™¼ç¾ {len(scan_result.get('assets', []))} å€‹è³‡ç”¢")

        return {
            "scenario_id": scenario_id,
            "flow_type": "scan",
            "result": scan_result,
            "analysis": analysis,
        }

    # ========== å ´æ™¯ 2: SQL æ³¨å…¥æª¢æ¸¬æµç¨‹ ==========

    async def simulate_sqli_detection_flow(
        self, target_url: str, param_name: str
    ) -> dict[str, Any]:
        """
        æ¨¡æ“¬å®Œæ•´çš„ SQL æ³¨å…¥æª¢æ¸¬æµç¨‹

        CLI å‘½ä»¤æ¨¡æ“¬:
            aiva detect sqli https://example.com/login --param username

        æµç¨‹:
            1. CLI ç™¼é€ TASK_FUNCTION_SQLI
            2. SQLi Worker åŸ·è¡Œå¤šå¼•æ“æª¢æ¸¬
            3. Worker ç™¼é€ RESULTS_FUNCTION_SQLI (å« FindingPayload)
            4. Integration é€²è¡Œé¢¨éšªè©•ä¼°å’Œé—œè¯åˆ†æ
            5. AI å­¸ç¿’æª¢æ¸¬ç­–ç•¥å’Œçµæœ
        """
        scenario_id = new_id("scenario")
        task_id = new_id("task")

        logger.info(f"ğŸ¬ å ´æ™¯ 2: SQL æ³¨å…¥æª¢æ¸¬æµç¨‹")
        logger.info(f"   å ´æ™¯ ID: {scenario_id}")
        logger.info(f"   ç›®æ¨™: {target_url}")
        logger.info(f"   åƒæ•¸: {param_name}")

        # æ­¥é©Ÿ 1: CLI ç™¼é€æª¢æ¸¬è«‹æ±‚
        logger.info("   æ­¥é©Ÿ 1/5: CLI ç™¼é€ SQLi æª¢æ¸¬è«‹æ±‚...")
        detection_request = {
            "task_id": task_id,
            "target_url": target_url,
            "param_name": param_name,
            "engines": ["error", "boolean", "time", "union"],
        }

        # AI æ±ºç­–: é¸æ“‡æª¢æ¸¬ç­–ç•¥
        decision_context = {
            "action": "sqli_detect",
            "target_url": target_url,
            "param_name": param_name,
        }
        ai_strategy = await self._ai_select_detection_strategy(decision_context)

        # æ­¥é©Ÿ 2: SQLi Worker åŸ·è¡Œæª¢æ¸¬
        logger.info("   æ­¥é©Ÿ 2/5: SQLi Worker åŸ·è¡Œå¤šå¼•æ“æª¢æ¸¬...")
        detection_result = await self._sqli_worker_execute(detection_request)

        # æ­¥é©Ÿ 3: Worker ç™¼é€ Finding
        logger.info("   æ­¥é©Ÿ 3/5: Worker ç™¼é€æª¢æ¸¬çµæœ...")
        findings = detection_result.get("findings", [])

        # æ­¥é©Ÿ 4: Integration é¢¨éšªè©•ä¼°
        logger.info("   æ­¥é©Ÿ 4/5: Integration é€²è¡Œé¢¨éšªè©•ä¼°...")
        risk_assessment = await self._integration_assess_risk(findings)

        # æ­¥é©Ÿ 5: AI å­¸ç¿’æª¢æ¸¬ç¶“é©—
        logger.info("   æ­¥é©Ÿ 5/5: AI å­¸ç¿’æª¢æ¸¬ç­–ç•¥...")
        experience = {
            "scenario_id": scenario_id,
            "flow_type": "sqli_detection",
            "strategy_selected": ai_strategy,
            "detection_request": detection_request,
            "findings": findings,
            "risk_assessment": risk_assessment,
            "timestamp": datetime.now(UTC).isoformat(),
        }

        await self.exp_manager.store_experience(
            experience_id=new_id("exp"),
            experience_data=experience,
            tags=["sqli", "detection", "complete"],
        )

        # æ›´æ–°çŸ¥è­˜åº«
        await self.kb.add_entry(
            entry_id=new_id("kb"),
            content=f"SQLi æª¢æ¸¬: {param_name} @ {target_url} -> {len(findings)} ç™¼ç¾",
            metadata={
                "type": "sqli_detection",
                "findings_count": len(findings),
                "strategy": ai_strategy,
            },
        )

        logger.info(f"âœ… å ´æ™¯ 2 å®Œæˆ: ç™¼ç¾ {len(findings)} å€‹ SQLi æ¼æ´")

        return {
            "scenario_id": scenario_id,
            "flow_type": "sqli_detection",
            "findings": findings,
            "risk_assessment": risk_assessment,
        }

    # ========== å ´æ™¯ 3: å®Œæ•´æ”»æ“Šéˆ ==========

    async def simulate_full_attack_chain(self, target_url: str) -> dict[str, Any]:
        """
        æ¨¡æ“¬å®Œæ•´æ”»æ“Šéˆ: Scan â†’ Multiple Detections â†’ Attack Path Analysis

        CLI å‘½ä»¤åºåˆ—:
            1. aiva scan start https://example.com
            2. aiva detect sqli <discovered_urls>
            3. aiva detect xss <discovered_urls>
            4. aiva report generate --attack-path
        """
        scenario_id = new_id("scenario")

        logger.info(f"ğŸ¬ å ´æ™¯ 3: å®Œæ•´æ”»æ“Šéˆæ¨¡æ“¬")
        logger.info(f"   å ´æ™¯ ID: {scenario_id}")

        # éšæ®µ 1: æƒæ
        logger.info("   éšæ®µ 1/4: åŸ·è¡Œæƒæ...")
        scan_result = await self.simulate_scan_flow(target_url)

        # éšæ®µ 2: å°æ‰€æœ‰è³‡ç”¢é€²è¡Œ SQLi æª¢æ¸¬
        logger.info("   éšæ®µ 2/4: å°ç™¼ç¾çš„è³‡ç”¢é€²è¡Œ SQLi æª¢æ¸¬...")
        sqli_results = []
        assets = scan_result["result"].get("assets", [])[:3]  # å–å‰3å€‹è³‡ç”¢æ¸¬è©¦
        for asset in assets:
            asset_url = asset.get("url", "")
            if "?" in asset_url:  # æœ‰åƒæ•¸çš„ URL
                result = await self.simulate_sqli_detection_flow(
                    asset_url, param_name="id"
                )
                sqli_results.append(result)

        # éšæ®µ 3: XSS æª¢æ¸¬
        logger.info("   éšæ®µ 3/4: åŸ·è¡Œ XSS æª¢æ¸¬...")
        # (ç°¡åŒ–ç‰ˆï¼Œå¯¦éš›æœƒé¡ä¼¼ SQLi æµç¨‹)

        # éšæ®µ 4: æ”»æ“Šè·¯å¾‘åˆ†æ
        logger.info("   éšæ®µ 4/4: ç”Ÿæˆæ”»æ“Šè·¯å¾‘åˆ†æ...")
        attack_path = await self._integration_build_attack_path(
            scan_result, sqli_results
        )

        # AI å­¸ç¿’å®Œæ•´æ”»æ“Šéˆ
        experience = {
            "scenario_id": scenario_id,
            "flow_type": "full_attack_chain",
            "scan_result": scan_result,
            "sqli_results": sqli_results,
            "attack_path": attack_path,
            "timestamp": datetime.now(UTC).isoformat(),
        }

        await self.exp_manager.store_experience(
            experience_id=new_id("exp"),
            experience_data=experience,
            tags=["attack_chain", "complete", "advanced"],
        )

        logger.info(f"âœ… å ´æ™¯ 3 å®Œæˆ: å®Œæ•´æ”»æ“Šéˆåˆ†æ")

        return {
            "scenario_id": scenario_id,
            "flow_type": "full_attack_chain",
            "attack_path": attack_path,
        }

    # ========== å…§éƒ¨è¼”åŠ©æ–¹æ³• ==========

    async def _cli_send_scan_request(
        self, scan_id: str, task_id: str, target_url: str
    ) -> dict[str, Any]:
        """æ¨¡æ“¬ CLI ç™¼é€æƒæè«‹æ±‚"""
        header = MessageHeader(
            message_id=new_id("msg"),
            source_module=ModuleName.CLI,
            target_module=ModuleName.SCAN,
            correlation_id=scan_id,
        )

        payload = ScanStartPayload(
            scan_id=scan_id,
            task_id=task_id,
            target_url=target_url,
            max_depth=3,
            max_pages=100,
            scope_domains=[target_url],
        )

        return {"header": header.model_dump(), "payload": payload.model_dump()}

    async def _ai_make_decision(self, context: dict[str, Any]) -> dict[str, Any]:
        """AI æ±ºç­–"""
        # ä½¿ç”¨ BioNeuronCore åšæ±ºç­–
        input_vector = self._context_to_vector(context)
        output = self.bio_net.forward(input_vector)

        return {
            "decision": "proceed",
            "confidence": float(output.max()),
            "reasoning": "Based on neural network decision",
        }

    async def _ai_select_detection_strategy(
        self, context: dict[str, Any]
    ) -> dict[str, Any]:
        """AI é¸æ“‡æª¢æ¸¬ç­–ç•¥"""
        # æŸ¥è©¢çŸ¥è­˜åº«ç²å–é¡ä¼¼æ¡ˆä¾‹
        similar_cases = await self.kb.search(
            query=f"SQLi detection {context['param_name']}", top_k=5
        )

        return {
            "engines": ["error", "boolean", "time"],
            "priority": "error_first",
            "similar_cases_count": len(similar_cases),
        }

    async def _scan_worker_execute(
        self, request: dict[str, Any]
    ) -> dict[str, Any]:
        """æ¨¡æ“¬ Scan Worker åŸ·è¡Œ"""
        # æ¨¡æ“¬æƒæçµæœ
        return {
            "scan_id": request["payload"]["scan_id"],
            "assets": [
                {"url": f"https://example.com/page{i}", "type": "html"}
                for i in range(5)
            ],
            "fingerprints": {"server": "nginx", "framework": "django"},
            "summary": {"total_assets": 5, "duration_sec": 10.5},
        }

    async def _worker_send_result(self, scan_id: str, result: dict[str, Any]):
        """æ¨¡æ“¬ Worker ç™¼é€çµæœ"""
        # å¯¦éš›æœƒç™¼é€åˆ° RabbitMQ
        pass

    async def _result_collector_forward(self, result: dict[str, Any]):
        """æ¨¡æ“¬ ResultCollector è½‰ç™¼"""
        pass

    async def _integration_analyze(self, result: dict[str, Any]) -> dict[str, Any]:
        """æ¨¡æ“¬ Integration åˆ†æ"""
        return {
            "risk_score": 3.5,
            "asset_classification": "web_application",
            "recommendations": ["Enable HTTPS", "Update framework"],
        }

    async def _sqli_worker_execute(
        self, request: dict[str, Any]
    ) -> dict[str, Any]:
        """æ¨¡æ“¬ SQLi Worker åŸ·è¡Œ"""
        # æ¨¡æ“¬æª¢æ¸¬çµæœ
        finding = {
            "finding_id": new_id("finding"),
            "task_id": request["task_id"],
            "scan_id": new_id("scan"),
            "status": "confirmed",
            "vulnerability": {
                "name": "SQL_INJECTION",
                "severity": Severity.HIGH.value,
                "confidence": "high",
                "description": "SQL injection vulnerability detected",
            },
            "target": {
                "url": request["target_url"],
                "parameter": request["param_name"],
            },
        }

        return {"findings": [finding], "engines_used": request["engines"]}

    async def _integration_assess_risk(
        self, findings: list[dict]
    ) -> dict[str, Any]:
        """æ¨¡æ“¬é¢¨éšªè©•ä¼°"""
        if not findings:
            return {"risk_level": "low", "score": 0.0}

        return {
            "risk_level": "high",
            "score": 8.5,
            "impact": "Data breach possible",
            "remediation_priority": 1,
        }

    async def _integration_build_attack_path(
        self, scan_result: dict, sqli_results: list[dict]
    ) -> dict[str, Any]:
        """æ¨¡æ“¬æ”»æ“Šè·¯å¾‘æ§‹å»º"""
        return {
            "path_id": new_id("path"),
            "stages": [
                {"stage": "reconnaissance", "result": scan_result},
                {"stage": "exploitation", "findings": sqli_results},
            ],
            "feasibility": 0.85,
            "overall_risk": 9.0,
        }

    def _context_to_vector(self, context: dict[str, Any]) -> Any:
        """å°‡ä¸Šä¸‹æ–‡è½‰æ›ç‚ºç¥ç¶“ç¶²è·¯è¼¸å…¥å‘é‡"""
        # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰è©²ä½¿ç”¨åµŒå…¥æ¨¡å‹
        import numpy as np

        return np.random.randn(512)


# ============================================================================
# AI è¨“ç·´ç·¨æ’å™¨
# ============================================================================


class AITrainingOrchestrator:
    """AI è¨“ç·´ç·¨æ’å™¨ - å”èª¿æ•´å€‹è¨“ç·´æµç¨‹"""

    def __init__(self, storage_path: Path = Path("./data/ai")):
        self.storage_path = storage_path
        self.storage_path.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–çµ„ä»¶
        self.bio_net = self._create_bio_net()
        self.exp_manager = self._create_experience_manager()
        self.kb = self._create_knowledge_base()
        self.simulator = None

    def _create_bio_net(self) -> ScalableBioNet:
        """å‰µå»º 500 è¬åƒæ•¸çš„ç¥ç¶“ç¶²è·¯"""
        logger.info("ğŸ§  åˆå§‹åŒ– ScalableBioNet (500è¬åƒæ•¸)...")

        net = ScalableBioNet(
            input_dim=512,  # è¼¸å…¥ç¶­åº¦
            hidden_dims=[1024, 2048, 1024],  # éš±è—å±¤: 1024 + 2048 + 1024
            output_dim=256,  # è¼¸å‡ºç¶­åº¦
        )

        param_count = net.count_params()
        logger.info(f"   âœ… ç¥ç¶“ç¶²è·¯åƒæ•¸é‡: {param_count:,}")

        return net

    def _create_experience_manager(self) -> ExperienceManager:
        """å‰µå»ºç¶“é©—ç®¡ç†å™¨"""
        storage_manager = StorageManager(
            backend_type="sqlite", db_path=str(self.storage_path / "experiences.db")
        )
        return ExperienceManager(storage_manager=storage_manager)

    def _create_knowledge_base(self) -> KnowledgeBase:
        """å‰µå»ºçŸ¥è­˜åº«"""
        return KnowledgeBase(storage_path=self.storage_path / "knowledge")

    async def initialize(self):
        """åˆå§‹åŒ–è¨“ç·´ç³»çµ±"""
        logger.info("ğŸš€ åˆå§‹åŒ– AI è¨“ç·´ç³»çµ±...")

        await self.exp_manager.initialize()
        await self.kb.initialize()

        self.simulator = TrainingScenarioSimulator(
            bio_net=self.bio_net,
            experience_manager=self.exp_manager,
            knowledge_base=self.kb,
        )

        await self.simulator.initialize()

        logger.info("âœ… AI è¨“ç·´ç³»çµ±åˆå§‹åŒ–å®Œæˆ")

    async def train_from_simulations(
        self, num_scenarios: int = 10, epochs: int = 5
    ):
        """å¾æ¨¡æ“¬å ´æ™¯é€²è¡Œè¨“ç·´"""
        logger.info(f"ğŸ“ é–‹å§‹è¨“ç·´: {num_scenarios} å€‹å ´æ™¯, {epochs} è¼ª")

        for epoch in range(epochs):
            logger.info(f"\n{'='*60}")
            logger.info(f"è¨“ç·´è¼ªæ¬¡ {epoch + 1}/{epochs}")
            logger.info(f"{'='*60}")

            for i in range(num_scenarios):
                logger.info(f"\nå ´æ™¯ {i + 1}/{num_scenarios}")

                # è¼ªæµåŸ·è¡Œä¸åŒå ´æ™¯
                if i % 3 == 0:
                    await self.simulator.simulate_scan_flow(
                        f"https://example{i}.com"
                    )
                elif i % 3 == 1:
                    await self.simulator.simulate_sqli_detection_flow(
                        f"https://example{i}.com/login", "username"
                    )
                else:
                    await self.simulator.simulate_full_attack_chain(
                        f"https://example{i}.com"
                    )

            # æ¯è¼ªçµæŸå¾Œæ›´æ–°æ¨¡å‹
            logger.info(f"\nğŸ”„ æ›´æ–°ç¥ç¶“ç¶²è·¯æ¨¡å‹...")
            await self._update_model(epoch)

        logger.info(f"\nâœ… è¨“ç·´å®Œæˆï¼")

    async def _update_model(self, epoch: int):
        """æ›´æ–°ç¥ç¶“ç¶²è·¯æ¨¡å‹"""
        # å¾ç¶“é©—ç®¡ç†å™¨ç²å–ç¶“é©—
        experiences = await self.exp_manager.get_recent_experiences(limit=100)

        logger.info(f"   å¾ {len(experiences)} æ¢ç¶“é©—ä¸­å­¸ç¿’...")

        # å¯¦éš›è¨“ç·´é‚è¼¯ (ç°¡åŒ–ç‰ˆ)
        # çœŸå¯¦æƒ…æ³æœƒé€²è¡Œåå‘å‚³æ’­å’Œåƒæ•¸æ›´æ–°

        # ä¿å­˜æ¨¡å‹æª¢æŸ¥é»
        checkpoint_path = self.storage_path / f"model_epoch_{epoch}.pkl"
        # self.bio_net.save(checkpoint_path)

        logger.info(f"   âœ… æ¨¡å‹æ›´æ–°å®Œæˆ (Epoch {epoch})")

    async def get_training_stats(self) -> dict[str, Any]:
        """ç²å–è¨“ç·´çµ±è¨ˆ"""
        exp_stats = await self.exp_manager.get_stats()
        kb_stats = await self.kb.get_stats()

        return {
            "model_params": self.bio_net.count_params(),
            "experiences_count": exp_stats.get("total_count", 0),
            "knowledge_entries": kb_stats.get("total_entries", 0),
            "last_update": datetime.now(UTC).isoformat(),
        }


# ============================================================================
# ä¸»å‡½æ•¸ - ä¾› CLI èª¿ç”¨
# ============================================================================


async def main():
    """ä¸»è¨“ç·´å‡½æ•¸"""
    logger.info("="*60)
    logger.info("AIVA AI è¨“ç·´ç³»çµ±")
    logger.info("åŸºæ–¼ 500 è¬åƒæ•¸ ScalableBioNet")
    logger.info("="*60)

    orchestrator = AITrainingOrchestrator()
    await orchestrator.initialize()

    # åŸ·è¡Œè¨“ç·´
    await orchestrator.train_from_simulations(num_scenarios=5, epochs=3)

    # é¡¯ç¤ºçµ±è¨ˆ
    stats = await orchestrator.get_training_stats()
    logger.info(f"\nğŸ“Š è¨“ç·´çµ±è¨ˆ:")
    logger.info(f"   æ¨¡å‹åƒæ•¸é‡: {stats['model_params']:,}")
    logger.info(f"   ç¶“é©—æ¢æ•¸: {stats['experiences_count']}")
    logger.info(f"   çŸ¥è­˜åº«æ¢ç›®: {stats['knowledge_entries']}")


if __name__ == "__main__":
    asyncio.run(main())
