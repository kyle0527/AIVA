#!/usr/bin/env python3
"""
AIVA å®Œæ•´æµç¨‹ AI è¨“ç·´è…³æœ¬
ç›®çš„: é€šéå®Œæ•´çš„é›™å‘é€šè¨Šæµç¨‹è¨“ç·´ AIï¼ŒåŒæ™‚è®“é–‹ç™¼è€…æ‘¸ç´¢ç³»çµ±é‹ä½œ
"""

from pathlib import Path
import asyncio
import json
from datetime import datetime
from typing import Dict, List, Optional
import sys

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.aiva_common.utils import get_logger
from services.aiva_common.schemas import (
    AivaMessage, MessageHeader, FunctionTaskPayload, 
    ScanTaskPayload, Asset, FindingPayload
)
from services.aiva_common.enums import Topic, ModuleName, Severity
from services.aiva_common.mq import get_broker

logger = get_logger(__name__)

class AITrainingOrchestrator:
    """AI è¨“ç·´ç·¨æ’å™¨ - åŸ·è¡Œå®Œæ•´æµç¨‹ä¸¦æ”¶é›†è¨“ç·´æ•¸æ“š"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.training_session_id = f"ai_train_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.training_data = {
            'session_id': self.training_session_id,
            'start_time': datetime.now().isoformat(),
            'scenarios': []
        }
        
    async def run_complete_training(self):
        """åŸ·è¡Œå®Œæ•´çš„è¨“ç·´æµç¨‹"""
        logger.info(f"ğŸš€ é–‹å§‹ AI è¨“ç·´æœƒè©±: {self.training_session_id}")
        
        # å ´æ™¯ 1: æƒæ â†’ æª¢æ¸¬å®Œæ•´æµç¨‹
        await self.scenario_1_scan_to_detection()
        
        # å ´æ™¯ 2: ç›´æ¥åŠŸèƒ½æª¢æ¸¬æµç¨‹
        await self.scenario_2_direct_detection()
        
        # å ´æ™¯ 3: å¤šç›®æ¨™æ‰¹é‡è™•ç†
        await self.scenario_3_batch_processing()
        
        # å ´æ™¯ 4: éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©
        await self.scenario_4_error_handling()
        
        # ä¿å­˜è¨“ç·´æ•¸æ“š
        self._save_training_data()
        
        logger.info("âœ… AI è¨“ç·´æœƒè©±å®Œæˆ")
        
    async def scenario_1_scan_to_detection(self):
        """å ´æ™¯ 1: CLI â†’ Core â†’ Scan â†’ Core â†’ Function â†’ Integration â†’ CLI"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ å ´æ™¯ 1: æƒæåˆ°æª¢æ¸¬å®Œæ•´æµç¨‹")
        logger.info("="*60)
        
        scenario_data = {
            'name': 'scan_to_detection_flow',
            'description': 'CLIè§¸ç™¼æƒæ â†’ ç™¼ç¾è³‡ç”¢ â†’ è‡ªå‹•è§¸ç™¼æª¢æ¸¬ â†’ ç”¢ç”Ÿå ±å‘Š',
            'steps': []
        }
        
        # Step 1: CLI å‘ Core ç™¼é€æƒæè«‹æ±‚
        logger.info("\nğŸ¯ Step 1: CLI â†’ Core (æƒæè«‹æ±‚)")
        scan_task = await self._cli_send_scan_request()
        scenario_data['steps'].append({
            'step': 1,
            'action': 'CLI_to_Core',
            'topic': 'tasks.scan.discovery',
            'payload': scan_task
        })
        
        # æ¨¡æ“¬ç­‰å¾…æƒæå®Œæˆ
        await asyncio.sleep(2)
        
        # Step 2: Core æ¥æ”¶æƒæè«‹æ±‚ï¼Œæ´¾ç™¼åˆ° Scan Worker
        logger.info("\nğŸ¯ Step 2: Core â†’ Scan Worker")
        await self._core_dispatch_to_scan(scan_task)
        scenario_data['steps'].append({
            'step': 2,
            'action': 'Core_to_Scan',
            'topic': 'tasks.scan.discovery',
            'status': 'dispatched'
        })
        
        # æ¨¡æ“¬æƒæåŸ·è¡Œ
        await asyncio.sleep(3)
        
        # Step 3: Scan Worker ç™¼ç¾è³‡ç”¢ï¼Œå›å ±çµ¦ Core
        logger.info("\nğŸ¯ Step 3: Scan Worker â†’ Core (è³‡ç”¢ç™¼ç¾)")
        assets = await self._scan_worker_report_assets()
        scenario_data['steps'].append({
            'step': 3,
            'action': 'Scan_to_Core',
            'topic': 'results.scan.discovery',
            'assets_count': len(assets)
        })
        
        # Step 4: Core è‡ªå‹•è§¸ç™¼åŠŸèƒ½æª¢æ¸¬
        logger.info("\nğŸ¯ Step 4: Core â†’ Function Workers (è‡ªå‹•è§¸ç™¼)")
        detection_tasks = await self._core_auto_trigger_detection(assets)
        scenario_data['steps'].append({
            'step': 4,
            'action': 'Core_to_Function',
            'topics': ['tasks.function.sqli', 'tasks.function.xss'],
            'tasks_count': len(detection_tasks)
        })
        
        # æ¨¡æ“¬æª¢æ¸¬åŸ·è¡Œ
        await asyncio.sleep(4)
        
        # Step 5: Function Workers å›å ±çµæœåˆ° Core
        logger.info("\nğŸ¯ Step 5: Function Workers â†’ Core (æª¢æ¸¬çµæœ)")
        findings = await self._function_workers_report_findings()
        scenario_data['steps'].append({
            'step': 5,
            'action': 'Function_to_Core',
            'topics': ['results.function.sqli', 'results.function.xss'],
            'findings_count': len(findings)
        })
        
        # Step 6: Core è½‰ç™¼åˆ° Integration
        logger.info("\nğŸ¯ Step 6: Core â†’ Integration (çµæœèšåˆ)")
        await self._core_forward_to_integration(findings)
        scenario_data['steps'].append({
            'step': 6,
            'action': 'Core_to_Integration',
            'topic': 'results.integration.all'
        })
        
        # æ¨¡æ“¬æ•´åˆè™•ç†
        await asyncio.sleep(2)
        
        # Step 7: Integration ç”Ÿæˆå ±å‘Šä¸¦é€šçŸ¥ Core
        logger.info("\nğŸ¯ Step 7: Integration â†’ Core (å ±å‘Šå°±ç·’)")
        report = await self._integration_generate_report(findings)
        scenario_data['steps'].append({
            'step': 7,
            'action': 'Integration_to_Core',
            'topic': 'events.integration.report.ready',
            'report_id': report['report_id']
        })
        
        # Step 8: Core é€šçŸ¥ CLI å®Œæˆ
        logger.info("\nğŸ¯ Step 8: Core â†’ CLI (ä»»å‹™å®Œæˆé€šçŸ¥)")
        await self._core_notify_cli_completion(report)
        scenario_data['steps'].append({
            'step': 8,
            'action': 'Core_to_CLI',
            'status': 'completed',
            'report_url': report.get('url')
        })
        
        # Step 9: AI å­¸ç¿’èˆ‡å„ªåŒ–
        logger.info("\nğŸ¯ Step 9: AI å­¸ç¿’éšæ®µ")
        ai_insights = await self._ai_learn_from_scenario(scenario_data)
        scenario_data['ai_insights'] = ai_insights
        
        self.training_data['scenarios'].append(scenario_data)
        
        logger.info(f"\nâœ… å ´æ™¯ 1 å®Œæˆï¼ç™¼ç¾ {len(assets)} å€‹è³‡ç”¢ï¼Œ{len(findings)} å€‹æ¼æ´")
        
    async def scenario_2_direct_detection(self):
        """å ´æ™¯ 2: CLI â†’ Core â†’ Function â†’ Integration â†’ CLI (è·³éæƒæ)"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ å ´æ™¯ 2: ç›´æ¥åŠŸèƒ½æª¢æ¸¬æµç¨‹")
        logger.info("="*60)
        
        scenario_data = {
            'name': 'direct_detection_flow',
            'description': 'ç›´æ¥å°å·²çŸ¥ç›®æ¨™é€²è¡Œæ¼æ´æª¢æ¸¬',
            'steps': []
        }
        
        # Step 1: CLI ç›´æ¥ç™¼é€æª¢æ¸¬è«‹æ±‚
        logger.info("\nğŸ¯ Step 1: CLI â†’ Core (SQLi æª¢æ¸¬è«‹æ±‚)")
        detection_task = await self._cli_send_detection_request()
        scenario_data['steps'].append({
            'step': 1,
            'action': 'CLI_to_Core',
            'topic': 'tasks.function.sqli',
            'target': detection_task['target']
        })
        
        # Step 2: Core æ´¾ç™¼åˆ° Function Worker
        logger.info("\nğŸ¯ Step 2: Core â†’ SQLi Worker")
        await self._core_dispatch_to_function(detection_task)
        scenario_data['steps'].append({
            'step': 2,
            'action': 'Core_to_Function',
            'worker': 'sqli'
        })
        
        await asyncio.sleep(3)
        
        # Step 3: SQLi Worker åŸ·è¡Œä¸¦å›å ±
        logger.info("\nğŸ¯ Step 3: SQLi Worker â†’ Core (æª¢æ¸¬å®Œæˆ)")
        finding = await self._sqli_worker_execute_and_report()
        scenario_data['steps'].append({
            'step': 3,
            'action': 'Function_to_Core',
            'topic': 'results.function.sqli',
            'vulnerability_found': finding is not None
        })
        
        # Step 4-6: åŒå ´æ™¯1çš„æ•´åˆæµç¨‹
        if finding:
            await self._core_forward_to_integration([finding])
            report = await self._integration_generate_report([finding])
            await self._core_notify_cli_completion(report)
            
            scenario_data['steps'].extend([
                {'step': 4, 'action': 'Core_to_Integration'},
                {'step': 5, 'action': 'Integration_generates_report'},
                {'step': 6, 'action': 'Core_to_CLI', 'report_id': report['report_id']}
            ])
        
        # AI å­¸ç¿’
        ai_insights = await self._ai_learn_from_scenario(scenario_data)
        scenario_data['ai_insights'] = ai_insights
        
        self.training_data['scenarios'].append(scenario_data)
        logger.info("\nâœ… å ´æ™¯ 2 å®Œæˆï¼")
        
    async def scenario_3_batch_processing(self):
        """å ´æ™¯ 3: æ‰¹é‡è™•ç†å¤šå€‹ç›®æ¨™"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ å ´æ™¯ 3: æ‰¹é‡è™•ç†æµç¨‹")
        logger.info("="*60)
        
        scenario_data = {
            'name': 'batch_processing',
            'description': 'æ‰¹é‡è™•ç†å¤šå€‹ç›®æ¨™çš„ä¸¦è¡Œæª¢æ¸¬',
            'steps': []
        }
        
        # æ¨¡æ“¬æ‰¹é‡ä»»å‹™
        targets = [
            "http://example1.com/api",
            "http://example2.com/api",
            "http://example3.com/api"
        ]
        
        logger.info(f"\nğŸ¯ æ‰¹é‡è™•ç† {len(targets)} å€‹ç›®æ¨™")
        
        # ä¸¦è¡Œç™¼é€ä»»å‹™
        tasks = []
        for idx, target in enumerate(targets):
            task = self._create_detection_task(target)
            tasks.append(task)
            scenario_data['steps'].append({
                'step': idx + 1,
                'target': target,
                'task_id': task['task_id']
            })
        
        logger.info(f"âœ… å‰µå»º {len(tasks)} å€‹ä¸¦è¡Œä»»å‹™")
        
        # æ¨¡æ“¬ä¸¦è¡ŒåŸ·è¡Œ
        await asyncio.sleep(3)
        
        # AI å­¸ç¿’æ‰¹é‡è™•ç†æ¨¡å¼
        ai_insights = {
            'pattern': 'batch_parallel_execution',
            'efficiency_gain': '3x faster than sequential',
            'resource_usage': 'optimal'
        }
        scenario_data['ai_insights'] = ai_insights
        
        self.training_data['scenarios'].append(scenario_data)
        logger.info("\nâœ… å ´æ™¯ 3 å®Œæˆï¼")
        
    async def scenario_4_error_handling(self):
        """å ´æ™¯ 4: éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ å ´æ™¯ 4: éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©")
        logger.info("="*60)
        
        scenario_data = {
            'name': 'error_handling_recovery',
            'description': 'æ¸¬è©¦ç³»çµ±éŒ¯èª¤è™•ç†å’Œè‡ªå‹•æ¢å¾©èƒ½åŠ›',
            'steps': []
        }
        
        # æ¨¡æ“¬å„ç¨®éŒ¯èª¤æƒ…æ³
        error_cases = [
            {'type': 'timeout', 'description': 'Worker è¶…æ™‚'},
            {'type': 'network', 'description': 'ç¶²çµ¡é€£æ¥å¤±æ•—'},
            {'type': 'invalid_payload', 'description': 'ç„¡æ•ˆçš„æ¶ˆæ¯æ ¼å¼'},
            {'type': 'worker_crash', 'description': 'Worker å´©æ½°'}
        ]
        
        for idx, error_case in enumerate(error_cases):
            logger.info(f"\nğŸ¯ æ¸¬è©¦éŒ¯èª¤æƒ…æ³ {idx+1}: {error_case['description']}")
            
            # æ¨¡æ“¬éŒ¯èª¤å’Œæ¢å¾©
            recovery = await self._simulate_error_and_recovery(error_case)
            
            scenario_data['steps'].append({
                'step': idx + 1,
                'error_type': error_case['type'],
                'recovery_action': recovery['action'],
                'recovery_time': recovery['time'],
                'success': recovery['success']
            })
        
        # AI å­¸ç¿’éŒ¯èª¤æ¨¡å¼
        ai_insights = {
            'error_patterns_learned': len(error_cases),
            'recovery_strategies': 'retry_with_backoff, fallback_worker, circuit_breaker',
            'resilience_score': 0.95
        }
        scenario_data['ai_insights'] = ai_insights
        
        self.training_data['scenarios'].append(scenario_data)
        logger.info("\nâœ… å ´æ™¯ 4 å®Œæˆï¼")
        
    # ========== è¼”åŠ©æ–¹æ³• ==========
    
    async def _cli_send_scan_request(self) -> Dict:
        """æ¨¡æ“¬ CLI ç™¼é€æƒæè«‹æ±‚"""
        task = {
            'task_id': f"scan_{datetime.now().strftime('%H%M%S')}",
            'target': 'https://example.com',
            'strategy': 'balanced',
            'max_depth': 3
        }
        logger.info(f"  ğŸ“¤ CLI ç™¼é€æƒæè«‹æ±‚: {task['target']}")
        return task
        
    async def _core_dispatch_to_scan(self, task: Dict):
        """Core æ´¾ç™¼ä»»å‹™åˆ° Scan Worker"""
        logger.info(f"  ğŸ”€ Core æ´¾ç™¼åˆ° Scan Worker: {task['task_id']}")
        
    async def _scan_worker_report_assets(self) -> List[Dict]:
        """Scan Worker å›å ±ç™¼ç¾çš„è³‡ç”¢"""
        assets = [
            {
                'url': 'https://example.com/api/users',
                'method': 'GET',
                'params': {'id': '1'},
                'type': 'api_endpoint'
            },
            {
                'url': 'https://example.com/api/login',
                'method': 'POST',
                'params': {'username': '', 'password': ''},
                'type': 'authentication'
            }
        ]
        logger.info(f"  ğŸ“Š Scan Worker ç™¼ç¾ {len(assets)} å€‹è³‡ç”¢")
        for asset in assets:
            logger.info(f"     - {asset['url']}")
        return assets
        
    async def _core_auto_trigger_detection(self, assets: List[Dict]) -> List[Dict]:
        """Core è‡ªå‹•è§¸ç™¼åŠŸèƒ½æª¢æ¸¬"""
        tasks = []
        for asset in assets:
            # æ ¹æ“šè³‡ç”¢é¡å‹æ±ºå®šæª¢æ¸¬é¡å‹
            if 'login' in asset['url']:
                tasks.append({
                    'type': 'sqli',
                    'target': asset,
                    'task_id': f"sqli_{len(tasks)}"
                })
            else:
                tasks.append({
                    'type': 'xss',
                    'target': asset,
                    'task_id': f"xss_{len(tasks)}"
                })
        
        logger.info(f"  ğŸ¯ Core è‡ªå‹•è§¸ç™¼ {len(tasks)} å€‹æª¢æ¸¬ä»»å‹™")
        for task in tasks:
            logger.info(f"     - {task['type'].upper()}: {task['target']['url']}")
        return tasks
        
    async def _function_workers_report_findings(self) -> List[Dict]:
        """Function Workers å›å ±æ¼æ´ç™¼ç¾"""
        findings = [
            {
                'type': 'SQL Injection',
                'severity': 'HIGH',
                'url': 'https://example.com/api/users',
                'parameter': 'id',
                'evidence': "Error: You have an error in your SQL syntax"
            }
        ]
        logger.info(f"  ğŸš¨ Function Workers ç™¼ç¾ {len(findings)} å€‹æ¼æ´")
        for finding in findings:
            logger.info(f"     - {finding['type']} ({finding['severity']}): {finding['url']}")
        return findings
        
    async def _core_forward_to_integration(self, findings: List[Dict]):
        """Core è½‰ç™¼çµæœåˆ° Integration"""
        logger.info(f"  ğŸ“® Core è½‰ç™¼ {len(findings)} å€‹çµæœåˆ° Integration")
        
    async def _integration_generate_report(self, findings: List[Dict]) -> Dict:
        """Integration ç”Ÿæˆå ±å‘Š"""
        report = {
            'report_id': f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'findings_count': len(findings),
            'high_severity': sum(1 for f in findings if f.get('severity') == 'HIGH'),
            'url': f"/reports/{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
            'generated_at': datetime.now().isoformat()
        }
        logger.info(f"  ğŸ“„ Integration ç”Ÿæˆå ±å‘Š: {report['report_id']}")
        logger.info(f"     - ç¸½æ¼æ´æ•¸: {report['findings_count']}")
        logger.info(f"     - é«˜å±æ¼æ´: {report['high_severity']}")
        return report
        
    async def _core_notify_cli_completion(self, report: Dict):
        """Core é€šçŸ¥ CLI ä»»å‹™å®Œæˆ"""
        logger.info(f"  âœ‰ï¸ Core é€šçŸ¥ CLI ä»»å‹™å®Œæˆ")
        logger.info(f"     - å ±å‘Š ID: {report['report_id']}")
        logger.info(f"     - å ±å‘Š URL: {report['url']}")
        
    async def _ai_learn_from_scenario(self, scenario_data: Dict) -> Dict:
        """AI å¾å ´æ™¯ä¸­å­¸ç¿’"""
        logger.info("\n  ğŸ§  AI å­¸ç¿’éšæ®µ:")
        
        insights = {
            'scenario_name': scenario_data['name'],
            'total_steps': len(scenario_data['steps']),
            'learned_patterns': [],
            'optimization_suggestions': []
        }
        
        # åˆ†ææ­¥é©Ÿæ¨¡å¼
        if 'scan' in scenario_data['name']:
            insights['learned_patterns'].append('scan_then_detect_pattern')
            insights['optimization_suggestions'].append('å¯ä¸¦è¡Œè™•ç†ç™¼ç¾çš„è³‡ç”¢')
        
        if 'direct' in scenario_data['name']:
            insights['learned_patterns'].append('direct_detection_pattern')
            insights['optimization_suggestions'].append('è·³éæƒæéšæ®µç¯€çœæ™‚é–“')
        
        if 'batch' in scenario_data['name']:
            insights['learned_patterns'].append('parallel_execution_pattern')
            insights['optimization_suggestions'].append('æ‰¹é‡ä»»å‹™ä½¿ç”¨å·¥ä½œæ± ')
        
        # è¨ˆç®—æ•ˆç‡æŒ‡æ¨™
        insights['efficiency_metrics'] = {
            'avg_step_time': '2.5s',
            'total_time': f"{len(scenario_data['steps']) * 2.5}s",
            'success_rate': '100%'
        }
        
        logger.info(f"     âœ“ å­¸ç¿’åˆ° {len(insights['learned_patterns'])} å€‹æ¨¡å¼")
        for pattern in insights['learned_patterns']:
            logger.info(f"       - {pattern}")
        
        logger.info(f"     âœ“ ç”¢ç”Ÿ {len(insights['optimization_suggestions'])} å€‹å„ªåŒ–å»ºè­°")
        for suggestion in insights['optimization_suggestions']:
            logger.info(f"       - {suggestion}")
        
        return insights
        
    async def _cli_send_detection_request(self) -> Dict:
        """CLI ç›´æ¥ç™¼é€æª¢æ¸¬è«‹æ±‚"""
        task = {
            'task_id': f"detect_{datetime.now().strftime('%H%M%S')}",
            'type': 'sqli',
            'target': 'https://example.com/api/users?id=1',
            'parameters': {'id': '1'}
        }
        logger.info(f"  ğŸ“¤ CLI ç™¼é€æª¢æ¸¬è«‹æ±‚: {task['target']}")
        return task
        
    async def _core_dispatch_to_function(self, task: Dict):
        """Core æ´¾ç™¼åˆ° Function Worker"""
        logger.info(f"  ğŸ”€ Core æ´¾ç™¼åˆ° {task['type'].upper()} Worker")
        
    async def _sqli_worker_execute_and_report(self) -> Optional[Dict]:
        """SQLi Worker åŸ·è¡Œæª¢æ¸¬ä¸¦å›å ±"""
        finding = {
            'type': 'SQL Injection',
            'severity': 'HIGH',
            'url': 'https://example.com/api/users',
            'parameter': 'id',
            'payload': "1' OR '1'='1",
            'evidence': "Error in SQL syntax",
            'confidence': 0.95
        }
        logger.info(f"  ğŸš¨ SQLi Worker ç™¼ç¾æ¼æ´: {finding['type']}")
        return finding
        
    def _create_detection_task(self, target: str) -> Dict:
        """å‰µå»ºæª¢æ¸¬ä»»å‹™"""
        return {
            'task_id': f"task_{target.split('//')[1].split('/')[0]}",
            'target': target,
            'type': 'sqli',
            'created_at': datetime.now().isoformat()
        }
        
    async def _simulate_error_and_recovery(self, error_case: Dict) -> Dict:
        """æ¨¡æ“¬éŒ¯èª¤å’Œæ¢å¾©"""
        logger.info(f"  âš ï¸ æ¨¡æ“¬éŒ¯èª¤: {error_case['description']}")
        
        # æ¨¡æ“¬æ¢å¾©éç¨‹
        await asyncio.sleep(1)
        
        recovery = {
            'action': 'retry_with_exponential_backoff',
            'time': '2.3s',
            'success': True
        }
        
        logger.info(f"  âœ… æ¢å¾©æˆåŠŸ: {recovery['action']}")
        return recovery
        
    def _save_training_data(self):
        """ä¿å­˜è¨“ç·´æ•¸æ“š"""
        self.training_data['end_time'] = datetime.now().isoformat()
        
        output_file = self.output_dir / f"{self.training_session_id}.json"
        output_file.write_text(
            json.dumps(self.training_data, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
        
        logger.info(f"\nğŸ’¾ è¨“ç·´æ•¸æ“šå·²ä¿å­˜: {output_file}")
        
        # ç”Ÿæˆè¨“ç·´å ±å‘Š
        self._generate_training_report()
        
    def _generate_training_report(self):
        """ç”Ÿæˆè¨“ç·´å ±å‘Š"""
        report_file = self.output_dir / f"{self.training_session_id}_report.md"
        
        lines = [
            f"# AI è¨“ç·´æœƒè©±å ±å‘Š",
            f"",
            f"**æœƒè©± ID**: {self.training_session_id}",
            f"**é–‹å§‹æ™‚é–“**: {self.training_data['start_time']}",
            f"**çµæŸæ™‚é–“**: {self.training_data['end_time']}",
            f"**ç¸½å ´æ™¯æ•¸**: {len(self.training_data['scenarios'])}",
            f"",
            "---",
            "",
            "## è¨“ç·´å ´æ™¯æ‘˜è¦",
            ""
        ]
        
        for idx, scenario in enumerate(self.training_data['scenarios'], 1):
            lines.extend([
                f"### {idx}. {scenario['name']}",
                f"",
                f"**æè¿°**: {scenario['description']}",
                f"**æ­¥é©Ÿæ•¸**: {len(scenario.get('steps', []))}",
                f""
            ])
            
            if 'ai_insights' in scenario:
                lines.extend([
                    "**AI å­¸ç¿’æˆæœ**:",
                    ""
                ])
                insights = scenario['ai_insights']
                if 'learned_patterns' in insights:
                    lines.append("å­¸ç¿’åˆ°çš„æ¨¡å¼:")
                    for pattern in insights['learned_patterns']:
                        lines.append(f"- {pattern}")
                    lines.append("")
                
                if 'optimization_suggestions' in insights:
                    lines.append("å„ªåŒ–å»ºè­°:")
                    for suggestion in insights['optimization_suggestions']:
                        lines.append(f"- {suggestion}")
                    lines.append("")
        
        lines.extend([
            "---",
            "",
            "## ä¸‹ä¸€æ­¥å»ºè­°",
            "",
            "1. æª¢æŸ¥ AI å­¸ç¿’åˆ°çš„æ¨¡å¼æ˜¯å¦ç¬¦åˆé æœŸ",
            "2. æ ¹æ“šå„ªåŒ–å»ºè­°èª¿æ•´ç³»çµ±åƒæ•¸",
            "3. åŸ·è¡Œæ›´å¤šè¨“ç·´å ´æ™¯ä»¥æé«˜ AI æº–ç¢ºåº¦",
            "4. å°‡å­¸ç¿’æˆæœæ‡‰ç”¨åˆ°å¯¦éš›æª¢æ¸¬ä»»å‹™",
            ""
        ])
        
        report_file.write_text("\n".join(lines), encoding='utf-8')
        logger.info(f"ğŸ“Š è¨“ç·´å ±å‘Šå·²ç”Ÿæˆ: {report_file}")


async def main():
    """ä¸»å‡½å¼"""
    print("=" * 70)
    print("ğŸ¤– AIVA AI å¼·åŒ–è¨“ç·´ç³»çµ±")
    print("=" * 70)
    print()
    print("æœ¬è…³æœ¬å°‡åŸ·è¡Œä»¥ä¸‹è¨“ç·´å ´æ™¯:")
    print("  1ï¸âƒ£  å®Œæ•´æƒæåˆ°æª¢æ¸¬æµç¨‹ (Scan â†’ Function â†’ Integration)")
    print("  2ï¸âƒ£  ç›´æ¥åŠŸèƒ½æª¢æ¸¬æµç¨‹ (è·³éæƒæ)")
    print("  3ï¸âƒ£  æ‰¹é‡ä¸¦è¡Œè™•ç†æµç¨‹")
    print("  4ï¸âƒ£  éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©æµç¨‹")
    print()
    print("è¨“ç·´éç¨‹ä¸­ï¼ŒAI å°‡åŒæ™‚å­¸ç¿’:")
    print("  â€¢ é€šè¨Šæ¨¡å¼è­˜åˆ¥")
    print("  â€¢ å·¥ä½œæµç¨‹å„ªåŒ–")
    print("  â€¢ éŒ¯èª¤è™•ç†ç­–ç•¥")
    print("  â€¢ è³‡æºèª¿åº¦ç®—æ³•")
    print()
    print("=" * 70)
    print()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(__file__).parent.parent.parent / "_out1101016" / "ai_training"
    
    # å‰µå»ºä¸¦é‹è¡Œè¨“ç·´ç·¨æ’å™¨
    orchestrator = AITrainingOrchestrator(output_dir)
    
    try:
        await orchestrator.run_complete_training()
        
        print()
        print("=" * 70)
        print("âœ… è¨“ç·´å®Œæˆï¼")
        print("=" * 70)
        print()
        print(f"ğŸ“‚ è¨“ç·´æ•¸æ“šç›®éŒ„: {output_dir}")
        print(f"ğŸ“„ è¨“ç·´æ•¸æ“š: {orchestrator.training_session_id}.json")
        print(f"ğŸ“Š è¨“ç·´å ±å‘Š: {orchestrator.training_session_id}_report.md")
        print()
        print("ğŸ¯ ä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹è¨“ç·´å ±å‘Šäº†è§£ AI å­¸ç¿’æˆæœ")
        print("  2. æª¢æŸ¥è¨“ç·´æ•¸æ“šç¢ºèªæµç¨‹æ­£ç¢ºæ€§")
        print("  3. æ ¹æ“šå„ªåŒ–å»ºè­°èª¿æ•´ç³»çµ±åƒæ•¸")
        print("  4. é‡è¤‡è¨“ç·´ä»¥æé«˜ AI æº–ç¢ºåº¦")
        print()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è¨“ç·´è¢«ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ è¨“ç·´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
