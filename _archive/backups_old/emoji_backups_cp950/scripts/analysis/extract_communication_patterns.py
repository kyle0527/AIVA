#!/usr/bin/env python3
"""
å¾æµç¨‹åœ–ä¸­æå–é€šè¨Šæ¨¡å¼
ç›®çš„: è‡ªå‹•åˆ†ææ‰€æœ‰ broker.publish/subscribe èª¿ç”¨ï¼Œå»ºç«‹é€šè¨Šé—œä¿‚åœ–
åŸºæ–¼ 1655 å€‹ py2mermaid ç”Ÿæˆçš„è©³ç´°æµç¨‹åœ–
"""

from pathlib import Path
import re
from collections import defaultdict
from typing import Dict, List, Tuple
import json

class CommunicationPatternExtractor:
    """é€šè¨Šæ¨¡å¼æå–å™¨"""
    
    def __init__(self, diagram_dir: Path):
        self.diagram_dir = diagram_dir
        self.patterns = {
            'publishes': [],     # (source_module, topic, details)
            'subscribes': [],    # (source_module, topic, details)
            'topics': [],        # (source_module, topic_constant)
            'message_flows': [], # (from_module, to_module, topic)
        }
        self.stats = defaultdict(int)
    
    def extract_all_patterns(self):
        """æå–æ‰€æœ‰é€šè¨Šæ¨¡å¼"""
        print("ğŸ” é–‹å§‹æƒææµç¨‹åœ–...")
        
        mmd_files = list(self.diagram_dir.glob("**/*.mmd"))
        total = len(mmd_files)
        
        for idx, mmd_file in enumerate(mmd_files, 1):
            if idx % 100 == 0:
                print(f"  é€²åº¦: {idx}/{total}")
            
            try:
                content = mmd_file.read_text(encoding='utf-8')
                module_name = self._extract_module_name(mmd_file.stem)
                
                # æå–å„ç¨®æ¨¡å¼
                self._find_publishes(content, module_name, mmd_file.stem)
                self._find_subscribes(content, module_name, mmd_file.stem)
                self._find_topics(content, module_name)
                self._find_message_handlers(content, module_name)
                
            except Exception as e:
                print(f"  âš ï¸ è™•ç† {mmd_file.name} æ™‚å‡ºéŒ¯: {e}")
        
        print(f"âœ… å®Œæˆæƒæ {total} å€‹æµç¨‹åœ–\n")
        self._calculate_stats()
    
    def _extract_module_name(self, filename: str) -> str:
        """å¾æª”æ¡ˆåæå–æ¨¡çµ„åç¨±"""
        # ç¯„ä¾‹: core_aiva_core_messaging_task_dispatcher_Module â†’ Core.TaskDispatcher
        parts = filename.split('_')
        
        if 'core' in parts[:2]:
            return f"Core.{parts[-2] if parts[-1] == 'Module' else parts[-1]}"
        elif 'function' in parts[:2]:
            func_type = parts[2] if len(parts) > 2 else 'unknown'
            return f"Function.{func_type.upper()}"
        elif 'scan' in parts[:2]:
            return "Scan"
        elif 'integration' in parts[:2]:
            return "Integration"
        else:
            return parts[0].capitalize()
    
    def _find_publishes(self, content: str, module: str, filename: str):
        """æŸ¥æ‰¾ publish èª¿ç”¨"""
        # åŒ¹é…æ¨¡å¼: broker.publish(...) æˆ– publish(...)
        patterns = [
            r'broker\.publish\s*\((.*?)\)',
            r'self\.broker\.publish\s*\((.*?)\)',
            r'\.publish\s*\((.*?)\)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches:
                # å˜—è©¦æå– topic
                topic = self._extract_topic_from_call(match)
                if topic:
                    self.patterns['publishes'].append((module, topic, filename))
                    self.stats['total_publishes'] += 1
    
    def _find_subscribes(self, content: str, module: str, filename: str):
        """æŸ¥æ‰¾ subscribe èª¿ç”¨"""
        patterns = [
            r'broker\.subscribe\s*\((.*?)\)',
            r'self\.broker\.subscribe\s*\((.*?)\)',
            r'\.subscribe\s*\((.*?)\)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches:
                topic = self._extract_topic_from_call(match)
                if topic:
                    self.patterns['subscribes'].append((module, topic, filename))
                    self.stats['total_subscribes'] += 1
    
    def _find_topics(self, content: str, module: str):
        """æŸ¥æ‰¾ Topic å¸¸é‡ä½¿ç”¨"""
        # åŒ¹é…: Topic.TASKS_FUNCTION_SQLI ç­‰
        pattern = r'Topic\.((?:TASKS|RESULTS|EVENTS|COMMANDS|STATUS|FEEDBACK|LOG)_[A-Z_]+)'
        matches = re.findall(pattern, content)
        
        for match in matches:
            full_topic = f"Topic.{match}"
            self.patterns['topics'].append((module, full_topic))
            self.stats['unique_topics'] = len(set([t for _, t in self.patterns['topics']]))
    
    def _find_message_handlers(self, content: str, module: str):
        """æŸ¥æ‰¾æ¶ˆæ¯è™•ç†å‡½å¼"""
        # åŒ¹é…: async def _handle_message, def process_task ç­‰
        patterns = [
            r'def\s+(_handle_\w+|process_\w+|_on_\w+)\s*\(',
            r'async\s+def\s+(_handle_\w+|process_\w+|_on_\w+)\s*\(',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content)
            self.stats[f'{module}_handlers'] += len(matches)
    
    def _extract_topic_from_call(self, call_str: str) -> str:
        """å¾å‡½å¼èª¿ç”¨ä¸­æå– Topic"""
        # å˜—è©¦åŒ¹é… Topic.XXX
        topic_match = re.search(r'Topic\.([A-Z_]+)', call_str)
        if topic_match:
            return f"Topic.{topic_match.group(1)}"
        
        # å˜—è©¦åŒ¹é…å­—ä¸²å¸¸é‡
        string_match = re.search(r'["\']([a-z_.]+)["\']', call_str)
        if string_match:
            return string_match.group(1)
        
        return None
    
    def _calculate_stats(self):
        """è¨ˆç®—çµ±è¨ˆè³‡æ–™"""
        # æ¨¡çµ„ç™¼å¸ƒçµ±è¨ˆ
        publish_by_module = defaultdict(int)
        for module, _, _ in self.patterns['publishes']:
            publish_by_module[module] += 1
        self.stats['publish_by_module'] = dict(publish_by_module)
        
        # æ¨¡çµ„è¨‚é–±çµ±è¨ˆ
        subscribe_by_module = defaultdict(int)
        for module, _, _ in self.patterns['subscribes']:
            subscribe_by_module[module] += 1
        self.stats['subscribe_by_module'] = dict(subscribe_by_module)
        
        # Topic ä½¿ç”¨çµ±è¨ˆ
        topic_usage = defaultdict(int)
        for _, topic in self.patterns['topics']:
            topic_usage[topic] += 1
        self.stats['topic_usage'] = dict(sorted(topic_usage.items(), key=lambda x: -x[1]))
        
        # å»ºç«‹é€šè¨Šæµ
        self._build_message_flows()
    
    def _build_message_flows(self):
        """å»ºç«‹æ¶ˆæ¯æµå‘é—œä¿‚"""
        # Publisher -> Topic æ˜ å°„
        topic_publishers = defaultdict(set)
        for module, topic, _ in self.patterns['publishes']:
            topic_publishers[topic].add(module)
        
        # Topic -> Subscriber æ˜ å°„
        topic_subscribers = defaultdict(set)
        for module, topic, _ in self.patterns['subscribes']:
            topic_subscribers[topic].add(module)
        
        # å»ºç«‹ Publisher -> Subscriber æµ
        for topic in set(topic_publishers.keys()) | set(topic_subscribers.keys()):
            publishers = topic_publishers.get(topic, set())
            subscribers = topic_subscribers.get(topic, set())
            
            for pub in publishers:
                for sub in subscribers:
                    if pub != sub:  # é¿å…è‡ªå·±ç™¼é€çµ¦è‡ªå·±
                        self.patterns['message_flows'].append((pub, sub, topic))
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Š"""
        lines = [
            "# AIVA é€šè¨Šæ¨¡å¼åˆ†æå ±å‘Š",
            "",
            f"**ç”Ÿæˆæ™‚é–“**: 2025-10-16",
            f"**åˆ†ææª”æ¡ˆæ•¸**: {self.stats.get('total_publishes', 0) + self.stats.get('total_subscribes', 0)}",
            "",
            "---",
            "",
            "## ğŸ“Š æ•´é«”çµ±è¨ˆ",
            "",
            f"- **ç¸½ç™¼å¸ƒæ¬¡æ•¸**: {self.stats.get('total_publishes', 0)}",
            f"- **ç¸½è¨‚é–±æ¬¡æ•¸**: {self.stats.get('total_subscribes', 0)}",
            f"- **å”¯ä¸€ Topic æ•¸é‡**: {self.stats.get('unique_topics', 0)}",
            f"- **æ¶ˆæ¯æµå‘æ•¸é‡**: {len(self.patterns['message_flows'])}",
            "",
            "---",
            "",
        ]
        
        # Publisher çµ±è¨ˆ
        lines.extend([
            "## ğŸ“¤ Publisher çµ±è¨ˆ (æŒ‰æ¨¡çµ„)",
            "",
            "| æ¨¡çµ„ | ç™¼å¸ƒæ¬¡æ•¸ |",
            "|------|---------|",
        ])
        
        for module, count in sorted(
            self.stats.get('publish_by_module', {}).items(),
            key=lambda x: -x[1]
        ):
            lines.append(f"| {module} | {count} |")
        
        lines.extend(["", "---", ""])
        
        # Subscriber çµ±è¨ˆ
        lines.extend([
            "## ğŸ“¥ Subscriber çµ±è¨ˆ (æŒ‰æ¨¡çµ„)",
            "",
            "| æ¨¡çµ„ | è¨‚é–±æ¬¡æ•¸ |",
            "|------|---------|",
        ])
        
        for module, count in sorted(
            self.stats.get('subscribe_by_module', {}).items(),
            key=lambda x: -x[1]
        ):
            lines.append(f"| {module} | {count} |")
        
        lines.extend(["", "---", ""])
        
        # Topic ä½¿ç”¨çµ±è¨ˆ
        lines.extend([
            "## ğŸ·ï¸ Topic ä½¿ç”¨é »ç‡ (Top 30)",
            "",
            "| Topic | ä½¿ç”¨æ¬¡æ•¸ | é¡å‹ |",
            "|-------|---------|------|",
        ])
        
        for topic, count in list(self.stats.get('topic_usage', {}).items())[:30]:
            topic_type = self._classify_topic(topic)
            lines.append(f"| `{topic}` | {count} | {topic_type} |")
        
        lines.extend(["", "---", ""])
        
        # æ¶ˆæ¯æµå‘
        lines.extend([
            "## ğŸ”„ ä¸»è¦æ¶ˆæ¯æµå‘ (Top 20)",
            "",
            "| ç™¼é€æ–¹ | æ¥æ”¶æ–¹ | Topic |",
            "|-------|-------|-------|",
        ])
        
        # è¨ˆç®—æµå‘é »ç‡
        flow_counts = defaultdict(int)
        for pub, sub, topic in self.patterns['message_flows']:
            flow_counts[(pub, sub, topic)] += 1
        
        for (pub, sub, topic), count in sorted(
            flow_counts.items(),
            key=lambda x: -x[1]
        )[:20]:
            lines.append(f"| {pub} | {sub} | `{topic}` |")
        
        lines.extend(["", "---", ""])
        
        # é€šè¨Šæ¨¡å¼åˆ†é¡
        lines.extend(self._generate_pattern_classification())
        
        return "\n".join(lines)
    
    def _classify_topic(self, topic: str) -> str:
        """åˆ†é¡ Topic é¡å‹"""
        if 'TASKS_' in topic:
            return "ğŸ“‹ ä»»å‹™æ´¾ç™¼"
        elif 'RESULTS_' in topic:
            return "ğŸ“Š çµæœå›å ±"
        elif 'EVENTS_' in topic:
            return "ğŸ¯ äº‹ä»¶å»£æ’­"
        elif 'COMMANDS_' in topic:
            return "ğŸ® æŒ‡ä»¤æ§åˆ¶"
        elif 'STATUS_' in topic:
            return "ğŸ’¡ ç‹€æ…‹åŒæ­¥"
        elif 'FEEDBACK_' in topic:
            return "ğŸ” åé¥‹å¾ªç’°"
        elif 'LOG_' in topic:
            return "ğŸ“ æ—¥èªŒèšåˆ"
        else:
            return "â“ å…¶ä»–"
    
    def _generate_pattern_classification(self) -> List[str]:
        """ç”Ÿæˆé€šè¨Šæ¨¡å¼åˆ†é¡"""
        lines = [
            "## ğŸ¯ é€šè¨Šæ¨¡å¼åˆ†é¡",
            "",
        ]
        
        # æŒ‰ Topic é¡å‹åˆ†çµ„
        patterns_by_type = defaultdict(list)
        for pub, sub, topic in self.patterns['message_flows']:
            pattern_type = self._classify_topic(topic)
            patterns_by_type[pattern_type].append((pub, sub, topic))
        
        for pattern_type, flows in sorted(patterns_by_type.items()):
            lines.extend([
                f"### {pattern_type}",
                "",
                f"**æµå‘æ•¸é‡**: {len(flows)}",
                "",
            ])
            
            # åˆ—å‡ºå‰ 5 å€‹ç¯„ä¾‹
            if flows:
                lines.append("**ç¯„ä¾‹**:")
                lines.append("")
                for pub, sub, topic in flows[:5]:
                    lines.append(f"- {pub} â†’ {sub} (`{topic}`)")
                if len(flows) > 5:
                    lines.append(f"- ... é‚„æœ‰ {len(flows) - 5} å€‹")
                lines.append("")
        
        return lines
    
    def export_graph(self, output_file: Path):
        """åŒ¯å‡ºé€šè¨Šåœ– (GraphViz DOT æ ¼å¼)"""
        lines = [
            "digraph communication {",
            "  rankdir=LR;",
            "  node [shape=box, style=rounded];",
            "  ",
            "  // æ¨¡çµ„ç¯€é»",
        ]
        
        # æ”¶é›†æ‰€æœ‰æ¨¡çµ„
        all_modules = set()
        for pub, sub, _ in self.patterns['message_flows']:
            all_modules.add(pub)
            all_modules.add(sub)
        
        # æ·»åŠ æ¨¡çµ„ç¯€é»ï¼ˆæŒ‰é¡å‹è‘—è‰²ï¼‰
        for module in sorted(all_modules):
            color = self._get_module_color(module)
            lines.append(f'  "{module}" [fillcolor="{color}", style="filled,rounded"];')
        
        lines.extend([
            "  ",
            "  // æ¶ˆæ¯æµå‘",
        ])
        
        # æ·»åŠ é‚Šï¼ˆæŒ‰ Topic é¡å‹åˆ†çµ„ï¼‰
        flow_groups = defaultdict(list)
        for pub, sub, topic in self.patterns['message_flows']:
            flow_groups[(pub, sub)].append(topic)
        
        for (pub, sub), topics in flow_groups.items():
            # åˆä½µç›¸åŒè·¯å¾‘çš„å¤šå€‹ Topic
            if len(topics) == 1:
                label = topics[0].replace('Topic.', '')
            else:
                label = f"{len(topics)} topics"
            
            lines.append(f'  "{pub}" -> "{sub}" [label="{label}"];')
        
        lines.append("}")
        
        output_file.write_text("\n".join(lines), encoding='utf-8')
        print(f"âœ… é€šè¨Šåœ–å·²åŒ¯å‡º: {output_file}")
    
    def _get_module_color(self, module: str) -> str:
        """å–å¾—æ¨¡çµ„é¡è‰²"""
        if module.startswith('Core'):
            return "lightblue"
        elif module.startswith('Function'):
            return "lightgreen"
        elif module.startswith('Scan'):
            return "lightyellow"
        elif module.startswith('Integration'):
            return "lightpink"
        else:
            return "lightgray"
    
    def export_json(self, output_file: Path):
        """åŒ¯å‡º JSON æ ¼å¼è³‡æ–™"""
        data = {
            'stats': dict(self.stats),
            'patterns': {
                'publishes': [
                    {'module': m, 'topic': t, 'source': s}
                    for m, t, s in self.patterns['publishes']
                ],
                'subscribes': [
                    {'module': m, 'topic': t, 'source': s}
                    for m, t, s in self.patterns['subscribes']
                ],
                'message_flows': [
                    {'from': pub, 'to': sub, 'topic': topic}
                    for pub, sub, topic in self.patterns['message_flows']
                ],
            },
            'metadata': {
                'generated_at': '2025-10-16',
                'total_diagrams_scanned': len(list(self.diagram_dir.glob("**/*.mmd"))),
            }
        }
        
        output_file.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding='utf-8')
        print(f"âœ… JSON è³‡æ–™å·²åŒ¯å‡º: {output_file}")


def main():
    """ä¸»å‡½å¼"""
    print("=" * 60)
    print("ğŸ” AIVA é€šè¨Šæ¨¡å¼æå–å·¥å…·")
    print("=" * 60)
    print()
    
    # è¨­å®šè·¯å¾‘
    base_dir = Path(__file__).parent.parent.parent
    diagram_dir = base_dir / "_out1101016" / "mermaid_details" / "all_services"
    output_dir = base_dir / "_out1101016"
    
    if not diagram_dir.exists():
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æµç¨‹åœ–ç›®éŒ„ {diagram_dir}")
        return
    
    # åŸ·è¡Œæå–
    extractor = CommunicationPatternExtractor(diagram_dir)
    extractor.extract_all_patterns()
    
    # ç”Ÿæˆå ±å‘Š
    print("ğŸ“ ç”Ÿæˆå ±å‘Š...")
    report = extractor.generate_report()
    report_file = output_dir / "COMMUNICATION_PATTERN_ANALYSIS.md"
    report_file.write_text(report, encoding='utf-8')
    print(f"  âœ… {report_file.name}")
    
    # åŒ¯å‡ºé€šè¨Šåœ–
    print("\nğŸ¨ åŒ¯å‡ºé€šè¨Šåœ–...")
    graph_file = output_dir / "communication_graph.dot"
    extractor.export_graph(graph_file)
    
    # åŒ¯å‡º JSON
    print("\nğŸ’¾ åŒ¯å‡º JSON è³‡æ–™...")
    json_file = output_dir / "communication_patterns.json"
    extractor.export_json(json_file)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print("\nğŸ“Œ å¾ŒçºŒæ­¥é©Ÿ:")
    print(f"  1. æŸ¥çœ‹åˆ†æå ±å‘Š: {report_file.name}")
    print(f"  2. ç”¢ç”Ÿé€šè¨Šåœ– PNG:")
    print(f"     dot -Tpng {graph_file.name} -o communication_graph.png")
    print(f"  3. æŸ¥çœ‹ JSON è³‡æ–™: {json_file.name}")
    print("=" * 60)


if __name__ == "__main__":
    main()
