# AIVA æ ¸å¿ƒæ¨¡çµ„é€šè¨Šæµç¨‹å®Œæ•´åˆ†æ

> **ç”Ÿæˆæ™‚é–“**: 2025-10-16  
> **è³‡æ–™ä¾†æº**: 1655 å€‹ py2mermaid æµç¨‹åœ– + 14 å€‹æ¶æ§‹åœ–  
> **åˆ†æç¯„åœ**: Core â†’ Scan/Function é›™å‘é€šè¨Šæµç¨‹

---

## ğŸ“‹ ç›®éŒ„

1. [æ ¸å¿ƒé€šè¨Šæ¶æ§‹](#æ ¸å¿ƒé€šè¨Šæ¶æ§‹)
2. [å®Œæ•´æŒ‡ä»¤ç™¼é€æµç¨‹](#å®Œæ•´æŒ‡ä»¤ç™¼é€æµç¨‹)
3. [çµæœåé¥‹æ”¶é›†æµç¨‹](#çµæœåé¥‹æ”¶é›†æµç¨‹)
4. [é—œéµæµç¨‹åœ–çµ„åˆ](#é—œéµæµç¨‹åœ–çµ„åˆ)
5. [CLI æŒ‡ä»¤åƒè€ƒ](#cli-æŒ‡ä»¤åƒè€ƒ)
6. [çµ„åœ–è…³æœ¬å»ºè­°](#çµ„åœ–è…³æœ¬å»ºè­°)

---

## 1. æ ¸å¿ƒé€šè¨Šæ¶æ§‹

### 1.1 é€šè¨Šå±¤ç´šçµæ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Core Module (æŒ‡æ®ä¸­å¿ƒ)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TaskDispatcher â”€â”€â”                    â”Œâ”€â”€ ResultCollector  â”‚
â”‚                   â”‚                    â”‚                     â”‚
â”‚  _get_topic_for_tool()  MessageBroker  _set_pending_result()â”‚
â”‚  _build_message()       (RabbitMQ)     register_handler()   â”‚
â”‚  _build_task_payload()                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Topic è·¯ç”±è¡¨     â”‚     â”‚  Result Topics  â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ tasks.scan.*    â”‚     â”‚ results.scan.* â”‚
         â”‚ tasks.function.*â”‚     â”‚ results.func.* â”‚
         â”‚ tasks.ai.*      â”‚     â”‚ results.ai.*   â”‚
         â”‚ tasks.rag.*     â”‚     â”‚ events.*       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            RabbitMQ Message Queue                  â”‚
    â”‚  Exchange: aiva.tasks (TOPIC)                     â”‚
    â”‚  QoS: prefetch_count=10, persistent=True          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Scan Worker    â”‚     â”‚ Function Worker â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ - run()         â”‚     â”‚ - run()         â”‚
         â”‚ - _perform_scan â”‚     â”‚ - process_task()â”‚
         â”‚ - publish resultâ”‚     â”‚ - _execute_task â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 é—œéµçµ„ä»¶å°æ‡‰æµç¨‹åœ–

| çµ„ä»¶ | æµç¨‹åœ–æª”æ¡ˆ | åŠŸèƒ½æè¿° |
|------|-----------|---------|
| **TaskDispatcher** | `core_aiva_core_messaging_task_dispatcher_Module.mmd` | ä»»å‹™æ´¾ç™¼å™¨ä¸»æ¨¡çµ„ |
| â”œâ”€ _get_topic_for_tool | `..._Function___get_topic_for_tool.mmd` | æ ¹æ“šå·¥å…·é¡å‹æ˜ å°„ Topic |
| â”œâ”€ _build_message | `..._Function___build_message.mmd` | æ§‹å»º AivaMessage |
| â”œâ”€ _build_task_payload | `..._Function___build_task_payload.mmd` | æ§‹å»º FunctionTaskPayload |
| **ResultCollector** | `core_aiva_core_messaging_result_collector_Module.mmd` | çµæœæ”¶é›†å™¨ä¸»æ¨¡çµ„ |
| â”œâ”€ register_handler | `..._Function__register_handler.mmd` | è¨»å†Šçµæœè™•ç†å™¨ |
| â”œâ”€ _set_pending_result | `..._Function___set_pending_result.mmd` | è¨­ç½®å¾…è™•ç†çµæœ |
| **MessageBroker** | `core_aiva_core_messaging_message_broker_Module.mmd` | RabbitMQ æŠ½è±¡å±¤ |
| **MQ Infrastructure** | `aiva_common_mq_Module.mmd` | MQ åŸºç¤è¨­æ–½ (RabbitBroker) |
| **Scan Worker** | `scan_aiva_scan_worker_Module.mmd` | æƒææ¨¡çµ„ Worker |
| **SQLi Worker** | `function_function_sqli_aiva_func_sqli_worker_Module.mmd` | SQL æ³¨å…¥æª¢æ¸¬ Worker |

---

## 2. å®Œæ•´æŒ‡ä»¤ç™¼é€æµç¨‹

### 2.1 æµç¨‹éšæ®µåˆ†è§£

#### **éšæ®µ 1: ä»»å‹™å‰µå»º (Coreå´)**

```mermaid
flowchart LR
    A[ç”¨æˆ¶è«‹æ±‚/è¨ˆç•«ç”Ÿæˆ] --> B[TaskDispatcher.__init__]
    B --> C[æ±ºå®šå·¥å…·é¡å‹<br/>function_sqli/scanç­‰]
    C --> D[_get_topic_for_tool]
    D --> E{Topic æ˜ å°„è¡¨}
    E -->|function_sqli| F[Topic.TASKS_FUNCTION_SQLI]
    E -->|scan| G[Topic.TASKS_SCAN_DISCOVERY]
    E -->|xss| H[Topic.TASKS_FUNCTION_XSS]
```

**å°æ‡‰æµç¨‹åœ–**:
- `core_aiva_core_messaging_task_dispatcher_Function___get_topic_for_tool.mmd`

**æ ¸å¿ƒç¨‹å¼ç¢¼é‚è¼¯** (å¾æµç¨‹åœ–æå–):
```python
topic_map = {
    'function_sqli': Topic.TASKS_FUNCTION_SQLI,
    'function_xss': Topic.TASKS_FUNCTION_XSS,
    'function_ssrf': Topic.TASKS_FUNCTION_SSRF,
    'function_idor': Topic.TASKS_FUNCTION_IDOR,
    'scan': Topic.TASKS_SCAN_DISCOVERY,
    # ... æ›´å¤šæ˜ å°„
}
return topic_map.get(tool_type, Topic.TASKS_DEFAULT)
```

---

#### **éšæ®µ 2: æ¶ˆæ¯æ§‹å»º (Coreå´)**

```mermaid
flowchart TB
    A[_build_task_payload] --> B[å‰µå»º FunctionTaskPayload]
    B --> C[task_id<br/>scan_id<br/>parameters]
    C --> D[_build_message]
    D --> E[å‰µå»º MessageHeader]
    E --> F[message_id = uuid4<br/>timestamp = UTC.now]
    F --> G[å‰µå»º AivaMessage]
    G --> H[header + payload]
    H --> I[è¿”å›å®Œæ•´æ¶ˆæ¯]
```

**å°æ‡‰æµç¨‹åœ–**:
- `core_aiva_core_messaging_task_dispatcher_Function___build_task_payload.mmd`
- `core_aiva_core_messaging_task_dispatcher_Function___build_message.mmd`

**æ¶ˆæ¯çµæ§‹** (å¾ schemas æµç¨‹åœ–æå–):
```python
AivaMessage:
  - header: MessageHeader
    - message_id: UUID
    - timestamp: datetime (UTC)
    - source: ModuleName.CORE
    - topic: Topic (å¦‚ TASKS_FUNCTION_SQLI)
  - payload: FunctionTaskPayload
    - task_id: str
    - scan_id: str
    - asset: Asset (url, method, params)
    - config: DetectionConfig
    - strategy: str
```

---

#### **éšæ®µ 3: æ¶ˆæ¯ç™¼å¸ƒ (Coreå´)**

```mermaid
flowchart TB
    A[TaskDispatcher.dispatch] --> B[broker.publish]
    B --> C{MessageBroker é¡å‹}
    C -->|RabbitBroker| D[aio_pika.publish]
    C -->|InMemoryBroker| E[æœ¬åœ°éšŠåˆ—.put]
    D --> F[RabbitMQ Exchange<br/>aiva.tasks]
    F --> G[è·¯ç”±åˆ°å°æ‡‰ Queue<br/>åŸºæ–¼ Topic]
    G --> H[Worker è¨‚é–±éšŠåˆ—]
```

**å°æ‡‰æµç¨‹åœ–**:
- `aiva_common_mq_Module.mmd` (RabbitBroker/InMemoryBroker)

**RabbitMQ é…ç½®** (å¾æµç¨‹åœ–æ¨å°):
- Exchange: `aiva.tasks` (TOPIC é¡å‹)
- Routing Key: `tasks.function.sqli` / `tasks.scan.discovery`
- QoS: `prefetch_count=10`
- Persistence: `delivery_mode=2` (æŒä¹…åŒ–)

---

### 2.2 Topic è·¯ç”±å®Œæ•´æ˜ å°„è¡¨

| å·¥å…·é¡å‹ | Topic å¸¸é‡ | Routing Key | è¨‚é–± Worker |
|---------|-----------|-------------|------------|
| **Scan Discovery** | `TASKS_SCAN_DISCOVERY` | `tasks.scan.discovery` | Scan Worker |
| **SQL Injection** | `TASKS_FUNCTION_SQLI` | `tasks.function.sqli` | SQLi Worker |
| **XSS** | `TASKS_FUNCTION_XSS` | `tasks.function.xss` | XSS Worker |
| **SSRF** | `TASKS_FUNCTION_SSRF` | `tasks.function.ssrf` | SSRF Worker |
| **IDOR** | `TASKS_FUNCTION_IDOR` | `tasks.function.idor` | IDOR Worker |
| **AI Analysis** | `TASKS_AI_ANALYZE` | `tasks.ai.analyze` | AI Worker |
| **RAG Query** | `TASKS_RAG_QUERY` | `tasks.rag.query` | RAG Worker |

*(å¾ `_get_topic_for_tool` æµç¨‹åœ–æå–)*

---

## 3. çµæœåé¥‹æ”¶é›†æµç¨‹

### 3.1 Worker ç«¯çµæœç™¼å¸ƒ

```mermaid
flowchart TB
    A[Worker åŸ·è¡Œæª¢æ¸¬] --> B{æª¢æ¸¬çµæœ}
    B -->|ç™¼ç¾æ¼æ´| C[å‰µå»º FindingPayload]
    B -->|ç„¡æ¼æ´| D[å‰µå»º ExecutionResult]
    C --> E[SqliResultBinderPublisher<br/>æˆ–å…¶ä»– ResultPublisher]
    D --> E
    E --> F[æ§‹å»º AivaMessage]
    F --> G[topic = RESULTS_FUNCTION_SQLI]
    G --> H[broker.publish]
    H --> I[ç™¼é€åˆ° results.* Queue]
```

**å°æ‡‰æµç¨‹åœ–**:
- `function_function_sqli_aiva_func_sqli_result_binder_publisher_Module.mmd`
- `function_function_ssrf_aiva_func_ssrf_result_publisher_Module.mmd`
- `function_function_xss_aiva_func_xss_result_publisher_Module.mmd`

**Worker åŸ·è¡Œæµç¨‹** (ä»¥ SQLi ç‚ºä¾‹):
```mermaid
sequenceDiagram
    participant MQ as RabbitMQ
    participant SW as SqliWorkerService
    participant ORC as SqliOrchestrator
    participant ENG as DetectionEngine
    participant PUB as ResultPublisher
    
    MQ->>SW: tasks.function.sqli æ¶ˆæ¯
    SW->>SW: _consume_queue()
    SW->>SW: process_task(message)
    SW->>ORC: execute(task_payload)
    ORC->>ENG: detect(url, params)
    ENG-->>ORC: DetectionResult
    ORC-->>SW: FindingPayload / None
    SW->>PUB: publish(result)
    PUB->>MQ: results.function.sqli
```

---

### 3.2 Core ç«¯çµæœæ”¶é›†

```mermaid
flowchart TB
    A[ResultCollector.__init__] --> B[è¨‚é–± results.* Topics]
    B --> C[broker.subscribe<br/>results.function.*]
    C --> D[broker.subscribe<br/>results.scan.*]
    D --> E[broker.subscribe<br/>results.ai.*]
    E --> F[è¨»å†Š Handler]
    F --> G{æ”¶åˆ°æ¶ˆæ¯}
    G --> H[_set_pending_result]
    H --> I[è§¸ç™¼ registered_handler]
    I --> J[è™•ç†çµæœ<br/>å„²å­˜/é€šçŸ¥/è§¸ç™¼ä¸‹ä¸€æ­¥]
```

**å°æ‡‰æµç¨‹åœ–**:
- `core_aiva_core_messaging_result_collector_Module.mmd`
- `core_aiva_core_messaging_result_collector_Function__register_handler.mmd`
- `core_aiva_core_messaging_result_collector_Function___set_pending_result.mmd`

**Result Topic æ˜ å°„è¡¨**:

| Result Type | Topic | ä¾†æº Worker | è™•ç†é‚è¼¯ |
|-------------|-------|------------|---------|
| Scan Results | `RESULTS_SCAN_DISCOVERY` | Scan Worker | æ›´æ–° Asset åº« |
| SQLi Findings | `RESULTS_FUNCTION_SQLI` | SQLi Worker | è¨˜éŒ„æ¼æ´ â†’ AI åˆ†æ |
| XSS Findings | `RESULTS_FUNCTION_XSS` | XSS Worker | è¨˜éŒ„æ¼æ´ â†’ é¢¨éšªè©•ä¼° |
| SSRF Findings | `RESULTS_FUNCTION_SSRF` | SSRF Worker | è¨˜éŒ„æ¼æ´ â†’ å…§ç¶²æ¢æ¸¬ |
| AI Analysis | `RESULTS_AI_ANALYSIS` | AI Worker | æ›´æ–° RAG çŸ¥è­˜åº« |
| Integration | `RESULTS_INTEGRATION_ALL` | Integration | ç”Ÿæˆå ±å‘Š |

---

## 4. é—œéµæµç¨‹åœ–çµ„åˆ

### 4.1 ç«¯åˆ°ç«¯å®Œæ•´æµç¨‹ (Scan â†’ SQLi æª¢æ¸¬)

**çµ„åˆçš„æµç¨‹åœ–æª”æ¡ˆ**:
1. `core_aiva_core_messaging_task_dispatcher_Function___get_topic_for_tool.mmd` (æ±ºå®š Topic)
2. `core_aiva_core_messaging_task_dispatcher_Function___build_message.mmd` (æ§‹å»ºæ¶ˆæ¯)
3. `aiva_common_mq_Module.mmd` (MQ ç™¼é€)
4. `function_function_sqli_aiva_func_sqli_worker_Module.mmd` (Worker æ¥æ”¶)
5. `function_function_sqli_aiva_func_sqli_engines_*_Module.mmd` (å¼•æ“æª¢æ¸¬)
6. `function_function_sqli_aiva_func_sqli_result_binder_publisher_Module.mmd` (ç™¼å¸ƒçµæœ)
7. `core_aiva_core_messaging_result_collector_Function___set_pending_result.mmd` (æ”¶é›†çµæœ)

**æ•´åˆæ™‚åºåœ–**:
```mermaid
sequenceDiagram
    autonumber
    participant User as ç”¨æˆ¶/è¨ˆç•«ç”Ÿæˆå™¨
    participant TD as TaskDispatcher
    participant MQ as RabbitMQ
    participant SW as SqliWorker
    participant ENG as DetectionEngine
    participant RP as ResultPublisher
    participant RC as ResultCollector
    participant DB as çµæœè™•ç†å™¨
    
    User->>TD: dispatch(tool='function_sqli')
    activate TD
    TD->>TD: _get_topic_for_tool('function_sqli')
    Note over TD: è¿”å› Topic.TASKS_FUNCTION_SQLI
    TD->>TD: _build_task_payload(asset, config)
    TD->>TD: _build_message(topic, payload)
    TD->>MQ: publish(topic='tasks.function.sqli')
    deactivate TD
    
    MQ->>SW: subscribe callback (AivaMessage)
    activate SW
    SW->>SW: process_task(message)
    SW->>ENG: detect(url='http://example.com/api')
    activate ENG
    Note over ENG: ErrorEngine<br/>BooleanEngine<br/>TimeEngine<br/>UnionEngine
    ENG-->>SW: DetectionResult (æ¼æ´/ç„¡æ¼æ´)
    deactivate ENG
    SW->>RP: publish_result(finding)
    deactivate SW
    
    RP->>MQ: publish(topic='results.function.sqli')
    MQ->>RC: subscribe callback (Result)
    activate RC
    RC->>RC: _set_pending_result(result)
    RC->>DB: trigger_handler(result)
    Note over DB: å„²å­˜åˆ°è³‡æ–™åº«<br/>æ›´æ–°é¢¨éšªåˆ†æ•¸<br/>è§¸ç™¼ AI åˆ†æ
    deactivate RC
```

---

### 4.2 å¤šæ¨¡çµ„å”åŒæµç¨‹ (Scan â†’ Function â†’ AI â†’ Integration)

```mermaid
graph TB
    subgraph "Core ç™¼é€éšæ®µ"
        A[TaskDispatcher] -->|tasks.scan.discovery| B[Scan Worker]
        A -->|tasks.function.*| C[Function Worker]
        A -->|tasks.ai.analyze| D[AI Worker]
    end
    
    subgraph "åŸ·è¡Œéšæ®µ"
        B -->|Asset ç™¼ç¾| E[Asset åˆ—è¡¨]
        E -->|results.scan.discovery| F[ResultCollector]
        F -->|è§¸ç™¼| A
        C -->|æ¼æ´ç™¼ç¾| G[Finding åˆ—è¡¨]
        G -->|results.function.*| F
        D -->|åˆ†æçµæœ| H[AI å»ºè­°]
        H -->|results.ai.*| F
    end
    
    subgraph "æ•´åˆéšæ®µ"
        F -->|tasks.integration| I[Integration Worker]
        I -->|é¢¨éšªè©•ä¼°<br/>é—œè¯åˆ†æ<br/>å ±å‘Šç”Ÿæˆ| J[æœ€çµ‚å ±å‘Š]
        J -->|results.integration| F
    end
```

---

## 5. CLI æŒ‡ä»¤åƒè€ƒ

### 5.1 åŸºæ–¼æµç¨‹åœ–çš„ CLI è¨­è¨ˆ

#### **5.1.1 ä»»å‹™æ´¾ç™¼æŒ‡ä»¤**

```bash
# åŸºæœ¬èªæ³• (å¾ TaskDispatcher æµç¨‹è¨­è¨ˆ)
aiva task dispatch \
  --tool <tool_type> \          # å°æ‡‰ _get_topic_for_tool æ˜ å°„
  --target <url> \               # Asset.url
  --scan-id <scan_id> \          # FunctionTaskPayload.scan_id
  --strategy <strategy> \        # aggressive/balanced/stealth
  --config <config_file>         # DetectionConfig JSON

# ç¯„ä¾‹ 1: æ´¾ç™¼ SQL æ³¨å…¥æª¢æ¸¬ä»»å‹™
aiva task dispatch \
  --tool function_sqli \
  --target "http://example.com/api/users?id=1" \
  --scan-id "scan_20251016_001" \
  --strategy aggressive \
  --config configs/sqli_deep.json

# å°æ‡‰å…§éƒ¨æµç¨‹:
# 1. _get_topic_for_tool('function_sqli') â†’ Topic.TASKS_FUNCTION_SQLI
# 2. _build_task_payload(url, params, config)
# 3. _build_message(Topic.TASKS_FUNCTION_SQLI, payload)
# 4. broker.publish('tasks.function.sqli', message)

# ç¯„ä¾‹ 2: æ´¾ç™¼æƒæä»»å‹™
aiva task dispatch \
  --tool scan \
  --target "https://example.com" \
  --scan-id "scan_20251016_002" \
  --strategy balanced \
  --max-depth 5 \
  --max-pages 1000

# ç¯„ä¾‹ 3: æ‰¹é‡æ´¾ç™¼ (åŸºæ–¼ Scan çµæœ)
aiva task dispatch-batch \
  --from-scan scan_20251016_002 \
  --tools function_sqli,function_xss,function_ssrf \
  --priority high
```

---

#### **5.1.2 çµæœæ”¶é›†æŒ‡ä»¤**

```bash
# åŸºæœ¬èªæ³• (å¾ ResultCollector æµç¨‹è¨­è¨ˆ)
aiva result collect \
  --scan-id <scan_id> \
  --type <result_type> \         # sqli/xss/ssrf/scan/all
  --format <format> \             # json/markdown/sarif
  --output <output_file>

# ç¯„ä¾‹ 1: æ”¶é›† SQLi æª¢æ¸¬çµæœ
aiva result collect \
  --scan-id "scan_20251016_001" \
  --type sqli \
  --format json \
  --output results/sqli_findings.json

# å°æ‡‰å…§éƒ¨æµç¨‹:
# 1. ResultCollector.register_handler(result_type='sqli')
# 2. è¨‚é–± Topic.RESULTS_FUNCTION_SQLI
# 3. _set_pending_result(result) ç•¶æ”¶åˆ°æ¶ˆæ¯
# 4. è§¸ç™¼ handler â†’ å„²å­˜åˆ°æŒ‡å®šæª”æ¡ˆ

# ç¯„ä¾‹ 2: å¯¦æ™‚ç›£è½çµæœ
aiva result watch \
  --scan-id "scan_20251016_001" \
  --follow

# ç¯„ä¾‹ 3: ç­‰å¾…æ‰€æœ‰çµæœå®Œæˆ
aiva result wait \
  --scan-id "scan_20251016_001" \
  --timeout 3600 \
  --expected-tasks 50
```

---

#### **5.1.3 æ¶ˆæ¯è¿½è¹¤æŒ‡ä»¤**

```bash
# åŸºæœ¬èªæ³•
aiva message trace \
  --message-id <uuid> \
  --show-payload

# ç¯„ä¾‹: è¿½è¹¤æ¶ˆæ¯æµå‘
aiva message trace \
  --message-id "550e8400-e29b-41d4-a716-446655440000" \
  --show-payload

# è¼¸å‡º:
# Message Trace:
# â”œâ”€ Source: Core.TaskDispatcher
# â”œâ”€ Topic: tasks.function.sqli
# â”œâ”€ Published: 2025-10-16 10:30:00 UTC
# â”œâ”€ Received by: SqliWorkerService (worker-01)
# â”œâ”€ Processed: 2025-10-16 10:30:15 UTC
# â”œâ”€ Result Topic: results.function.sqli
# â””â”€ Collected by: Core.ResultCollector (2025-10-16 10:30:16 UTC)

# ç¯„ä¾‹: æŸ¥çœ‹ Topic çµ±è¨ˆ
aiva message stats \
  --topic tasks.function.sqli \
  --time-range 24h

# è¼¸å‡º:
# Topic Statistics (tasks.function.sqli):
# â”œâ”€ Messages Sent: 1,234
# â”œâ”€ Messages Consumed: 1,230
# â”œâ”€ Pending: 4
# â”œâ”€ Average Latency: 2.3s
# â””â”€ Error Rate: 0.3%
```

---

### 5.2 Worker ç®¡ç†æŒ‡ä»¤

```bash
# å•Ÿå‹• Worker (åŸºæ–¼ worker_Module.mmd æµç¨‹)
aiva worker start \
  --type sqli \                  # sqli/xss/ssrf/scan
  --workers 5 \                  # ä¸¦ç™¼ Worker æ•¸é‡
  --queue tasks.function.sqli \  # è¨‚é–±çš„ Queue
  --prefetch 10                  # QoS prefetch_count

# ç¯„ä¾‹: å•Ÿå‹• SQLi Worker
aiva worker start \
  --type sqli \
  --workers 3 \
  --config configs/sqli_worker.yaml

# å°æ‡‰å…§éƒ¨æµç¨‹:
# 1. SqliWorkerService.__init__(config)
# 2. broker.subscribe(Topic.TASKS_FUNCTION_SQLI)
# 3. run() â†’ _consume_queue() å¾ªç’°
# 4. process_task(message) è™•ç†æ¯å€‹ä»»å‹™

# æŸ¥çœ‹ Worker ç‹€æ…‹
aiva worker status

# è¼¸å‡º:
# Worker Status:
# â”œâ”€ sqli-worker-01: RUNNING (tasks: 45, errors: 2)
# â”œâ”€ sqli-worker-02: RUNNING (tasks: 48, errors: 0)
# â”œâ”€ xss-worker-01: RUNNING (tasks: 32, errors: 1)
# â””â”€ scan-worker-01: IDLE

# åœæ­¢ Worker
aiva worker stop --type sqli --worker-id sqli-worker-01
```

---

## 6. çµ„åœ–è…³æœ¬å»ºè­°

### 6.1 è‡ªå‹•åŒ–çµ„åœ–è…³æœ¬è¨­è¨ˆ

åŸºæ–¼ 1655 å€‹è©³ç´°æµç¨‹åœ–ï¼Œè¨­è¨ˆè‡ªå‹•åŒ–çµ„åœ–å·¥å…·ï¼š

**è…³æœ¬ 1: `combine_communication_flows.py`**

```python
#!/usr/bin/env python3
"""
çµ„åˆé€šè¨Šæµç¨‹åœ–è…³æœ¬
ç›®çš„: å°‡åˆ†æ•£çš„ Module/Function æµç¨‹åœ–çµ„åˆæˆç«¯åˆ°ç«¯æµç¨‹
"""

from pathlib import Path
from typing import List, Dict
import re

class MermaidFlowCombiner:
    """Mermaid æµç¨‹åœ–çµ„åˆå™¨"""
    
    def __init__(self, diagram_dir: Path):
        self.diagram_dir = diagram_dir
        self.flows = self._load_all_flows()
    
    def _load_all_flows(self) -> Dict[str, str]:
        """è¼‰å…¥æ‰€æœ‰ .mmd æª”æ¡ˆ"""
        flows = {}
        for mmd_file in self.diagram_dir.glob("**/*.mmd"):
            flows[mmd_file.stem] = mmd_file.read_text(encoding='utf-8')
        return flows
    
    def combine_task_dispatch_flow(self) -> str:
        """çµ„åˆä»»å‹™æ´¾ç™¼å®Œæ•´æµç¨‹"""
        components = [
            "core_aiva_core_messaging_task_dispatcher_Function___get_topic_for_tool",
            "core_aiva_core_messaging_task_dispatcher_Function___build_task_payload",
            "core_aiva_core_messaging_task_dispatcher_Function___build_message",
            "aiva_common_mq_Module",  # MQ ç™¼é€
        ]
        
        combined = self._merge_flowcharts(components)
        return self._add_header(combined, "ä»»å‹™æ´¾ç™¼å®Œæ•´æµç¨‹")
    
    def combine_sqli_detection_flow(self) -> str:
        """çµ„åˆ SQLi æª¢æ¸¬å®Œæ•´æµç¨‹"""
        components = [
            "function_function_sqli_aiva_func_sqli_worker_Module",
            "function_function_sqli_aiva_func_sqli_engines_error_detection_engine_Module",
            "function_function_sqli_aiva_func_sqli_engines_boolean_detection_engine_Module",
            "function_function_sqli_aiva_func_sqli_result_binder_publisher_Module",
        ]
        
        combined = self._merge_flowcharts(components)
        return self._add_header(combined, "SQLi æª¢æ¸¬å®Œæ•´æµç¨‹")
    
    def combine_result_collection_flow(self) -> str:
        """çµ„åˆçµæœæ”¶é›†å®Œæ•´æµç¨‹"""
        components = [
            "core_aiva_core_messaging_result_collector_Module",
            "core_aiva_core_messaging_result_collector_Function__register_handler",
            "core_aiva_core_messaging_result_collector_Function___set_pending_result",
        ]
        
        combined = self._merge_flowcharts(components)
        return self._add_header(combined, "çµæœæ”¶é›†å®Œæ•´æµç¨‹")
    
    def _merge_flowcharts(self, component_names: List[str]) -> str:
        """åˆä½µå¤šå€‹æµç¨‹åœ–"""
        merged_nodes = []
        merged_edges = []
        node_id_offset = 0
        
        for comp_name in component_names:
            if comp_name not in self.flows:
                print(f"è­¦å‘Š: æœªæ‰¾åˆ°æµç¨‹åœ– {comp_name}")
                continue
            
            flow_content = self.flows[comp_name]
            nodes, edges = self._parse_mermaid(flow_content)
            
            # èª¿æ•´ç¯€é» ID é¿å…è¡çª
            adjusted_nodes = self._adjust_node_ids(nodes, node_id_offset)
            adjusted_edges = self._adjust_edge_ids(edges, node_id_offset)
            
            merged_nodes.extend(adjusted_nodes)
            merged_edges.extend(adjusted_edges)
            
            node_id_offset += len(nodes)
        
        # ç”Ÿæˆæ–°çš„ Mermaid èªæ³•
        return self._generate_mermaid(merged_nodes, merged_edges)
    
    def _parse_mermaid(self, content: str) -> tuple:
        """è§£æ Mermaid æµç¨‹åœ–å…§å®¹"""
        # æå–ç¯€é»å®šç¾©
        node_pattern = r'n(\d+)\[(.*?)\]'
        nodes = re.findall(node_pattern, content)
        
        # æå–é‚Šå®šç¾©
        edge_pattern = r'n(\d+)\s*-->\s*(?:\|([^|]+)\|)?n(\d+)'
        edges = re.findall(edge_pattern, content)
        
        return nodes, edges
    
    def _adjust_node_ids(self, nodes: List, offset: int) -> List:
        """èª¿æ•´ç¯€é» ID"""
        return [(int(id) + offset, label) for id, label in nodes]
    
    def _adjust_edge_ids(self, edges: List, offset: int) -> List:
        """èª¿æ•´é‚Š ID"""
        adjusted = []
        for edge in edges:
            from_id = int(edge[0]) + offset
            to_id = int(edge[2]) + offset
            label = edge[1] if edge[1] else ""
            adjusted.append((from_id, label, to_id))
        return adjusted
    
    def _generate_mermaid(self, nodes: List, edges: List) -> str:
        """ç”Ÿæˆ Mermaid èªæ³•"""
        lines = ["flowchart TB"]
        
        # æ·»åŠ ç¯€é»
        for node_id, label in nodes:
            lines.append(f"    n{node_id}[{label}]")
        
        # æ·»åŠ é‚Š
        for from_id, label, to_id in edges:
            if label:
                lines.append(f"    n{from_id} -->|{label}| n{to_id}")
            else:
                lines.append(f"    n{from_id} --> n{to_id}")
        
        return "\n".join(lines)
    
    def _add_header(self, content: str, title: str) -> str:
        """æ·»åŠ æ¨™é¡Œè¨»é‡‹"""
        return f"""```mermaid
---
title: {title}
---
{content}
```"""
    
    def generate_all_combined_flows(self, output_dir: Path):
        """ç”Ÿæˆæ‰€æœ‰çµ„åˆæµç¨‹åœ–"""
        output_dir.mkdir(parents=True, exist_ok=True)
        
        flows = {
            "task_dispatch_complete.mmd": self.combine_task_dispatch_flow(),
            "sqli_detection_complete.mmd": self.combine_sqli_detection_flow(),
            "result_collection_complete.mmd": self.combine_result_collection_flow(),
        }
        
        for filename, content in flows.items():
            output_file = output_dir / filename
            output_file.write_text(content, encoding='utf-8')
            print(f"âœ… å·²ç”Ÿæˆ: {output_file}")


if __name__ == "__main__":
    diagram_dir = Path("_out1101016/mermaid_details/all_services")
    output_dir = Path("_out1101016/combined_flows")
    
    combiner = MermaidFlowCombiner(diagram_dir)
    combiner.generate_all_combined_flows(output_dir)
    
    print("\nğŸ‰ çµ„åœ–å®Œæˆï¼")
```

---

**è…³æœ¬ 2: `extract_communication_patterns.py`**

```python
#!/usr/bin/env python3
"""
å¾æµç¨‹åœ–ä¸­æå–é€šè¨Šæ¨¡å¼
ç›®çš„: è‡ªå‹•åˆ†ææ‰€æœ‰ broker.publish/subscribe èª¿ç”¨
"""

from pathlib import Path
import re
from collections import defaultdict

class CommunicationPatternExtractor:
    """é€šè¨Šæ¨¡å¼æå–å™¨"""
    
    def __init__(self, diagram_dir: Path):
        self.diagram_dir = diagram_dir
        self.patterns = defaultdict(list)
    
    def extract_all_patterns(self):
        """æå–æ‰€æœ‰é€šè¨Šæ¨¡å¼"""
        for mmd_file in self.diagram_dir.glob("**/*.mmd"):
            content = mmd_file.read_text(encoding='utf-8')
            
            # æŸ¥æ‰¾ broker.publish èª¿ç”¨
            publishes = self._find_publishes(content, mmd_file.stem)
            self.patterns['publishes'].extend(publishes)
            
            # æŸ¥æ‰¾ broker.subscribe èª¿ç”¨
            subscribes = self._find_subscribes(content, mmd_file.stem)
            self.patterns['subscribes'].extend(subscribes)
            
            # æŸ¥æ‰¾ Topic ä½¿ç”¨
            topics = self._find_topics(content, mmd_file.stem)
            self.patterns['topics'].extend(topics)
    
    def _find_publishes(self, content: str, source: str) -> list:
        """æŸ¥æ‰¾ publish èª¿ç”¨"""
        pattern = r'broker\.publish\((.*?)\)'
        matches = re.findall(pattern, content)
        return [(source, match) for match in matches]
    
    def _find_subscribes(self, content: str, source: str) -> list:
        """æŸ¥æ‰¾ subscribe èª¿ç”¨"""
        pattern = r'broker\.subscribe\((.*?)\)'
        matches = re.findall(pattern, content)
        return [(source, match) for match in matches]
    
    def _find_topics(self, content: str, source: str) -> list:
        """æŸ¥æ‰¾ Topic å¸¸é‡"""
        pattern = r'Topic\.(TASKS_|RESULTS_|EVENTS_|COMMANDS_)[A-Z_]+'
        matches = re.findall(pattern, content)
        return [(source, f"Topic.{match}") for match in matches]
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        report = ["# é€šè¨Šæ¨¡å¼åˆ†æå ±å‘Š\n"]
        
        # Publisher çµ±è¨ˆ
        report.append("## Publisher çµ±è¨ˆ\n")
        publish_count = defaultdict(int)
        for source, _ in self.patterns['publishes']:
            module = source.split('_')[0]
            publish_count[module] += 1
        
        for module, count in sorted(publish_count.items()):
            report.append(f"- {module}: {count} æ¬¡ç™¼å¸ƒ")
        
        # Subscriber çµ±è¨ˆ
        report.append("\n## Subscriber çµ±è¨ˆ\n")
        subscribe_count = defaultdict(int)
        for source, _ in self.patterns['subscribes']:
            module = source.split('_')[0]
            subscribe_count[module] += 1
        
        for module, count in sorted(subscribe_count.items()):
            report.append(f"- {module}: {count} æ¬¡è¨‚é–±")
        
        # Topic ä½¿ç”¨çµ±è¨ˆ
        report.append("\n## Topic ä½¿ç”¨çµ±è¨ˆ\n")
        topic_usage = defaultdict(int)
        for _, topic in self.patterns['topics']:
            topic_usage[topic] += 1
        
        for topic, count in sorted(topic_usage.items(), key=lambda x: -x[1]):
            report.append(f"- {topic}: {count} æ¬¡ä½¿ç”¨")
        
        return "\n".join(report)
    
    def export_graph(self, output_file: Path):
        """åŒ¯å‡ºé€šè¨Šåœ– (GraphViz æ ¼å¼)"""
        lines = ["digraph communication {", "  rankdir=LR;", "  node [shape=box];"]
        
        # æ·»åŠ  publish é‚Š
        for source, topic in self.patterns['publishes']:
            module = source.split('_Module')[0]
            lines.append(f'  "{module}" -> "{topic}" [label="publish"];')
        
        # æ·»åŠ  subscribe é‚Š
        for source, topic in self.patterns['subscribes']:
            module = source.split('_Module')[0]
            lines.append(f'  "{topic}" -> "{module}" [label="subscribe"];')
        
        lines.append("}")
        
        output_file.write_text("\n".join(lines), encoding='utf-8')
        print(f"âœ… é€šè¨Šåœ–å·²åŒ¯å‡º: {output_file}")


if __name__ == "__main__":
    diagram_dir = Path("_out1101016/mermaid_details/all_services")
    
    extractor = CommunicationPatternExtractor(diagram_dir)
    extractor.extract_all_patterns()
    
    # ç”Ÿæˆå ±å‘Š
    report = extractor.generate_report()
    report_file = Path("_out1101016/communication_pattern_report.md")
    report_file.write_text(report, encoding='utf-8')
    print(f"âœ… å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    # åŒ¯å‡ºé€šè¨Šåœ–
    graph_file = Path("_out1101016/communication_graph.dot")
    extractor.export_graph(graph_file)
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"å¯ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨:")
    print(f"  dot -Tpng {graph_file} -o communication_graph.png")
```

---

### 6.2 ä½¿ç”¨çµ„åœ–è…³æœ¬

```bash
# 1. çµ„åˆæ ¸å¿ƒé€šè¨Šæµç¨‹
python scripts/combine_communication_flows.py

# è¼¸å‡º:
# _out1101016/combined_flows/
# â”œâ”€â”€ task_dispatch_complete.mmd
# â”œâ”€â”€ sqli_detection_complete.mmd
# â””â”€â”€ result_collection_complete.mmd

# 2. æå–é€šè¨Šæ¨¡å¼
python scripts/extract_communication_patterns.py

# è¼¸å‡º:
# _out1101016/communication_pattern_report.md
# _out1101016/communication_graph.dot

# 3. ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨
dot -Tpng _out1101016/communication_graph.dot -o _out1101016/communication_graph.png
```

---

## 7. ç¸½çµèˆ‡å»ºè­°

### 7.1 é—œéµç™¼ç¾

åŸºæ–¼ 1655 å€‹è©³ç´°æµç¨‹åœ–çš„åˆ†æ:

1. **é€šè¨Šæ¶æ§‹æ¸…æ™°**: Core â†” Worker é›™å‘é€šè¨Šé€é RabbitMQ Topic Exchange
2. **Topic æ˜ å°„å®Œæ•´**: 66+ Topics è¦†è“‹æ‰€æœ‰æ¨¡çµ„é–“é€šè¨Š
3. **çµæœåé¥‹æ©Ÿåˆ¶å¥å…¨**: ResultCollector çµ±ä¸€æ”¶é›†æ‰€æœ‰ Worker çµæœ
4. **æµç¨‹åœ–å“è³ªé«˜**: py2mermaid ç”Ÿæˆçš„åœ–è¡¨åŒ…å«å®Œæ•´çš„ç¨‹å¼é‚è¼¯æµç¨‹

### 7.2 å¾ŒçºŒå·¥ä½œå»ºè­°

1. **ä¿®å¾©æ¸²æŸ“å•é¡Œ**:
   - éƒ¨åˆ†æµç¨‹åœ–èªæ³•éœ€è¦èª¿æ•´ (å¦‚ `mermaid.radar` â†’ `mermaid`)
   - ç‰¹æ®Šå­—å…ƒéœ€è¦æ­£ç¢ºè½‰ç¾© (`&amp;&#35;39;` â†’ `'`)

2. **CLI å·¥å…·é–‹ç™¼**:
   - åŸºæ–¼æœ¬æ–‡æª”çš„æŒ‡ä»¤è¨­è¨ˆå¯¦ç¾ `aiva` CLI
   - æ•´åˆ TaskDispatcher å’Œ ResultCollector ç‚ºæŒ‡ä»¤ä»‹é¢

3. **çµ„åœ–è…³æœ¬å®Œå–„**:
   - å¯¦ç¾ `combine_communication_flows.py`
   - å¯¦ç¾ `extract_communication_patterns.py`
   - è‡ªå‹•ç”Ÿæˆç«¯åˆ°ç«¯æµç¨‹åœ–

4. **æ–‡æª”æŒçºŒæ›´æ–°**:
   - éš¨è‘—ç¨‹å¼ç¢¼è®Šæ›´ï¼Œé‡æ–°åŸ·è¡Œ py2mermaid
   - æ›´æ–°æœ¬æ–‡æª”çš„æµç¨‹åœ–åƒç…§

---

**æ–‡æª”ç‰ˆæœ¬**: 1.0  
**æœ€å¾Œæ›´æ–°**: 2025-10-16  
**ç¶­è­·è€…**: AIVA æ¶æ§‹åœ˜éšŠ
