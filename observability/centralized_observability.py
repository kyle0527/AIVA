"""
AIVA é›†ä¸­åŒ–å¯è§€æ¸¬æ€§æ¡†æ¶
åŸºæ–¼ OpenTelemetry æ¨™æº–å¯¦æ–½åˆ†æ•£å¼è¿½è¹¤ã€é›†ä¸­åŒ–æ—¥èªŒè¨˜éŒ„å’Œå³æ™‚ç›£æ§

åŠŸèƒ½ç‰¹æ€§ï¼š
1. åˆ†æ•£å¼è¿½è¹¤ (Distributed Tracing)
2. çµæ§‹åŒ–æ—¥èªŒè¨˜éŒ„ (Structured Logging)
3. åº¦é‡æŒ‡æ¨™æ”¶é›† (Metrics Collection)
4. æ•ˆèƒ½ç›£æ§ (Performance Monitoring)
5. éŒ¯èª¤è¿½è¹¤èˆ‡è­¦å ± (Error Tracking & Alerting)
"""

import asyncio
import json
import time
import uuid
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Union
from contextlib import asynccontextmanager
import logging
from pathlib import Path
import threading
from datetime import datetime, timezone
from enum import Enum

# OpenTelemetry imports
try:
    from opentelemetry import trace, metrics
    from opentelemetry.exporter.jaeger.thrift import JaegerExporter
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.sdk.metrics import MeterProvider
    from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
    from opentelemetry.exporter.prometheus import PrometheusMetricReader
    from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
    from opentelemetry.instrumentation.requests import RequestsInstrumentor
    from opentelemetry.instrumentation.asyncio import AsyncioInstrumentor
    from opentelemetry.semantic_conventions.trace import SpanAttributes
    OPENTELEMETRY_AVAILABLE = True
except ImportError:
    OPENTELEMETRY_AVAILABLE = False
    print("âš ï¸ OpenTelemetry æœªå®‰è£ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬")

# AIVA å…§éƒ¨å°å…¥
from services.aiva_common.utils import get_logger

class ObservabilityLevel(Enum):
    """å¯è§€æ¸¬æ€§ç´šåˆ¥"""
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class MetricType(Enum):
    """åº¦é‡é¡å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"

@dataclass
class TraceContext:
    """è¿½è¹¤ä¸Šä¸‹æ–‡"""
    trace_id: str
    span_id: str
    parent_span_id: Optional[str] = None
    service_name: str = ""
    operation_name: str = ""
    start_time: float = field(default_factory=time.time)
    attributes: Dict[str, Any] = field(default_factory=dict)

@dataclass
class LogEntry:
    """æ—¥èªŒæ¢ç›®"""
    timestamp: datetime
    level: ObservabilityLevel
    service_name: str
    operation: str
    message: str
    trace_id: Optional[str] = None
    span_id: Optional[str] = None
    attributes: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None

@dataclass 
class MetricEntry:
    """åº¦é‡æ¢ç›®"""
    name: str
    value: float
    metric_type: MetricType
    timestamp: datetime
    service_name: str
    tags: Dict[str, str] = field(default_factory=dict)
    unit: Optional[str] = None

class StructuredLogger:
    """çµæ§‹åŒ–æ—¥èªŒè¨˜éŒ„å™¨"""
    
    def __init__(self, service_name: str, output_path: Optional[str] = None):
        self.service_name = service_name
        self.output_path = Path(output_path) if output_path else Path("./logs")
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # è¨­ç½®æ¨™æº–æ—¥èªŒ
        self.logger = get_logger(f"observability.{service_name}")
        
        # è¨­ç½®æª”æ¡ˆè™•ç†å™¨
        log_file = self.output_path / f"{service_name}.log"
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(
            logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        )
        self.logger.addHandler(file_handler)
        
    def log(self, level: ObservabilityLevel, operation: str, message: str, 
            trace_context: Optional[TraceContext] = None, **attributes):
        """è¨˜éŒ„çµæ§‹åŒ–æ—¥èªŒ"""
        log_entry = LogEntry(
            timestamp=datetime.now(timezone.utc),
            level=level,
            service_name=self.service_name,
            operation=operation,
            message=message,
            trace_id=trace_context.trace_id if trace_context else None,
            span_id=trace_context.span_id if trace_context else None,
            attributes=attributes
        )
        
        # è½‰æ›ç‚º JSON æ ¼å¼
        log_data = {
            "timestamp": log_entry.timestamp.isoformat(),
            "level": log_entry.level.value,
            "service": log_entry.service_name,
            "operation": log_entry.operation,
            "message": log_entry.message,
            "trace_id": log_entry.trace_id,
            "span_id": log_entry.span_id,
            "attributes": log_entry.attributes
        }
        
        # å¯«å…¥æª”æ¡ˆ
        log_file = self.output_path / f"{self.service_name}-structured.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_data, ensure_ascii=False) + '\n')
        
        # æ¨™æº–æ—¥èªŒè¼¸å‡º
        log_level = getattr(logging, level.value.upper())
        self.logger.log(log_level, f"[{operation}] {message} {attributes}")

class MetricsCollector:
    """åº¦é‡æ”¶é›†å™¨"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
        self.metrics: List[MetricEntry] = []
        self.lock = threading.Lock()
        
        # OpenTelemetry è¨­ç½®
        if OPENTELEMETRY_AVAILABLE:
            self.meter = metrics.get_meter(service_name)
            self._setup_metrics()
        
    def _setup_metrics(self):
        """è¨­ç½®åº¦é‡æŒ‡æ¨™"""
        if not OPENTELEMETRY_AVAILABLE:
            return
            
        # è«‹æ±‚è¨ˆæ•¸å™¨
        self.request_counter = self.meter.create_counter(
            name=f"{self.service_name}_requests_total",
            description="Total number of requests",
        )
        
        # éŸ¿æ‡‰æ™‚é–“ç›´æ–¹åœ–
        self.response_time_histogram = self.meter.create_histogram(
            name=f"{self.service_name}_response_time_seconds",
            description="Response time in seconds",
            unit="s"
        )
        
        # éŒ¯èª¤è¨ˆæ•¸å™¨
        self.error_counter = self.meter.create_counter(
            name=f"{self.service_name}_errors_total",
            description="Total number of errors",
        )
        
        # æ´»èºé€£ç·šæ•¸
        self.active_connections_gauge = self.meter.create_up_down_counter(
            name=f"{self.service_name}_active_connections",
            description="Number of active connections",
        )
    
    def increment_counter(self, name: str, value: float = 1.0, **tags):
        """å¢åŠ è¨ˆæ•¸å™¨"""
        metric = MetricEntry(
            name=name,
            value=value,
            metric_type=MetricType.COUNTER,
            timestamp=datetime.now(timezone.utc),
            service_name=self.service_name,
            tags=tags
        )
        
        with self.lock:
            self.metrics.append(metric)
            
        if OPENTELEMETRY_AVAILABLE and hasattr(self, 'request_counter'):
            self.request_counter.add(value, tags)
    
    def record_histogram(self, name: str, value: float, **tags):
        """è¨˜éŒ„ç›´æ–¹åœ–å€¼"""
        metric = MetricEntry(
            name=name,
            value=value,
            metric_type=MetricType.HISTOGRAM,
            timestamp=datetime.now(timezone.utc),
            service_name=self.service_name,
            tags=tags
        )
        
        with self.lock:
            self.metrics.append(metric)
            
        if OPENTELEMETRY_AVAILABLE and hasattr(self, 'response_time_histogram'):
            self.response_time_histogram.record(value, tags)
    
    def set_gauge(self, name: str, value: float, **tags):
        """è¨­ç½®å„€è¡¨å€¼"""
        metric = MetricEntry(
            name=name,
            value=value,
            metric_type=MetricType.GAUGE,
            timestamp=datetime.now(timezone.utc),
            service_name=self.service_name,
            tags=tags
        )
        
        with self.lock:
            self.metrics.append(metric)
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """ç²å–åº¦é‡æ‘˜è¦"""
        with self.lock:
            total_metrics = len(self.metrics)
            metric_types = {}
            
            for metric in self.metrics:
                metric_type = metric.metric_type.value
                if metric_type not in metric_types:
                    metric_types[metric_type] = 0
                metric_types[metric_type] += 1
            
            return {
                "service": self.service_name,
                "total_metrics": total_metrics,
                "metric_types": metric_types,
                "last_updated": datetime.now(timezone.utc).isoformat()
            }

class DistributedTracer:
    """åˆ†æ•£å¼è¿½è¹¤å™¨"""
    
    def __init__(self, service_name: str, jaeger_endpoint: Optional[str] = None):
        self.service_name = service_name
        self.active_spans: Dict[str, TraceContext] = {}
        
        # OpenTelemetry è¨­ç½®
        if OPENTELEMETRY_AVAILABLE:
            self._setup_tracing(jaeger_endpoint)
        
    def _setup_tracing(self, jaeger_endpoint: Optional[str]):
        """è¨­ç½®è¿½è¹¤"""
        # è¨­ç½®è¿½è¹¤å™¨æä¾›è€…
        trace.set_tracer_provider(TracerProvider())
        tracer_provider = trace.get_tracer_provider()
        
        # è¨­ç½® Jaeger å°å‡ºå™¨ï¼ˆå¦‚æœæä¾›ç«¯é»ï¼‰
        if jaeger_endpoint:
            jaeger_exporter = JaegerExporter(
                agent_host_name="localhost",
                agent_port=14268,
            )
            span_processor = BatchSpanProcessor(jaeger_exporter)
            tracer_provider.add_span_processor(span_processor)
        
        self.tracer = trace.get_tracer(self.service_name)
    
    def start_span(self, operation_name: str, parent_context: Optional[TraceContext] = None) -> TraceContext:
        """é–‹å§‹æ–°çš„è·¨åº¦"""
        trace_id = str(uuid.uuid4())
        span_id = str(uuid.uuid4())
        
        context = TraceContext(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_context.span_id if parent_context else None,
            service_name=self.service_name,
            operation_name=operation_name,
            start_time=time.time()
        )
        
        self.active_spans[span_id] = context
        
        return context
    
    def add_span_attribute(self, span_id: str, key: str, value: Any):
        """æ·»åŠ è·¨åº¦å±¬æ€§"""
        if span_id in self.active_spans:
            self.active_spans[span_id].attributes[key] = value
    
    def finish_span(self, span_id: str, status: str = "ok", error: Optional[str] = None):
        """çµæŸè·¨åº¦"""
        if span_id in self.active_spans:
            context = self.active_spans[span_id]
            context.attributes["duration"] = time.time() - context.start_time
            context.attributes["status"] = status
            
            if error:
                context.attributes["error"] = error
                
            # ç§»é™¤æ´»èºè·¨åº¦
            del self.active_spans[span_id]
    
    @asynccontextmanager
    async def trace_operation(self, operation_name: str, parent_context: Optional[TraceContext] = None):
        """è¿½è¹¤æ“ä½œçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        context = self.start_span(operation_name, parent_context)
        try:
            yield context
            self.finish_span(context.span_id, "ok")
        except Exception as e:
            self.finish_span(context.span_id, "error", str(e))
            raise

class ObservabilityFramework:
    """å¯è§€æ¸¬æ€§æ¡†æ¶ - ä¸»è¦å”èª¿å™¨"""
    
    def __init__(self, service_name: str, config: Optional[Dict[str, Any]] = None):
        self.service_name = service_name
        self.config = config or {}
        
        # åˆå§‹åŒ–å…ƒä»¶
        self.logger = StructuredLogger(service_name, self.config.get("log_path"))
        self.metrics = MetricsCollector(service_name)
        self.tracer = DistributedTracer(
            service_name, 
            self.config.get("jaeger_endpoint")
        )
        
        # å¥åº·æª¢æŸ¥
        self.start_time = time.time()
        self.request_count = 0
        self.error_count = 0
        
    async def record_request(self, operation: str, duration: float, status: str = "success", **attributes):
        """è¨˜éŒ„è«‹æ±‚"""
        self.request_count += 1
        
        # è¨˜éŒ„åº¦é‡
        self.metrics.increment_counter("requests_total", tags={"operation": operation, "status": status})
        self.metrics.record_histogram("request_duration_seconds", duration, operation=operation)
        
        # è¨˜éŒ„æ—¥èªŒ
        level = ObservabilityLevel.INFO if status == "success" else ObservabilityLevel.ERROR
        self.logger.log(
            level, 
            operation, 
            f"Request completed in {duration:.3f}s",
            operation=operation,
            duration=duration,
            status=status,
            **attributes
        )
        
        if status == "error":
            self.error_count += 1
    
    async def record_error(self, operation: str, error: Exception, trace_context: Optional[TraceContext] = None):
        """è¨˜éŒ„éŒ¯èª¤"""
        self.error_count += 1
        
        # è¨˜éŒ„åº¦é‡
        self.metrics.increment_counter("errors_total", tags={"operation": operation, "error_type": type(error).__name__})
        
        # è¨˜éŒ„æ—¥èªŒ
        self.logger.log(
            ObservabilityLevel.ERROR,
            operation,
            f"Error occurred: {str(error)}",
            trace_context,
            error_type=type(error).__name__,
            error_message=str(error)
        )
    
    @asynccontextmanager
    async def observe_operation(self, operation_name: str, **attributes):
        """è§€å¯Ÿæ“ä½œçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        
        async with self.tracer.trace_operation(operation_name) as trace_context:
            # æ·»åŠ å±¬æ€§åˆ°è·¨åº¦
            for key, value in attributes.items():
                self.tracer.add_span_attribute(trace_context.span_id, key, value)
            
            try:
                yield trace_context
                duration = time.time() - start_time
                await self.record_request(operation_name, duration, "success", **attributes)
                
            except Exception as e:
                duration = time.time() - start_time
                await self.record_request(operation_name, duration, "error", **attributes)
                await self.record_error(operation_name, e, trace_context)
                raise
    
    def get_health_status(self) -> Dict[str, Any]:
        """ç²å–å¥åº·ç‹€æ…‹"""
        uptime = time.time() - self.start_time
        error_rate = (self.error_count / max(self.request_count, 1)) * 100
        
        return {
            "service": self.service_name,
            "status": "healthy" if error_rate < 5 else "degraded" if error_rate < 20 else "unhealthy",
            "uptime_seconds": uptime,
            "total_requests": self.request_count,
            "total_errors": self.error_count,
            "error_rate_percent": error_rate,
            "metrics_summary": self.metrics.get_metrics_summary(),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """ç²å–å„€è¡¨æ¿æ•¸æ“š"""
        return {
            "service_info": {
                "name": self.service_name,
                "uptime": time.time() - self.start_time,
                "version": "1.0.0"
            },
            "health": self.get_health_status(),
            "metrics": self.metrics.get_metrics_summary(),
            "active_traces": len(self.tracer.active_spans)
        }

# å…¨åŸŸè§€æ¸¬æ€§ç®¡ç†å™¨
_observability_frameworks: Dict[str, ObservabilityFramework] = {}

def get_observability_framework(service_name: str, config: Optional[Dict[str, Any]] = None) -> ObservabilityFramework:
    """ç²å–æˆ–å‰µå»ºå¯è§€æ¸¬æ€§æ¡†æ¶"""
    if service_name not in _observability_frameworks:
        _observability_frameworks[service_name] = ObservabilityFramework(service_name, config)
    return _observability_frameworks[service_name]

def setup_aiva_observability():
    """è¨­ç½® AIVA äº”å¤§æ¨¡çµ„çš„å¯è§€æ¸¬æ€§"""
    modules = ["core", "features", "integration", "scan", "aiva_common"]
    
    config = {
        "log_path": "./logs",
        "jaeger_endpoint": "http://localhost:14268/api/traces"
    }
    
    frameworks = {}
    for module in modules:
        frameworks[module] = get_observability_framework(module, config)
    
    return frameworks

# è£é£¾å™¨æ”¯æ´
def observe_function(operation_name: str = None, service_name: str = "default"):
    """å‡½æ•¸å¯è§€æ¸¬æ€§è£é£¾å™¨"""
    def decorator(func):
        async def async_wrapper(*args, **kwargs):
            op_name = operation_name or func.__name__
            framework = get_observability_framework(service_name)
            
            async with framework.observe_operation(op_name, function=func.__name__):
                return await func(*args, **kwargs)
        
        def sync_wrapper(*args, **kwargs):
            op_name = operation_name or func.__name__
            framework = get_observability_framework(service_name)
            
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                asyncio.create_task(framework.record_request(op_name, duration, "success"))
                return result
            except Exception as e:
                duration = time.time() - start_time
                asyncio.create_task(framework.record_request(op_name, duration, "error"))
                asyncio.create_task(framework.record_error(op_name, e))
                raise
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

# æ¸¬è©¦å’Œé©—è­‰
async def test_observability_framework():
    """æ¸¬è©¦å¯è§€æ¸¬æ€§æ¡†æ¶"""
    print("ğŸ“Š æ¸¬è©¦ AIVA å¯è§€æ¸¬æ€§æ¡†æ¶")
    
    # è¨­ç½®æ¡†æ¶
    frameworks = setup_aiva_observability()
    
    # æ¸¬è©¦å„å€‹å…ƒä»¶
    test_framework = frameworks["core"]
    
    # æ¸¬è©¦æ“ä½œè§€å¯Ÿ
    async with test_framework.observe_operation("test_operation", test_param="value"):
        await asyncio.sleep(0.1)  # æ¨¡æ“¬æ“ä½œ
        
    # æ¸¬è©¦éŒ¯èª¤è¨˜éŒ„
    try:
        async with test_framework.observe_operation("test_error"):
            raise ValueError("æ¸¬è©¦éŒ¯èª¤")
    except ValueError:
        pass
    
    # ç²å–å¥åº·ç‹€æ…‹
    health = test_framework.get_health_status()
    dashboard = test_framework.get_dashboard_data()
    
    print(f"âœ… å¥åº·ç‹€æ…‹: {health['status']}")
    print(f"âœ… ç¸½è«‹æ±‚æ•¸: {health['total_requests']}")
    print(f"âœ… éŒ¯èª¤ç‡: {health['error_rate_percent']:.1f}%")
    print(f"âœ… åº¦é‡æ‘˜è¦: {health['metrics_summary']['total_metrics']} å€‹åº¦é‡")
    
    return {
        "health": health,
        "dashboard": dashboard,
        "frameworks_count": len(frameworks)
    }

if __name__ == "__main__":
    asyncio.run(test_observability_framework())