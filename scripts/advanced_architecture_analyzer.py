#!/usr/bin/env python3
"""
AIVA Features æ·±åº¦çµ„åœ–åˆ†æå™¨
ç™¼ç¾éš±è—çš„çµ„ç¹”èƒ½åŠ›å’Œæ¶æ§‹æ¨¡å¼
"""

import json
import sys
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Any, Tuple
import re

def analyze_advanced_patterns():
    """é€²è¡Œæ·±åº¦æ¶æ§‹æ¨¡å¼åˆ†æ"""
    
    # è®€å–åˆ†é¡æ•¸æ“š
    classification_file = Path("_out/architecture_diagrams/features_diagram_classification.json")
    with open(classification_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    classifications = data.get('classifications', {})
    
    # 1. æŒ‰è¤‡é›œåº¦å’ŒæŠ½è±¡å±¤ç´šçµ„åœ–
    complexity_abstraction_map = analyze_complexity_abstraction_patterns(classifications)
    
    # 2. æŒ‰ä¾è³´é—œä¿‚çµ„åœ– 
    dependency_patterns = analyze_dependency_patterns(classifications)
    
    # 3. æŒ‰å‘½åæ¨¡å¼çµ„åœ–
    naming_patterns = analyze_naming_patterns(classifications)
    
    # 4. æŒ‰æ–‡ä»¶è·¯å¾‘æ¨¡å¼çµ„åœ–
    path_patterns = analyze_path_patterns(classifications)
    
    # 5. æŒ‰è·¨èªè¨€å”ä½œæ¨¡å¼çµ„åœ–
    cross_language_patterns = analyze_cross_language_patterns(classifications)
    
    # 6. æŒ‰åŠŸèƒ½èšé¡çµ„åœ–
    functional_clusters = analyze_functional_clusters(classifications)
    
    # 7. æŒ‰æ¶æ§‹è§’è‰²çµ„åœ–
    architectural_roles = analyze_architectural_roles(classifications)
    
    # 8. æŒ‰æŠ€è¡“å‚µå‹™æ¨¡å¼çµ„åœ–
    technical_debt_patterns = analyze_technical_debt_patterns(classifications)
    
    return {
        "complexity_abstraction": complexity_abstraction_map,
        "dependency_patterns": dependency_patterns,
        "naming_patterns": naming_patterns,
        "path_patterns": path_patterns,
        "cross_language_patterns": cross_language_patterns,
        "functional_clusters": functional_clusters,
        "architectural_roles": architectural_roles,
        "technical_debt_patterns": technical_debt_patterns
    }

def analyze_complexity_abstraction_patterns(classifications):
    """åˆ†æè¤‡é›œåº¦èˆ‡æŠ½è±¡å±¤ç´šçš„çµ„åˆæ¨¡å¼"""
    patterns = defaultdict(lambda: defaultdict(list))
    
    for name, info in classifications.items():
        complexity = info.get('complexity', 'unknown')
        abstraction = info.get('abstraction_level', 'unknown')
        language = info.get('language', 'unknown')
        priority = info.get('priority', 5)
        
        patterns[complexity][abstraction].append({
            'name': name,
            'language': language,
            'priority': priority,
            'file_path': info.get('file_path', '')
        })
    
    return dict(patterns)

def analyze_dependency_patterns(classifications):
    """åˆ†æä¾è³´é—œä¿‚æ¨¡å¼"""
    dependency_graph = defaultdict(list)
    isolated_components = []
    
    for name, info in classifications.items():
        deps = info.get('dependencies', [])
        cross_lang_deps = info.get('cross_language_dependencies')
        
        if not deps and not cross_lang_deps:
            isolated_components.append({
                'name': name,
                'language': info.get('language'),
                'category': info.get('category'),
                'complexity': info.get('complexity')
            })
        else:
            dependency_graph[name] = {
                'same_language_deps': deps,
                'cross_language_deps': cross_lang_deps,
                'info': info
            }
    
    return {
        'dependency_graph': dict(dependency_graph),
        'isolated_components': isolated_components
    }

def analyze_naming_patterns(classifications):
    """åˆ†æå‘½åæ¨¡å¼"""
    patterns = {
        'manager_pattern': [],
        'worker_pattern': [],  
        'config_pattern': [],
        'detector_pattern': [],
        'engine_pattern': [],
        'handler_pattern': [],
        'helper_pattern': [],
        'test_pattern': [],
        'schema_pattern': [],
        'model_pattern': [],
        'payload_pattern': [],
        'result_pattern': [],
        'factory_pattern': [],
        'builder_pattern': [],
        'adapter_pattern': [],
        'validator_pattern': [],
        'parser_pattern': [],
        'formatter_pattern': [],
        'executor_pattern': [],
        'controller_pattern': []
    }
    
    for name, info in classifications.items():
        lower_name = name.lower()
        
        # æª¢æŸ¥å„ç¨®å‘½åæ¨¡å¼
        if 'manager' in lower_name:
            patterns['manager_pattern'].append((name, info))
        if 'worker' in lower_name:
            patterns['worker_pattern'].append((name, info))
        if 'config' in lower_name:
            patterns['config_pattern'].append((name, info))
        if 'detect' in lower_name:
            patterns['detector_pattern'].append((name, info))
        if 'engine' in lower_name:
            patterns['engine_pattern'].append((name, info))
        if 'handler' in lower_name or 'handle' in lower_name:
            patterns['handler_pattern'].append((name, info))
        if 'helper' in lower_name or 'util' in lower_name:
            patterns['helper_pattern'].append((name, info))
        if 'test' in lower_name:
            patterns['test_pattern'].append((name, info))
        if 'schema' in lower_name:
            patterns['schema_pattern'].append((name, info))
        if 'model' in lower_name:
            patterns['model_pattern'].append((name, info))
        if 'payload' in lower_name:
            patterns['payload_pattern'].append((name, info))
        if 'result' in lower_name:
            patterns['result_pattern'].append((name, info))
        if 'factory' in lower_name:
            patterns['factory_pattern'].append((name, info))
        if 'builder' in lower_name:
            patterns['builder_pattern'].append((name, info))
        if 'adapter' in lower_name:
            patterns['adapter_pattern'].append((name, info))
        if 'valid' in lower_name:
            patterns['validator_pattern'].append((name, info))
        if 'pars' in lower_name:
            patterns['parser_pattern'].append((name, info))
        if 'format' in lower_name:
            patterns['formatter_pattern'].append((name, info))
        if 'execut' in lower_name:
            patterns['executor_pattern'].append((name, info))
        if 'control' in lower_name:
            patterns['controller_pattern'].append((name, info))
    
    # éæ¿¾ç©ºçš„æ¨¡å¼
    return {k: v for k, v in patterns.items() if v}

def analyze_path_patterns(classifications):
    """åˆ†ææ–‡ä»¶è·¯å¾‘æ¨¡å¼"""
    path_clusters = defaultdict(list)
    
    for name, info in classifications.items():
        file_path = info.get('file_path', '')
        if file_path:
            # æå–ç›®éŒ„çµæ§‹
            path_parts = file_path.replace('\\', '/').split('/')
            
            # åˆ†æä¸åŒå±¤ç´šçš„ç›®éŒ„æ¨¡å¼
            if len(path_parts) >= 3:
                # services/features/xxx
                if len(path_parts) >= 4:
                    module_dir = path_parts[2]  # function_xxx
                    path_clusters[f"module_{module_dir}"].append((name, info))
                
                # æŒ‰åŠŸèƒ½ç›®éŒ„åˆ†é¡
                for i, part in enumerate(path_parts[2:], 2):
                    if part.startswith('function_'):
                        path_clusters[f"function_module_{part}"].append((name, info))
                    elif part in ['common', 'base']:
                        path_clusters[f"shared_module_{part}"].append((name, info))
    
    return dict(path_clusters)

def analyze_cross_language_patterns(classifications):
    """åˆ†æè·¨èªè¨€å”ä½œæ¨¡å¼"""
    language_interfaces = defaultdict(list)
    shared_concepts = defaultdict(list)
    
    # æ”¶é›†ç›¸åŒåç¨±ä½†ä¸åŒèªè¨€çš„çµ„ä»¶
    name_language_map = defaultdict(list)
    
    for name, info in classifications.items():
        language = info.get('language', 'unknown')
        name_language_map[name].append((language, info))
    
    # æ‰¾å‡ºè·¨èªè¨€çš„ç›¸åŒæ¦‚å¿µ
    for name, lang_infos in name_language_map.items():
        if len(lang_infos) > 1:
            shared_concepts[name] = lang_infos
    
    # åˆ†ææ¥å£æ¨¡å¼
    for name, info in classifications.items():
        if info.get('cross_language_dependencies'):
            language_interfaces[info.get('language', 'unknown')].append((name, info))
    
    return {
        'shared_concepts': dict(shared_concepts),
        'language_interfaces': dict(language_interfaces)
    }

def analyze_functional_clusters(classifications):
    """åˆ†æåŠŸèƒ½èšé¡æ¨¡å¼"""
    clusters = {
        'authentication_cluster': [],
        'detection_cluster': [],
        'injection_cluster': [],
        'ssrf_cluster': [],
        'xss_cluster': [],
        'idor_cluster': [],
        'oauth_cluster': [],
        'jwt_cluster': [],
        'sast_cluster': [],
        'config_cluster': [],
        'schema_cluster': [],
        'worker_cluster': [],
        'telemetry_cluster': [],
        'statistics_cluster': [],
        'validation_cluster': [],
        'analysis_cluster': [],
        'bypass_cluster': [],
        'exploit_cluster': [],
        'payload_cluster': []
    }
    
    for name, info in classifications.items():
        lower_name = name.lower()
        file_path = info.get('file_path', '').lower()
        
        # æ ¹æ“šåç¨±å’Œè·¯å¾‘åˆ†é¡åˆ°åŠŸèƒ½èšé¡
        if 'auth' in lower_name or 'auth' in file_path:
            clusters['authentication_cluster'].append((name, info))
        if 'detect' in lower_name or 'detect' in file_path:
            clusters['detection_cluster'].append((name, info))
        if 'injection' in lower_name or 'sqli' in lower_name or 'sql' in file_path:
            clusters['injection_cluster'].append((name, info))
        if 'ssrf' in lower_name or 'ssrf' in file_path:
            clusters['ssrf_cluster'].append((name, info))
        if 'xss' in lower_name or 'xss' in file_path:
            clusters['xss_cluster'].append((name, info))
        if 'idor' in lower_name or 'idor' in file_path:
            clusters['idor_cluster'].append((name, info))
        if 'oauth' in lower_name or 'oauth' in file_path:
            clusters['oauth_cluster'].append((name, info))
        if 'jwt' in lower_name or 'jwt' in file_path:
            clusters['jwt_cluster'].append((name, info))
        if 'sast' in lower_name or 'sast' in file_path:
            clusters['sast_cluster'].append((name, info))
        if 'config' in lower_name:
            clusters['config_cluster'].append((name, info))
        if 'schema' in lower_name:
            clusters['schema_cluster'].append((name, info))
        if 'worker' in lower_name:
            clusters['worker_cluster'].append((name, info))
        if 'telemetry' in lower_name or 'metric' in lower_name:
            clusters['telemetry_cluster'].append((name, info))
        if 'statistic' in lower_name:
            clusters['statistics_cluster'].append((name, info))
        if 'valid' in lower_name:
            clusters['validation_cluster'].append((name, info))
        if 'analys' in lower_name:
            clusters['analysis_cluster'].append((name, info))
        if 'bypass' in lower_name:
            clusters['bypass_cluster'].append((name, info))
        if 'exploit' in lower_name:
            clusters['exploit_cluster'].append((name, info))
        if 'payload' in lower_name:
            clusters['payload_cluster'].append((name, info))
    
    # éæ¿¾ç©ºçš„èšé¡
    return {k: v for k, v in clusters.items() if v}

def analyze_architectural_roles(classifications):
    """åˆ†ææ¶æ§‹è§’è‰²æ¨¡å¼"""
    roles = {
        'coordinators': [],      # å”èª¿è€… - Manager, Controller
        'processors': [],        # è™•ç†è€… - Worker, Engine, Processor  
        'validators': [],        # é©—è­‰è€… - Validator, Checker
        'adapters': [],         # é©é…è€… - Adapter, Converter
        'repositories': [],     # å­˜å„²è€… - Repository, Store
        'factories': [],        # å·¥å»  - Factory, Builder, Creator
        'observers': [],        # è§€å¯Ÿè€… - Monitor, Tracker, Listener
        'strategies': [],       # ç­–ç•¥ - Strategy, Policy
        'utilities': [],        # å·¥å…· - Utils, Helper, Tool
        'models': [],          # æ¨¡å‹ - Model, Schema, Entity
        'interfaces': [],      # ä»‹é¢ - Interface, API, Contract
        'decorators': [],      # è£é£¾è€… - Decorator, Wrapper
        'singletons': [],      # å–®ä¾‹ - Singleton, Global
        'facades': []          # é–€é¢ - Facade, Gateway
    }
    
    for name, info in classifications.items():
        lower_name = name.lower()
        abstraction = info.get('abstraction_level', '')
        
        # æ ¹æ“šå‘½åå’ŒæŠ½è±¡å±¤ç´šåˆ¤æ–·æ¶æ§‹è§’è‰²
        if any(x in lower_name for x in ['manager', 'coordinator', 'controller']):
            roles['coordinators'].append((name, info))
        elif any(x in lower_name for x in ['worker', 'engine', 'processor', 'executor']):
            roles['processors'].append((name, info))
        elif any(x in lower_name for x in ['valid', 'check', 'verify']):
            roles['validators'].append((name, info))
        elif any(x in lower_name for x in ['adapter', 'convert', 'transform']):
            roles['adapters'].append((name, info))
        elif any(x in lower_name for x in ['repository', 'store', 'cache']):
            roles['repositories'].append((name, info))
        elif any(x in lower_name for x in ['factory', 'builder', 'creator']):
            roles['factories'].append((name, info))
        elif any(x in lower_name for x in ['monitor', 'track', 'listen', 'observer']):
            roles['observers'].append((name, info))
        elif any(x in lower_name for x in ['strategy', 'policy']):
            roles['strategies'].append((name, info))
        elif any(x in lower_name for x in ['util', 'helper', 'tool']):
            roles['utilities'].append((name, info))
        elif any(x in lower_name for x in ['model', 'schema', 'entity']) or abstraction == 'component':
            roles['models'].append((name, info))
        elif any(x in lower_name for x in ['interface', 'api', 'contract']):
            roles['interfaces'].append((name, info))
        elif any(x in lower_name for x in ['decorator', 'wrapper']):
            roles['decorators'].append((name, info))
        elif any(x in lower_name for x in ['singleton', 'global', 'instance']):
            roles['singletons'].append((name, info))
        elif any(x in lower_name for x in ['facade', 'gateway']):
            roles['facades'].append((name, info))
    
    return {k: v for k, v in roles.items() if v}

def analyze_technical_debt_patterns(classifications):
    """åˆ†ææŠ€è¡“å‚µå‹™æ¨¡å¼"""
    debt_patterns = {
        'duplicate_implementations': [],
        'inconsistent_naming': [],
        'missing_abstractions': [],
        'god_objects': [],
        'scattered_responsibilities': [],
        'language_inconsistencies': []
    }
    
    # æª¢æ¸¬é‡è¤‡å¯¦ç¾
    name_groups = defaultdict(list)
    for name, info in classifications.items():
        # æå–æ ¸å¿ƒåç¨±ï¼ˆå»é™¤å‰ç¶´å¾Œç¶´ï¼‰
        core_name = re.sub(r'^(get_|set_|create_|build_)', '', name.lower())
        core_name = re.sub(r'(worker|manager|config|engine)$', '', core_name)
        name_groups[core_name].append((name, info))
    
    for core_name, items in name_groups.items():
        if len(items) > 1 and core_name.strip():
            # æª¢æŸ¥æ˜¯å¦ç‚ºçœŸæ­£çš„é‡è¤‡å¯¦ç¾
            languages = set(item[1].get('language') for item in items)
            categories = set(item[1].get('category') for item in items)
            
            if len(languages) > 1 or len(categories) > 1:
                debt_patterns['duplicate_implementations'].append({
                    'core_concept': core_name,
                    'implementations': items,
                    'languages': list(languages),
                    'categories': list(categories)
                })
    
    # æª¢æ¸¬å‘½åä¸ä¸€è‡´
    naming_styles = defaultdict(list)
    for name, info in classifications.items():
        if '_' in name:
            naming_styles['snake_case'].append((name, info))
        elif any(c.isupper() for c in name[1:]):
            naming_styles['camelCase'].append((name, info))
        else:
            naming_styles['lowercase'].append((name, info))
    
    if len(naming_styles) > 1:
        debt_patterns['inconsistent_naming'] = dict(naming_styles)
    
    # æª¢æ¸¬ç¼ºå¤±çš„æŠ½è±¡
    function_groups = defaultdict(list)
    for name, info in classifications.items():
        if info.get('abstraction_level') == 'function':
            category = info.get('category', 'unknown')
            function_groups[category].append((name, info))
    
    for category, functions in function_groups.items():
        if len(functions) > 10:  # å¦‚æœæŸå€‹é¡åˆ¥æœ‰å¤ªå¤šå‡½æ•¸ç´šçµ„ä»¶
            debt_patterns['missing_abstractions'].append({
                'category': category,
                'function_count': len(functions),
                'functions': functions[:5]  # åªé¡¯ç¤ºå‰5å€‹ä½œç‚ºç¯„ä¾‹
            })
    
    # æª¢æ¸¬ä¸Šå¸ç‰©ä»¶
    for name, info in classifications.items():
        if (info.get('complexity') == 'high' and 
            info.get('abstraction_level') == 'service' and
            'manager' in name.lower()):
            debt_patterns['god_objects'].append((name, info))
    
    return debt_patterns

def generate_advanced_analysis_report(analysis_results):
    """ç”Ÿæˆæ·±åº¦åˆ†æå ±å‘Š"""
    
    report = """# AIVA Features æ·±åº¦æ¶æ§‹åˆ†æå ±å‘Š

## ğŸ” **ç™¼ç¾çš„éš±è—çµ„ç¹”èƒ½åŠ›**

### 1. è¤‡é›œåº¦èˆ‡æŠ½è±¡å±¤ç´šçŸ©é™£åˆ†æ

"""
    
    # è¤‡é›œåº¦æŠ½è±¡å±¤ç´šåˆ†æ
    complexity_data = analysis_results['complexity_abstraction']
    for complexity, abstractions in complexity_data.items():
        report += f"#### **{complexity.upper()} è¤‡é›œåº¦çµ„ä»¶**\n"
        for abstraction, components in abstractions.items():
            if components:
                report += f"- **{abstraction}** å±¤ç´š: {len(components)} å€‹çµ„ä»¶\n"
                
                # æŒ‰èªè¨€çµ±è¨ˆ
                lang_count = Counter(comp['language'] for comp in components)
                lang_stats = ', '.join(f"{lang}: {count}" for lang, count in lang_count.items())
                report += f"  - èªè¨€åˆ†ä½ˆ: {lang_stats}\n"
                
                # é«˜å„ªå…ˆç´šçµ„ä»¶
                high_priority = [comp for comp in components if comp['priority'] <= 2]
                if high_priority:
                    report += f"  - é«˜å„ªå…ˆç´šçµ„ä»¶: {', '.join(comp['name'] for comp in high_priority[:3])}\n"
        report += "\n"
    
    report += """### 2. åŠŸèƒ½èšé¡åˆ†æ

"""
    
    # åŠŸèƒ½èšé¡åˆ†æ
    clusters = analysis_results['functional_clusters']
    for cluster_name, components in clusters.items():
        if len(components) >= 3:  # åªå ±å‘Šæœ‰æ„ç¾©çš„èšé¡
            report += f"#### **{cluster_name.replace('_', ' ').title()}**\n"
            report += f"- çµ„ä»¶æ•¸é‡: {len(components)}\n"
            
            # èªè¨€åˆ†ä½ˆ
            languages = Counter(comp[1].get('language') for comp in components)
            report += f"- ä¸»è¦èªè¨€: {', '.join(f'{lang}({count})' for lang, count in languages.most_common(3))}\n"
            
            # è¤‡é›œåº¦åˆ†ä½ˆ
            complexities = Counter(comp[1].get('complexity') for comp in components)
            report += f"- è¤‡é›œåº¦åˆ†ä½ˆ: {', '.join(f'{comp}({count})' for comp, count in complexities.items())}\n"
            
            # æ ¸å¿ƒçµ„ä»¶
            high_priority_components = [comp for comp in components if comp[1].get('priority', 5) <= 2]
            if high_priority_components:
                report += f"- æ ¸å¿ƒçµ„ä»¶: {', '.join(comp[0] for comp in high_priority_components[:3])}\n"
            
            report += "\n"
    
    report += """### 3. æ¶æ§‹è§’è‰²æ¨¡å¼åˆ†æ

"""
    
    # æ¶æ§‹è§’è‰²åˆ†æ
    roles = analysis_results['architectural_roles']
    for role_name, components in roles.items():
        if components:
            report += f"#### **{role_name.replace('_', ' ').title()}** ({len(components)} çµ„ä»¶)\n"
            
            # èªè¨€åå¥½
            languages = Counter(comp[1].get('language') for comp in components)
            dominant_lang = languages.most_common(1)[0] if languages else ('unknown', 0)
            report += f"- ä¸»å°èªè¨€: {dominant_lang[0]} ({dominant_lang[1]}/{len(components)})\n"
            
            # ç¤ºä¾‹çµ„ä»¶
            examples = [comp[0] for comp in components[:3]]
            report += f"- å…¸å‹çµ„ä»¶: {', '.join(examples)}\n\n"
    
    report += """### 4. æŠ€è¡“å‚µå‹™åˆ†æ

"""
    
    # æŠ€è¡“å‚µå‹™åˆ†æ
    debt = analysis_results['technical_debt_patterns']
    
    if debt.get('duplicate_implementations'):
        report += "#### **ğŸš¨ é‡è¤‡å¯¦ç¾å•é¡Œ**\n"
        for dup in debt['duplicate_implementations'][:5]:  # åªé¡¯ç¤ºå‰5å€‹
            report += f"- **{dup['core_concept']}**: {len(dup['implementations'])} å€‹å¯¦ç¾\n"
            report += f"  - æ¶‰åŠèªè¨€: {', '.join(dup['languages'])}\n"
            report += f"  - è·¨å±¤ç´š: {', '.join(dup['categories'])}\n"
        report += "\n"
    
    if debt.get('inconsistent_naming'):
        report += "#### **ğŸ“ å‘½åé¢¨æ ¼ä¸ä¸€è‡´**\n"
        for style, components in debt['inconsistent_naming'].items():
            report += f"- **{style}**: {len(components)} å€‹çµ„ä»¶\n"
        report += "\n"
    
    if debt.get('missing_abstractions'):
        report += "#### **ğŸ—ï¸ ç¼ºå¤±æŠ½è±¡å±¤**\n"
        for missing in debt['missing_abstractions']:
            report += f"- **{missing['category']}** é¡åˆ¥: {missing['function_count']} å€‹å‡½æ•¸ç´šçµ„ä»¶ï¼Œéœ€è¦æŠ½è±¡åŒ–\n"
        report += "\n"
    
    if debt.get('god_objects'):
        report += "#### **ğŸ‘¹ ä¸Šå¸ç‰©ä»¶**\n"
        for god_obj, info in debt['god_objects']:
            report += f"- **{god_obj}**: é«˜è¤‡é›œåº¦æœå‹™ç´šçµ„ä»¶ï¼Œå»ºè­°æ‹†åˆ†\n"
        report += "\n"
    
    report += """### 5. è·¨èªè¨€å”ä½œæ¨¡å¼

"""
    
    # è·¨èªè¨€åˆ†æ
    cross_lang = analysis_results['cross_language_patterns']
    
    if cross_lang.get('shared_concepts'):
        report += "#### **ğŸ”— å…±äº«æ¦‚å¿µ**\n"
        for concept, implementations in cross_lang['shared_concepts'].items():
            if len(implementations) > 1:
                languages = [impl[0] for impl in implementations]
                report += f"- **{concept}**: åœ¨ {', '.join(languages)} ä¸­éƒ½æœ‰å¯¦ç¾\n"
        report += "\n"
    
    report += """### 6. å‘½åæ¨¡å¼çµ±è¨ˆ

"""
    
    # å‘½åæ¨¡å¼åˆ†æ
    naming = analysis_results['naming_patterns']
    pattern_stats = {k: len(v) for k, v in naming.items()}
    sorted_patterns = sorted(pattern_stats.items(), key=lambda x: x[1], reverse=True)
    
    for pattern, count in sorted_patterns[:10]:  # é¡¯ç¤ºå‰10å€‹æœ€å¸¸è¦‹çš„æ¨¡å¼
        if count > 0:
            report += f"- **{pattern.replace('_', ' ').title()}**: {count} å€‹çµ„ä»¶\n"
    
    report += """

## ğŸ’¡ **æ–°ç™¼ç¾çš„çµ„ç¹”å»ºè­°**

### ğŸ¯ **æŒ‰æŠ€è¡“æ£§é‡æ–°çµ„ç¹”**
1. **å‰ç«¯å®‰å…¨æ£§**: JavaScript åˆ†æã€XSS æª¢æ¸¬ã€å®¢æˆ¶ç«¯ç¹é
2. **å¾Œç«¯å®‰å…¨æ£§**: SQL æ³¨å…¥ã€SSRFã€IDOR æª¢æ¸¬  
3. **èº«ä»½é©—è­‰æ£§**: JWTã€OAuthã€èªè­‰ç¹é
4. **åŸºç¤è¨­æ–½æ£§**: Workerã€é…ç½®ã€çµ±è¨ˆã€Schema

### ğŸ”„ **æŒ‰ç”Ÿå‘½é€±æœŸçµ„ç¹”**
1. **æª¢æ¸¬éšæ®µ**: å„ç¨® Detector å’Œ Engine
2. **åˆ†æéšæ®µ**: å„ç¨® Analyzer å’Œ Parser
3. **å ±å‘Šéšæ®µ**: å„ç¨® Reporter å’Œ Formatter
4. **ç®¡ç†éšæ®µ**: å„ç¨® Manager å’Œ Controller

### ğŸ“Š **æŒ‰æ•¸æ“šæµçµ„ç¹”**
1. **è¼¸å…¥è™•ç†**: Parserã€Validatorã€Converter
2. **æ ¸å¿ƒè™•ç†**: Engineã€Processorã€Detector
3. **çµæœè™•ç†**: Formatterã€Reporterã€Exporter
4. **ç‹€æ…‹ç®¡ç†**: Statisticsã€Telemetryã€Monitor

### ğŸ¨ **æŒ‰è¨­è¨ˆæ¨¡å¼çµ„ç¹”**
1. **å‰µå»ºæ¨¡å¼**: Factoryã€Builderã€Singleton
2. **çµæ§‹æ¨¡å¼**: Adapterã€Decoratorã€Facade  
3. **è¡Œç‚ºæ¨¡å¼**: Strategyã€Observerã€Command
4. **ä½µç™¼æ¨¡å¼**: Workerã€Queueã€Pool

---

**ğŸ“Š åˆ†æçµ±è¨ˆ**:
- ç™¼ç¾ **{total_components}** å€‹çµ„ä»¶
- è­˜åˆ¥ **{total_patterns}** ç¨®æ¶æ§‹æ¨¡å¼
- æª¢æ¸¬ **{debt_issues}** å€‹æŠ€è¡“å‚µå‹™å•é¡Œ
- å»ºè­° **4** ç¨®æ–°çš„çµ„ç¹”æ–¹å¼

*é€™ä»½æ·±åº¦åˆ†ææ­ç¤ºäº† AIVA Features æ¨¡çµ„çš„éš±è—çµ„ç¹”æ½›åŠ›å’Œæ¶æ§‹å„ªåŒ–æ©Ÿæœƒã€‚*
""".format(
        total_components=sum(len(v) if isinstance(v, list) else sum(len(vv) for vv in v.values()) 
                           for v in analysis_results.values() if v),
        total_patterns=len([k for k, v in analysis_results.items() if v]),
        debt_issues=len(debt.get('duplicate_implementations', [])) + 
                   len(debt.get('missing_abstractions', [])) + 
                   len(debt.get('god_objects', []))
    )
    
    return report

if __name__ == "__main__":
    print("ğŸ” é–‹å§‹æ·±åº¦æ¶æ§‹åˆ†æ...")
    
    analysis_results = analyze_advanced_patterns()
    
    print("ğŸ“Š ç”Ÿæˆåˆ†æå ±å‘Š...")
    report = generate_advanced_analysis_report(analysis_results)
    
    # ä¿å­˜å ±å‘Š
    output_file = Path("services/features/ADVANCED_ARCHITECTURE_ANALYSIS_REPORT.md")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… æ·±åº¦åˆ†æå®Œæˆï¼å ±å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    
    # ä¿å­˜è©³ç´°åˆ†ææ•¸æ“š
    analysis_data_file = Path("_out/architecture_diagrams/advanced_analysis_data.json")
    with open(analysis_data_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ è©³ç´°æ•¸æ“šå·²ä¿å­˜åˆ°: {analysis_data_file}")