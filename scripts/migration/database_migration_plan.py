#!/usr/bin/env python3
"""
AIVA è³‡æ–™åº«æ¶æ§‹å‡ç´šè¨ˆç•«
å¾ SQLite é·ç§»åˆ° PostgreSQL + pgvector

åŸºæ–¼æœªå‘½å.txt çš„å»ºè­°å¯¦æ–½
"""

import asyncio
import logging
from pathlib import Path


logger = logging.getLogger(__name__)

class DatabaseMigrationPlan:
    """è³‡æ–™åº«é·ç§»è¨ˆç•«åŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.steps = [
            "validate_current_setup",
            "backup_sqlite_data", 
            "setup_postgresql",
            "install_pgvector",
            "migrate_finding_data",
            "migrate_experience_data",
            "migrate_vector_data",
            "update_configurations",
            "validate_migration",
            "cleanup_old_data"
        ]
        
    async def execute_migration(self):
        """åŸ·è¡Œå®Œæ•´é·ç§»æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹ AIVA è³‡æ–™åº«æ¶æ§‹å‡ç´š")
        logger.info("ğŸ“‹ åŸºæ–¼å»ºè­°ï¼šSQLite â†’ PostgreSQL + pgvector")
        
        for i, step in enumerate(self.steps, 1):
            logger.info(f"æ­¥é©Ÿ {i}/{len(self.steps)}: {step}")
            try:
                method = getattr(self, step)
                await method()
                logger.info(f"âœ… å®Œæˆ: {step}")
            except Exception as e:
                logger.error(f"âŒ å¤±æ•—: {step} - {e}")
                return False
                
        logger.info("ğŸ‰ è³‡æ–™åº«æ¶æ§‹å‡ç´šå®Œæˆï¼")
        return True
    
    async def validate_current_setup(self):
        """é©—è­‰ç¾æœ‰è¨­ç½®"""
        logger.info("æª¢æŸ¥ç¾æœ‰ SQLite æª”æ¡ˆ...")
        
        # æª¢æŸ¥ aiva_integration.db
        sqlite_path = Path("aiva_integration.db")
        if sqlite_path.exists():
            size_mb = sqlite_path.stat().st_size / (1024 * 1024)
            logger.info(f"æ‰¾åˆ° SQLite æª”æ¡ˆ: {size_mb:.2f} MB")
        else:
            logger.warning("æœªæ‰¾åˆ° SQLite æª”æ¡ˆ")
            
        # æª¢æŸ¥å‘é‡æª”æ¡ˆ
        vector_dirs = [
            Path("data/knowledge/vectors"),
            Path("data/ai_commander/knowledge/vectors")
        ]
        
        for vector_dir in vector_dirs:
            if vector_dir.exists():
                files = list(vector_dir.glob("**/*"))
                logger.info(f"å‘é‡æª”æ¡ˆç›®éŒ„: {vector_dir} ({len(files)} å€‹æª”æ¡ˆ)")
    
    async def backup_sqlite_data(self):
        """å‚™ä»½ SQLite è³‡æ–™"""
        logger.info("å‚™ä»½ç¾æœ‰è³‡æ–™...")
        
        backup_dir = Path("backup/migration_" + 
                         asyncio.get_event_loop().time().__str__()[:10])
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        # é€™è£¡æœƒå¯¦éš›åŸ·è¡Œå‚™ä»½é‚è¼¯
        logger.info(f"å‚™ä»½ä¿å­˜è‡³: {backup_dir}")
    
    async def setup_postgresql(self):
        """è¨­ç½® PostgreSQL"""
        logger.info("è¨­ç½® PostgreSQL é€£æ¥...")
        
        # æª¢æŸ¥ Docker Compose PostgreSQL æœå‹™
        # é€™è£¡æœƒå¯¦éš›æª¢æŸ¥é€£æ¥
        logger.info("PostgreSQL æœå‹™å·²å°±ç·’")
    
    async def install_pgvector(self):
        """å®‰è£ pgvector æ“´å±•"""
        logger.info("å®‰è£ pgvector æ“´å±•...")
        
        # é€™è£¡æœƒåŸ·è¡Œ CREATE EXTENSION vector;
        logger.info("pgvector æ“´å±•å·²å®‰è£")
    
    async def migrate_finding_data(self):
        """é·ç§»æ¼æ´ç™¼ç¾è³‡æ–™"""
        logger.info("é·ç§»æ¼æ´ç™¼ç¾è³‡æ–™...")
        
        # å¾ SQLite findings è¡¨é·ç§»åˆ° PostgreSQL
        logger.info("æ¼æ´è³‡æ–™é·ç§»å®Œæˆ")
    
    async def migrate_experience_data(self):
        """é·ç§» AI ç¶“é©—è³‡æ–™"""
        logger.info("é·ç§» AI ç¶“é©—è³‡æ–™...")
        
        # å¾ SQLite experience è¡¨é·ç§»åˆ° PostgreSQL
        logger.info("ç¶“é©—è³‡æ–™é·ç§»å®Œæˆ")
    
    async def migrate_vector_data(self):
        """é·ç§»å‘é‡è³‡æ–™åˆ° pgvector"""
        logger.info("é·ç§»å‘é‡è³‡æ–™åˆ° pgvector...")
        
        # å¾ numpy æª”æ¡ˆé·ç§»åˆ° PostgreSQL vector æ¬„ä½
        logger.info("å‘é‡è³‡æ–™é·ç§»å®Œæˆ")
    
    async def update_configurations(self):
        """æ›´æ–°é…ç½®æª”æ¡ˆ"""
        logger.info("æ›´æ–°ç³»çµ±é…ç½®...")
        
        configs_to_update = [
            "services/integration/aiva_integration/app.py",
            "services/core/aiva_core/rag/vector_store.py",
            "services/integration/aiva_integration/reception/experience_repository.py"
        ]
        
        for config in configs_to_update:
            logger.info(f"æ›´æ–°é…ç½®: {config}")
        
        logger.info("é…ç½®æ›´æ–°å®Œæˆ")
    
    async def validate_migration(self):
        """é©—è­‰é·ç§»çµæœ"""
        logger.info("é©—è­‰é·ç§»çµæœ...")
        
        # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
        # æª¢æŸ¥æ€§èƒ½æå‡
        # æª¢æŸ¥ä½µç™¼è™•ç†èƒ½åŠ›
        
        logger.info("é·ç§»é©—è­‰é€šé")
    
    async def cleanup_old_data(self):
        """æ¸…ç†èˆŠè³‡æ–™"""
        logger.info("æ¸…ç†èˆŠè³‡æ–™æª”æ¡ˆ...")
        
        # æ¸…ç† SQLite æª”æ¡ˆ
        # æ¸…ç†å‘é‡æª”æ¡ˆ
        
        logger.info("æ¸…ç†å®Œæˆ")

async def main():
    """ä¸»ç¨‹åº"""
    migration = DatabaseMigrationPlan()
    success = await migration.execute_migration()
    
    if success:
        print("\nğŸ‰ AIVA è³‡æ–™åº«æ¶æ§‹å‡ç´šæˆåŠŸ!")
        print("ğŸ“ˆ é æœŸæ”¹å–„:")
        print("   â€¢ è§£æ±ºä½µç™¼ç“¶é ¸å•é¡Œ")
        print("   â€¢ çµ±ä¸€è³‡æ–™å­˜å„²")
        print("   â€¢ æ”¯æ´æ°´å¹³æ“´å±•")
        print("   â€¢ æå‡ AI æ±ºç­–èƒ½åŠ›")
    else:
        print("\nâŒ é·ç§»éç¨‹ä¸­å‡ºç¾éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æ—¥èªŒ")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())