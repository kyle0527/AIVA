#!/usr/bin/env python3
"""
AIVA å ±å‘Šæ¸…ç†å·¥å…·
åˆ†æä¸¦æ¸…ç†è¶…éä¸€é€±çš„è€èˆŠä¸”å·²å®Œæˆçš„å ±å‘Š
"""

import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional

class AIVAReportCleaner:
    """AIVA å ±å‘Šæ¸…ç†å™¨"""
    
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path).resolve()
        self.reports_dir = self.root_path / "reports"
        self.current_date = datetime.now()
        self.one_week_ago = self.current_date - timedelta(days=7)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å®šç¾©å·²å®Œæˆçš„å ±å‘Šé—œéµå­—
        self.completion_keywords = [
            'COMPLETE', 'COMPLETION', 'FINISHED', 'FINAL', 'DONE',
            'å®Œæˆ', 'çµæŸ', 'å®Œçµ', 'SUCCESS', 'RESOLVED'
        ]
        
        # å®šç¾©é‡è¦å ±å‘Šé—œéµå­—ï¼ˆä¸æ‡‰è©²åˆªé™¤ï¼‰
        self.important_keywords = [
            'GUIDE', 'DOCUMENTATION', 'README', 'MANUAL', 'HANDBOOK',
            'REFERENCE', 'API', 'SCHEMA', 'ARCHITECTURE', 'ANALYSIS'
        ]
        
        # ä¿ç•™çš„å ±å‘Šé¡å‹
        self.keep_categories = [
            'documentation',  # æ–‡æª”é¡å ±å‘Š
            'architecture',   # æ¶æ§‹å ±å‘Š
            'schema'         # Schema å ±å‘Š
        ]
        
    def extract_date_from_content(self, file_path: Path) -> Optional[datetime]:
        """å¾æª”æ¡ˆå…§å®¹ä¸­æå–æ—¥æœŸè³‡è¨Š"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(500)  # åªè®€å‰500å­—ç¬¦
            
            # å°‹æ‰¾ Created: æˆ– Last Modified: æ—¥æœŸ
            date_pattern = r'(?:Created|Last Modified):\s*(\d{4}-\d{2}-\d{2})'
            matches = re.findall(date_pattern, content)
            
            if matches:
                # ä½¿ç”¨æœ€æ–°çš„æ—¥æœŸ
                latest_date_str = max(matches)
                return datetime.strptime(latest_date_str, '%Y-%m-%d')
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦å…¶ä»–æ ¼å¼
            date_patterns = [
                r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',
                r'(\d{4}/\d{1,2}/\d{1,2})',
                r'(\d{4}-\d{1,2}-\d{1,2})',
            ]
            
            for pattern in date_patterns:
                matches = re.findall(pattern, content)
                if matches:
                    date_str = matches[0]
                    # å˜—è©¦è§£æä¸åŒæ ¼å¼
                    for fmt in ['%Yå¹´%mæœˆ%dæ—¥', '%Y/%m/%d', '%Y-%m-%d']:
                        try:
                            return datetime.strptime(date_str, fmt)
                        except ValueError:
                            continue
            
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è®€å– {file_path.name}: {e}")
        
        return None
    
    def extract_date_from_filename(self, filename: str) -> Optional[datetime]:
        """å¾æª”æ¡ˆåä¸­æå–æ—¥æœŸ"""
        # å°‹æ‰¾æª”æ¡ˆåä¸­çš„æ™‚é–“æˆ³æ ¼å¼
        patterns = [
            r'(\d{8})_\d{6}',  # YYYYMMDD_HHMMSS
            r'(\d{8})',        # YYYYMMDD
            r'(\d{4}\d{2}\d{2})',  # YYYYMMDD
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                date_str = match.group(1)
                try:
                    return datetime.strptime(date_str, '%Y%m%d')
                except ValueError:
                    continue
        
        return None
    
    def get_file_modification_date(self, file_path: Path) -> datetime:
        """ç²å–æª”æ¡ˆç³»çµ±ä¿®æ”¹æ™‚é–“"""
        return datetime.fromtimestamp(file_path.stat().st_mtime)
    
    def is_completed_report(self, file_path: Path) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå·²å®Œæˆçš„å ±å‘Š"""
        filename = file_path.name.upper()
        
        # æª¢æŸ¥æª”æ¡ˆåæ˜¯å¦åŒ…å«å®Œæˆé—œéµå­—
        for keyword in self.completion_keywords:
            if keyword in filename:
                return True
        
        # æª¢æŸ¥æª”æ¡ˆå…§å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(200).upper()
            
            for keyword in self.completion_keywords:
                if keyword in content:
                    return True
        except:
            pass
        
        return False
    
    def is_important_report(self, file_path: Path) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºé‡è¦å ±å‘Šï¼ˆä¸æ‡‰åˆªé™¤ï¼‰"""
        filename = file_path.name.upper()
        
        # æª¢æŸ¥æª”æ¡ˆåæ˜¯å¦åŒ…å«é‡è¦é—œéµå­—
        for keyword in self.important_keywords:
            if keyword in filename:
                return True
        
        # æª¢æŸ¥æ˜¯å¦åœ¨ä¿ç•™çš„åˆ†é¡ä¸­
        parent_dir = file_path.parent.name
        if parent_dir in self.keep_categories:
            return True
        
        return False
    
    def analyze_reports(self) -> Dict[str, List[Dict]]:
        """åˆ†ææ‰€æœ‰å ±å‘Šæª”æ¡ˆ"""
        analysis = {
            'old_completed': [],     # è¶…éä¸€é€±çš„å·²å®Œæˆå ±å‘Š
            'old_important': [],     # è¶…éä¸€é€±çš„é‡è¦å ±å‘Š
            'recent': [],            # æœ€è¿‘çš„å ±å‘Š
            'unknown_date': [],      # ç„¡æ³•ç¢ºå®šæ—¥æœŸçš„å ±å‘Š
            'cleanup_candidates': [] # æ¸…ç†å€™é¸
        }
        
        print("ğŸ” åˆ†æå ±å‘Šæª”æ¡ˆ...")
        
        for report_file in self.reports_dir.rglob('*.md'):
            if report_file.is_file():
                # ç²å–æ—¥æœŸè³‡è¨Š
                content_date = self.extract_date_from_content(report_file)
                filename_date = self.extract_date_from_filename(report_file.name)
                file_mod_date = self.get_file_modification_date(report_file)
                
                # é¸æ“‡æœ€å¯é çš„æ—¥æœŸ
                report_date = content_date or filename_date or file_mod_date
                
                file_info = {
                    'path': report_file,
                    'relative_path': report_file.relative_to(self.root_path),
                    'name': report_file.name,
                    'size': report_file.stat().st_size,
                    'date': report_date,
                    'date_source': 'content' if content_date else ('filename' if filename_date else 'filesystem'),
                    'is_completed': self.is_completed_report(report_file),
                    'is_important': self.is_important_report(report_file),
                    'category': report_file.parent.name
                }
                
                # åˆ†é¡
                if report_date < self.one_week_ago:
                    if file_info['is_important']:
                        analysis['old_important'].append(file_info)
                    elif file_info['is_completed']:
                        analysis['old_completed'].append(file_info)
                        analysis['cleanup_candidates'].append(file_info)
                    else:
                        analysis['old_completed'].append(file_info)
                elif report_date is None:
                    analysis['unknown_date'].append(file_info)
                else:
                    analysis['recent'].append(file_info)
        
        return analysis
    
    def generate_cleanup_plan(self, analysis: Dict) -> str:
        """ç”Ÿæˆæ¸…ç†è¨ˆåŠƒ"""
        plan = f"""# AIVA å ±å‘Šæ¸…ç†è¨ˆåŠƒ

---
Created: {self.current_date.strftime('%Y-%m-%d')}
Last Modified: {self.current_date.strftime('%Y-%m-%d')}
Document Type: Plan
---

## æ¸…ç†æ‘˜è¦

- **åˆ†ææ—¥æœŸ**: {self.current_date.strftime('%Y-%m-%d')}
- **æ¸…ç†æ¨™æº–**: è¶…é 7 å¤©ä¸”å·²å®Œæˆçš„å ±å‘Š
- **ç¸½å ±å‘Šæ•¸**: {sum(len(v) for v in analysis.values())}

## åˆ†é¡çµ±è¨ˆ

### ğŸ“Š å ±å‘Šåˆ†é¡
- **æœ€è¿‘å ±å‘Š** (< 7å¤©): {len(analysis['recent'])} å€‹
- **èˆŠé‡è¦å ±å‘Š** (> 7å¤©, é‡è¦): {len(analysis['old_important'])} å€‹
- **èˆŠå·²å®Œæˆå ±å‘Š** (> 7å¤©, å·²å®Œæˆ): {len(analysis['old_completed'])} å€‹
- **æ—¥æœŸä¸æ˜å ±å‘Š**: {len(analysis['unknown_date'])} å€‹
- **æ¸…ç†å€™é¸**: {len(analysis['cleanup_candidates'])} å€‹

### ğŸ—‘ï¸ å»ºè­°æ¸…ç†çš„å ±å‘Š

"""
        
        if analysis['cleanup_candidates']:
            total_size = 0
            for report in sorted(analysis['cleanup_candidates'], key=lambda x: x['date']):
                size_kb = report['size'] / 1024
                total_size += size_kb
                plan += f"- **{report['name']}**\n"
                plan += f"  - è·¯å¾‘: `{report['relative_path']}`\n"
                plan += f"  - æ—¥æœŸ: {report['date'].strftime('%Y-%m-%d')} ({report['date_source']})\n"
                plan += f"  - å¤§å°: {size_kb:.1f} KB\n"
                plan += f"  - åˆ†é¡: {report['category']}\n"
                plan += "\n"
            
            plan += f"**é è¨ˆé‡‹æ”¾ç©ºé–“**: {total_size:.1f} KB\n\n"
        else:
            plan += "âœ… æ²’æœ‰ç™¼ç¾éœ€è¦æ¸…ç†çš„å ±å‘Š\n\n"
        
        plan += """### ğŸ”’ ä¿ç•™çš„é‡è¦å ±å‘Š

"""
        
        if analysis['old_important']:
            for report in sorted(analysis['old_important'], key=lambda x: x['date']):
                plan += f"- **{report['name']}** (ä¿ç•™åŸå› : é‡è¦æ–‡æª”)\n"
                plan += f"  - è·¯å¾‘: `{report['relative_path']}`\n"
                plan += f"  - æ—¥æœŸ: {report['date'].strftime('%Y-%m-%d')}\n\n"
        
        plan += """### âš ï¸ æ—¥æœŸä¸æ˜çš„å ±å‘Š

"""
        
        if analysis['unknown_date']:
            for report in analysis['unknown_date']:
                plan += f"- **{report['name']}**\n"
                plan += f"  - è·¯å¾‘: `{report['relative_path']}`\n"
                plan += f"  - å»ºè­°: æ‰‹å‹•æª¢æŸ¥ä¸¦æ·»åŠ æ™‚é–“æˆ³\n\n"
        
        plan += """## æ¸…ç†æ“ä½œ

### è‡ªå‹•æ¸…ç†
```bash
# åŸ·è¡Œæ¸…ç†è¨ˆåŠƒ
python scripts/misc/cleanup_old_reports.py --execute

# åƒ…é è¦½æ¸…ç†
python scripts/misc/cleanup_old_reports.py --preview
```

### æ‰‹å‹•æ¸…ç†
å»ºè­°çš„æ¸…ç†æ­¥é©Ÿï¼š
1. å‚™ä»½é‡è¦å ±å‘Š
2. ç§»å‹•åˆ° `_archive` ç›®éŒ„è€Œéç›´æ¥åˆªé™¤
3. 30å¤©å¾Œå†æ°¸ä¹…åˆªé™¤

## å®‰å…¨æªæ–½

- âœ… è‡ªå‹•å‚™ä»½åˆ° `_archive/cleanup_{timestamp}/`
- âœ… ä¿ç•™æ‰€æœ‰é‡è¦æ–‡æª”å’ŒæŒ‡å—
- âœ… ä¸åˆªé™¤æœ€è¿‘ 7 å¤©å…§çš„å ±å‘Š
- âœ… æä¾›å¾©åŸæ©Ÿåˆ¶

---

**æ¸…ç†å·¥å…·**: `cleanup_old_reports.py`  
**å‚™ä»½ä½ç½®**: `_archive/cleanup_{timestamp}/`
"""
        
        return plan
    
    def execute_cleanup(self, analysis: Dict, dry_run: bool = True) -> Dict:
        """åŸ·è¡Œæ¸…ç†æ“ä½œ"""
        cleanup_stats = {
            'planned': len(analysis['cleanup_candidates']),
            'moved': 0,
            'failed': 0,
            'total_size': 0
        }
        
        if not analysis['cleanup_candidates']:
            print("âœ… æ²’æœ‰éœ€è¦æ¸…ç†çš„å ±å‘Š")
            return cleanup_stats
        
        # å‰µå»ºå‚™ä»½ç›®éŒ„
        backup_dir = self.root_path / "_archive" / f"cleanup_{self.timestamp}"
        
        if not dry_run:
            backup_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ å‰µå»ºå‚™ä»½ç›®éŒ„: {backup_dir.relative_to(self.root_path)}")
        
        print(f"\n{'ğŸ” é è¦½' if dry_run else 'ğŸ—‘ï¸ åŸ·è¡Œ'} æ¸…ç†æ“ä½œ:")
        print("-" * 50)
        
        for report in analysis['cleanup_candidates']:
            try:
                cleanup_stats['total_size'] += report['size']
                
                if dry_run:
                    print(f"ğŸ“„ å°‡ç§»å‹•: {report['relative_path']}")
                else:
                    # å‰µå»ºå‚™ä»½ç›®éŒ„çµæ§‹
                    backup_file_dir = backup_dir / report['path'].parent.relative_to(self.reports_dir)
                    backup_file_dir.mkdir(parents=True, exist_ok=True)
                    
                    # ç§»å‹•æª”æ¡ˆåˆ°å‚™ä»½ç›®éŒ„
                    backup_file_path = backup_file_dir / report['path'].name
                    report['path'].rename(backup_file_path)
                    
                    print(f"âœ… å·²ç§»å‹•: {report['relative_path']} â†’ _archive/")
                    cleanup_stats['moved'] += 1
                    
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•— {report['name']}: {e}")
                cleanup_stats['failed'] += 1
        
        return cleanup_stats
    
    def save_cleanup_plan(self, plan: str) -> bool:
        """ä¿å­˜æ¸…ç†è¨ˆåŠƒ"""
        try:
            plan_file = self.reports_dir / "project_status" / f"REPORT_CLEANUP_PLAN_{self.timestamp}.md"
            plan_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(plan_file, 'w', encoding='utf-8') as f:
                f.write(plan)
            
            print(f"ğŸ“‹ æ¸…ç†è¨ˆåŠƒå·²ä¿å­˜: {plan_file.relative_to(self.root_path)}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¸…ç†è¨ˆåŠƒå¤±æ•—: {e}")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='AIVA å ±å‘Šæ¸…ç†å·¥å…·')
    parser.add_argument('--execute', action='store_true', help='åŸ·è¡Œæ¸…ç†æ“ä½œ')
    parser.add_argument('--preview', action='store_true', help='åƒ…é è¦½æ¸…ç†è¨ˆåŠƒ')
    args = parser.parse_args()
    
    cleaner = AIVAReportCleaner()
    
    print("ğŸš€ é–‹å§‹åˆ†æ AIVA å ±å‘Šæª”æ¡ˆ")
    print("=" * 50)
    
    # åˆ†æå ±å‘Š
    analysis = cleaner.analyze_reports()
    
    # ç”Ÿæˆæ¸…ç†è¨ˆåŠƒ
    plan = cleaner.generate_cleanup_plan(analysis)
    cleaner.save_cleanup_plan(plan)
    
    # é¡¯ç¤ºçµ±è¨ˆ
    print(f"\nğŸ“Š åˆ†æå®Œæˆçµ±è¨ˆ:")
    print(f"   æœ€è¿‘å ±å‘Š: {len(analysis['recent'])} å€‹")
    print(f"   èˆŠé‡è¦å ±å‘Š: {len(analysis['old_important'])} å€‹")
    print(f"   èˆŠå·²å®Œæˆå ±å‘Š: {len(analysis['old_completed'])} å€‹")
    print(f"   æ¸…ç†å€™é¸: {len(analysis['cleanup_candidates'])} å€‹")
    
    # åŸ·è¡Œæˆ–é è¦½æ¸…ç†
    if args.execute:
        print(f"\nğŸ—‘ï¸ åŸ·è¡Œæ¸…ç†æ“ä½œ...")
        stats = cleaner.execute_cleanup(analysis, dry_run=False)
        print(f"\nâœ¨ æ¸…ç†å®Œæˆ:")
        print(f"   è¨ˆåŠƒæ¸…ç†: {stats['planned']} å€‹")
        print(f"   æˆåŠŸç§»å‹•: {stats['moved']} å€‹")
        print(f"   å¤±æ•—: {stats['failed']} å€‹")
        print(f"   é‡‹æ”¾ç©ºé–“: {stats['total_size']/1024:.1f} KB")
    elif args.preview or len(analysis['cleanup_candidates']) > 0:
        print(f"\nğŸ” é è¦½æ¸…ç†æ“ä½œ...")
        cleaner.execute_cleanup(analysis, dry_run=True)
        print(f"\nğŸ’¡ åŸ·è¡Œæ¸…ç†: python scripts/misc/cleanup_old_reports.py --execute")

if __name__ == "__main__":
    main()