#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIVA Word æ–‡æª”è½‰ Markdown å·¥å…·
å°‡ .docx æª”æ¡ˆè½‰æ›ç‚º .md æ ¼å¼ä¸¦é€²è¡Œå…§å®¹åˆ†æ
"""

import sys
import os
from pathlib import Path
from docx import Document
import re
from typing import List, Dict, Any

class DocxToMarkdownConverter:
    """Word æ–‡æª”è½‰ Markdown è½‰æ›å™¨"""
    
    def __init__(self):
        self.content_stats = {
            'total_paragraphs': 0,
            'total_tables': 0,
            'total_images': 0,
            'headings': {},
            'key_sections': []
        }
    
    def convert_docx_to_markdown(self, docx_path: str, output_path: str = None) -> str:
        """
        å°‡ Word æ–‡æª”è½‰æ›ç‚º Markdown
        
        Args:
            docx_path: Word æ–‡æª”è·¯å¾‘
            output_path: è¼¸å‡º Markdown æª”æ¡ˆè·¯å¾‘
        
        Returns:
            Markdown å…§å®¹å­—ä¸²
        """
        try:
            # è®€å– Word æ–‡æª”
            doc = Document(docx_path)
            markdown_content = []
            
            # è™•ç†æ–‡æª”æ¨™é¡Œ
            if hasattr(doc, 'core_properties') and doc.core_properties.title:
                markdown_content.append(f"# {doc.core_properties.title}\n")
            
            # è™•ç†æ®µè½
            for paragraph in doc.paragraphs:
                self.content_stats['total_paragraphs'] += 1
                md_line = self._convert_paragraph_to_markdown(paragraph)
                if md_line.strip():
                    markdown_content.append(md_line)
            
            # è™•ç†è¡¨æ ¼
            for table in doc.tables:
                self.content_stats['total_tables'] += 1
                md_table = self._convert_table_to_markdown(table)
                markdown_content.append(md_table)
            
            # åˆä½µå…§å®¹
            full_markdown = '\n'.join(markdown_content)
            
            # å¦‚æœæŒ‡å®šäº†è¼¸å‡ºè·¯å¾‘ï¼Œå¯«å…¥æª”æ¡ˆ
            if output_path:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(full_markdown)
                print(f"âœ… Markdown æª”æ¡ˆå·²ä¿å­˜è‡³: {output_path}")
            
            return full_markdown
            
        except Exception as e:
            print(f"âŒ è½‰æ›å¤±æ•—: {e}")
            return ""
    
    def _convert_paragraph_to_markdown(self, paragraph) -> str:
        """å°‡æ®µè½è½‰æ›ç‚º Markdown æ ¼å¼"""
        if not paragraph.text.strip():
            return ""
        
        text = paragraph.text.strip()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™é¡Œ
        if paragraph.style.name.startswith('Heading'):
            level = int(paragraph.style.name.split()[-1]) if paragraph.style.name.split()[-1].isdigit() else 1
            self.content_stats['headings'][level] = self.content_stats['headings'].get(level, 0) + 1
            return f"{'#' * level} {text}\n"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ—è¡¨é …
        if paragraph.style.name in ['List Paragraph', 'ListParagraph']:
            return f"- {text}\n"
        
        # ä¸€èˆ¬æ®µè½
        return f"{text}\n"
    
    def _convert_table_to_markdown(self, table) -> str:
        """å°‡è¡¨æ ¼è½‰æ›ç‚º Markdown æ ¼å¼"""
        if not table.rows:
            return ""
        
        markdown_table = []
        
        # è™•ç†è¡¨é ­
        header_row = table.rows[0]
        headers = [cell.text.strip() for cell in header_row.cells]
        markdown_table.append("| " + " | ".join(headers) + " |")
        markdown_table.append("| " + " | ".join(["---"] * len(headers)) + " |")
        
        # è™•ç†è³‡æ–™è¡Œ
        for row in table.rows[1:]:
            cells = [cell.text.strip() for cell in row.cells]
            markdown_table.append("| " + " | ".join(cells) + " |")
        
        return "\n".join(markdown_table) + "\n\n"
    
    def analyze_content(self, markdown_content: str) -> Dict[str, Any]:
        """åˆ†æ Markdown å…§å®¹"""
        analysis = {
            'document_stats': self.content_stats.copy(),
            'content_analysis': {},
            'key_topics': [],
            'technical_sections': [],
            'recommendations': []
        }
        
        # å­—æ•¸çµ±è¨ˆ
        word_count = len(markdown_content.split())
        char_count = len(markdown_content)
        line_count = len(markdown_content.split('\n'))
        
        analysis['content_analysis'] = {
            'word_count': word_count,
            'character_count': char_count,
            'line_count': line_count,
            'estimated_reading_time': f"{word_count // 200} åˆ†é˜"
        }
        
        # å°‹æ‰¾é—œéµä¸»é¡Œ
        key_patterns = [
            r'å¤šèªè¨€.*?ç¨‹å¼',
            r'AIVA.*?ç³»çµ±',
            r'Python.*?Go.*?Rust',
            r'å®‰å…¨.*?å¹³å°',
            r'æ¶æ§‹.*?è¨­è¨ˆ',
            r'æ€§èƒ½.*?å„ªåŒ–',
            r'æ¨¡çµ„.*?æ•´åˆ'
        ]
        
        for pattern in key_patterns:
            matches = re.findall(pattern, markdown_content, re.IGNORECASE)
            if matches:
                analysis['key_topics'].extend(matches[:3])  # æœ€å¤šå– 3 å€‹åŒ¹é…
        
        # å°‹æ‰¾æŠ€è¡“æ®µè½
        tech_patterns = [
            r'.*?API.*?',
            r'.*?æ¶æ§‹.*?',
            r'.*?æ¨¡çµ„.*?',
            r'.*?ç³»çµ±.*?',
            r'.*?å¯¦ç¾.*?',
            r'.*?å„ªåŒ–.*?'
        ]
        
        lines = markdown_content.split('\n')
        for line in lines:
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in tech_patterns):
                if len(line.strip()) > 10:  # éæ¿¾å¤ªçŸ­çš„è¡Œ
                    analysis['technical_sections'].append(line.strip())
        
        # é™åˆ¶æŠ€è¡“æ®µè½æ•¸é‡
        analysis['technical_sections'] = analysis['technical_sections'][:10]
        
        return analysis
    
    def generate_analysis_report(self, analysis: Dict[str, Any], markdown_content: str) -> str:
        """ç”¢ç”Ÿåˆ†æå ±å‘Š"""
        report = []
        
        report.append("# ğŸ“Š AIVA å¤šèªè¨€ç¨‹å¼è™•ç†èƒ½åŠ›å¯¦ç¾ç ”ç©¶ - åˆ†æå ±å‘Š\n")
        
        # æ–‡æª”çµ±è¨ˆ
        report.append("## ğŸ“ˆ æ–‡æª”çµ±è¨ˆè³‡è¨Š")
        stats = analysis['content_analysis']
        report.append(f"- **å­—æ•¸**: {stats['word_count']:,} å­—")
        report.append(f"- **å­—å…ƒæ•¸**: {stats['character_count']:,} å­—å…ƒ")
        report.append(f"- **è¡Œæ•¸**: {stats['line_count']:,} è¡Œ")
        report.append(f"- **é ä¼°é–±è®€æ™‚é–“**: {stats['estimated_reading_time']}")
        report.append(f"- **æ®µè½æ•¸**: {analysis['document_stats']['total_paragraphs']}")
        report.append(f"- **è¡¨æ ¼æ•¸**: {analysis['document_stats']['total_tables']}")
        report.append("")
        
        # æ¨™é¡Œçµæ§‹
        if analysis['document_stats']['headings']:
            report.append("## ğŸ“‹ æ–‡æª”çµæ§‹")
            for level, count in sorted(analysis['document_stats']['headings'].items()):
                report.append(f"- ç¬¬ {level} ç´šæ¨™é¡Œ: {count} å€‹")
            report.append("")
        
        # é—œéµä¸»é¡Œ
        if analysis['key_topics']:
            report.append("## ğŸ¯ é—œéµä¸»é¡Œ")
            for topic in set(analysis['key_topics'][:5]):  # å»é‡ä¸¦é™åˆ¶æ•¸é‡
                report.append(f"- {topic}")
            report.append("")
        
        # æŠ€è¡“é‡é»
        if analysis['technical_sections']:
            report.append("## ğŸ”§ æŠ€è¡“é‡é»æ®µè½")
            for i, section in enumerate(analysis['technical_sections'][:5], 1):
                report.append(f"{i}. {section}")
            report.append("")
        
        # å…§å®¹é è¦½
        report.append("## ğŸ“„ æ–‡æª”å…§å®¹é è¦½")
        lines = markdown_content.split('\n')
        preview_lines = [line for line in lines[:20] if line.strip()][:10]
        for line in preview_lines:
            if line.startswith('#'):
                report.append(f"\n{line}")
            else:
                report.append(f"   {line}")
        
        if len(lines) > 20:
            report.append("\n   ... (å…§å®¹å·²æˆªæ–·)")
        
        report.append("")
        
        return '\n'.join(report)

def main():
    """ä¸»å‡½æ•¸"""
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    docx_file = r"C:\D\fold7\AIVA-git\_out\AIVA å¤šèªè¨€ç¨‹å¼è™•ç†èƒ½åŠ›çš„å¯¦ç¾ç ”ç©¶.docx"
    md_file = r"C:\D\fold7\AIVA-git\_out\AIVA_å¤šèªè¨€ç¨‹å¼è™•ç†èƒ½åŠ›çš„å¯¦ç¾ç ”ç©¶.md"
    analysis_file = r"C:\D\fold7\AIVA-git\_out\AIVA_å¤šèªè¨€ç¨‹å¼è™•ç†èƒ½åŠ›åˆ†æå ±å‘Š.md"
    
    if not os.path.exists(docx_file):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {docx_file}")
        return
    
    print(f"ğŸ”„ é–‹å§‹è½‰æ› Word æ–‡æª”...")
    print(f"ğŸ“ ä¾†æºæª”æ¡ˆ: {docx_file}")
    
    # å»ºç«‹è½‰æ›å™¨
    converter = DocxToMarkdownConverter()
    
    # è½‰æ›ç‚º Markdown
    markdown_content = converter.convert_docx_to_markdown(docx_file, md_file)
    
    if markdown_content:
        print(f"âœ… è½‰æ›å®Œæˆ!")
        
        # åˆ†æå…§å®¹
        print(f"ğŸ” æ­£åœ¨åˆ†æå…§å®¹...")
        analysis = converter.analyze_content(markdown_content)
        
        # ç”¢ç”Ÿåˆ†æå ±å‘Š
        report = converter.generate_analysis_report(analysis, markdown_content)
        
        # ä¿å­˜åˆ†æå ±å‘Š
        with open(analysis_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“Š åˆ†æå ±å‘Šå·²ä¿å­˜è‡³: {analysis_file}")
        
        # é¡¯ç¤ºç°¡è¦çµ±è¨ˆ
        print(f"\nğŸ“ˆ å¿«é€Ÿçµ±è¨ˆ:")
        print(f"   - å­—æ•¸: {analysis['content_analysis']['word_count']:,}")
        print(f"   - æ®µè½: {analysis['document_stats']['total_paragraphs']}")
        print(f"   - è¡¨æ ¼: {analysis['document_stats']['total_tables']}")
        print(f"   - é ä¼°é–±è®€æ™‚é–“: {analysis['content_analysis']['estimated_reading_time']}")
        
    else:
        print("âŒ è½‰æ›å¤±æ•—")

if __name__ == "__main__":
    main()