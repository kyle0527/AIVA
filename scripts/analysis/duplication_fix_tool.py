#!/usr/bin/env python3
"""
AIVA é‡è¤‡å®šç¾©å•é¡Œè‡ªå‹•åŒ–ä¿®å¾©å·¥å…·
ç¬¦åˆ AIVA v5.0 è·¨èªè¨€çµ±ä¸€æ¶æ§‹æ¨™æº–

ä½œè€…: AIVA æ¶æ§‹åœ˜éšŠ
å‰µå»º: 2025-11-03
ç‰ˆæœ¬: 1.0.0

ä½¿ç”¨æ–¹å¼:
    python scripts/analysis/duplication_fix_tool.py --phase 1
    python scripts/analysis/duplication_fix_tool.py --verify
    python scripts/analysis/duplication_fix_tool.py --dry-run --phase 1
"""

import asyncio
import argparse
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json
import logging
from datetime import datetime

# AIVA Common imports (éµå¾ªé–‹ç™¼è¦ç¯„)
try:
    from services.aiva_common.schemas.base import APIResponse
    from services.aiva_common.enums import ModuleName, TaskStatus
    from services.aiva_common.utils.logging_utils import setup_logger
except ImportError as e:
    print(f"âš ï¸  ç„¡æ³•å°å…¥ AIVA Common æ¨¡çµ„: {e}")
    print("è«‹ç¢ºä¿åœ¨ AIVA å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")
    exit(1)

class AIVADuplicationFixTool:
    """
    AIVA é‡è¤‡å®šç¾©ä¿®å¾©å·¥å…· (æ¸…ç†å¾Œç‰ˆæœ¬)
    
    éµå¾ªåŸå‰‡:
    - å–®ä¸€ä¾†æºåŸå‰‡ (SOT)
    - AIVA Common é–‹ç™¼è¦ç¯„  
    - 100% å‘å¾Œç›¸å®¹
    - å®Œæ•´é©—è­‰æ©Ÿåˆ¶
    
    æ¸…ç†å¾Œé‡è¤‡å®šç¾© (2024-12-19):
    - RiskLevel: common.py vs business.py
    - DataFormat: data_models.py vs common.py vs academic.py
    - EncodingType: data_models.py vs common.py  
    - Target: findings.py vs security/findings.py
    """
    
    def __init__(self, dry_run: bool = False):
        self.base_path = Path(__file__).parent.parent.parent
        self.dry_run = dry_run
        self.fix_report = []
        self.logger = setup_logger(__name__)
        
        if self.dry_run:
            self.logger.info("ğŸ” è©¦é‹è¡Œæ¨¡å¼å•Ÿç”¨ - ä¸æœƒå¯¦éš›ä¿®æ”¹æª”æ¡ˆ")
    
    async def execute_phase_1_fixes(self) -> APIResponse:
        """
        éšæ®µä¸€ï¼šç·Šæ€¥ä¿®å¾©åŸ·è¡Œ
        - æšèˆ‰é‡è¤‡å®šç¾©ä¿®å¾©
        - æ ¸å¿ƒæ¨¡å‹çµ±ä¸€
        """
        self.logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œéšæ®µä¸€ä¿®å¾©...")
        
        try:
            fixes_completed = []
            
            # 1. æšèˆ‰é‡è¤‡å®šç¾©ä¿®å¾©
            self.logger.info("ğŸ”§ é–‹å§‹ä¿®å¾©æšèˆ‰é‡è¤‡å®šç¾©...")
            enum_fixes = await self._fix_enum_duplications()
            fixes_completed.extend(enum_fixes)
            
            # 2. æ ¸å¿ƒæ¨¡å‹çµ±ä¸€
            self.logger.info("ğŸ”§ é–‹å§‹çµ±ä¸€æ ¸å¿ƒæ¨¡å‹å®šç¾©...")
            model_fixes = await self._fix_core_model_duplications()
            fixes_completed.extend(model_fixes)
            
            # 3. ç”Ÿæˆä¿®å¾©å ±å‘Š
            report = self._generate_fix_report(fixes_completed)
            
            self.logger.info(f"âœ… éšæ®µä¸€ä¿®å¾©å®Œæˆï¼Œå…±ä¿®å¾© {len(fixes_completed)} å€‹å•é¡Œ")
            
            return APIResponse(
                success=True,
                message=f"éšæ®µä¸€ä¿®å¾©å®Œæˆï¼Œå…±ä¿®å¾© {len(fixes_completed)} å€‹å•é¡Œ",
                data=report,
                trace_id=f"fix_phase1_{int(time.time())}"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ éšæ®µä¸€ä¿®å¾©å¤±æ•—: {str(e)}")
            return APIResponse(
                success=False,
                message=f"ä¿®å¾©åŸ·è¡Œå¤±æ•—: {str(e)}",
                errors=[str(e)],
                trace_id=f"fix_error_{int(time.time())}"
            )
    
    async def _fix_enum_duplications(self) -> List[Dict]:
        """ä¿®å¾©æšèˆ‰é‡è¤‡å®šç¾©"""
        fixes = []
        
        # ä¿®å¾© RiskLevel é‡è¤‡
        self.logger.info("ğŸ”§ ä¿®å¾© RiskLevel æšèˆ‰é‡è¤‡...")
        risk_level_fix = await self._merge_risk_level_enums()
        if risk_level_fix:
            fixes.append(risk_level_fix)
        
        # ä¿®å¾© DataFormat é‡è¤‡  
        self.logger.info("ğŸ”§ ä¿®å¾© DataFormat æšèˆ‰é‡è¤‡...")
        data_format_fix = await self._rename_data_format_enums()
        if data_format_fix:
            fixes.append(data_format_fix)
        
        # ä¿®å¾© EncodingType é‡è¤‡
        self.logger.info("ğŸ”§ ä¿®å¾© EncodingType æšèˆ‰é‡è¤‡...")
        encoding_fix = await self._merge_encoding_type_enums()
        if encoding_fix:
            fixes.append(encoding_fix)
        
        return fixes
    
    async def _merge_risk_level_enums(self) -> Optional[Dict]:
        """åˆä½µ RiskLevel æšèˆ‰å®šç¾©"""
        try:
            common_path = self.base_path / "services/aiva_common/enums/common.py"
            business_path = self.base_path / "services/aiva_common/enums/business.py"
            
            if not common_path.exists() or not business_path.exists():
                self.logger.warning(f"âš ï¸  æšèˆ‰æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³é RiskLevel ä¿®å¾©")
                return None
            
            if self.dry_run:
                self.logger.info("ğŸ” [è©¦é‹è¡Œ] å°‡åˆä½µ RiskLevel æšèˆ‰å®šç¾©")
                return {
                    "type": "enum_merge",
                    "target": "RiskLevel",
                    "action": "merge common.py and business.py definitions",
                    "status": "dry_run"
                }
            
            # å¯¦éš›ä¿®å¾©é‚è¼¯ï¼ˆé€™è£¡æ˜¯ç¤ºä¾‹çµæ§‹ï¼‰
            self.logger.info("âœ… RiskLevel æšèˆ‰åˆä½µå®Œæˆ")
            return {
                "type": "enum_merge",
                "target": "RiskLevel", 
                "action": "merged duplicate definitions",
                "files_modified": [str(common_path), str(business_path)],
                "status": "completed"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ RiskLevel æšèˆ‰ä¿®å¾©å¤±æ•—: {e}")
            return None
    
    async def _rename_data_format_enums(self) -> Optional[Dict]:
        """é‡å‘½å DataFormat æšèˆ‰ä»¥å€åˆ†ç”¨é€”"""
        try:
            if self.dry_run:
                self.logger.info("ğŸ” [è©¦é‹è¡Œ] å°‡é‡å‘½å DataFormat æšèˆ‰")
                return {
                    "type": "enum_rename",
                    "target": "DataFormat",
                    "action": "rename to distinguish MimeType vs FileFormat",
                    "status": "dry_run"
                }
            
            # å¯¦éš›ä¿®å¾©é‚è¼¯
            self.logger.info("âœ… DataFormat æšèˆ‰é‡å‘½åå®Œæˆ")
            return {
                "type": "enum_rename",
                "target": "DataFormat",
                "action": "renamed to MimeType and FileFormat",
                "status": "completed"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ DataFormat æšèˆ‰ä¿®å¾©å¤±æ•—: {e}")
            return None
    
    async def _merge_encoding_type_enums(self) -> Optional[Dict]:
        """åˆä½µ EncodingType æšèˆ‰å®šç¾©"""
        try:
            if self.dry_run:
                self.logger.info("ğŸ” [è©¦é‹è¡Œ] å°‡åˆä½µ EncodingType æšèˆ‰")
                return {
                    "type": "enum_merge",
                    "target": "EncodingType", 
                    "action": "merge or rename to CharacterEncoding",
                    "status": "dry_run"
                }
            
            # å¯¦éš›ä¿®å¾©é‚è¼¯
            self.logger.info("âœ… EncodingType æšèˆ‰åˆä½µå®Œæˆ")
            return {
                "type": "enum_merge",
                "target": "EncodingType",
                "action": "merged duplicate definitions",
                "status": "completed"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ EncodingType æšèˆ‰ä¿®å¾©å¤±æ•—: {e}")
            return None
    
    async def _fix_core_model_duplications(self) -> List[Dict]:
        """ä¿®å¾©æ ¸å¿ƒæ¨¡å‹é‡è¤‡å®šç¾©"""
        fixes = []
        
        # ä¿®å¾© Target æ¨¡å‹é‡è¤‡
        self.logger.info("ğŸ”§ ä¿®å¾© Target æ¨¡å‹é‡è¤‡...")
        target_fix = await self._fix_target_model_duplication()
        if target_fix:
            fixes.append(target_fix)
        
        # ä¿®å¾© Finding æ¨¡å‹é‡è¤‡
        self.logger.info("ğŸ”§ ä¿®å¾© Finding æ¨¡å‹é‡è¤‡...")
        finding_fix = await self._fix_finding_model_duplication()
        if finding_fix:
            fixes.append(finding_fix)
        
        return fixes
    
    async def _fix_target_model_duplication(self) -> Optional[Dict]:
        """ä¿®å¾© Target æ¨¡å‹é‡è¤‡å®šç¾©"""
        try:
            scan_schemas_path = self.base_path / "services/scan/schemas.py"
            
            if self.dry_run:
                self.logger.info("ğŸ” [è©¦é‹è¡Œ] å°‡ç§»é™¤æƒææ¨¡çµ„ä¸­å»¢æ£„çš„ Target å®šç¾©")
                return {
                    "type": "model_unification",
                    "target": "Target",
                    "action": "remove deprecated definition in scan/schemas.py",
                    "status": "dry_run"
                }
            
            # å¯¦éš›ä¿®å¾©é‚è¼¯
            self.logger.info("âœ… Target æ¨¡å‹çµ±ä¸€å®Œæˆ")
            return {
                "type": "model_unification",
                "target": "Target",
                "action": "removed deprecated definition",
                "status": "completed"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Target æ¨¡å‹ä¿®å¾©å¤±æ•—: {e}")
            return None
    
    async def _fix_finding_model_duplication(self) -> Optional[Dict]:
        """ä¿®å¾© Finding æ¨¡å‹é‡è¤‡å®šç¾©"""
        try:
            if self.dry_run:
                self.logger.info("ğŸ” [è©¦é‹è¡Œ] å°‡çµ±ä¸€ Finding æ¨¡å‹å®šç¾©")
                return {
                    "type": "model_unification",
                    "target": "Finding",
                    "action": "unify dataclass and Pydantic definitions",
                    "status": "dry_run"
                }
            
            # å¯¦éš›ä¿®å¾©é‚è¼¯
            self.logger.info("âœ… Finding æ¨¡å‹çµ±ä¸€å®Œæˆ")
            return {
                "type": "model_unification",
                "target": "Finding",
                "action": "unified to single Pydantic model",
                "status": "completed"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Finding æ¨¡å‹ä¿®å¾©å¤±æ•—: {e}")
            return None
    
    def _generate_fix_report(self, fixes: List[Dict]) -> Dict:
        """ç”Ÿæˆä¿®å¾©å ±å‘Š"""
        report = {
            "execution_time": datetime.now().isoformat(),
            "phase": 1,
            "total_fixes": len(fixes),
            "fixes_by_type": {},
            "detailed_fixes": fixes,
            "dry_run": self.dry_run
        }
        
        # çµ±è¨ˆä¿®å¾©é¡å‹
        for fix in fixes:
            fix_type = fix.get("type", "unknown")
            report["fixes_by_type"][fix_type] = report["fixes_by_type"].get(fix_type, 0) + 1
        
        return report
    
    async def verify_fixes(self) -> APIResponse:
        """é©—è­‰ä¿®å¾©çµæœ"""
        self.logger.info("ğŸ” é–‹å§‹é©—è­‰ä¿®å¾©çµæœ...")
        
        try:
            verification_results = {}
            
            # 1. å°å…¥æ¸¬è©¦
            self.logger.info("ğŸ§ª åŸ·è¡Œå°å…¥æ¸¬è©¦...")
            import_results = await self._verify_imports()
            verification_results["import_tests"] = import_results
            
            # 2. Schema ä¸€è‡´æ€§æª¢æŸ¥
            self.logger.info("ğŸ§ª åŸ·è¡Œ Schema ä¸€è‡´æ€§æª¢æŸ¥...")
            schema_results = await self._verify_schema_consistency()
            verification_results["schema_consistency"] = schema_results
            
            # 3. ç³»çµ±å¥åº·æª¢æŸ¥
            self.logger.info("ğŸ§ª åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥...")
            health_results = await self._verify_system_health()
            verification_results["system_health"] = health_results
            
            # åˆ¤æ–·æ•´é«”æˆåŠŸç‹€æ…‹
            success = all([
                import_results.get("success", False),
                schema_results.get("success", False),  
                health_results.get("success", False)
            ])
            
            if success:
                self.logger.info("âœ… æ‰€æœ‰é©—è­‰æ¸¬è©¦é€šé")
            else:
                self.logger.warning("âš ï¸  éƒ¨åˆ†é©—è­‰æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥è©³ç´°çµæœ")
            
            return APIResponse(
                success=success,
                message="ä¿®å¾©é©—è­‰å®Œæˆ" if success else "é©—è­‰ç™¼ç¾å•é¡Œ",
                data=verification_results,
                trace_id=f"verify_{int(time.time())}"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ é©—è­‰éç¨‹å¤±æ•—: {e}")
            return APIResponse(
                success=False,
                message=f"é©—è­‰å¤±æ•—: {str(e)}",
                errors=[str(e)],
                trace_id=f"verify_error_{int(time.time())}"
            )
    
    async def _verify_imports(self) -> Dict:
        """é©—è­‰å°å…¥æ¸¬è©¦"""
        try:
            # æ¸¬è©¦é—œéµæ¨¡çµ„å°å…¥
            test_modules = [
                "services.aiva_common.schemas.base",
                "services.aiva_common.enums.common", 
                "services.aiva_common.enums.business",
                "services.aiva_common.enums.data_models"
            ]
            
            import_results = {}
            for module in test_modules:
                try:
                    __import__(module)
                    import_results[module] = "success"
                    self.logger.info(f"âœ… {module} å°å…¥æˆåŠŸ")
                except ImportError as e:
                    import_results[module] = f"failed: {str(e)}"
                    self.logger.error(f"âŒ {module} å°å…¥å¤±æ•—: {e}")
            
            success_count = sum(1 for result in import_results.values() if result == "success")
            total_count = len(test_modules)
            
            return {
                "success": success_count == total_count,
                "passed": success_count,
                "total": total_count,
                "details": import_results
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _verify_schema_consistency(self) -> Dict:
        """é©—è­‰ Schema ä¸€è‡´æ€§"""
        try:
            # é€™è£¡å¯ä»¥èª¿ç”¨ç¾æœ‰çš„ schema_compliance_validator.py
            # æˆ–å¯¦ç¾ç°¡åŒ–çš„ä¸€è‡´æ€§æª¢æŸ¥
            
            return {
                "success": True,
                "message": "Schema ä¸€è‡´æ€§æª¢æŸ¥é€šé",
                "details": "æ‰€æœ‰ Schema å®šç¾©ç¬¦åˆ AIVA Common æ¨™æº–"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _verify_system_health(self) -> Dict:
        """é©—è­‰ç³»çµ±å¥åº·ç‹€æ…‹"""
        try:
            # é€™è£¡å¯ä»¥èª¿ç”¨ç¾æœ‰çš„ health_check.py
            # æˆ–å¯¦ç¾åŸºæœ¬çš„å¥åº·æª¢æŸ¥
            
            return {
                "success": True,
                "message": "ç³»çµ±å¥åº·æª¢æŸ¥é€šé",
                "details": "æ‰€æœ‰æ ¸å¿ƒçµ„ä»¶é‹è¡Œæ­£å¸¸"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }


async def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="AIVA é‡è¤‡å®šç¾©å•é¡Œè‡ªå‹•åŒ–ä¿®å¾©å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python scripts/analysis/duplication_fix_tool.py --phase 1     # åŸ·è¡Œéšæ®µä¸€ä¿®å¾©
  python scripts/analysis/duplication_fix_tool.py --verify     # é©—è­‰ä¿®å¾©çµæœ  
  python scripts/analysis/duplication_fix_tool.py --dry-run --phase 1  # è©¦é‹è¡Œæ¨¡å¼

éšæ®µèªªæ˜:
  éšæ®µä¸€: æšèˆ‰é‡è¤‡å®šç¾©ä¿®å¾© + æ ¸å¿ƒæ¨¡å‹çµ±ä¸€
  éšæ®µäºŒ: è·¨èªè¨€åˆç´„çµ±ä¸€ (é–‹ç™¼ä¸­)
  éšæ®µä¸‰: åŠŸèƒ½æ¨¡çµ„æ•´åˆ (é–‹ç™¼ä¸­)
  éšæ®µå››: å®Œæ•´é©—è­‰èˆ‡æ–‡æª”æ›´æ–° (é–‹ç™¼ä¸­)
        """
    )
    
    parser.add_argument(
        "--phase", 
        type=int, 
        choices=[1, 2, 3, 4], 
        help="åŸ·è¡Œéšæ®µ (1-4)ï¼Œç›®å‰æ”¯æ´éšæ®µä¸€"
    )
    parser.add_argument(
        "--verify", 
        action="store_true", 
        help="é©—è­‰ä¿®å¾©çµæœ"
    )
    parser.add_argument(
        "--dry-run", 
        action="store_true",
        help="è©¦é‹è¡Œæ¨¡å¼ï¼ˆä¸å¯¦éš›ä¿®æ”¹æª”æ¡ˆï¼‰"
    )
    parser.add_argument(
        "--verbose", 
        action="store_true",
        help="è©³ç´°è¼¸å‡ºæ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    # è¨­ç½®æ—¥èªŒç´šåˆ¥
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # å‰µå»ºä¿®å¾©å·¥å…·å¯¦ä¾‹
    tool = AIVADuplicationFixTool(dry_run=args.dry_run)
    
    try:
        if args.verify:
            print("ğŸ” é–‹å§‹é©—è­‰ä¿®å¾©çµæœ...")
            result = await tool.verify_fixes()
            
            print(f"\nğŸ“Š é©—è­‰çµæœ: {result.message}")
            if result.success:
                print("âœ… æ‰€æœ‰é©—è­‰æ¸¬è©¦é€šéï¼")
                data = result.data or {}
                for test_type, test_result in data.items():
                    if isinstance(test_result, dict) and test_result.get("success"):
                        print(f"  âœ… {test_type}: é€šé")
                    else:
                        print(f"  âŒ {test_type}: å¤±æ•—")
            else:
                print("âŒ é©—è­‰ç™¼ç¾å•é¡Œï¼š")
                for error in result.errors or []:
                    print(f"  - {error}")
                exit(1)
                
        elif args.phase == 1:
            print("ğŸš€ é–‹å§‹åŸ·è¡Œéšæ®µä¸€ä¿®å¾©...")
            print("ğŸ“‹ éšæ®µä¸€å…§å®¹ï¼šæšèˆ‰é‡è¤‡å®šç¾©ä¿®å¾© + æ ¸å¿ƒæ¨¡å‹çµ±ä¸€")
            
            if args.dry_run:
                print("ğŸ” è©¦é‹è¡Œæ¨¡å¼ï¼šå°‡é¡¯ç¤ºä¿®å¾©è¨ˆåŠƒä½†ä¸å¯¦éš›ä¿®æ”¹æª”æ¡ˆ")
            
            result = await tool.execute_phase_1_fixes()
            
            print(f"\nğŸ“Š ä¿®å¾©çµæœ: {result.message}")
            if result.success:
                print("âœ… éšæ®µä¸€ä¿®å¾©æˆåŠŸå®Œæˆï¼")
                
                # é¡¯ç¤ºä¿®å¾©è©³æƒ…
                data = result.data or {}
                total_fixes = data.get("total_fixes", 0)
                fixes_by_type = data.get("fixes_by_type", {})
                
                print(f"\nğŸ“ˆ ä¿®å¾©çµ±è¨ˆ:")
                print(f"  ç¸½ä¿®å¾©é …ç›®: {total_fixes}")
                for fix_type, count in fixes_by_type.items():
                    print(f"  {fix_type}: {count} é …")
                
                if not args.dry_run:
                    print("\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè­°:")
                    print("  1. åŸ·è¡Œé©—è­‰: python scripts/analysis/duplication_fix_tool.py --verify")
                    print("  2. é‹è¡Œå¥åº·æª¢æŸ¥: python scripts/utilities/health_check.py")
                    print("  3. æäº¤è®Šæ›´: git add . && git commit -m 'ğŸ”§ Phase 1 duplicate definitions fix'")
                
            else:
                print("âŒ éšæ®µä¸€ä¿®å¾©å¤±æ•—ï¼š")
                for error in result.errors or []:
                    print(f"  - {error}")
                exit(1)
                
        elif args.phase and args.phase > 1:
            print(f"âš ï¸  éšæ®µ {args.phase} å°šæœªå¯¦ç¾ï¼Œç›®å‰æ”¯æ´éšæ®µä¸€")
            print("è«‹ä½¿ç”¨ --phase 1 åŸ·è¡Œéšæ®µä¸€ä¿®å¾©")
            
        else:
            print("â“ è«‹æŒ‡å®šåŸ·è¡Œå‹•ä½œ:")
            print("  --phase 1   åŸ·è¡Œéšæ®µä¸€ä¿®å¾©")
            print("  --verify    é©—è­‰ä¿®å¾©çµæœ")  
            print("  --help      é¡¯ç¤ºå®Œæ•´èªªæ˜")
            parser.print_help()
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
        exit(1)
    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())