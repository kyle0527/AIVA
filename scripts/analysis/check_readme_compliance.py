#!/usr/bin/env python3
"""
AIVA README åˆè¦æ€§æª¢æŸ¥å·¥å…·

æª¢æŸ¥æ‰€æœ‰ README.md æª”æ¡ˆæ˜¯å¦éµå¾ª aiva_common ä¿®è­·è¦ç¯„
ä¸¦è‡ªå‹•æ›´æ–°ç¼ºå¤±çš„è¦ç¯„å…§å®¹
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json

class ReadmeComplianceChecker:
    """README åˆè¦æ€§æª¢æŸ¥å™¨"""
    
    def __init__(self, workspace_root: str):
        self.workspace_root = Path(workspace_root)
        self.compliance_template = self._load_compliance_template()
        self.results = []
        
    def _load_compliance_template(self) -> Dict[str, str]:
        """è¼‰å…¥ aiva_common ä¿®è­·è¦ç¯„æ¨¡æ¿"""
        return {
            "section_title": "## ğŸ”§ é–‹ç™¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸",
            "aiva_common_header": "### ğŸ“ **aiva_common ä¿®è­·è¦ç¯„éµå¾ª**",
            "importance_note": "> **é‡è¦**: æœ¬æ¨¡çµ„åš´æ ¼éµå¾ª [aiva_common ä¿®è­·è¦ç¯„](../aiva_common/README.md#ğŸ”§-é–‹ç™¼æŒ‡å—)ï¼Œç¢ºä¿æ‰€æœ‰å®šç¾©ã€æšèˆ‰å¼•ç”¨åŠä¿®å¾©éƒ½åœ¨åŒä¸€å¥—æ¨™æº–ä¹‹ä¸‹ã€‚",
            "standard_import_header": "#### âœ… **æ¨™æº–å°å…¥ç¯„ä¾‹**",
            "prohibited_practices_header": "#### ğŸš¨ **åš´æ ¼ç¦æ­¢çš„åšæ³•**",
            "module_specific_header": "#### ğŸ” **æ¨¡çµ„ç‰¹å®šæšèˆ‰åˆ¤æ–·æ¨™æº–**",
            "development_checklist_header": "#### ğŸ“‹ **é–‹ç™¼æª¢æŸ¥æ¸…å–®**",
            "repair_principles_header": "#### ğŸ› ï¸ **ä¿®å¾©åŸå‰‡**",
            "repair_principle_text": "**ä¿ç•™æœªä½¿ç”¨å‡½æ•¸åŸå‰‡**: åœ¨ç¨‹å¼ç¢¼ä¿®å¾©éç¨‹ä¸­ï¼Œè‹¥ç™¼ç¾æœ‰å®šç¾©ä½†å°šæœªä½¿ç”¨çš„å‡½æ•¸æˆ–æ–¹æ³•ï¼Œåªè¦ä¸å½±éŸ¿ç¨‹å¼æ­£å¸¸é‹ä½œï¼Œå»ºè­°äºˆä»¥ä¿ç•™ã€‚é€™äº›å¯èƒ½æ˜¯é ç•™çš„ API ä»‹é¢æˆ–æœªä¾†åŠŸèƒ½çš„åŸºç¤æ¶æ§‹ã€‚"
        }
    
    def scan_all_readmes(self) -> List[Path]:
        """æƒææ‰€æœ‰ README.md æª”æ¡ˆï¼ˆæ’é™¤ç¬¬ä¸‰æ–¹åº«ï¼‰"""
        readme_files = []
        
        # æ’é™¤çš„ç›®éŒ„æ¨¡å¼
        exclude_patterns = [
            "node_modules",
            ".git",
            "__pycache__",
            ".venv",
            "venv",
            ".pytest_cache",
            "target",  # Rust build ç›®éŒ„
            "build",
            "dist",
            "vendor",  # Go vendor ç›®éŒ„
        ]
        
        def should_exclude(path: Path) -> bool:
            """æª¢æŸ¥è·¯å¾‘æ˜¯å¦æ‡‰è¢«æ’é™¤"""
            path_parts = path.parts
            for pattern in exclude_patterns:
                if pattern in path_parts:
                    return True
            return False
        
        # ä¸»è¦æœå‹™æ¨¡çµ„
        services_dir = self.workspace_root / "services"
        if services_dir.exists():
            for readme in services_dir.rglob("README.md"):
                if not should_exclude(readme) and "aiva_common" not in str(readme):
                    readme_files.append(readme)
        
        # å·¥å…·æ¨¡çµ„
        tools_dir = self.workspace_root / "tools"
        if tools_dir.exists():
            for readme in tools_dir.rglob("README.md"):
                if not should_exclude(readme):
                    readme_files.append(readme)
        
        # å…¶ä»–é‡è¦æ¨¡çµ„
        for subdir in ["web", "testing", "utilities"]:
            subdir_path = self.workspace_root / subdir
            if subdir_path.exists():
                readme_path = subdir_path / "README.md"
                if readme_path.exists() and not should_exclude(readme_path):
                    readme_files.append(readme_path)
        
        # æ ¹ç›®éŒ„ README
        root_readme = self.workspace_root / "README.md"
        if root_readme.exists():
            readme_files.append(root_readme)
            
        return sorted(readme_files)
    
    def check_readme_compliance(self, readme_path: Path) -> Dict:
        """æª¢æŸ¥å–®å€‹ README çš„åˆè¦æ€§"""
        try:
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return {
                "file": str(readme_path),
                "error": f"ç„¡æ³•è®€å–æª”æ¡ˆ: {e}",
                "compliant": False
            }
        
        # æª¢æŸ¥é …ç›®
        checks = {}
        
        # 1. æª¢æŸ¥æ˜¯å¦æœ‰ç›®éŒ„ä¸”åœ¨æœ€å‰é¢
        toc_pattern = r'^## ğŸ“‹? ç›®éŒ„|^## ğŸ“‘ ç›®éŒ„|^## ï¿½ ç›®éŒ„'
        has_toc = bool(re.search(toc_pattern, content, re.MULTILINE))
        
        # æª¢æŸ¥ç›®éŒ„ä½ç½®ï¼ˆæ‡‰åœ¨å‰ 200 è¡Œå…§ï¼‰
        lines = content.split('\n')
        toc_early = False
        if has_toc:
            for i, line in enumerate(lines[:200]):
                if re.match(toc_pattern, line):
                    toc_early = True
                    break
        
        checks["has_toc"] = has_toc
        checks["toc_early"] = toc_early
        
        # 2. æª¢æŸ¥æ˜¯å¦æœ‰é–‹ç™¼è¦ç¯„ç« ç¯€
        has_dev_standards = "é–‹ç™¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸" in content
        checks["has_dev_standards"] = has_dev_standards
        
        # 3. æª¢æŸ¥æ˜¯å¦æœ‰ aiva_common ä¿®è­·è¦ç¯„
        has_aiva_common_section = "aiva_common ä¿®è­·è¦ç¯„" in content or "aiva_common" in content
        checks["has_aiva_common_section"] = has_aiva_common_section
        
        # 4. æª¢æŸ¥æ˜¯å¦æœ‰æ¨™æº–å°å…¥ç¯„ä¾‹
        has_import_examples = "æ¨™æº–å°å…¥ç¯„ä¾‹" in content or "from.*aiva_common" in content
        checks["has_import_examples"] = has_import_examples
        
        # 5. æª¢æŸ¥æ˜¯å¦æœ‰ç¦æ­¢åšæ³•èªªæ˜
        has_prohibited_practices = "ç¦æ­¢åšæ³•" in content or "åš´æ ¼ç¦æ­¢" in content
        checks["has_prohibited_practices"] = has_prohibited_practices
        
        # 6. æª¢æŸ¥æ˜¯å¦æœ‰ä¿®å¾©åŸå‰‡
        has_repair_principles = "ä¿®å¾©åŸå‰‡" in content or "ä¿ç•™æœªä½¿ç”¨å‡½æ•¸" in content
        checks["has_repair_principles"] = has_repair_principles
        
        # 7. æª¢æŸ¥ç›¸å°è·¯å¾‘å¼•ç”¨çš„ aiva_common
        relative_path = self._get_aiva_common_relative_path(readme_path)
        correct_aiva_common_path = f"[aiva_common ä¿®è­·è¦ç¯„]({relative_path}/README.md#ğŸ”§-é–‹ç™¼æŒ‡å—)" in content
        checks["correct_aiva_common_path"] = correct_aiva_common_path
        
        # è¨ˆç®—åˆè¦æ€§åˆ†æ•¸
        total_checks = len(checks)
        passed_checks = sum(1 for v in checks.values() if v)
        compliance_score = passed_checks / total_checks
        
        # åˆ¤æ–·æ˜¯å¦åˆè¦ï¼ˆ80% ä»¥ä¸Šé€šéï¼‰
        is_compliant = compliance_score >= 0.8
        
        return {
            "file": str(readme_path),
            "relative_path": str(readme_path.relative_to(self.workspace_root)),
            "checks": checks,
            "compliance_score": compliance_score,
            "compliant": is_compliant,
            "missing_items": [k for k, v in checks.items() if not v],
            "aiva_common_relative_path": relative_path
        }
    
    def _get_aiva_common_relative_path(self, readme_path: Path) -> str:
        """è¨ˆç®—åˆ° aiva_common çš„ç›¸å°è·¯å¾‘"""
        try:
            # å¾ README ä½ç½®åˆ° aiva_common çš„ç›¸å°è·¯å¾‘
            readme_dir = readme_path.parent
            aiva_common_path = self.workspace_root / "services" / "aiva_common"
            relative = os.path.relpath(aiva_common_path, readme_dir)
            return relative.replace("\\", "/")  # çµ±ä¸€ä½¿ç”¨ Unix é¢¨æ ¼è·¯å¾‘
        except Exception:
            return "../aiva_common"  # é è¨­å€¼
    
    def generate_compliance_section(self, readme_path: Path, module_type: str = "service") -> str:
        """ç”Ÿæˆåˆè¦æ€§ç« ç¯€å…§å®¹"""
        relative_path = self._get_aiva_common_relative_path(readme_path)
        
        # æ ¹æ“šæ¨¡çµ„é¡å‹èª¿æ•´å…§å®¹
        if "integration" in str(readme_path).lower():
            module_name = "Integration"
            import_example = """# âœ… æ­£ç¢º - Integration æ¨¡çµ„çš„æ¨™æº–å°å…¥
from ..aiva_common.enums import (
    Severity,                # é¢¨éšªè©•ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    Confidence,              # ä¿¡å¿ƒåº¦ (CERTAIN, FIRM, POSSIBLE)
    TaskStatus,              # ä»»å‹™ç‹€æ…‹ (PENDING, RUNNING, COMPLETED)
    AssetType,               # è³‡ç”¢é¡å‹ (URL, HOST, REPOSITORY)
    VulnerabilityStatus,     # æ¼æ´ç‹€æ…‹ (NEW, OPEN, IN_PROGRESS)
)
from ..aiva_common.schemas import (
    FindingPayload,          # ç™¼ç¾çµæœæ¨™æº–æ ¼å¼
    CVSSv3Metrics,           # CVSS v3.1 æ¨™æº–è©•åˆ†
    SARIFResult,             # SARIF v2.1.0 å ±å‘Šæ ¼å¼
    AivaMessage,             # çµ±ä¸€è¨Šæ¯æ ¼å¼
)"""
        elif "core" in str(readme_path).lower():
            module_name = "Core"
            import_example = """# âœ… æ­£ç¢º - Core æ¨¡çµ„çš„æ¨™æº–å°å…¥
from ..aiva_common.enums import (
    Severity,                # é¢¨éšªè©•ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    Confidence,              # ä¿¡å¿ƒåº¦ (CERTAIN, FIRM, POSSIBLE)
    TaskStatus,              # ä»»å‹™ç‹€æ…‹ (PENDING, RUNNING, COMPLETED)
    RiskLevel,               # é¢¨éšªç­‰ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    ThreatLevel,             # å¨è„…ç­‰ç´š
)
from ..aiva_common.schemas import (
    TaskUpdatePayload,       # ä»»å‹™æ›´æ–°æ ¼å¼
    AivaMessage,             # çµ±ä¸€è¨Šæ¯æ ¼å¼
    FindingPayload,          # ç™¼ç¾çµæœæ¨™æº–æ ¼å¼
)"""
        elif "scan" in str(readme_path).lower():
            module_name = "Scan"
            import_example = """# âœ… æ­£ç¢º - Scan æ¨¡çµ„çš„æ¨™æº–å°å…¥
from ..aiva_common.enums import (
    Severity,                # é¢¨éšªè©•ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    Confidence,              # ä¿¡å¿ƒåº¦ (CERTAIN, FIRM, POSSIBLE)
    VulnerabilityType,       # æ¼æ´é¡å‹ (SQL_INJECTION, XSS, SSRF)
    AssetType,               # è³‡ç”¢é¡å‹ (URL, HOST, REPOSITORY)
)
from ..aiva_common.schemas import (
    ScanStartPayload,        # æƒæå•Ÿå‹•æ ¼å¼
    SARIFResult,             # SARIF v2.1.0 å ±å‘Šæ ¼å¼
    CVSSv3Metrics,           # CVSS v3.1 æ¨™æº–è©•åˆ†
    FindingPayload,          # ç™¼ç¾çµæœæ¨™æº–æ ¼å¼
)"""
        elif "features" in str(readme_path).lower():
            module_name = "Features"
            import_example = """# âœ… æ­£ç¢º - Features æ¨¡çµ„çš„æ¨™æº–å°å…¥
from ..aiva_common.enums import (
    Severity,                # é¢¨éšªè©•ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    Confidence,              # ä¿¡å¿ƒåº¦ (CERTAIN, FIRM, POSSIBLE)
    VulnerabilityType,       # æ¼æ´é¡å‹ (SQL_INJECTION, XSS, SSRF)
    Exploitability,          # å¯åˆ©ç”¨æ€§è©•ä¼°
)
from ..aiva_common.schemas import (
    FunctionTaskPayload,     # åŠŸèƒ½ä»»å‹™æ ¼å¼
    FunctionTaskResult,      # åŠŸèƒ½çµæœæ ¼å¼
    FindingPayload,          # ç™¼ç¾çµæœæ¨™æº–æ ¼å¼
    SARIFResult,             # SARIF v2.1.0 å ±å‘Šæ ¼å¼
)"""
        else:
            module_name = "æœ¬æ¨¡çµ„"
            import_example = """# âœ… æ­£ç¢º - æ¨™æº–å°å…¥ç¯„ä¾‹
from ..aiva_common.enums import (
    Severity,                # é¢¨éšªè©•ç´š (CRITICAL, HIGH, MEDIUM, LOW)
    Confidence,              # ä¿¡å¿ƒåº¦ (CERTAIN, FIRM, POSSIBLE)
    TaskStatus,              # ä»»å‹™ç‹€æ…‹ (PENDING, RUNNING, COMPLETED)
)
from ..aiva_common.schemas import (
    FindingPayload,          # ç™¼ç¾çµæœæ¨™æº–æ ¼å¼
    AivaMessage,             # çµ±ä¸€è¨Šæ¯æ ¼å¼
)"""
        
        template = f"""## ğŸ”§ é–‹ç™¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸

### ğŸ“ **aiva_common ä¿®è­·è¦ç¯„éµå¾ª**

> **é‡è¦**: {module_name} æ¨¡çµ„åš´æ ¼éµå¾ª [aiva_common ä¿®è­·è¦ç¯„]({relative_path}/README.md#ğŸ”§-é–‹ç™¼æŒ‡å—)ï¼Œç¢ºä¿æ‰€æœ‰å®šç¾©ã€æšèˆ‰å¼•ç”¨åŠä¿®å¾©éƒ½åœ¨åŒä¸€å¥—æ¨™æº–ä¹‹ä¸‹ã€‚

#### âœ… **æ¨™æº–å°å…¥ç¯„ä¾‹**

```python
{import_example}
```

#### ğŸš¨ **åš´æ ¼ç¦æ­¢çš„åšæ³•**

```python
# âŒ ç¦æ­¢ - é‡è¤‡å®šç¾©é€šç”¨æšèˆ‰
class Severity(str, Enum):  # éŒ¯èª¤!ä½¿ç”¨ aiva_common.Severity
    CRITICAL = "critical"

# âŒ ç¦æ­¢ - é‡è¤‡å®šç¾©æ¨™æº–çµæ§‹  
class FindingPayload(BaseModel):  # éŒ¯èª¤!ä½¿ç”¨ aiva_common.FindingPayload
    finding_id: str

# âŒ ç¦æ­¢ - è‡ªå‰µè©•åˆ†æ¨™æº–
class CustomCVSS(BaseModel):  # éŒ¯èª¤!ä½¿ç”¨ aiva_common.CVSSv3Metrics
    score: float
```

#### ğŸ” **æ¨¡çµ„ç‰¹å®šæšèˆ‰åˆ¤æ–·æ¨™æº–**

åªæœ‰æ»¿è¶³ **æ‰€æœ‰** æ¢ä»¶æ™‚ï¼Œæ‰å…è¨±åœ¨æ¨¡çµ„å…§å®šç¾©å°ˆå±¬æšèˆ‰ï¼š

1. **å®Œå…¨å°ˆå±¬æ€§**: è©²æšèˆ‰æ¦‚å¿µåƒ…ç”¨æ–¼æœ¬æ¨¡çµ„å…§éƒ¨é‚è¼¯
2. **éé€šç”¨æ¦‚å¿µ**: ä¸æ˜¯è·¨æ¨¡çµ„å…±äº«çš„æ¦‚å¿µï¼ˆå¦‚ Severityã€Confidenceï¼‰
3. **é«˜åº¦æŠ€è¡“å°ˆå±¬**: èˆ‡æ¨¡çµ„ç‰¹å®šæŠ€è¡“å¯¦ç¾ç·Šå¯†ç›¸é—œ
4. **ä¸å½±éŸ¿äº’æ“ä½œæ€§**: ä¸æœƒç ´å£è·¨æ¨¡çµ„æ•¸æ“šäº¤æ›

#### ğŸ“‹ **é–‹ç™¼æª¢æŸ¥æ¸…å–®**

åœ¨{module_name}æ¨¡çµ„é–‹ç™¼æ™‚ï¼Œè«‹ç¢ºèªï¼š

- [ ] **åœ‹éš›æ¨™æº–å„ªå…ˆ**: å„ªå…ˆä½¿ç”¨ CVSSã€SARIFã€CVEã€CWE ç­‰å®˜æ–¹æ¨™æº–
- [ ] **aiva_common å°å…¥**: æ‰€æœ‰é€šç”¨æ¦‚å¿µéƒ½å¾ aiva_common å°å…¥
- [ ] **ç„¡é‡è¤‡å®šç¾©**: ç¢ºä¿æ²’æœ‰é‡è¤‡å®šç¾©å·²å­˜åœ¨çš„æšèˆ‰æˆ– Schema
- [ ] **æ¨¡çµ„å°ˆç”¨æ€§**: æ–°å®šç¾©çš„æšèˆ‰ç¢ºå¯¦åƒ…ç”¨æ–¼æœ¬æ¨¡çµ„å…§éƒ¨
- [ ] **æ–‡æª”å®Œæ•´æ€§**: æ‰€æœ‰è‡ªå®šç¾©é¡å‹éƒ½æœ‰å®Œæ•´çš„ docstring èªªæ˜

#### ğŸ› ï¸ **ä¿®å¾©åŸå‰‡**

**ä¿ç•™æœªä½¿ç”¨å‡½æ•¸åŸå‰‡**: åœ¨ç¨‹å¼ç¢¼ä¿®å¾©éç¨‹ä¸­ï¼Œè‹¥ç™¼ç¾æœ‰å®šç¾©ä½†å°šæœªä½¿ç”¨çš„å‡½æ•¸æˆ–æ–¹æ³•ï¼Œåªè¦ä¸å½±éŸ¿ç¨‹å¼æ­£å¸¸é‹ä½œï¼Œå»ºè­°äºˆä»¥ä¿ç•™ã€‚é€™äº›å¯èƒ½æ˜¯é ç•™çš„ API ä»‹é¢æˆ–æœªä¾†åŠŸèƒ½çš„åŸºç¤æ¶æ§‹ã€‚

---"""
        
        return template
    
    def update_readme_with_compliance(self, readme_path: Path) -> bool:
        """æ›´æ–° README ä½¿å…¶ç¬¦åˆåˆè¦æ€§è¦æ±‚"""
        try:
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ ç„¡æ³•è®€å– {readme_path}: {e}")
            return False
        
        # æª¢æŸ¥ç•¶å‰åˆè¦æ€§
        compliance_check = self.check_readme_compliance(readme_path)
        
        if compliance_check["compliant"]:
            print(f"âœ… {readme_path.name} å·²ç¶“ç¬¦åˆè¦ç¯„")
            return True
        
        modified = False
        
        # 1. æª¢æŸ¥ä¸¦æ·»åŠ ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨æˆ–ä½ç½®ä¸æ­£ç¢ºï¼‰
        if not compliance_check["checks"]["has_toc"] or not compliance_check["checks"]["toc_early"]:
            content = self._ensure_toc_at_top(content)
            modified = True
        
        # 2. æª¢æŸ¥ä¸¦æ·»åŠ é–‹ç™¼è¦ç¯„ç« ç¯€
        if not compliance_check["checks"]["has_dev_standards"]:
            compliance_section = self.generate_compliance_section(readme_path)
            
            # åœ¨æ–‡æª”æœ«å°¾æ·»åŠ åˆè¦æ€§ç« ç¯€
            if "---\n\n**ç¶­è­·ç‹€æ…‹**" in content:
                # åœ¨ç¶­è­·ç‹€æ…‹å‰æ’å…¥
                content = content.replace("---\n\n**ç¶­è­·ç‹€æ…‹**", f"{compliance_section}\n\n---\n\n**ç¶­è­·ç‹€æ…‹**")
            elif content.endswith("---"):
                # åœ¨æœ€å¾Œçš„åˆ†éš”ç·šå‰æ’å…¥
                content = content[:-3] + f"\n{compliance_section}\n\n---"
            else:
                # ç›´æ¥æ·»åŠ åˆ°æœ«å°¾
                content += f"\n\n{compliance_section}"
            
            modified = True
        
        # 3. æ›´æ–° aiva_common ç›¸å°è·¯å¾‘å¼•ç”¨
        if not compliance_check["checks"]["correct_aiva_common_path"]:
            relative_path = compliance_check["aiva_common_relative_path"]
            
            # ä¿®æ­£ aiva_common è·¯å¾‘å¼•ç”¨
            patterns = [
                (r'\[aiva_common ä¿®è­·è¦ç¯„\]\([^)]+\)', f'[aiva_common ä¿®è­·è¦ç¯„]({relative_path}/README.md#ğŸ”§-é–‹ç™¼æŒ‡å—)'),
                (r'\[aiva_common\]\([^)]+\)', f'[aiva_common]({relative_path}/README.md)'),
            ]
            
            for pattern, replacement in patterns:
                if re.search(pattern, content):
                    content = re.sub(pattern, replacement, content)
                    modified = True
        
        # å„²å­˜ä¿®æ”¹
        if modified:
            try:
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… å·²æ›´æ–° {readme_path.name}")
                return True
            except Exception as e:
                print(f"âŒ ç„¡æ³•å¯«å…¥ {readme_path}: {e}")
                return False
        
        return True
    
    def _ensure_toc_at_top(self, content: str) -> str:
        """ç¢ºä¿ç›®éŒ„åœ¨æ–‡æª”å‰é¢"""
        lines = content.split('\n')
        
        # å°‹æ‰¾ç¾æœ‰ç›®éŒ„
        toc_start = -1
        toc_end = -1
        
        for i, line in enumerate(lines):
            if re.match(r'^## ğŸ“‹? ç›®éŒ„|^## ğŸ“‘ ç›®éŒ„|^## ï¿½ ç›®éŒ„', line):
                toc_start = i
                # å°‹æ‰¾ç›®éŒ„çµæŸï¼ˆä¸‹ä¸€å€‹ ## æˆ– ---ï¼‰
                for j in range(i + 1, len(lines)):
                    if lines[j].startswith('##') or lines[j].startswith('---'):
                        toc_end = j
                        break
                break
        
        # å¦‚æœæ²’æœ‰ç›®éŒ„ï¼Œå‰µå»ºä¸€å€‹åŸºæœ¬çš„
        if toc_start == -1:
            # æ‰¾åˆ°æ¨™é¡Œå¾Œæ’å…¥ç›®éŒ„
            header_end = 0
            for i, line in enumerate(lines):
                if line.startswith('# ') or line.startswith('## '):
                    if i > 0:  # ä¸æ˜¯ç¬¬ä¸€è¡Œ
                        header_end = i
                        break
            
            # æ’å…¥åŸºæœ¬ç›®éŒ„
            basic_toc = [
                "",
                "## ğŸ“‹ ç›®éŒ„",
                "",
                "- [ğŸ› ï¸ é–‹ç™¼å·¥å…·ç®±](#ï¸-é–‹ç™¼å·¥å…·ç®±)",
                "- [ğŸ“Š æ¦‚è¦½](#-æ¦‚è¦½)",
                "- [ğŸš€ å¿«é€Ÿé–‹å§‹](#-å¿«é€Ÿé–‹å§‹)",
                "- [ğŸ”§ é–‹ç™¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸](#-é–‹ç™¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸)",
                "- [ğŸ“š æ–‡æª”](#-æ–‡æª”)",
                "",
                "---",
                ""
            ]
            
            lines = lines[:header_end] + basic_toc + lines[header_end:]
        
        return '\n'.join(lines)
    
    def run_full_check(self) -> Dict:
        """åŸ·è¡Œå®Œæ•´çš„åˆè¦æ€§æª¢æŸ¥"""
        readme_files = self.scan_all_readmes()
        results = {
            "total_files": len(readme_files),
            "compliant_files": 0,
            "non_compliant_files": 0,
            "files": [],
            "summary": {}
        }
        
        print(f"ğŸ” æƒæåˆ° {len(readme_files)} å€‹ README æª”æ¡ˆ")
        print("=" * 60)
        
        for readme_path in readme_files:
            print(f"\nğŸ“ æª¢æŸ¥: {readme_path.relative_to(self.workspace_root)}")
            
            compliance_check = self.check_readme_compliance(readme_path)
            results["files"].append(compliance_check)
            
            if compliance_check["compliant"]:
                results["compliant_files"] += 1
                print(f"  âœ… åˆè¦ ({compliance_check['compliance_score']:.1%})")
            else:
                results["non_compliant_files"] += 1
                print(f"  âŒ ä¸åˆè¦ ({compliance_check['compliance_score']:.1%})")
                print(f"     ç¼ºå¤±é …ç›®: {', '.join(compliance_check['missing_items'])}")
        
        # ç”Ÿæˆæ‘˜è¦
        results["summary"] = {
            "compliance_rate": results["compliant_files"] / results["total_files"] if results["total_files"] > 0 else 0,
            "common_issues": self._analyze_common_issues(results["files"])
        }
        
        return results
    
    def _analyze_common_issues(self, files_data: List[Dict]) -> Dict[str, int]:
        """åˆ†æå¸¸è¦‹å•é¡Œ"""
        issues = {}
        for file_data in files_data:
            for missing_item in file_data.get("missing_items", []):
                issues[missing_item] = issues.get(missing_item, 0) + 1
        return dict(sorted(issues.items(), key=lambda x: x[1], reverse=True))
    
    def fix_all_readmes(self) -> Dict:
        """ä¿®å¾©æ‰€æœ‰ä¸åˆè¦çš„ README"""
        readme_files = self.scan_all_readmes()
        results = {
            "total_files": len(readme_files),
            "updated_files": 0,
            "failed_files": 0,
            "already_compliant": 0,
            "details": []
        }
        
        print(f"ğŸ”§ é–‹å§‹ä¿®å¾© {len(readme_files)} å€‹ README æª”æ¡ˆ")
        print("=" * 60)
        
        for readme_path in readme_files:
            print(f"\nğŸ“ è™•ç†: {readme_path.relative_to(self.workspace_root)}")
            
            # æª¢æŸ¥ç•¶å‰ç‹€æ…‹
            before_check = self.check_readme_compliance(readme_path)
            
            if before_check["compliant"]:
                results["already_compliant"] += 1
                results["details"].append({
                    "file": str(readme_path.relative_to(self.workspace_root)),
                    "status": "already_compliant",
                    "before_score": before_check["compliance_score"],
                    "after_score": before_check["compliance_score"]
                })
                continue
            
            # å˜—è©¦ä¿®å¾©
            success = self.update_readme_with_compliance(readme_path)
            
            if success:
                # é‡æ–°æª¢æŸ¥
                after_check = self.check_readme_compliance(readme_path)
                results["updated_files"] += 1
                results["details"].append({
                    "file": str(readme_path.relative_to(self.workspace_root)),
                    "status": "updated",
                    "before_score": before_check["compliance_score"],
                    "after_score": after_check["compliance_score"],
                    "improvements": [item for item in before_check["missing_items"] 
                                  if item not in after_check.get("missing_items", [])]
                })
            else:
                results["failed_files"] += 1
                results["details"].append({
                    "file": str(readme_path.relative_to(self.workspace_root)),
                    "status": "failed",
                    "before_score": before_check["compliance_score"],
                    "error": "æ›´æ–°å¤±æ•—"
                })
        
        return results


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AIVA README åˆè¦æ€§æª¢æŸ¥å·¥å…·")
    parser.add_argument("--workspace", default=".", help="å·¥ä½œå€æ ¹ç›®éŒ„è·¯å¾‘")
    parser.add_argument("--check-only", action="store_true", help="åƒ…æª¢æŸ¥ï¼Œä¸åŸ·è¡Œä¿®å¾©")
    parser.add_argument("--fix", action="store_true", help="è‡ªå‹•ä¿®å¾©ä¸åˆè¦çš„æª”æ¡ˆ")
    parser.add_argument("--output", help="è¼¸å‡ºçµæœåˆ° JSON æª”æ¡ˆ")
    
    args = parser.parse_args()
    
    checker = ReadmeComplianceChecker(args.workspace)
    
    if args.fix:
        print("ğŸš€ åŸ·è¡Œè‡ªå‹•ä¿®å¾©æ¨¡å¼")
        results = checker.fix_all_readmes()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¿®å¾©çµæœæ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ“ ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
        print(f"âœ… å·²åˆè¦æª”æ¡ˆ: {results['already_compliant']}")
        print(f"ğŸ”§ å·²ä¿®å¾©æª”æ¡ˆ: {results['updated_files']}")
        print(f"âŒ ä¿®å¾©å¤±æ•—: {results['failed_files']}")
        
        if results['updated_files'] > 0:
            print(f"\nğŸ‰ æˆåŠŸæ›´æ–°äº† {results['updated_files']} å€‹æª”æ¡ˆ!")
            print("\nğŸ“ æ›´æ–°è©³æƒ…:")
            for detail in results['details']:
                if detail['status'] == 'updated':
                    score_improvement = detail['after_score'] - detail['before_score']
                    print(f"  âœ… {detail['file']}")
                    print(f"     åˆè¦æ€§: {detail['before_score']:.1%} â†’ {detail['after_score']:.1%} (+{score_improvement:.1%})")
                    if detail.get('improvements'):
                        print(f"     æ”¹é€²é …ç›®: {', '.join(detail['improvements'])}")
    
    else:
        print("ğŸ” åŸ·è¡Œåˆè¦æ€§æª¢æŸ¥")
        results = checker.run_full_check()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æª¢æŸ¥çµæœæ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ“ ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
        print(f"âœ… åˆè¦æª”æ¡ˆ: {results['compliant_files']}")
        print(f"âŒ ä¸åˆè¦æª”æ¡ˆ: {results['non_compliant_files']}")
        print(f"ğŸ“ˆ æ•´é«”åˆè¦ç‡: {results['summary']['compliance_rate']:.1%}")
        
        if results['summary']['common_issues']:
            print(f"\nğŸ” å¸¸è¦‹å•é¡Œçµ±è¨ˆ:")
            for issue, count in results['summary']['common_issues'].items():
                print(f"  â€¢ {issue}: {count} å€‹æª”æ¡ˆ")
        
        if results['non_compliant_files'] > 0:
            print(f"\nğŸ’¡ å»ºè­°åŸ·è¡Œ: python {__file__} --fix ä¾†è‡ªå‹•ä¿®å¾©å•é¡Œ")
    
    # è¼¸å‡ºçµæœåˆ°æª”æ¡ˆ
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ çµæœå·²å„²å­˜åˆ°: {args.output}")


if __name__ == "__main__":
    main()