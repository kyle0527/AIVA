#!/usr/bin/env python3
"""
AIVA Schema Code Generation Tool
===============================

åŸºæ–¼ core_schema_sot.yaml è‡ªå‹•ç”Ÿæˆè·¨èªè¨€ Schema å®šç¾©

åŠŸèƒ½ç‰¹è‰²:
- ğŸ”„ æ”¯æ´ Python (Pydantic v2) + Go (structs) + Rust (Serde)
- ğŸ“ è‡ªå‹•ç”Ÿæˆæ–‡æª”å’Œé¡å‹è¨»è§£
- ğŸ” Schema é©—è­‰å’Œå‘å¾Œå…¼å®¹æ€§æª¢æŸ¥
- ğŸš€ VS Code æ•´åˆï¼Œæ”¯æ´ Pylance å’Œ Go æ“´å……åŠŸèƒ½
- ğŸ¯ å–®ä¸€äº‹å¯¦ä¾†æº (Single Source of Truth)

ä½¿ç”¨æ–¹å¼:
    python tools/schema_codegen_tool.py --generate-all
    python tools/schema_codegen_tool.py --lang python --validate
    python tools/schema_codegen_tool.py --lang go --output-dir custom/path
"""

import argparse
import logging

# è¨­å®šæ—¥èªŒ - æ”¯æ´ Unicode
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

import yaml
from jinja2 import Environment, FileSystemLoader, Template

# ==================== å¸¸æ•¸å®šç¾© ====================
OPTIONAL_PREFIX = "Optional["
LIST_PREFIX = "List["
CHRONO_DATETIME = "chrono::DateTime<chrono::Utc>"
STRING_NEW = "String::new()"
URL_URL = "url::Url"



logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("schema_codegen.log", encoding="utf-8"),
    ],
)
logger = logging.getLogger(__name__)


class SchemaCodeGenerator:
    """Schema ä»£ç¢¼ç”Ÿæˆå™¨ - æ”¯æ´å¤šèªè¨€è‡ªå‹•ç”Ÿæˆ"""

    def __init__(self, sot_file: str = "services/aiva_common/core_schema_sot.yaml"):
        """åˆå§‹åŒ–ä»£ç¢¼ç”Ÿæˆå™¨

        Args:
            sot_file: Schema SOT YAML æª”æ¡ˆè·¯å¾‘
        """
        self.sot_file = Path(sot_file)
        self.sot_data: dict[str, Any] = {}
        self.jinja_env = Environment(
            loader=FileSystemLoader(Path(__file__).parent / "templates"),
            trim_blocks=True,
            lstrip_blocks=True,
        )

        # è¼‰å…¥ SOT è³‡æ–™
        self._load_sot_data()

    def _load_sot_data(self) -> None:
        """è¼‰å…¥ Schema SOT è³‡æ–™"""
        try:
            with open(self.sot_file, encoding="utf-8") as f:
                self.sot_data = yaml.safe_load(f)
            logger.info(f"âœ… æˆåŠŸè¼‰å…¥ SOT æª”æ¡ˆ: {self.sot_file}")
        except FileNotFoundError:
            logger.error(f"âŒ SOT æª”æ¡ˆä¸å­˜åœ¨: {self.sot_file}")
            sys.exit(1)
        except yaml.YAMLError as e:
            logger.error(f"âŒ YAML è§£æéŒ¯èª¤: {e}")
            sys.exit(1)

    def generate_python_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Python Pydantic v2 Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["python"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”ŸæˆåŸºç¤é¡å‹
        if "base_types" in self.sot_data:
            base_file = target_dir / "base_types.py"
            content = self._render_python_base_types()
            with open(base_file, "w", encoding="utf-8") as f:
                f.write(content)
            generated_files.append(str(base_file))  # type: ignore
            logger.info(f"âœ… ç”Ÿæˆ Python åŸºç¤é¡å‹: {base_file}")

        # ç”Ÿæˆå„æ¨¡çµ„ Schema - åŒ…å«æ‰€æœ‰æ–°å¢çš„åˆ†é¡
        categories = ["messaging", "tasks", "findings", "async_utils", "plugins", "cli"]
        for category in categories:
            if category in self.sot_data:
                module_file = target_dir / f"{category}.py"
                content = self._render_python_category(category)
                with open(module_file, "w", encoding="utf-8") as f:
                    f.write(content)
                generated_files.append(str(module_file))  # type: ignore
                logger.info(f"âœ… ç”Ÿæˆ Python {category} Schema: {module_file}")

        # ç”Ÿæˆ __init__.py
        init_file = target_dir / "__init__.py"
        content = self._render_python_init()
        with open(init_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(init_file))  # type: ignore

        return generated_files

    def generate_go_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Go struct Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["go"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”Ÿæˆçµ±ä¸€çš„ schemas.go æª”æ¡ˆ
        schema_file = target_dir / "schemas.go"
        content = self._render_go_schemas()
        with open(schema_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(schema_file))  # type: ignore
        logger.info(f"âœ… ç”Ÿæˆ Go Schema: {schema_file}")

        return generated_files

    def generate_rust_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Rust Serde Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["rust"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”Ÿæˆ mod.rs
        mod_file = target_dir / "mod.rs"
        content = self._render_rust_schemas()
        with open(mod_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(mod_file))  # type: ignore
        logger.info(f"âœ… ç”Ÿæˆ Rust Schema: {mod_file}")

        return generated_files

    def _render_python_base_types(self) -> str:
        """æ¸²æŸ“ Python åŸºç¤é¡å‹"""
        content = []
        content.append('"""')  # type: ignore
        content.append("AIVA åŸºç¤é¡å‹ Schema - è‡ªå‹•ç”Ÿæˆ")  # type: ignore
        content.append("=====================================")  # type: ignore
        content.append("")  # type: ignore
        content.append(self.sot_data["metadata"]["description"])  # type: ignore
        content.append("")  # type: ignore
        content.append(f"âš ï¸  {self.sot_data['metadata']['generated_note']}")  # type: ignore
        content.append(f"ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}")  # type: ignore
        content.append(f"ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}")  # type: ignore
        content.append('"""')  # type: ignore
        content.append("")  # type: ignore

        # æ·»åŠ imports
        for imp in self.sot_data["generation_config"]["python"]["base_imports"]:
            content.append(imp)  # type: ignore
        content.append("")  # type: ignore
        content.append("")  # type: ignore

        # ç”Ÿæˆé¡åˆ¥
        for class_name, class_info in self.sot_data["base_types"].items():
            content.append(f"class {class_name}(BaseModel):")  # type: ignore
            content.append(f'    """{class_info["description"]}"""')  # type: ignore
            content.append("")  # type: ignore

            for field_name, field_info in class_info["fields"].items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            content.append("")  # type: ignore

        return "\n".join(content)

    def _render_python_category(self, category: str) -> str:
        """æ¸²æŸ“ Python åˆ†é¡ Schema"""
        content = []
        content.append('"""')  # type: ignore
        content.append(f"AIVA {category.title()} Schema - è‡ªå‹•ç”Ÿæˆ")  # type: ignore
        content.append("=====================================")  # type: ignore
        content.append("")  # type: ignore
        content.append(self.sot_data["metadata"]["description"])  # type: ignore
        content.append("")  # type: ignore
        content.append(f"âš ï¸  {self.sot_data['metadata']['generated_note']}")  # type: ignore
        content.append(f"ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}")  # type: ignore
        content.append(f"ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}")  # type: ignore
        content.append('"""')  # type: ignore
        content.append("")  # type: ignore

        # æ·»åŠ imports
        for imp in self.sot_data["generation_config"]["python"]["base_imports"]:
            content.append(imp)  # type: ignore
        content.append("")  # type: ignore
        content.append("from .base_types import *")  # type: ignore
        content.append("")  # type: ignore
        content.append("")  # type: ignore

        # ç”Ÿæˆé¡åˆ¥
        for class_name, class_info in self.sot_data[category].items():
            content.append(f"class {class_name}(BaseModel):")  # type: ignore
            content.append(f'    """{class_info["description"]}"""')  # type: ignore
            content.append("")  # type: ignore

            # æª¢æŸ¥æ˜¯å¦æœ‰extends
            if "extends" in class_info:
                content.append(f'    # ç¹¼æ‰¿è‡ª: {class_info["extends"]}')  # type: ignore
                content.append("")  # type: ignore

            # è™•ç†fields
            for field_name, field_info in class_info.get("fields", {}).items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            # è™•ç†additional_fields
            for field_name, field_info in class_info.get(
                "additional_fields", {}
            ).items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            content.append("")  # type: ignore

        return "\n".join(content)

    def _render_python_init(self) -> str:
        """æ¸²æŸ“ Python __init__.py"""
        template = Template(
            '''"""
AIVA Schema è‡ªå‹•ç”Ÿæˆæ¨¡çµ„
======================

æ­¤æ¨¡çµ„åŒ…å«æ‰€æœ‰ç”± core_schema_sot.yaml è‡ªå‹•ç”Ÿæˆçš„ Schema å®šç¾©

âš ï¸  è«‹å‹¿æ‰‹å‹•ä¿®æ”¹æ­¤æ¨¡çµ„ä¸­çš„æª”æ¡ˆ
ğŸ”„  å¦‚éœ€æ›´æ–°ï¼Œè«‹ä¿®æ”¹ core_schema_sot.yaml å¾Œé‡æ–°ç”Ÿæˆ
"""

# åŸºç¤é¡å‹
from .base_types import *

# è¨Šæ¯é€šè¨Š
from .messaging import *

# ä»»å‹™ç®¡ç†
from .tasks import *

# ç™¼ç¾çµæœ
from .findings import *

__version__ = "{{ version }}"
__generated_at__ = "{{ generated_at }}"

__all__ = [
    # åŸºç¤é¡å‹
    "MessageHeader",
    "Target", 
    "Vulnerability",
    
    # è¨Šæ¯é€šè¨Š
    "AivaMessage",
    "AIVARequest",
    "AIVAResponse",
    
    # ä»»å‹™ç®¡ç†
    "FunctionTaskPayload",
    "FunctionTaskTarget", 
    "FunctionTaskContext",
    "FunctionTaskTestConfig",
    "ScanTaskPayload",
    
    # ç™¼ç¾çµæœ
    "FindingPayload",
    "FindingEvidence",
    "FindingImpact", 
    "FindingRecommendation",
]
'''
        )

        return template.render(
            version=self.sot_data["version"], generated_at=datetime.now().isoformat()
        )

    def _render_go_schemas(self) -> str:
        """æ¸²æŸ“ Go çµ±ä¸€ Schema - é‡æ§‹å¾Œé™ä½èªçŸ¥è¤‡é›œåº¦"""
        content = []
        
        # ç”Ÿæˆæ–‡ä»¶é ­éƒ¨ä¿¡æ¯
        self._add_go_header(content)
        
        # ç”Ÿæˆå°å…¥èªå¥
        self._add_go_imports(content)
        
        # ç”Ÿæˆæšèˆ‰é¡å‹
        self._add_go_enums(content)
        
        # ç”ŸæˆåŸºç¤é¡å‹
        self._add_go_base_types(content)
        
        # ç”Ÿæˆå…¶ä»–åˆ†é¡
        self._add_go_other_sections(content)
        
        return "\n".join(content)

    def _add_go_header(self, content: list[str]) -> None:
        """æ·»åŠ  Go æ–‡ä»¶é ­éƒ¨ä¿¡æ¯"""
        metadata = self.sot_data["metadata"]
        content.extend([
            "// AIVA Go Schema - è‡ªå‹•ç”Ÿæˆ",
            "// ===========================",
            "//",
            f'// {metadata["description"]}',
            "//",
            f'// âš ï¸  {metadata["generated_note"]}',
            f'// ğŸ“… æœ€å¾Œæ›´æ–°: {metadata["last_updated"]}',
            f'// ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data["version"]}',
            ""
        ])

    def _add_go_imports(self, content: list[str]) -> None:
        """æ·»åŠ  Go å°å…¥èªå¥"""
        base_imports = self.sot_data["generation_config"]["go"]["base_imports"]
        content.extend(base_imports)
        content.append("")

    def _add_go_enums(self, content: list[str]) -> None:
        """æ·»åŠ  Go æšèˆ‰é¡å‹"""
        if "enums" not in self.sot_data:
            return
            
        content.extend([
            "// ==================== æšèˆ‰é¡å‹ ====================",
            ""
        ])
        
        for enum_name, enum_info in self.sot_data["enums"].items():
            self._generate_go_enum(content, enum_name, enum_info)

    def _generate_go_enum(self, content: list[str], enum_name: str, enum_info: dict) -> None:
        """ç”Ÿæˆå–®å€‹ Go æšèˆ‰"""
        description = enum_info.get("description", "")
        content.extend([
            f'// {enum_name} {description}',
            f"type {enum_name} string",
            "",
            "const ("
        ])
        
        for value_key, value_desc in enum_info.get("values", {}).items():
            const_name = f"{enum_name}{value_key.title()}"
            content.append(f'    {const_name:<30} {enum_name} = "{value_key}"  // {value_desc}')
        
        content.extend([")", ""])

    def _add_go_base_types(self, content: list[str]) -> None:
        """æ·»åŠ  Go åŸºç¤é¡å‹"""
        content.extend([
            "// ==================== åŸºç¤é¡å‹ ====================",
            ""
        ])
        
        for class_name, class_info in self.sot_data["base_types"].items():
            self._generate_go_struct(content, class_name, class_info, "base_types")

    def _add_go_other_sections(self, content: list[str]) -> None:
        """æ·»åŠ  Go å…¶ä»–åˆ†é¡"""
        sections = [
            ("messaging", "è¨Šæ¯é€šè¨Š"),
            ("tasks", "ä»»å‹™ç®¡ç†"),
            ("findings", "ç™¼ç¾çµæœ"),
            ("async_utils", "ç•°æ­¥å·¥å…·"),
            ("plugins", "æ’ä»¶ç®¡ç†"),
            ("cli", "CLI ç•Œé¢"),
        ]
        
        for section, title in sections:
            if section in self.sot_data:
                self._generate_go_section(content, section, title)

    def _generate_go_section(self, content: list[str], section: str, title: str) -> None:
        """ç”Ÿæˆ Go åˆ†é¡å€å¡Š"""
        content.extend([
            f"// ==================== {title} ====================",
            ""
        ])
        
        for class_name, class_info in self.sot_data[section].items():
            self._generate_go_struct(content, class_name, class_info, section)

    def _generate_go_struct(self, content: list[str], class_name: str, class_info: dict, section: str) -> None:
        """ç”Ÿæˆ Go çµæ§‹é«”"""
        description = class_info["description"]
        content.extend([
            f'// {class_name} {description}',
            f"type {class_name} struct {{"
        ])
        
        # ç²å–æ‰€æœ‰å­—æ®µï¼ˆåŒ…æ‹¬ç¹¼æ‰¿çš„å­—æ®µï¼‰
        all_fields = self._get_all_fields(class_info, section)
        
        # ç”Ÿæˆæ‰€æœ‰å­—æ®µ
        for field_name, field_info in all_fields.items():
            self._generate_go_struct_field(content, field_name, field_info)
        
        content.extend(["}", ""])

    def _generate_go_struct_field(self, content: list[str], field_name: str, field_info: dict) -> None:
        """ç”Ÿæˆ Go çµæ§‹é«”æ¬„ä½"""
        go_name = self._to_go_field_name(field_name)
        go_type = self._get_go_type(field_info["type"])
        json_tag = self._get_go_json_tag(field_info.get("required", True))
        description = field_info["description"]
        
        content.append(
            f'    {go_name:<20} {go_type:<25} `json:"{field_name}{json_tag}"`  // {description}'
        )

    def _render_rust_schemas(self) -> str:
        """
        æ¸²æŸ“å®Œæ•´çš„ Rust Schema

        ç”ŸæˆåŒ…å«æ‰€æœ‰çµæ§‹é«”ã€æšèˆ‰å’Œåºåˆ—åŒ–æ”¯æŒçš„ Rust ä»£ç¢¼
        """
        rust_code = f"""// AIVA Rust Schema - è‡ªå‹•ç”Ÿæˆ
// ç‰ˆæœ¬: {self.sot_data['version']}
// ç”Ÿæˆæ™‚é–“: {self.sot_data.get('generated_at', 'N/A')}
// 
// å®Œæ•´çš„ Rust Schema å¯¦ç¾ï¼ŒåŒ…å«åºåˆ—åŒ–/ååºåˆ—åŒ–æ”¯æŒ

use serde::{{Serialize, Deserialize}};
use std::collections::HashMap;
use chrono::{{DateTime, Utc}};

// å¯é¸ä¾è³´ - æ ¹æ“šå¯¦éš›ä½¿ç”¨æƒ…æ³å•Ÿç”¨
#[cfg(feature = "uuid")]
use uuid::Uuid;

#[cfg(feature = "url")]
use url::Url;

"""

        # ç”Ÿæˆæšèˆ‰
        for enum_name, enum_data in self.sot_data.get("enums", {}).items():
            rust_code += self._render_rust_enum(enum_name, enum_data)
            rust_code += "\n\n"

        # ç”Ÿæˆçµæ§‹é«” - è™•ç†æ‰€æœ‰é ‚å±¤åˆ†é¡
        all_schemas = {}

        # æ”¶é›†æ‰€æœ‰schemaå®šç¾© - åŒ…å«æ‰€æœ‰æ–°å¢çš„åˆ†é¡
        categories = [
            "base_types",
            "messaging",
            "tasks",
            "findings",
            "async_utils",
            "plugins",
            "cli",
        ]
        for category in categories:
            category_schemas = self.sot_data.get(category, {})
            if isinstance(category_schemas, dict):
                all_schemas.update(category_schemas)

        for schema_name, schema_data in all_schemas.items():
            rust_code += self._render_rust_struct(schema_name, schema_data)
            rust_code += "\n\n"

        return rust_code

    def _render_rust_enum(self, enum_name: str, enum_data: dict) -> str:
        """æ¸²æŸ“ Rust æšèˆ‰"""
        description = enum_data.get("description", f"{enum_name} æšèˆ‰")
        values = enum_data.get("values", {})

        rust_enum = f"""/// {description}
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum {enum_name} {{"""

        for value, desc in values.items():
            rust_enum += f"""
    /// {desc}
    {value.replace('-', '_').upper()},"""

        rust_enum += (
            """
}

impl std::fmt::Display for """
            + enum_name
            + """ {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {"""
        )

        for value in values.keys():
            rust_value = value.replace("-", "_").upper()
            rust_enum += f"""
            {enum_name}::{rust_value} => write!(f, "{value}"),"""

        rust_enum += (
            """
        }
    }
}

impl std::str::FromStr for """
            + enum_name
            + """ {
    type Err = String;
    
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_uppercase().as_str() {"""
        )

        for value in values.keys():
            rust_value = value.replace("-", "_").upper()
            rust_enum += f"""
            "{value.upper()}" => Ok({enum_name}::{rust_value}),"""

        rust_enum += f"""
            _ => Err(format!("Invalid {enum_name}: {{}}", s)),
        }}
    }}
}}"""

        return rust_enum

    def _render_rust_struct(self, struct_name: str, struct_data: dict) -> str:
        """æ¸²æŸ“ Rust çµæ§‹é«” - é‡æ§‹å¾Œé™ä½èªçŸ¥è¤‡é›œåº¦"""
        struct_info = self._extract_struct_metadata(struct_name, struct_data)
        
        struct_header = self._generate_rust_struct_header(struct_name, struct_info.description)
        struct_fields = self._generate_rust_struct_fields(struct_info)
        struct_impl = self._generate_rust_struct_impl(struct_name, struct_info)
        
        return struct_header + struct_fields + struct_impl

    def _extract_struct_metadata(self, struct_name: str, struct_data: dict):
        """æå–çµæ§‹é«”å…ƒæ•¸æ“š"""
        from collections import namedtuple
        StructInfo = namedtuple('StructInfo', ['description', 'properties', 'required'])
        
        description = struct_data.get("description", f"{struct_name} çµæ§‹é«”")
        properties = struct_data.get("properties", struct_data.get("fields", {}))
        required = struct_data.get("required", [])
        
        return StructInfo(description, properties, required)

    def _generate_rust_struct_header(self, struct_name: str, description: str) -> str:
        """ç”Ÿæˆ Rust çµæ§‹é«”é ­éƒ¨"""
        return f"""/// {description}
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct {struct_name} {{"""

    def _generate_rust_struct_fields(self, struct_info) -> str:
        """ç”Ÿæˆ Rust çµæ§‹é«”æ¬„ä½å®šç¾©"""
        fields_code = ""
        
        for field_name, field_data in struct_info.properties.items():
            field_desc = field_data.get("description", f"{field_name} æ¬„ä½")
            field_type, is_optional = self._determine_rust_field_type(
                field_name, field_data, struct_info.required
            )
            
            fields_code += f"""
    /// {field_desc}"""
            
            if is_optional:
                fields_code += f"""
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub {field_name}: {field_type},"""
            else:
                fields_code += f"""
    pub {field_name}: {field_type},"""
        
        return fields_code + """
}

"""

    def _determine_rust_field_type(self, field_name: str, field_data: dict, required: list) -> tuple[str, bool]:
        """æ±ºå®š Rust æ¬„ä½é¡å‹å’Œæ˜¯å¦ç‚ºå¯é¸"""
        original_type = field_data.get("type")
        field_required = field_data.get("required", True)
        is_required_in_struct = field_name in required or field_required

        if original_type and original_type.startswith(OPTIONAL_PREFIX):
            return self._convert_to_rust_type(original_type, field_data), True
        elif not is_required_in_struct:
            base_type = self._convert_to_rust_type(original_type, field_data)
            return f"Option<{base_type}>", True
        else:
            return self._convert_to_rust_type(original_type, field_data), False

    def _generate_rust_struct_impl(self, struct_name: str, struct_info) -> str:
        """ç”Ÿæˆ Rust çµæ§‹é«”å¯¦ç¾éƒ¨åˆ†"""
        new_method = self._generate_rust_new_method(struct_info)
        validate_method = self._generate_rust_validate_method(struct_info)
        default_impl = self._generate_rust_default_impl(struct_name)
        
        return f"""impl {struct_name} {{
    /// å‰µå»ºæ–°çš„å¯¦ä¾‹
    pub fn new() -> Self {{
        Self {{{new_method}
        }}
    }}
    
    /// é©—è­‰çµæ§‹é«”æ•¸æ“š
    pub fn validate(&self) -> Result<(), String> {{{validate_method}
        Ok(())
    }}
}}

{default_impl}"""

    def _generate_rust_new_method(self, struct_info) -> str:
        """ç”Ÿæˆ Rust new æ–¹æ³•çš„æ¬„ä½åˆå§‹åŒ–"""
        init_code = ""
        
        for field_name, field_data in struct_info.properties.items():
            original_type = field_data.get("type")
            field_required = field_data.get("required", True)
            is_required_in_struct = field_name in struct_info.required or field_required

            if self._is_optional_field(original_type, is_required_in_struct):
                init_code += f"""
            {field_name}: None,"""
            else:
                converted_type = self._get_converted_type_for_default(
                    original_type, field_data, is_required_in_struct
                )
                default_value = self._get_rust_default_value(converted_type, field_data)
                init_code += f"""
            {field_name}: {default_value},"""
        
        return init_code

    def _is_optional_field(self, original_type: str, is_required_in_struct: bool) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºå¯é¸æ¬„ä½"""
        return (original_type and original_type.startswith(OPTIONAL_PREFIX)) or not is_required_in_struct

    def _get_converted_type_for_default(self, original_type: str, field_data: dict, is_required_in_struct: bool) -> str:
        """ç²å–ç”¨æ–¼é è¨­å€¼çš„è½‰æ›é¡å‹"""
        if original_type and original_type.startswith(OPTIONAL_PREFIX):
            return self._convert_to_rust_type(original_type, field_data)
        elif not is_required_in_struct:
            base_type = self._convert_to_rust_type(original_type, field_data)
            return f"Option<{base_type}>"
        else:
            return self._convert_to_rust_type(original_type, field_data)

    def _generate_rust_validate_method(self, struct_info) -> str:
        """ç”Ÿæˆ Rust é©—è­‰æ–¹æ³•"""
        validation_code = ""
        
        for field_name in struct_info.required:
            if field_name in struct_info.properties:
                field_type = struct_info.properties[field_name].get("type")
                if field_type == "string":
                    validation_code += f"""
        if self.{field_name}.is_empty() {{
            return Err("Field '{field_name}' is required and cannot be empty".to_string());
        }}"""
        
        return validation_code

    def _generate_rust_default_impl(self, struct_name: str) -> str:
        """ç”Ÿæˆ Rust Default å¯¦ç¾"""
        return f"""impl Default for {struct_name} {{
    fn default() -> Self {{
        Self::new()
    }}
}}"""

    def _convert_to_rust_type(
        self, json_type: str, field_data: dict[str, Any] | None = None
    ) -> str:
        """å°‡ JSON Schema é¡å‹è½‰æ›ç‚º Rust é¡å‹"""
        if field_data is None:
            field_data = {}

        # è™•ç†è¤‡åˆé¡å‹
        compound_type = self._handle_rust_compound_types(json_type, field_data)
        if compound_type:
            return compound_type

        # è™•ç†è‡ªå®šç¾©é¡å‹
        custom_type = self._handle_rust_custom_types(json_type)
        if custom_type:
            return custom_type

        # è™•ç†ç‰¹æ®Šé¡å‹ï¼ˆæšèˆ‰å’Œæ ¼å¼åŒ–ï¼‰
        special_type = self._handle_rust_special_types(field_data)
        if special_type:
            return special_type

        # è™•ç†åŸºæœ¬é¡å‹
        return self._handle_rust_basic_types(json_type)

    def _handle_rust_compound_types(
        self, json_type: str, field_data: dict[str, Any]
    ) -> str | None:
        """è™•ç†è¤‡åˆé¡å‹ï¼šOptional, List, Dict"""
        if not json_type:
            return None

        # è™•ç† Optional é¡å‹
        if json_type.startswith(OPTIONAL_PREFIX):
            inner_type = json_type[len(OPTIONAL_PREFIX):-1]
            return f"Option<{self._convert_to_rust_type(inner_type, field_data)}>"

        # è™•ç† List é¡å‹
        if json_type.startswith(LIST_PREFIX):
            inner_type = json_type[len(LIST_PREFIX):-1]
            return f"Vec<{self._convert_to_rust_type(inner_type, field_data)}>"

        # è™•ç† Dict é¡å‹
        if json_type.startswith("Dict["):
            return self._convert_rust_dict_type(json_type)

        return None

    def _convert_rust_dict_type(self, json_type: str) -> str:
        """è½‰æ› Dict é¡å‹ç‚º HashMap"""
        dict_content = json_type[5:-1]  # ç§»é™¤ 'Dict[' å’Œ ']'
        
        if dict_content == "str, str":
            return "std::collections::HashMap<String, String>"
        elif dict_content == "str, Any":
            return "std::collections::HashMap<String, serde_json::Value>"
        else:
            return "std::collections::HashMap<String, serde_json::Value>"

    def _handle_rust_custom_types(self, json_type: str) -> str | None:
        """è™•ç†è‡ªå®šç¾©é¡å‹ï¼ˆSOT ä¸­çš„çµæ§‹é«”ï¼‰"""
        all_types = set()
        for category in ["base_types", "messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_types.update(self.sot_data[category].keys())

        if json_type in all_types:
            return json_type  # è‡ªå®šç¾©é¡å‹ä¿æŒåŸå
        return None

    def _handle_rust_special_types(
        self, field_data: dict[str, Any]
    ) -> str | None:
        """è™•ç†ç‰¹æ®Šé¡å‹ï¼šæšèˆ‰å’Œæ ¼å¼åŒ–é¡å‹"""
        # è™•ç†æšèˆ‰é¡å‹
        if "enum" in field_data:
            return "String"

        # è™•ç†æ ¼å¼åŒ–é¡å‹
        format_type = field_data.get("format")
        if format_type:
            return self._get_rust_format_type(format_type)

        return None

    def _get_rust_format_type(self, format_type: str) -> str:
        """æ ¹æ“šæ ¼å¼é¡å‹è¿”å›å°æ‡‰çš„ Rust é¡å‹"""
        format_mapping = {
            "date-time": CHRONO_DATETIME,
            "uuid": "uuid::Uuid",
            "uri": URL_URL,
            "url": URL_URL,
        }
        return format_mapping.get(format_type, "String")

    def _handle_rust_basic_types(self, json_type: str) -> str:
        """è™•ç†åŸºæœ¬é¡å‹æ˜ å°„"""
        type_mapping = {
            "str": "String",
            "string": "String",
            "int": "i32",
            "integer": "i32",
            "float": "f64",
            "number": "f64",
            "bool": "bool",
            "boolean": "bool",
            "datetime": CHRONO_DATETIME,
            "Any": "serde_json::Value",
        }
        return type_mapping.get(json_type, "String")

    def _get_rust_default_value(
        self, json_type: str, field_data: dict[str, Any] | None = None
    ) -> str:
        """ç²å– Rust é¡å‹çš„é»˜èªå€¼"""
        if field_data is None:
            field_data = {}

        # æª¢æŸ¥æ˜¯å¦æœ‰æ˜ç¢ºå®šç¾©çš„é è¨­å€¼
        explicit_default = self._get_explicit_default_value(field_data)
        if explicit_default:
            return explicit_default

        # æª¢æŸ¥ç‰¹æ®Šé¡å‹çš„é è¨­å€¼
        special_default = self._get_special_type_default(json_type)
        if special_default:
            return special_default

        # æª¢æŸ¥è‡ªå®šç¾©é¡å‹çš„é è¨­å€¼
        custom_default = self._get_custom_type_default(json_type)
        if custom_default:
            return custom_default

        # è¿”å›åŸºæœ¬é¡å‹çš„é è¨­å€¼
        return self._get_basic_type_default(json_type)

    def _get_explicit_default_value(self, field_data: dict[str, Any]) -> str | None:
        """è™•ç†æ˜ç¢ºå®šç¾©çš„é è¨­å€¼"""
        if "default" not in field_data:
            return None

        default_val = field_data["default"]
        
        if isinstance(default_val, str):
            return f'"{default_val}".to_string()'
        elif isinstance(default_val, bool):
            return str(default_val).lower()
        elif isinstance(default_val, (int, float)):
            return str(default_val)
        elif isinstance(default_val, list):
            return "Vec::new()"
        elif isinstance(default_val, dict):
            return "std::collections::HashMap::new()"
        
        return None

    def _get_special_type_default(self, json_type: str) -> str | None:
        """è™•ç†ç‰¹æ®Šé¡å‹çš„é è¨­å€¼ (Optional, Vec, HashMap)"""
        if not json_type:
            return None

        # è™•ç† Optional é¡å‹
        if json_type.startswith("Option<"):
            return "None"

        # è™•ç† Vec é¡å‹  
        if json_type.startswith("Vec<"):
            return "Vec::new()"

        # è™•ç† HashMap é¡å‹
        if json_type.startswith("std::collections::HashMap<"):
            return "std::collections::HashMap::new()"

        return None

    def _get_custom_type_default(self, json_type: str) -> str | None:
        """è™•ç†è‡ªå®šç¾©é¡å‹çš„é è¨­å€¼"""
        all_types = self._get_all_defined_types()
        
        if json_type in all_types:
            return f"{json_type}::default()"
        
        return None

    def _get_all_defined_types(self) -> set[str]:
        """ç²å–æ‰€æœ‰å®šç¾©çš„è‡ªå®šç¾©é¡å‹"""
        all_types = set()
        for category in ["base_types", "messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_types.update(self.sot_data[category].keys())
        return all_types

    def _get_basic_type_default(self, json_type: str) -> str:
        """ç²å–åŸºæœ¬é¡å‹çš„é è¨­å€¼"""
        defaults = {
            "String": STRING_NEW,
            "str": STRING_NEW,
            "string": STRING_NEW,
            "i32": "0",
            "int": "0", 
            "integer": "0",
            "f64": "0.0",
            "float": "0.0",
            "number": "0.0",
            "bool": "false",
            "boolean": "false",
            CHRONO_DATETIME: "chrono::Utc::now()",
            "serde_json::Value": "serde_json::Value::Null",
            "uuid::Uuid": "uuid::Uuid::new_v4()",
            URL_URL: 'url::Url::parse("https://example.com").unwrap()',
        }
        return defaults.get(json_type, STRING_NEW)

    def _get_python_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º Python é¡å‹"""
        mapping = self.sot_data["generation_config"]["python"]["field_mapping"]
        return mapping.get(type_str, type_str)

    def _get_python_default(self, default_value: Any) -> str:
        """ç²å– Python é è¨­å€¼"""
        if isinstance(default_value, str):
            return f'"{default_value}"'
        elif isinstance(default_value, bool):
            return str(default_value)
        elif isinstance(default_value, dict):
            return "Field(default_factory=dict)"
        elif isinstance(default_value, list):
            return "Field(default_factory=list)"
        return str(default_value)

    def _get_python_validation(self, value: Any) -> str:
        """ç²å– Python é©—è­‰åƒæ•¸"""
        if isinstance(value, str):
            return f'"{value}"'
        elif isinstance(value, list):
            return f"{value}"
        return str(value)

    def generate_typescript_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ TypeScript Schema
        
        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„
            
        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        # TypeScript ç”Ÿæˆé…ç½®
        if output_dir:
            target_dir = Path(output_dir)
        else:
            target_dir = Path("services/features/common/typescript/aiva_common_ts/schemas/generated")
        
        target_dir.mkdir(parents=True, exist_ok=True)
        generated_files = []

        # ç”Ÿæˆä¸»è¦çš„ schemas.ts æ–‡ä»¶
        schema_file = target_dir / "schemas.ts"
        content = self._render_typescript_schemas()
        with open(schema_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(schema_file))
        logger.info(f"âœ… ç”Ÿæˆ TypeScript Schema: {schema_file}")

        # ç”Ÿæˆ index.ts å°å‡ºæ–‡ä»¶
        index_file = target_dir / "index.ts"
        index_content = self._render_typescript_index()
        with open(index_file, "w", encoding="utf-8") as f:
            f.write(index_content)
        generated_files.append(str(index_file))
        logger.info(f"âœ… ç”Ÿæˆ TypeScript Index: {index_file}")

        return generated_files

    def _render_typescript_schemas(self) -> str:
        """æ¸²æŸ“ TypeScript schemas"""
        content = []
        
        # æ–‡ä»¶é ­éƒ¨
        content.extend([
            "/**",
            " * AIVA Common TypeScript Schemas - è‡ªå‹•ç”Ÿæˆ",
            " * ==========================================",
            " * ",
            f" * {self.sot_data['metadata']['description']}",
            " * ",
            f" * âš ï¸  {self.sot_data['metadata']['generated_note']}",
            f" * ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}",
            f" * ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}",
            " * ",
            " * éµå¾ªå–®ä¸€äº‹å¯¦åŸå‰‡ï¼Œèˆ‡ Python aiva_common.schemas ä¿æŒå®Œå…¨ä¸€è‡´",
            " */",
            "",
            "// ==================== æšèˆ‰é¡å‹å®šç¾© ====================",
            ""
        ])

        # ç”Ÿæˆæšèˆ‰ (å¾ Python enums æ˜ å°„)
        content.extend([
            "export enum Severity {",
            "  CRITICAL = \"critical\",",
            "  HIGH = \"high\",",
            "  MEDIUM = \"medium\",",
            "  LOW = \"low\",",
            "  INFORMATIONAL = \"info\"",
            "}",
            "",
            "export enum Confidence {",
            "  CERTAIN = \"certain\",",
            "  FIRM = \"firm\",", 
            "  POSSIBLE = \"possible\"",
            "}",
            "",
            "export enum VulnerabilityType {",
            "  XSS = \"XSS\",",
            "  SQLI = \"SQL Injection\",",
            "  SSRF = \"SSRF\",",
            "  IDOR = \"IDOR\",",
            "  BOLA = \"BOLA\",",
            "  INFO_LEAK = \"Information Leak\",",
            "  WEAK_AUTH = \"Weak Authentication\",",
            "  RCE = \"Remote Code Execution\",",
            "  AUTHENTICATION_BYPASS = \"Authentication Bypass\"",
            "}",
            "",
            "// ==================== åŸºç¤ä»‹é¢å®šç¾© ====================",
            ""
        ])

        # ç”ŸæˆåŸºç¤é¡å‹
        for class_name, class_info in self.sot_data["base_types"].items():
            content.extend(self._render_typescript_interface(class_name, class_info))
            content.append("")

        # ç”Ÿæˆ messaging é¡å‹
        if "messaging" in self.sot_data:
            content.append("// ==================== è¨Šæ¯é€šè¨Šé¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["messaging"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        # ç”Ÿæˆ findings é¡å‹  
        if "findings" in self.sot_data:
            content.append("// ==================== æ¼æ´ç™¼ç¾é¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["findings"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        # ç”Ÿæˆ tasks é¡å‹
        if "tasks" in self.sot_data:
            content.append("// ==================== ä»»å‹™ç®¡ç†é¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["tasks"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        return "\n".join(content)

    def _render_typescript_interface(self, interface_name: str, interface_info: dict) -> list[str]:
        """æ¸²æŸ“ TypeScript ä»‹é¢"""
        lines = []
        lines.append("/**")
        lines.append(f" * {interface_info['description']}")
        lines.append(" */")
        lines.append(f"export interface {interface_name} {{")
        
        # ç”Ÿæˆå­—æ®µ
        for field_name, field_info in interface_info.get("fields", {}).items():
            ts_type = self._get_typescript_type(field_info["type"])
            optional_marker = "?" if not field_info.get("required", True) else ""
            description = field_info.get("description", "")
            
            if description:
                lines.append(f"  /** {description} */")
            lines.append(f"  {field_name}{optional_marker}: {ts_type};")
        
        lines.append("}")
        return lines

    def _get_typescript_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º TypeScript é¡å‹"""
        import re
        
        # è™•ç† Optional[T]
        if type_str.startswith(OPTIONAL_PREFIX):
            inner = type_str[len(OPTIONAL_PREFIX):-1]
            return f"{self._get_typescript_type(inner)} | null"
        
        # è™•ç† List[T]
        if type_str.startswith(LIST_PREFIX):
            inner = type_str[len(LIST_PREFIX):-1]
            return f"{self._get_typescript_type(inner)}[]"
        
        # è™•ç† Dict[str, T]
        dict_match = re.match(r"Dict\[str,\s*(.+)\]", type_str)
        if dict_match:
            value_type = dict_match.group(1).strip()
            return f"Record<string, {self._get_typescript_type(value_type)}>"
        
        # åŸºæœ¬é¡å‹æ˜ å°„
        type_mapping = {
            "str": "string",
            "int": "number", 
            "float": "number",
            "bool": "boolean",
            "datetime": "string",  # ISO 8601 æ ¼å¼
            "Any": "any",
            "VulnerabilityType": "VulnerabilityType",
            "Severity": "Severity", 
            "Confidence": "Confidence"
        }
        
        return type_mapping.get(type_str, type_str)

    def _render_typescript_index(self) -> str:
        """æ¸²æŸ“ TypeScript index.ts"""
        content = []
        content.extend([
            "/**",
            " * AIVA TypeScript Schemas - çµ±ä¸€å°å‡º",
            " * ==================================",
            " * ",
            " * æ­¤æ–‡ä»¶å°å‡ºæ‰€æœ‰æ¨™æº–ç”Ÿæˆçš„ Schema å®šç¾©",
            " * éµå¾ªå–®ä¸€äº‹å¯¦åŸå‰‡ï¼Œç¢ºä¿èˆ‡ Python ç‰ˆæœ¬ä¸€è‡´",
            " */",
            "",
            "// å°å‡ºæ‰€æœ‰ schemas",
            "export * from './schemas';",
            "",
            "// ç‰ˆæœ¬ä¿¡æ¯",
            f"export const SCHEMA_VERSION = '{self.sot_data['version']}';",
            f"export const GENERATED_AT = '{datetime.now().isoformat()}';",
            ""
        ])
        
        return "\n".join(content)

    def _generate_python_field(self, field_name: str, field_info: dict) -> str:
        """ç”ŸæˆPythonå­—æ®µå®šç¾© - é‡æ§‹å¾Œé™ä½èªçŸ¥è¤‡é›œåº¦"""
        field_type = self._get_python_type(field_info["type"])
        field_declaration = f"{field_name}: {field_type}"
        
        validation_params = self._extract_validation_parameters(field_info)
        field_assignment = self._generate_field_assignment(field_info, validation_params)
        
        return field_declaration + field_assignment

    def _extract_validation_parameters(self, field_info: dict) -> list[str]:
        """æå–é©—è­‰åƒæ•¸"""
        if "validation" not in field_info:
            return []
        
        validation_handlers = {
            "enum": lambda val: f"values={val}",
            "pattern": lambda val: f'pattern=r"{val}"',
            "format": self._handle_format_validation,
            "max_length": lambda val: f"max_length={val}",
            "minimum": lambda val: f"ge={val}",
            "maximum": lambda val: f"le={val}"
        }
        
        params = []
        for key, value in field_info["validation"].items():
            if key in validation_handlers:
                handler = validation_handlers[key]
                param = handler(value) if callable(handler) else handler
                if param:  # æŸäº› handler å¯èƒ½è¿”å› None
                    params.append(param)
        
        return params

    def _handle_format_validation(self, format_value: str) -> str:
        """è™•ç†æ ¼å¼é©—è­‰åƒæ•¸"""
        format_mapping = {
            "url": "url=True"
        }
        return format_mapping.get(format_value, "")

    def _generate_field_assignment(self, field_info: dict, validation_params: list[str]) -> str:
        """ç”Ÿæˆæ¬„ä½è³¦å€¼éƒ¨åˆ†"""
        is_required = field_info.get("required", True)
        has_default = "default" in field_info
        
        if not is_required:
            return self._generate_optional_field_assignment(field_info, validation_params)
        elif has_default:
            return self._generate_required_field_with_default(field_info, validation_params)
        elif validation_params:
            return f" = Field({', '.join(validation_params)})"
        else:
            return ""

    def _generate_optional_field_assignment(self, field_info: dict, validation_params: list[str]) -> str:
        """ç”Ÿæˆå¯é¸æ¬„ä½è³¦å€¼"""
        if "default" in field_info:
            default_val = self._get_python_default(field_info["default"])
            return self._combine_field_params_with_default(validation_params, default_val)
        else:
            return self._combine_field_params_with_default(validation_params, "None")

    def _generate_required_field_with_default(self, field_info: dict, validation_params: list[str]) -> str:
        """ç”Ÿæˆæœ‰é è¨­å€¼çš„å¿…å¡«æ¬„ä½"""
        default_val = self._get_python_default(field_info["default"])
        all_params = validation_params + [f"default={default_val}"]
        return f" = Field({', '.join(all_params)})"

    def _combine_field_params_with_default(self, validation_params: list[str], default_val: str) -> str:
        """çµ„åˆé©—è­‰åƒæ•¸å’Œé è¨­å€¼"""
        if validation_params:
            all_params = validation_params + [f"default={default_val}"]
            return f" = Field({', '.join(all_params)})"
        else:
            return f" = {default_val}"

    def _get_go_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º Go é¡å‹ - æ”¯æ´åµŒå¥—é¡å‹æ˜ å°„"""
        import re

        # è™•ç† Optional[T] - è½‰æ›ç‚º *T
        if type_str.startswith(OPTIONAL_PREFIX):
            inner = type_str[len(OPTIONAL_PREFIX):-1]  # æå–å…§éƒ¨é¡å‹
            mapped = self._get_go_type(inner)  # éæ­¸æ˜ å°„
            # å¦‚æœå…§éƒ¨é¡å‹å·²ç¶“æ˜¯æŒ‡é‡æˆ–map/slice,ä¸å†æ·»åŠ *
            if (
                mapped.startswith("*")
                or mapped.startswith("map[")
                or mapped.startswith("[]")
            ):
                return mapped
            return f"*{mapped}"

        # è™•ç† Dict[K, V] - è½‰æ›ç‚º map[K]V
        dict_match = re.match(r"Dict\[(.+?),\s*(.+)\]", type_str)
        if dict_match:
            key_type_raw = dict_match.group(1).strip()
            val_type_raw = dict_match.group(2).strip()
            key_type = self._get_go_type(key_type_raw)
            val_type = self._get_go_type(val_type_raw)
            return f"map[{key_type}]{val_type}"

        # è™•ç† List[T] - è½‰æ›ç‚º []T
        if type_str.startswith("List["):
            inner = type_str[5:-1]
            mapped = self._get_go_type(inner)
            return f"[]{mapped}"

        # åŸºæœ¬é¡å‹æ˜ å°„
        mapping = self.sot_data["generation_config"]["go"]["field_mapping"]
        return mapping.get(type_str, type_str)

    def _to_go_field_name(self, field_name: str) -> str:
        """
        è½‰æ›ç‚º Go æ¬„ä½åç¨±ï¼ˆPascalCaseï¼‰ï¼Œç¬¦åˆ Go Initialisms æ¨™æº–
        åƒè€ƒ: https://go.dev/wiki/CodeReviewComments#initialisms
        """
        # Go å®˜æ–¹ç¸®å¯«æ¨™æº– - å¿…é ˆçµ±ä¸€å¤§å°å¯«
        initialisms = {
            "url": "URL",
            "http": "HTTP",
            "https": "HTTPS",
            "id": "ID",
            "api": "API",
            "json": "JSON",
            "xml": "XML",
            "html": "HTML",
            "css": "CSS",
            "js": "JS",
            "sql": "SQL",
            "cwe": "CWE",
            "cve": "CVE",
            "owasp": "OWASP",
            "uuid": "UUID",
            "uri": "URI",
            "tcp": "TCP",
            "udp": "UDP",
            "ip": "IP",
            "os": "OS",
            "cpu": "CPU",
            "ram": "RAM",
            "db": "DB",
        }

        # åˆ†å‰²å­—æ®µåä¸¦è™•ç†æ¯å€‹éƒ¨åˆ†
        parts = field_name.split("_")
        go_parts = []

        for part in parts:
            lower_part = part.lower()
            if lower_part in initialisms:
                go_parts.append(initialisms[lower_part])
            else:
                go_parts.append(part.capitalize())

        return "".join(go_parts)

    def _get_go_json_tag(self, required: bool) -> str:
        """ç²å– Go JSON æ¨™ç±¤"""
        return "" if required else ",omitempty"

    def _get_all_fields(self, class_info: dict, current_section: str) -> dict:
        """
        ç²å–é¡çš„æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬ç¹¼æ‰¿çš„å­—æ®µ

        Args:
            class_info: é¡å®šç¾©ä¿¡æ¯
            current_section: ç•¶å‰æ‰€åœ¨çš„ section (base_types, findings, etc.)

        Returns:
            åŒ…å«æ‰€æœ‰å­—æ®µçš„å­—å…¸
        """
        all_fields = {}

        # é¦–å…ˆè™•ç†ç¹¼æ‰¿
        if "extends" in class_info:
            base_class_name = class_info["extends"]
            base_class_info = None

            # åœ¨æ‰€æœ‰å¯èƒ½çš„ section ä¸­æŸ¥æ‰¾åŸºé¡
            for section_name in [
                "base_types",
                "findings",
                "messaging",
                "tasks",
                "plugins",
                "cli",
            ]:
                if (
                    section_name in self.sot_data
                    and base_class_name in self.sot_data[section_name]
                ):
                    base_class_info = self.sot_data[section_name][base_class_name]
                    break

            if base_class_info:
                # éæ­¸ç²å–åŸºé¡çš„æ‰€æœ‰å­—æ®µ
                base_fields = self._get_all_fields(base_class_info, current_section)
                all_fields.update(base_fields)
            else:
                logger.warning(f"æ‰¾ä¸åˆ°åŸºé¡: {base_class_name}")

        # æ·»åŠ ç•¶å‰é¡çš„ç›´æ¥å­—æ®µ
        if "fields" in class_info:
            all_fields.update(class_info["fields"])

        # æ·»åŠ ç•¶å‰é¡çš„é¡å¤–å­—æ®µ
        if "additional_fields" in class_info:
            all_fields.update(class_info["additional_fields"])

        return all_fields

    def validate_schemas(self) -> bool:
        """é©—è­‰ Schema å®šç¾©çš„ä¸€è‡´æ€§"""
        logger.info("ğŸ” é–‹å§‹ Schema é©—è­‰...")

        errors = []
        
        # åŸ·è¡Œå„é …é©—è­‰æª¢æŸ¥
        errors.extend(self._validate_required_keys())
        errors.extend(self._validate_version_format())
        errors.extend(self._validate_type_references())

        # è¿”å›é©—è­‰çµæœ
        return self._report_validation_results(errors)

    def _validate_required_keys(self) -> list[str]:
        """æª¢æŸ¥å¿…è¦çš„é ‚å±¤éµ"""
        errors = []
        required_keys = ["version", "metadata", "base_types", "generation_config"]
        
        for key in required_keys:
            if key not in self.sot_data:
                errors.append(f"ç¼ºå°‘å¿…è¦çš„é ‚å±¤éµ: {key}")
        
        return errors

    def _validate_version_format(self) -> list[str]:
        """æª¢æŸ¥ç‰ˆæœ¬æ ¼å¼"""
        errors = []
        version = self.sot_data.get("version", "")
        
        if not version or not version.replace(".", "").isdigit():
            errors.append(f"ç‰ˆæœ¬æ ¼å¼ç„¡æ•ˆ: {version}")
        
        return errors

    def _validate_type_references(self) -> list[str]:
        """æª¢æŸ¥é¡å‹å¼•ç”¨çš„æœ‰æ•ˆæ€§"""
        errors = []
        defined_types, all_schemas = self._collect_schema_types()
        
        for schema_name, schema_info in all_schemas.items():
            schema_errors = self._validate_schema_fields(schema_name, schema_info, defined_types)
            errors.extend(schema_errors)
        
        return errors

    def _collect_schema_types(self) -> tuple[set[str], dict[str, Any]]:
        """æ”¶é›†æ‰€æœ‰å®šç¾©çš„é¡å‹å’Œæ¨¡å¼"""
        defined_types = set(self.sot_data.get("base_types", {}).keys())
        all_schemas = {}
        
        for category in ["messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_schemas.update(self.sot_data[category])
                defined_types.update(self.sot_data[category].keys())
        
        return defined_types, all_schemas

    def _validate_schema_fields(
        self, schema_name: str, schema_info: dict[str, Any], defined_types: set[str]
    ) -> list[str]:
        """é©—è­‰å–®å€‹æ¨¡å¼çš„æ¬„ä½é¡å‹å¼•ç”¨"""
        errors = []
        
        for field_name, field_info in schema_info.get("fields", {}).items():
            field_type = field_info.get("type", "")
            core_type = self._extract_core_type(field_type)
            
            if not self._is_valid_type(core_type, defined_types):
                errors.append(f"åœ¨ {schema_name}.{field_name} ä¸­å¼•ç”¨äº†æœªå®šç¾©çš„é¡å‹: {core_type}")
        
        return errors

    def _extract_core_type(self, field_type: str) -> str:
        """å¾è¤‡åˆé¡å‹ä¸­æå–æ ¸å¿ƒé¡å‹"""
        return (
            field_type.replace(OPTIONAL_PREFIX, "")
            .replace(LIST_PREFIX, "")
            .replace("Dict[str, ", "")
            .replace("]", "")
            .replace(">", "")
        )

    def _is_valid_type(self, core_type: str, defined_types: set[str]) -> bool:
        """æª¢æŸ¥é¡å‹æ˜¯å¦æœ‰æ•ˆï¼ˆåŸºæœ¬é¡å‹æˆ–å·²å®šç¾©é¡å‹ï¼‰"""
        basic_types = {"str", "int", "float", "bool", "datetime", "Any"}
        return core_type in basic_types or core_type in defined_types

    def _report_validation_results(self, errors: list[str]) -> bool:
        """å ±å‘Šé©—è­‰çµæœ"""
        if errors:
            logger.error("âŒ Schema é©—è­‰å¤±æ•—:")
            for error in errors:
                logger.error(f"  - {error}")
            return False

        logger.info("âœ… Schema é©—è­‰é€šé!")
        return True

    def generate_grpc_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ gRPC Protocol Buffers Schema
        
        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„
            
        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        # gRPC ç”Ÿæˆé…ç½®
        if output_dir:
            target_dir = Path(output_dir)
        else:
            target_dir = Path("services/aiva_common/grpc/generated")
        
        target_dir.mkdir(parents=True, exist_ok=True)
        generated_files = []

        # ç”Ÿæˆä¸»è¦çš„ aiva.proto æ–‡ä»¶
        proto_file = target_dir / "aiva.proto"
        content = self._render_proto_file()
        with open(proto_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(proto_file))
        logger.info(f"âœ… ç”Ÿæˆ gRPC Proto: {proto_file}")

        # ç”Ÿæˆç·¨è­¯è…³æœ¬
        compile_script = target_dir / "compile_protos.py"
        script_content = self._render_proto_compile_script()
        with open(compile_script, "w", encoding="utf-8") as f:
            f.write(script_content)
        generated_files.append(str(compile_script))
        logger.info(f"âœ… ç”Ÿæˆç·¨è­¯è…³æœ¬: {compile_script}")

        return generated_files

    def _render_proto_file(self) -> str:
        """æ¸²æŸ“ Protocol Buffers æª”æ¡ˆ"""
        content = []
        
        # Proto æª”æ¡ˆé ­éƒ¨
        content.extend([
            "// AIVA gRPC Protocol Buffers å®šç¾© - è‡ªå‹•ç”Ÿæˆ",
            "// ============================================",
            "//",
            f"// {self.sot_data['metadata']['description']}",
            "//",
            f"// âš ï¸  {self.sot_data['metadata']['generated_note']}",
            f"// ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}",
            f"// ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}",
            "//",
            "// åŸºæ–¼ core_schema_sot.yaml ç”Ÿæˆï¼Œèˆ‡æ‰€æœ‰èªè¨€ Schema ä¿æŒä¸€è‡´",
            "",
            "syntax = \"proto3\";",
            "",
            "package aiva.v1;",
            "",
            "option go_package = \"github.com/kyle0527/AIVA/services/aiva_common_go/grpc/generated\";",
            "",
            "import \"google/protobuf/timestamp.proto\";",
            "import \"google/protobuf/struct.proto\";",
            "",
            "// ==================== åŸºç¤è¨Šæ¯é¡å‹ ====================",
            ""
        ])

        # ç”ŸæˆåŸºç¤è¨Šæ¯é¡å‹
        content.extend([
            "// è¨Šæ¯æ¨™é ­",
            "message MessageHeader {",
            "  string message_id = 1;",
            "  string trace_id = 2;",
            "  string correlation_id = 3;",
            "  string source_module = 4;",
            "  google.protobuf.Timestamp timestamp = 5;",
            "  string version = 6;",
            "}",
            "",
            "// çµ±ä¸€ API è«‹æ±‚",
            "message AIVARequest {",
            "  string request_id = 1;",
            "  string task = 2;",
            "  google.protobuf.Struct parameters = 3;",
            "  double timeout = 4;",
            "  string trace_id = 5;",
            "  google.protobuf.Struct metadata = 6;",
            "}",
            "",
            "// çµ±ä¸€ API éŸ¿æ‡‰",
            "message AIVAResponse {",
            "  string request_id = 1;",
            "  bool success = 2;",
            "  google.protobuf.Struct result = 3;",
            "  string error_code = 4;",
            "  string error_message = 5;",
            "  google.protobuf.Timestamp timestamp = 6;",
            "  double duration = 7;",
            "}",
            "",
            "// ç›®æ¨™è³‡è¨Š",
            "message Target {",
            "  string url = 1;",
            "  string host = 2;",
            "  int32 port = 3;",
            "  string protocol = 4;",
            "  string path = 5;",
            "  google.protobuf.Struct metadata = 6;",
            "}",
            "",
            "// é¢¨éšªç´šåˆ¥æšèˆ‰",
            "enum RiskLevel {",
            "  RISK_LEVEL_UNSPECIFIED = 0;",
            "  RISK_LEVEL_CRITICAL = 1;",
            "  RISK_LEVEL_HIGH = 2;",
            "  RISK_LEVEL_MEDIUM = 3;",
            "  RISK_LEVEL_LOW = 4;",
            "  RISK_LEVEL_INFO = 5;",
            "}",
            "",
            "// ä»»å‹™ç‹€æ…‹æšèˆ‰",
            "enum TaskStatus {",
            "  TASK_STATUS_UNSPECIFIED = 0;",
            "  TASK_STATUS_PENDING = 1;",
            "  TASK_STATUS_RUNNING = 2;",
            "  TASK_STATUS_COMPLETED = 3;",
            "  TASK_STATUS_FAILED = 4;",
            "  TASK_STATUS_CANCELLED = 5;",
            "}",
            "",
            "// æ¼æ´ç™¼ç¾",
            "message FindingPayload {",
            "  string finding_id = 1;",
            "  string vulnerability_type = 2;",
            "  string title = 3;",
            "  string description = 4;",
            "  RiskLevel risk_level = 5;",
            "  double confidence = 6;",
            "  Target target = 7;",
            "  repeated string evidence = 8;",
            "  repeated string recommendations = 9;",
            "  google.protobuf.Timestamp discovered_at = 10;",
            "}",
            "",
            "// ä»»å‹™é…ç½®",
            "message TaskConfig {",
            "  string task_id = 1;",
            "  string task_type = 2;",
            "  Target target = 3;",
            "  google.protobuf.Struct parameters = 4;",
            "  int32 timeout = 5;",
            "  int32 priority = 6;",
            "  google.protobuf.Timestamp created_at = 7;",
            "}",
            "",
            "// ä»»å‹™çµæœ",
            "message TaskResult {",
            "  string task_id = 1;",
            "  TaskStatus status = 2;",
            "  repeated FindingPayload findings = 3;",
            "  string error = 4;",
            "  google.protobuf.Timestamp started_at = 5;",
            "  google.protobuf.Timestamp completed_at = 6;",
            "  double duration = 7;",
            "  google.protobuf.Struct metadata = 8;",
            "}",
            "",
            "// ==================== gRPC æœå‹™å®šç¾© ====================",
            "",
            "// ä»»å‹™ç®¡ç†æœå‹™",
            "service TaskService {",
            "  // å‰µå»ºæ–°ä»»å‹™",
            "  rpc CreateTask(TaskConfig) returns (AIVAResponse);",
            "  ",
            "  // ç²å–ä»»å‹™ç‹€æ…‹",
            "  rpc GetTaskStatus(AIVARequest) returns (TaskResult);",
            "  ",
            "  // å–æ¶ˆä»»å‹™",
            "  rpc CancelTask(AIVARequest) returns (AIVAResponse);",
            "  ",
            "  // ä¸²æµä»»å‹™é€²åº¦",
            "  rpc StreamTaskProgress(AIVARequest) returns (stream AIVAResponse);",
            "}",
            "",
            "// è·¨èªè¨€é€šä¿¡æœå‹™",
            "service CrossLanguageService {",
            "  // åŸ·è¡Œè·¨èªè¨€ä»»å‹™",
            "  rpc ExecuteTask(AIVARequest) returns (AIVAResponse);",
            "  ",
            "  // å¥åº·æª¢æŸ¥",
            "  rpc HealthCheck(AIVARequest) returns (AIVAResponse);",
            "  ",
            "  // ç²å–æœå‹™è³‡è¨Š",
            "  rpc GetServiceInfo(AIVARequest) returns (AIVAResponse);",
            "  ",
            "  // é›™å‘ä¸²æµé€šä¿¡",
            "  rpc BidirectionalStream(stream AIVARequest) returns (stream AIVAResponse);",
            "}",
            ""
        ])

        return "\n".join(content)

    def _render_proto_compile_script(self) -> str:
        """ç”Ÿæˆ Proto ç·¨è­¯è…³æœ¬"""
        return '''#!/usr/bin/env python3
"""
gRPC Protocol Buffers ç·¨è­¯è…³æœ¬
è‡ªå‹•ç·¨è­¯ .proto æª”æ¡ˆç‚ºå„èªè¨€çš„ gRPC å­˜æ ¹ä»£ç¢¼
"""

import subprocess
import sys
from pathlib import Path

def compile_protos():
    """ç·¨è­¯ Protocol Buffers æª”æ¡ˆ"""
    proto_dir = Path(__file__).parent
    proto_file = proto_dir / "aiva.proto"
    
    if not proto_file.exists():
        print(f"âŒ Proto æª”æ¡ˆä¸å­˜åœ¨: {proto_file}")
        return False
    
    # Python ç·¨è­¯
    print("ğŸ”„ ç·¨è­¯ Python gRPC å­˜æ ¹...")
    python_out = proto_dir / "python"
    python_out.mkdir(exist_ok=True)
    
    cmd = [
        sys.executable, "-m", "grpc_tools.protoc",
        f"--proto_path={proto_dir}",
        f"--python_out={python_out}",
        f"--grpc_python_out={python_out}",
        str(proto_file)
    ]
    
    try:
        subprocess.run(cmd, check=True)
        print("âœ… Python gRPC å­˜æ ¹ç·¨è­¯å®Œæˆ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Python ç·¨è­¯å¤±æ•—: {e}")
        return False
    
    # Go ç·¨è­¯
    print("ğŸ”„ ç·¨è­¯ Go gRPC å­˜æ ¹...")
    go_out = proto_dir / "go"
    go_out.mkdir(exist_ok=True)
    
    cmd = [
        "protoc",
        f"--proto_path={proto_dir}",
        f"--go_out={go_out}",
        f"--go-grpc_out={go_out}",
        str(proto_file)
    ]
    
    try:
        subprocess.run(cmd, check=True)
        print("âœ… Go gRPC å­˜æ ¹ç·¨è­¯å®Œæˆ")
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print(f"âš ï¸  Go ç·¨è­¯è·³é (protoc-gen-go æœªå®‰è£): {e}")
    
    print("ğŸ‰ gRPC ç·¨è­¯å®Œæˆ!")
    return True

if __name__ == "__main__":
    success = compile_protos()
    sys.exit(0 if success else 1)
'''

    def generate_all(self, validate: bool = True) -> dict[str, list[str]]:
        """ç”Ÿæˆæ‰€æœ‰èªè¨€çš„ Schema

        Args:
            validate: æ˜¯å¦å…ˆé€²è¡Œé©—è­‰

        Returns:
            å„èªè¨€ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        if validate and not self.validate_schemas():
            logger.error("âŒ Schema é©—è­‰å¤±æ•—ï¼Œåœæ­¢ç”Ÿæˆ")
            return {}

        results = {}

        logger.info("ğŸš€ é–‹å§‹ç”Ÿæˆæ‰€æœ‰èªè¨€ Schema...")

        # ç”Ÿæˆ Python
        try:
            results["python"] = self.generate_python_schemas()
            logger.info(f"âœ… Python Schema ç”Ÿæˆå®Œæˆ: {len(results['python'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Python Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["python"] = []

        # ç”Ÿæˆ Go
        try:
            results["go"] = self.generate_go_schemas()
            logger.info(f"âœ… Go Schema ç”Ÿæˆå®Œæˆ: {len(results['go'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Go Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["go"] = []

        # ç”Ÿæˆ Rust (ç°¡åŒ–ç‰ˆæœ¬)
        try:
            results["rust"] = self.generate_rust_schemas()
            logger.info(f"âœ… Rust Schema ç”Ÿæˆå®Œæˆ: {len(results['rust'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Rust Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["rust"] = []

        # ç”Ÿæˆ TypeScript
        try:
            results["typescript"] = self.generate_typescript_schemas()
            logger.info(f"âœ… TypeScript Schema ç”Ÿæˆå®Œæˆ: {len(results['typescript'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ TypeScript Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["typescript"] = []

        # ç”Ÿæˆ gRPC Protocol Buffers
        try:
            results["grpc"] = self.generate_grpc_schemas()
            logger.info(f"âœ… gRPC Schema ç”Ÿæˆå®Œæˆ: {len(results['grpc'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ gRPC Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["grpc"] = []

        total_files = sum(len(files) for files in results.values())
        logger.info(f"ğŸ‰ æ‰€æœ‰èªè¨€ Schema ç”Ÿæˆå®Œæˆ! ç¸½è¨ˆ: {total_files} å€‹æª”æ¡ˆ")

        return results


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    parser = argparse.ArgumentParser(description="AIVA Schema ä»£ç¢¼ç”Ÿæˆå·¥å…·")
    parser.add_argument(
        "--lang",
        choices=["python", "go", "rust", "typescript", "grpc", "all"],
        default="all",
        help="ç”Ÿæˆçš„èªè¨€",
    )
    parser.add_argument("--validate", action="store_true", help="åƒ…é€²è¡Œ Schema é©—è­‰")
    parser.add_argument("--output-dir", help="è‡ªè¨‚è¼¸å‡ºç›®éŒ„")
    parser.add_argument(
        "--sot-file",
        default="services/aiva_common/core_schema_sot.yaml",
        help="SOT æª”æ¡ˆè·¯å¾‘",
    )

    args = parser.parse_args()

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = SchemaCodeGenerator(args.sot_file)

    if args.validate:
        # åƒ…é©—è­‰
        success = generator.validate_schemas()
        sys.exit(0 if success else 1)

    # ç”Ÿæˆä»£ç¢¼
    if args.lang == "all":
        results = generator.generate_all()
    elif args.lang == "python":
        results = {"python": generator.generate_python_schemas(args.output_dir)}
    elif args.lang == "go":
        results = {"go": generator.generate_go_schemas(args.output_dir)}
    elif args.lang == "rust":
        results = {"rust": generator.generate_rust_schemas(args.output_dir)}
    elif args.lang == "typescript":
        results = {"typescript": generator.generate_typescript_schemas(args.output_dir)}
    elif args.lang == "grpc":
        results = {"grpc": generator.generate_grpc_schemas(args.output_dir)}

    # è¼¸å‡ºçµæœ
    success = all(len(files) > 0 for files in results.values())
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
