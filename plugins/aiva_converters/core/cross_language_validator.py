#!/usr/bin/env python3
"""
è·¨èªè¨€ Schema ä¸€è‡´æ€§é©—è­‰å·¥å…·
============================

æ­¤å·¥å…·é©—è­‰ Pythonã€Goã€Rust ä¸‰ç¨®èªè¨€çš„ Schema å®šç¾©æ˜¯å¦å®Œå…¨ä¸€è‡´ï¼Œ
ç¢ºä¿è·¨èªè¨€æ¶æ§‹çš„æ•¸æ“šå®Œæ•´æ€§å’ŒAPIå…¼å®¹æ€§ã€‚

åŠŸèƒ½ç‰¹è‰²:
- ğŸ” æ·±åº¦ä¸€è‡´æ€§åˆ†æ
- ğŸ“Š è©³ç´°å·®ç•°å ±å‘Š
- ğŸš¨ è‡ªå‹•å•é¡Œæª¢æ¸¬
- ğŸ› ï¸ ä¿®å¾©å»ºè­°ç”Ÿæˆ
- ğŸ“ˆ è¦†è“‹ç‡çµ±è¨ˆ
"""

import json
import re
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Any

from .cross_language_interface import CrossLanguageSchemaInterface, SchemaDefinition


@dataclass
class ValidationIssue:
    """é©—è­‰å•é¡Œå®šç¾©"""

    severity: str  # critical, warning, info
    category: str  # missing, mismatch, format
    message: str
    schema_name: str
    field_name: str | None = None
    languages: list[str] | None = None
    suggestion: str | None = None


@dataclass
class ValidationReport:
    """é©—è­‰å ±å‘Š"""

    timestamp: str
    total_schemas: int
    total_fields: int
    issues: list[ValidationIssue]
    coverage_stats: dict[str, Any]

    def to_dict(self) -> dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        return asdict(self)


class CrossLanguageValidator:
    """è·¨èªè¨€ Schema ä¸€è‡´æ€§é©—è­‰å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–é©—è­‰å™¨"""
        self.interface = CrossLanguageSchemaInterface()
        self.issues: list[ValidationIssue] = []

        # ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾‘
        self.generated_files = {
            "python": {
                "base_types": Path(
                    "services/aiva_common/schemas/generated/base_types.py"
                ),
                "messaging": Path(
                    "services/aiva_common/schemas/generated/messaging.py"
                ),
                "tasks": Path("services/aiva_common/schemas/generated/tasks.py"),
                "findings": Path("services/aiva_common/schemas/generated/findings.py"),
                "async_utils": Path(
                    "services/aiva_common/schemas/generated/async_utils.py"
                ),
                "plugins": Path("services/aiva_common/schemas/generated/plugins.py"),
                "cli": Path("services/aiva_common/schemas/generated/cli.py"),
            },
            "go": {
                "all": Path(
                    "services/features/common/go/aiva_common_go/schemas/generated/schemas.go"
                )
            },
            "rust": {
                "all": Path(
                    "services/scan/info_gatherer_rust/src/schemas/generated/mod.rs"
                )
            },
        }

    def validate_all(self) -> ValidationReport:
        """åŸ·è¡Œå®Œæ•´çš„è·¨èªè¨€é©—è­‰

        Returns:
            è©³ç´°çš„é©—è­‰å ±å‘Š
        """
        self.issues = []

        print("ğŸ” é–‹å§‹è·¨èªè¨€ Schema ä¸€è‡´æ€§é©—è­‰...")

        # 1. æª¢æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        self._validate_file_existence()

        # 2. é©—è­‰ Schema å®šç¾©ä¸€è‡´æ€§
        self._validate_schema_definitions()

        # 3. é©—è­‰é¡å‹æ˜ å°„å®Œæ•´æ€§
        self._validate_type_mappings()

        # 4. é©—è­‰ç”Ÿæˆçš„ä»£ç¢¼çµæ§‹
        self._validate_generated_code_structure()

        # 5. ç”Ÿæˆè¦†è“‹ç‡çµ±è¨ˆ
        coverage_stats = self._generate_coverage_stats()

        # å‰µå»ºå ±å‘Š
        report = ValidationReport(
            timestamp=datetime.now().isoformat(),
            total_schemas=len(self.interface.get_all_schemas()),
            total_fields=sum(len(s.fields) for s in self.interface.get_all_schemas()),
            issues=self.issues,
            coverage_stats=coverage_stats,
        )

        return report

    def _validate_file_existence(self) -> None:
        """é©—è­‰ç”Ÿæˆæ–‡ä»¶çš„å­˜åœ¨æ€§"""
        print("ğŸ“ æª¢æŸ¥ç”Ÿæˆæ–‡ä»¶å­˜åœ¨æ€§...")

        for language, files in self.generated_files.items():
            for _file_type, file_path in files.items():
                if not file_path.exists():
                    self._add_issue(
                        "critical",
                        "missing",
                        f"{language.capitalize()} ç”Ÿæˆæ–‡ä»¶ç¼ºå¤±: {file_path}",
                        "file_system",
                        languages=[language],
                        suggestion=f"é‹è¡Œä»£ç¢¼ç”Ÿæˆå·¥å…·é‡æ–°ç”Ÿæˆ {language} Schema",
                    )

    def _validate_schema_definitions(self) -> None:
        """é©—è­‰ Schema å®šç¾©çš„ä¸€è‡´æ€§"""
        print("ğŸ” é©—è­‰ Schema å®šç¾©ä¸€è‡´æ€§...")

        all_schemas = self.interface.get_all_schemas()

        for schema in all_schemas:
            # æª¢æŸ¥æ¯å€‹å­—æ®µçš„é¡å‹æ˜ å°„
            for field in schema.fields:
                self._validate_field_consistency(schema, field)

    def _validate_field_consistency(self, schema: SchemaDefinition, field: Any) -> None:
        """é©—è­‰å–®å€‹å­—æ®µçš„è·¨èªè¨€ä¸€è‡´æ€§"""
        source_type = field.type

        # ç²å–å„èªè¨€çš„é¡å‹æ˜ å°„
        type_mappings = {}
        for lang in ["python", "go", "rust"]:
            mapped_type = self.interface.convert_type_to_language(source_type, lang)
            type_mappings[lang] = mapped_type

            # å¦‚æœæ˜ å°„å¤±æ•—ï¼ˆè¿”å›åŸé¡å‹ï¼‰ï¼Œè¨˜éŒ„å•é¡Œ
            if mapped_type == source_type and source_type not in [
                "str",
                "int",
                "bool",
                "float",
            ]:
                self._add_issue(
                    "warning",
                    "mismatch",
                    f"é¡å‹ '{source_type}' åœ¨ {lang} èªè¨€ä¸­æ²’æœ‰æ˜ å°„",
                    schema.name,
                    field.name,
                    [lang],
                    f"åœ¨ {lang} é¡å‹æ˜ å°„ä¸­æ·»åŠ  '{source_type}' çš„å®šç¾©",
                )

        # æª¢æŸ¥å¿…éœ€æ€§ä¸€è‡´æ€§
        if hasattr(field, "required"):
            if not field.required:
                # å¯é¸å­—æ®µæ‡‰è©²æœ‰é©ç•¶çš„é¡å‹æ¨™è¨˜
                expected_patterns = {
                    "python": r"Optional\[.*\]",
                    "go": r"\*.*",  # æŒ‡é‡é¡å‹
                    "rust": r"Option<.*>",
                }

                for lang, pattern in expected_patterns.items():
                    if not re.match(pattern, type_mappings[lang]):
                        self._add_issue(
                            "warning",
                            "mismatch",
                            f"å¯é¸å­—æ®µ '{field.name}' åœ¨ {lang} ä¸­é¡å‹æ¨™è¨˜ä¸æ­£ç¢º",
                            schema.name,
                            field.name,
                            [lang],
                            f"ä½¿ç”¨ {expected_patterns[lang]} æ ¼å¼æ¨™è¨˜å¯é¸é¡å‹",
                        )

    def _validate_type_mappings(self) -> None:
        """é©—è­‰é¡å‹æ˜ å°„çš„å®Œæ•´æ€§"""
        print("ğŸ”„ é©—è­‰é¡å‹æ˜ å°„å®Œæ•´æ€§...")

        # ç²å–æ‰€æœ‰ä½¿ç”¨çš„é¡å‹
        used_types = set()
        for schema in self.interface.get_all_schemas():
            for field in schema.fields:
                used_types.add(field.type)

        # æª¢æŸ¥æ¯ç¨®èªè¨€æ˜¯å¦éƒ½æœ‰æ˜ å°„
        for lang in ["python", "go", "rust"]:
            mappings = self.interface.language_mappings.get(lang, {})
            for used_type in used_types:
                if used_type not in mappings:
                    self._add_issue(
                        "warning",
                        "missing",
                        f"é¡å‹ '{used_type}' ç¼ºå°‘ {lang} èªè¨€æ˜ å°„",
                        "type_mapping",
                        languages=[lang],
                        suggestion=f"åœ¨ {lang} é…ç½®ä¸­æ·»åŠ  '{used_type}' çš„é¡å‹æ˜ å°„",
                    )

    def _validate_generated_code_structure(self) -> None:
        """é©—è­‰ç”Ÿæˆä»£ç¢¼çš„çµæ§‹å®Œæ•´æ€§"""
        print("ğŸ—ï¸  é©—è­‰ç”Ÿæˆä»£ç¢¼çµæ§‹...")

        all_schemas = self.interface.get_all_schemas()
        schema_names = {s.name for s in all_schemas}

        # æª¢æŸ¥ Go ç”Ÿæˆæ–‡ä»¶
        go_file = self.generated_files["go"]["all"]
        if go_file.exists():
            go_content = go_file.read_text(encoding="utf-8")
            missing_go_schemas = []

            for schema_name in schema_names:
                if f"type {schema_name} struct" not in go_content:
                    missing_go_schemas.append(schema_name)  # type: ignore

            if missing_go_schemas:
                self._add_issue(
                    "critical",
                    "missing",
                    f"Go ä»£ç¢¼ä¸­ç¼ºå°‘ {len(missing_go_schemas)} å€‹ Schema: {', '.join(missing_go_schemas[:5])}{'...' if len(missing_go_schemas) > 5 else ''}",
                    "code_generation",
                    languages=["go"],
                    suggestion="é‡æ–°é‹è¡Œ Go ä»£ç¢¼ç”Ÿæˆï¼Œç¢ºä¿åŒ…å«æ‰€æœ‰ Schema åˆ†é¡",
                )

        # æª¢æŸ¥ Rust ç”Ÿæˆæ–‡ä»¶
        rust_file = self.generated_files["rust"]["all"]
        if rust_file.exists():
            rust_content = rust_file.read_text(encoding="utf-8")
            missing_rust_schemas = []

            for schema_name in schema_names:
                if f"pub struct {schema_name}" not in rust_content:
                    missing_rust_schemas.append(schema_name)  # type: ignore

            if missing_rust_schemas:
                self._add_issue(
                    "critical",
                    "missing",
                    f"Rust ä»£ç¢¼ä¸­ç¼ºå°‘ {len(missing_rust_schemas)} å€‹ Schema: {', '.join(missing_rust_schemas[:5])}{'...' if len(missing_rust_schemas) > 5 else ''}",
                    "code_generation",
                    languages=["rust"],
                    suggestion="é‡æ–°é‹è¡Œ Rust ä»£ç¢¼ç”Ÿæˆï¼Œç¢ºä¿åŒ…å«æ‰€æœ‰ Schema åˆ†é¡",
                )

    def _generate_coverage_stats(self) -> dict[str, Any]:
        """ç”Ÿæˆè¦†è“‹ç‡çµ±è¨ˆ"""
        all_schemas = self.interface.get_all_schemas()

        stats = {
            "total_schemas": len(all_schemas),
            "schemas_by_category": {},
            "language_coverage": {},
            "field_type_distribution": {},
            "validation_summary": {
                "critical_issues": len([i for i in self.issues if i.severity == "critical"]),  # type: ignore
                "warning_issues": len([i for i in self.issues if i.severity == "warning"]),  # type: ignore
                "info_issues": len([i for i in self.issues if i.severity == "info"]),  # type: ignore
            },
        }

        # æŒ‰é¡åˆ¥çµ±è¨ˆ
        for schema in all_schemas:
            if schema.category not in stats["schemas_by_category"]:
                stats["schemas_by_category"][schema.category] = 0
            stats["schemas_by_category"][schema.category] += 1

        # èªè¨€ä¸€è‡´æ€§è©•ä¼°ï¼ˆåŸºæ–¼å¯¦éš›å•é¡Œè€Œéæ•¸å­—è¦†è“‹ç‡ï¼‰
        for lang in ["python", "go", "rust"]:
            lang_issues = [
                i for i in self.issues if i.languages and lang in i.languages
            ]

            # åˆ†é¡å•é¡Œåš´é‡ç¨‹åº¦
            critical_issues = [
                i for i in lang_issues if i.severity in ["critical", "error"]
            ]
            warning_issues = [i for i in lang_issues if i.severity == "warning"]

            # åŠŸèƒ½å®Œæ•´æ€§è©•ä¼°ï¼šæœ‰åš´é‡å•é¡Œæ‰ç®—å¤±æ•—
            # è­¦å‘Šé€šå¸¸æ˜¯æ­£å¸¸çš„è·¨èªè¨€èªæ³•å·®ç•°ï¼Œä¸å½±éŸ¿åŠŸèƒ½
            if critical_issues:
                consistency_score = 0  # æœ‰åš´é‡å•é¡Œå°±æ˜¯ä¸ä¸€è‡´
            elif warning_issues:
                # è­¦å‘Šæ•¸é‡å¾ˆå¤šæ™‚ï¼Œä½†æ²’æœ‰åš´é‡å•é¡Œï¼ŒåŠŸèƒ½ä»ç„¶å®Œæ•´
                consistency_score = max(60, 100 - min(40, len(warning_issues) // 10))  # type: ignore
            else:
                consistency_score = 100  # å®Œç¾ä¸€è‡´

            stats["language_coverage"][lang] = {
                "coverage_percentage": consistency_score,
                "issues_count": len(lang_issues),  # type: ignore
                "critical_issues": len(critical_issues),  # type: ignore
                "warning_issues": len(warning_issues),  # type: ignore
                "functional_integrity": critical_issues == 0,
            }

        # å­—æ®µé¡å‹åˆ†å¸ƒ
        type_counts = {}
        for schema in all_schemas:
            for field in schema.fields:
                field_type = field.type
                if field_type not in type_counts:
                    type_counts[field_type] = 0
                type_counts[field_type] += 1

        stats["field_type_distribution"] = dict(
            sorted(type_counts.items(), key=lambda x: x[1], reverse=True)
        )

        return stats

    def _add_issue(
        self,
        severity: str,
        category: str,
        message: str,
        schema_name: str,
        field_name: str | None = None,
        languages: list[str] | None = None,
        suggestion: str | None = None,
    ) -> None:
        """æ·»åŠ é©—è­‰å•é¡Œ"""
        issue = ValidationIssue(
            severity=severity,
            category=category,
            message=message,
            schema_name=schema_name,
            field_name=field_name,
            languages=languages or [],
            suggestion=suggestion,
        )
        self.issues.append(issue)  # type: ignore

    def generate_report_file(
        self,
        report: ValidationReport,
        output_path: str = "cross_language_validation_report.json",
    ) -> None:
        """ç”Ÿæˆé©—è­‰å ±å‘Šæ–‡ä»¶"""
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(report.to_dict(), f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ é©—è­‰å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}")

    def print_summary(self, report: ValidationReport) -> None:
        """æ‰“å°é©—è­‰æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ” è·¨èªè¨€ Schema é©—è­‰å ±å‘Šæ‘˜è¦")
        print("=" * 60)

        print(
            f"ğŸ“Š ç¸½è¨ˆ: {report.total_schemas} å€‹ Schema, {report.total_fields} å€‹å­—æ®µ"
        )

        # å•é¡Œçµ±è¨ˆ
        critical = len([i for i in report.issues if i.severity == "critical"])  # type: ignore
        warning = len([i for i in report.issues if i.severity == "warning"])  # type: ignore
        info = len([i for i in report.issues if i.severity == "info"])  # type: ignore

        print(f"ğŸš¨ å•é¡Œçµ±è¨ˆ: {critical} åš´é‡, {warning} è­¦å‘Š, {info} ä¿¡æ¯")

        # èªè¨€è¦†è“‹ç‡
        print("\nğŸ“ˆ èªè¨€è¦†è“‹ç‡:")
        for lang, stats in report.coverage_stats["language_coverage"].items():
            print(
                f"   {lang}: {stats['coverage_percentage']:.1f}% ({stats['issues_count']} å•é¡Œ)"
            )

        # åš´é‡å•é¡Œè©³æƒ…
        if critical > 0:
            print(f"\nğŸš¨ åš´é‡å•é¡Œ ({critical} å€‹):")
            for issue in report.issues:
                if issue.severity == "critical":
                    print(f"   âŒ {issue.message}")
                    if issue.suggestion:
                        print(f"      ğŸ’¡ å»ºè­°: {issue.suggestion}")

        # æ•´é«”ç‹€æ…‹
        if critical == 0:
            print("\nâœ… è·¨èªè¨€ä¸€è‡´æ€§é©—è­‰é€šéï¼")
        else:
            print(f"\nâŒ ç™¼ç¾ {critical} å€‹åš´é‡å•é¡Œéœ€è¦ä¿®å¾©")


def main():
    """ä¸»å‡½æ•¸"""
    validator = CrossLanguageValidator()
    report = validator.validate_all()

    # æ‰“å°æ‘˜è¦
    validator.print_summary(report)

    # ç”Ÿæˆè©³ç´°å ±å‘Š
    validator.generate_report_file(report)

    return len([i for i in report.issues if i.severity == "critical"]) == 0  # type: ignore


if __name__ == "__main__":
    import sys

    success = main()
    sys.exit(0 if success else 1)
