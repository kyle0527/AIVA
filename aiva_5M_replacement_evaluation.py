#!/usr/bin/env python3
"""
AIVA 5M æ¨¡å‹æ›¿æ›è©•ä¼°å·¥å…·
ç”¨æ–¼è©•ä¼°ä½¿ç”¨ aiva_5M_weights.pth æ›¿æ›ç¾æœ‰æ¨¡å‹çš„èƒ½åŠ›å·®ç•°
"""

import torch
import torch.nn as nn
import time
import traceback
import json
from pathlib import Path
import numpy as np

class ModelAdapter(nn.Module):
    """æ¨¡å‹é©é…å™¨ï¼Œç”¨æ–¼è™•ç†ä¸åŒè¼¸å‡ºç¶­åº¦"""
    def __init__(self, input_dim, target_dim=128):
        super().__init__()
        self.adapter = nn.Linear(input_dim, target_dim)
        
    def forward(self, x):
        return self.adapter(x)

class AIVA5MReplacementEvaluator:
    """5M æ¨¡å‹æ›¿æ›è©•ä¼°å™¨"""
    
    def __init__(self):
        self.models = {}
        self.adapters = {}
        self.evaluation_results = {}
        
    def load_models(self):
        """è¼‰å…¥æ‰€æœ‰æ¨¡å‹é€²è¡Œæ¯”è¼ƒ"""
        model_files = [
            'aiva_real_ai_core.pth',
            'aiva_real_weights.pth', 
            'aiva_5M_weights.pth'
        ]
        
        print("ğŸ”„ è¼‰å…¥æ¨¡å‹ä¸­...")
        
        for model_file in model_files:
            if Path(model_file).exists():
                try:
                    print(f"   è¼‰å…¥ {model_file}...")
                    data = torch.load(model_file, map_location='cpu')
                    
                    if isinstance(data, dict) and 'model_state_dict' in data:
                        state_dict = data['model_state_dict']
                    else:
                        state_dict = data
                    
                    # åˆ†ææ¨¡å‹çµæ§‹
                    model_info = self._analyze_model_structure(state_dict)
                    model_info['state_dict'] = state_dict
                    model_info['file_name'] = model_file
                    
                    self.models[model_file] = model_info
                    
                    # ç‚ºéæ¨™æº–è¼¸å‡ºç¶­åº¦å‰µå»ºé©é…å™¨
                    if model_info['output_dim'] != 128:
                        adapter = ModelAdapter(model_info['output_dim'], 128)
                        self.adapters[model_file] = adapter
                    
                    print(f"   âœ… {model_file} è¼‰å…¥æˆåŠŸ")
                    
                except Exception as e:
                    print(f"   âŒ {model_file} è¼‰å…¥å¤±æ•—: {e}")
                    
        return len(self.models)
    
    def _analyze_model_structure(self, state_dict):
        """åˆ†ææ¨¡å‹çµæ§‹"""
        total_params = sum(t.numel() for t in state_dict.values())
        layer_count = len(state_dict)
        
        # æ‰¾å‡ºæ¬Šé‡å±¤ä»¥ç¢ºå®šè¼¸å…¥è¼¸å‡ºç¶­åº¦
        weight_layers = [(k, v) for k, v in state_dict.items() 
                        if 'weight' in k and len(v.shape) >= 2]
        
        if weight_layers:
            first_layer = weight_layers[0][1]
            last_layer = weight_layers[-1][1]
            input_dim = first_layer.shape[-1]
            output_dim = last_layer.shape[0]
        else:
            input_dim = output_dim = None
            
        return {
            'total_params': total_params,
            'layer_count': layer_count,
            'input_dim': input_dim,
            'output_dim': output_dim,
            'weight_layers': len(weight_layers)
        }
    
    def create_mock_neural_network(self, model_info):
        """ç‚ºæ¸¬è©¦å‰µå»ºæ¨¡æ“¬ç¥ç¶“ç¶²è·¯"""
        if model_info['input_dim'] and model_info['output_dim']:
            layers = []
            
            # ç°¡åŒ–çš„ç¶²è·¯æ¶æ§‹é‡å»º
            input_size = model_info['input_dim']
            output_size = model_info['output_dim']
            
            # æ ¹æ“šåƒæ•¸é‡æ¨ä¼°éš±è—å±¤å¤§å°
            estimated_hidden = int((model_info['total_params'] / (input_size + output_size)) ** 0.5)
            estimated_hidden = max(64, min(1024, estimated_hidden))
            
            layers.extend([
                nn.Linear(input_size, estimated_hidden),
                nn.ReLU(),
                nn.Linear(estimated_hidden, estimated_hidden // 2),
                nn.ReLU(), 
                nn.Linear(estimated_hidden // 2, output_size)
            ])
            
            return nn.Sequential(*layers)
        
        return None
    
    def evaluate_computational_performance(self):
        """è©•ä¼°è¨ˆç®—æ€§èƒ½"""
        print("\nğŸš€ è¨ˆç®—æ€§èƒ½è©•ä¼°...")
        
        # æ¸¬è©¦è¼¸å…¥
        test_input = torch.randn(32, 512)  # æ‰¹æ¬¡å¤§å° 32, è¼¸å…¥ç¶­åº¦ 512
        
        for model_name, model_info in self.models.items():
            print(f"\n   æ¸¬è©¦ {model_name}...")
            
            try:
                # å‰µå»ºæ¨¡æ“¬ç¶²è·¯
                network = self.create_mock_neural_network(model_info)
                if network is None:
                    print("      âŒ ç„¡æ³•å‰µå»ºæ¸¬è©¦ç¶²è·¯")
                    continue
                
                # è¼‰å…¥æ¬Šé‡ (éƒ¨åˆ†è¼‰å…¥ï¼Œåƒ…ç”¨æ–¼æ¸¬è©¦)
                try:
                    network.load_state_dict(model_info['state_dict'], strict=False)
                    print("      âœ… æ¬Šé‡éƒ¨åˆ†è¼‰å…¥æˆåŠŸ")
                except:
                    print("      âš ï¸ æ¬Šé‡è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–")
                
                # æ¸¬è©¦æ¨ç†æ™‚é–“
                network.eval()
                with torch.no_grad():
                    # ç†±èº«
                    _ = network(test_input)
                    
                    # è¨ˆæ™‚æ¸¬è©¦
                    start_time = time.time()
                    for _ in range(100):
                        output = network(test_input)
                    end_time = time.time()
                    
                    avg_time = (end_time - start_time) / 100
                    
                    # æ‡‰ç”¨é©é…å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if model_name in self.adapters:
                        adapter_start = time.time()
                        adapted_output = self.adapters[model_name](output)
                        adapter_time = time.time() - adapter_start
                        print(f"      é©é…å™¨è™•ç†æ™‚é–“: {adapter_time*1000:.2f}ms")
                        final_output = adapted_output
                    else:
                        final_output = output
                    
                    self.evaluation_results[model_name] = {
                        'avg_inference_time_ms': avg_time * 1000,
                        'output_shape': list(final_output.shape),
                        'memory_footprint_mb': model_info['total_params'] * 4 / (1024*1024),  # å‡è¨­ float32
                        'computational_complexity': model_info['total_params'] / 1000000  # M åƒæ•¸
                    }
                    
                    print(f"      å¹³å‡æ¨ç†æ™‚é–“: {avg_time*1000:.2f}ms")
                    print(f"      è¼¸å‡ºå½¢ç‹€: {final_output.shape}")
                    print(f"      è¨˜æ†¶é«”ä½”ç”¨: {self.evaluation_results[model_name]['memory_footprint_mb']:.1f}MB")
                    
            except Exception as e:
                print(f"      âŒ æ¸¬è©¦å¤±æ•—: {e}")
                self.evaluation_results[model_name] = {'error': str(e)}
    
    def analyze_capability_differences(self):
        """åˆ†æèƒ½åŠ›å·®ç•°"""
        print("\nğŸ“Š èƒ½åŠ›å·®ç•°åˆ†æ...")
        
        if 'aiva_5M_weights.pth' not in self.models:
            print("âŒ 5M æ¨¡å‹æœªè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œæ¯”è¼ƒ")
            return
            
        target_model = self.models['aiva_5M_weights.pth']
        
        print(f"\nğŸ¯ 5M æ¨¡å‹ (aiva_5M_weights.pth) è©³ç´°åˆ†æ:")
        print(f"   åƒæ•¸ç¸½é‡: {target_model['total_params']:,}")
        print(f"   å±¤æ•¸: {target_model['layer_count']}")
        print(f"   è¼¸å…¥ç¶­åº¦: {target_model['input_dim']}")
        print(f"   è¼¸å‡ºç¶­åº¦: {target_model['output_dim']}")
        print(f"   æ¬Šé‡å±¤æ•¸: {target_model['weight_layers']}")
        
        # èˆ‡å…¶ä»–æ¨¡å‹æ¯”è¼ƒ
        print(f"\nğŸ“ˆ èˆ‡å…¶ä»–æ¨¡å‹æ¯”è¼ƒ:")
        
        for model_name, model_info in self.models.items():
            if model_name == 'aiva_5M_weights.pth':
                continue
                
            param_ratio = target_model['total_params'] / model_info['total_params']
            layer_diff = target_model['layer_count'] - model_info['layer_count']
            output_ratio = target_model['output_dim'] / model_info['output_dim']
            
            print(f"\n   vs {model_name}:")
            print(f"      åƒæ•¸é‡æ¯”ä¾‹: {param_ratio:.2f}x")
            print(f"      å±¤æ•¸å·®ç•°: {layer_diff:+d}")
            print(f"      è¼¸å‡ºç¶­åº¦æ¯”ä¾‹: {output_ratio:.2f}x")
            
            # èƒ½åŠ›é æ¸¬
            if param_ratio > 1.2:
                complexity_level = "ğŸ”º é¡¯è‘—æå‡"
            elif param_ratio > 1.1:
                complexity_level = "ğŸ”º é©åº¦æå‡"
            else:
                complexity_level = "â¡ï¸ ç›¸è¿‘"
                
            print(f"      é æœŸå­¸ç¿’èƒ½åŠ›: {complexity_level}")
    
    def generate_replacement_recommendation(self):
        """ç”Ÿæˆæ›¿æ›å»ºè­°"""
        print("\nğŸ’¡ æ›¿æ›å»ºè­°ç”Ÿæˆ...")
        
        if 'aiva_5M_weights.pth' not in self.evaluation_results:
            print("âŒ ç¼ºå°‘ 5M æ¨¡å‹è©•ä¼°çµæœ")
            return
            
        result = self.evaluation_results['aiva_5M_weights.pth']
        
        print(f"\nğŸ“‹ 5M æ¨¡å‹æ›¿æ›è©•ä¼°çµæœ:")
        
        # æ€§èƒ½è©•ä¼°
        if 'avg_inference_time_ms' in result:
            if result['avg_inference_time_ms'] < 10:
                performance_rating = "ğŸŸ¢ å„ªç§€"
            elif result['avg_inference_time_ms'] < 50:
                performance_rating = "ğŸŸ¡ è‰¯å¥½"
            else:
                performance_rating = "ğŸ”´ éœ€è¦å„ªåŒ–"
                
            print(f"   æ¨ç†æ€§èƒ½: {performance_rating} ({result['avg_inference_time_ms']:.2f}ms)")
        
        # è¨˜æ†¶é«”è©•ä¼°
        if 'memory_footprint_mb' in result:
            if result['memory_footprint_mb'] < 50:
                memory_rating = "ğŸŸ¢ è¼•é‡"
            elif result['memory_footprint_mb'] < 100:
                memory_rating = "ğŸŸ¡ é©ä¸­"
            else:
                memory_rating = "ğŸ”´ è¼ƒé‡"
                
            print(f"   è¨˜æ†¶é«”è² è¼‰: {memory_rating} ({result['memory_footprint_mb']:.1f}MB)")
        
        # ç¶œåˆå»ºè­°
        print(f"\nğŸ¯ æ›¿æ›å»ºè­°:")
        
        target_model = self.models['aiva_5M_weights.pth']
        
        if target_model['output_dim'] == 531:
            print("   âœ… å»ºè­°é€²è¡Œæ›¿æ›ï¼Œä½†éœ€è¦è™•ç†ä»¥ä¸‹äº‹é …:")
            print("      1. å»ºç«‹è¼¸å‡ºç¶­åº¦é©é…å±¤ (531â†’128)")
            print("      2. æ¸¬è©¦æ±ºç­–é‚è¼¯å…¼å®¹æ€§")
            print("      3. ç›£æ§å¯¦éš›é‹è¡Œæ€§èƒ½")
            print("      4. é©—è­‰æ±ºç­–å“è³ªæ”¹å–„")
            
            print(f"\n   ğŸ“ˆ é æœŸæ”¹å–„:")
            print("      â€¢ æ±ºç­–è¤‡é›œåº¦: å¤§å¹…æå‡ (531ç¶­è±å¯Œè¼¸å‡º)")
            print("      â€¢ ç‰¹å¾µå­¸ç¿’: é¡¯è‘—æ”¹å–„ (14å±¤æ·±åº¦)")
            print("      â€¢ è¡¨é”èƒ½åŠ›: å¢å¼· (5Måƒæ•¸)")
            
            print(f"\n   âš ï¸ æ³¨æ„äº‹é …:")
            print("      â€¢ éœ€è¦èª¿æ•´å¾ŒçºŒè™•ç†é‚è¼¯")
            print("      â€¢ å¯èƒ½å¢åŠ è¨ˆç®—è² è¼‰")
            print("      â€¢ å»ºè­°å…ˆåœ¨æ¸¬è©¦ç’°å¢ƒé©—è­‰")
        
    def save_evaluation_report(self):
        """ä¿å­˜è©•ä¼°å ±å‘Š"""
        report_file = "AIVA_5M_MODEL_REPLACEMENT_EVALUATION.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# AIVA 5M æ¨¡å‹æ›¿æ›è©•ä¼°å ±å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æ¨¡å‹æ¦‚è¦½\n\n")
            for model_name, model_info in self.models.items():
                f.write(f"### {model_name}\n")
                f.write(f"- åƒæ•¸é‡: {model_info['total_params']:,}\n")
                f.write(f"- å±¤æ•¸: {model_info['layer_count']}\n")
                f.write(f"- è¼¸å…¥ç¶­åº¦: {model_info['input_dim']}\n")
                f.write(f"- è¼¸å‡ºç¶­åº¦: {model_info['output_dim']}\n\n")
            
            f.write("## æ€§èƒ½è©•ä¼°çµæœ\n\n")
            for model_name, result in self.evaluation_results.items():
                f.write(f"### {model_name}\n")
                if 'error' in result:
                    f.write(f"- è©•ä¼°ç‹€æ…‹: å¤±æ•— ({result['error']})\n\n")
                else:
                    f.write(f"- å¹³å‡æ¨ç†æ™‚é–“: {result.get('avg_inference_time_ms', 'N/A'):.2f}ms\n")
                    f.write(f"- è¨˜æ†¶é«”ä½”ç”¨: {result.get('memory_footprint_mb', 'N/A'):.1f}MB\n")
                    f.write(f"- è¨ˆç®—è¤‡é›œåº¦: {result.get('computational_complexity', 'N/A'):.2f}M åƒæ•¸\n\n")
            
            f.write("## æ›¿æ›å»ºè­°\n\n")
            f.write("åŸºæ–¼è©•ä¼°çµæœï¼Œaiva_5M_weights.pth æ¨¡å‹å…·æœ‰ä»¥ä¸‹ç‰¹é»:\n\n")
            f.write("### å„ªå‹¢\n")
            f.write("- é«˜å®¹é‡è¼¸å‡º (531 ç¶­åº¦)\n")
            f.write("- æ·±å±¤æ¶æ§‹ (14 å±¤)\n")
            f.write("- å¼·å¤§çš„è¡¨é”èƒ½åŠ› (5M åƒæ•¸)\n\n")
            
            f.write("### æŒ‘æˆ°\n")
            f.write("- éœ€è¦é©é…è¼¸å‡ºç¶­åº¦\n")
            f.write("- å¯èƒ½å¢åŠ è¨ˆç®—è² è¼‰\n")
            f.write("- éœ€è¦é©—è­‰å…¼å®¹æ€§\n\n")
            
            f.write("### å»ºè­°æ­¥é©Ÿ\n")
            f.write("1. å»ºç«‹è¼¸å‡ºé©é…å±¤\n")
            f.write("2. æ¸¬è©¦ç’°å¢ƒé©—è­‰\n")
            f.write("3. æ€§èƒ½ç›£æ§\n")
            f.write("4. æ¼¸é€²å¼éƒ¨ç½²\n\n")
        
        print(f"ğŸ“„ è©•ä¼°å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    def run_full_evaluation(self):
        """åŸ·è¡Œå®Œæ•´è©•ä¼°"""
        print("ğŸš€ é–‹å§‹ AIVA 5M æ¨¡å‹æ›¿æ›è©•ä¼°")
        print("=" * 60)
        
        # è¼‰å…¥æ¨¡å‹
        loaded_count = self.load_models()
        if loaded_count == 0:
            print("âŒ æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•æ¨¡å‹")
            return
            
        print(f"âœ… æˆåŠŸè¼‰å…¥ {loaded_count} å€‹æ¨¡å‹")
        
        # æ€§èƒ½è©•ä¼°
        self.evaluate_computational_performance()
        
        # èƒ½åŠ›åˆ†æ
        self.analyze_capability_differences()
        
        # ç”Ÿæˆå»ºè­°
        self.generate_replacement_recommendation()
        
        # ä¿å­˜å ±å‘Š
        self.save_evaluation_report()
        
        print("\nğŸ‰ è©•ä¼°å®Œæˆ!")

if __name__ == "__main__":
    evaluator = AIVA5MReplacementEvaluator()
    evaluator.run_full_evaluation()