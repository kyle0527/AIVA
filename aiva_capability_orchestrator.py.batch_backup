#!/usr/bin/env python3
"""
ğŸ”— AIVA æ ¸å¿ƒèƒ½åŠ›èˆ‡5Mç¥ç¶“ç¶²è·¯ä¸²æ¥å™¨

æ•´åˆAIVAç¾æœ‰çš„æ‰€æœ‰æ ¸å¿ƒèƒ½åŠ›æ¨¡çµ„ï¼š
- éœæ…‹åˆ†æ (ç¨‹å¼ç¢¼åˆ†æã€æ¼æ´æª¢æ¸¬)
- å‹•æ…‹æƒæ (ç¶²è·¯æƒæã€æ¼æ´æƒæ)
- é¢¨éšªè©•ä¼° (CVSSè¨ˆç®—ã€å¨è„…æƒ…å ±)
- æ”»æ“Šç·¨æ’ (SQLæ³¨å…¥ã€XSSã€SSRFç­‰)
- æƒ…å ±æ”¶é›† (ç›®æ¨™æ¢ç´¢ã€æŠ€è¡“æ£§è­˜åˆ¥)

å°‡æ‰€æœ‰èƒ½åŠ›çš„è¼¸å‡ºçµ±ä¸€æ ¼å¼åŒ–ç‚º512ç¶­ç‰¹å¾µå‘é‡ï¼Œ
é¤µå…¥5Mç¥ç¶“ç¶²è·¯é€²è¡Œæ™ºèƒ½æ±ºç­–ã€‚
"""

import asyncio
import json
import numpy as np
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging

# è¨­å®šè·¯å¾‘
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir / 'services' / 'core'))

logger = logging.getLogger(__name__)

class CapabilityType(str, Enum):
    """èƒ½åŠ›é¡å‹æšèˆ‰"""
    STATIC_ANALYSIS = "static_analysis"
    VULNERABILITY_SCANNING = "vulnerability_scanning" 
    NETWORK_RECONNAISSANCE = "network_reconnaissance"
    WEB_ATTACK = "web_attack"
    RISK_ASSESSMENT = "risk_assessment"
    INTELLIGENCE_GATHERING = "intelligence_gathering"
    CODE_EXPLORATION = "code_exploration"

@dataclass
class CapabilityResult:
    """èƒ½åŠ›åŸ·è¡Œçµæœ"""
    capability_type: CapabilityType
    status: str
    confidence: float
    data: Dict[str, Any]
    features: Optional[np.ndarray] = None
    execution_time: float = 0.0
    error_message: Optional[str] = None

class FeatureExtractor:
    """ç‰¹å¾µæå–å™¨ - å°‡å„ç¨®èƒ½åŠ›çµæœè½‰æ›ç‚º512ç¶­ç‰¹å¾µå‘é‡"""
    
    def __init__(self):
        self.feature_dimensions = {
            'vulnerability_features': 100,    # æ¼æ´ç‰¹å¾µ
            'network_features': 80,           # ç¶²è·¯ç‰¹å¾µ
            'code_features': 90,              # ç¨‹å¼ç¢¼ç‰¹å¾µ
            'risk_features': 60,              # é¢¨éšªç‰¹å¾µ
            'attack_features': 70,            # æ”»æ“Šç‰¹å¾µ
            'intel_features': 50,             # æƒ…å ±ç‰¹å¾µ
            'meta_features': 62               # å…ƒç‰¹å¾µï¼ˆæ™‚é–“ã€ä¿¡å¿ƒåº¦ç­‰ï¼‰
        }
        total_dims = sum(self.feature_dimensions.values())
        assert total_dims == 512, f"ç‰¹å¾µç¶­åº¦ç¸½å’Œå¿…é ˆç‚º512ï¼Œç•¶å‰ç‚º{total_dims}"
    
    def extract_vulnerability_features(self, vuln_data: Dict) -> np.ndarray:
        """æå–æ¼æ´ç‰¹å¾µ (100ç¶­) - é‡æ§‹å¾Œä¸»å‡½æ•¸ï¼Œè¤‡é›œåº¦â‰¤8"""
        features = np.zeros(100)
        
        if not vuln_data:
            return features
        
        # æŒ‰è·è²¬åˆ†é›¢æå–ä¸åŒé¡å‹ç‰¹å¾µ
        self._extract_vulnerability_type_features(vuln_data, features)
        self._extract_severity_features(vuln_data, features)  
        self._extract_cvss_features(vuln_data, features)
        self._extract_exploit_difficulty_features(vuln_data, features)
        self._extract_impact_scope_features(vuln_data, features)
        self._extract_detection_confidence_features(vuln_data, features)
        
        return features
    
    def _extract_vulnerability_type_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–æ¼æ´é¡å‹ç‰¹å¾µ (20ç¶­) - è¤‡é›œåº¦â‰¤5"""
        vuln_types = ['sqli', 'xss', 'ssrf', 'idor', 'bola', 'info_leak', 
                     'weak_auth', 'rce', 'lfi', 'rfi', 'csrf', 'xxe',
                     'deserialization', 'injection', 'broken_auth', 
                     'sensitive_exposure', 'xml_injection', 'ldap_injection',
                     'command_injection', 'path_traversal']
        
        vuln_data_str = str(vuln_data).lower()
        for i, vuln_type in enumerate(vuln_types):
            if vuln_type in vuln_data_str:
                features[i] = 1.0
    
    def _extract_severity_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–åš´é‡åº¦ç‰¹å¾µ (10ç¶­) - è¤‡é›œåº¦â‰¤8"""
        severity_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'info': 0}
        
        vulnerabilities = vuln_data.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            severity = vuln.get('severity', '').lower()
            if severity in severity_counts:
                severity_counts[severity] += 1
        
        # æ­¸ä¸€åŒ–åš´é‡åº¦è¨ˆæ•¸
        max_count = max(severity_counts.values()) if any(severity_counts.values()) else 1
        for i, (sev, count) in enumerate(severity_counts.items()):
            features[20 + i] = count / max_count
            features[25 + i] = min(count / 10.0, 1.0)  # åŸå§‹è¨ˆæ•¸(æ­¸ä¸€åŒ–)
    
    def _extract_cvss_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–CVSSç‰¹å¾µ (20ç¶­) - è¤‡é›œåº¦â‰¤6"""
        cvss_scores = []
        
        vulnerabilities = vuln_data.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            score = vuln.get('cvss_score', 0.0)
            if score > 0:
                cvss_scores.append(score)
        
        if cvss_scores:
            features[30] = np.mean(cvss_scores) / 10.0  # å¹³å‡CVSS
            features[31] = np.max(cvss_scores) / 10.0   # æœ€é«˜CVSS
            features[32] = np.min(cvss_scores) / 10.0   # æœ€ä½CVSS
            features[33] = np.std(cvss_scores) / 3.0    # CVSSæ¨™æº–å·®
            features[34] = len(cvss_scores) / 50.0      # æ¼æ´æ•¸é‡
    
    def _extract_exploit_difficulty_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–åˆ©ç”¨é›£åº¦ç‰¹å¾µ (15ç¶­) - è¤‡é›œåº¦â‰¤4"""
        exploit_difficulty = vuln_data.get('exploit_difficulty', {})
        difficulties = ['trivial', 'easy', 'medium', 'hard', 'expert']
        
        for i, difficulty in enumerate(difficulties):
            features[35 + i] = exploit_difficulty.get(difficulty, 0) / 10.0
    
    def _extract_impact_scope_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–å½±éŸ¿ç¯„åœç‰¹å¾µ (15ç¶­) - è¤‡é›œåº¦â‰¤3"""
        impact_scope = vuln_data.get('impact_scope', {})
        scopes = ['confidentiality', 'integrity', 'availability']
        
        for i, scope in enumerate(scopes):
            features[40 + i] = impact_scope.get(scope, 0.0)
    
    def _extract_detection_confidence_features(self, vuln_data: Dict, features: np.ndarray) -> None:
        """æå–æª¢æ¸¬ç½®ä¿¡åº¦ç‰¹å¾µ (20ç¶­) - è¤‡é›œåº¦â‰¤4"""
        detection_confidence = vuln_data.get('detection_confidence', [])
        
        if detection_confidence:
            conf_array = np.array(detection_confidence[:20])
            features[50:70] = np.pad(conf_array, (0, max(0, 20 - len(conf_array))))
    
    def extract_network_features(self, network_data: Dict) -> np.ndarray:
        """æå–ç¶²è·¯ç‰¹å¾µ (80ç¶­)"""
        features = np.zeros(80)
        
        if not network_data:
            return features
        
        # é–‹æ”¾ç«¯å£ç‰¹å¾µ (20ç¶­)
        common_ports = [21, 22, 23, 25, 53, 80, 110, 143, 443, 993, 995, 
                       1433, 3306, 3389, 5432, 5900, 6379, 27017, 8080, 8443]
        
        open_ports = network_data.get('open_ports', [])
        for i, port in enumerate(common_ports):
            if port in open_ports:
                features[i] = 1.0
        
        # æœå‹™ç‰¹å¾µ (20ç¶­)
        services = network_data.get('services', {})
        service_types = ['http', 'https', 'ftp', 'ssh', 'telnet', 'smtp', 'dns',
                        'mysql', 'postgresql', 'redis', 'mongodb', 'mssql',
                        'vnc', 'rdp', 'ldap', 'snmp', 'nfs', 'smb', 'nginx', 'apache']
        
        for i, service in enumerate(service_types):
            if service in str(services).lower():
                features[20 + i] = 1.0
        
        # ç¶²è·¯æ‹“æ’²ç‰¹å¾µ (20ç¶­)
        topology = network_data.get('topology', {})
        features[40] = len(open_ports) / 65535.0 if open_ports else 0
        features[41] = network_data.get('response_time', 0) / 1000.0  # éŸ¿æ‡‰æ™‚é–“
        features[42] = network_data.get('bandwidth', 0) / 1000000.0   # å¸¶å¯¬
        features[43] = len(services) / 50.0 if services else 0        # æœå‹™æ•¸é‡
        
        # TTLå’ŒæŒ‡ç´‹ç‰¹å¾µ (20ç¶­)
        fingerprint = network_data.get('os_fingerprint', {})
        features[60] = fingerprint.get('ttl', 64) / 255.0
        features[61] = fingerprint.get('window_size', 0) / 65535.0
        
        # WAFæª¢æ¸¬
        waf_detected = network_data.get('waf_detected', False)
        features[70] = 1.0 if waf_detected else 0.0
        
        # CDNæª¢æ¸¬  
        cdn_detected = network_data.get('cdn_detected', False)
        features[71] = 1.0 if cdn_detected else 0.0
        
        return features
    
    def extract_code_features(self, code_data: Dict) -> np.ndarray:
        """æå–ç¨‹å¼ç¢¼ç‰¹å¾µ (90ç¶­)"""
        features = np.zeros(90)
        
        if not code_data:
            return features
        
        # ç¨‹å¼èªè¨€ç‰¹å¾µ (20ç¶­)
        languages = ['python', 'javascript', 'java', 'csharp', 'cpp', 'c',
                    'go', 'rust', 'php', 'ruby', 'swift', 'kotlin',
                    'typescript', 'scala', 'shell', 'powershell',
                    'sql', 'html', 'css', 'xml']
        
        detected_languages = code_data.get('languages', [])
        for i, lang in enumerate(languages):
            if lang in detected_languages:
                features[i] = 1.0
        
        # è¤‡é›œåº¦ç‰¹å¾µ (20ç¶­)
        complexity = code_data.get('complexity', {})
        features[20] = min(complexity.get('cyclomatic_complexity', 0) / 50.0, 1.0)
        features[21] = min(complexity.get('halstead_difficulty', 0) / 100.0, 1.0)
        features[22] = min(complexity.get('lines_of_code', 0) / 10000.0, 1.0)
        features[23] = min(complexity.get('maintainability_index', 0) / 100.0, 1.0)
        
        # å®‰å…¨æ¨¡å¼ç‰¹å¾µ (25ç¶­)
        security_patterns = code_data.get('security_patterns', {})
        dangerous_patterns = ['eval', 'exec', 'system', 'shell_exec', 'passthru',
                            'deserialize', 'unserialize', 'pickle', 'yaml_load',
                            'sql_query', 'raw_input', 'input', 'os.system',
                            'subprocess.call', '__import__', 'compile', 'globals',
                            'locals', 'vars', 'getattr', 'setattr', 'hasattr',
                            'delattr', 'callable', 'isinstance']
        
        for i, pattern in enumerate(dangerous_patterns):
            if pattern in security_patterns:
                features[24 + i] = security_patterns[pattern] / 10.0
        
        # ä¾è³´é …ç‰¹å¾µ (25ç¶­)
        dependencies = code_data.get('dependencies', [])
        risky_deps = ['requests', 'urllib', 'subprocess', 'os', 'sys',
                     'socket', 'pickle', 'yaml', 'json', 'xml',
                     'sqlite3', 'mysql', 'psycopg2', 'redis', 'mongodb']
        
        for i, dep in enumerate(risky_deps):
            if dep in dependencies:
                features[49 + i] = 1.0
        
        return features
    
    def extract_risk_features(self, risk_data: Dict) -> np.ndarray:
        """æå–é¢¨éšªç‰¹å¾µ (60ç¶­)"""
        features = np.zeros(60)
        
        if not risk_data:
            return features
        
        # CVSS v3 åŸºç¤ç‰¹å¾µ (20ç¶­)
        cvss = risk_data.get('cvss_v3', {})
        features[0] = cvss.get('attack_vector', 0.0)      # æ”»æ“Šå‘é‡
        features[1] = cvss.get('attack_complexity', 0.0)  # æ”»æ“Šè¤‡é›œåº¦
        features[2] = cvss.get('privileges_required', 0.0) # æ‰€éœ€æ¬Šé™
        features[3] = cvss.get('user_interaction', 0.0)   # ç”¨æˆ¶äº¤äº’
        features[4] = cvss.get('confidentiality_impact', 0.0) # æ©Ÿå¯†æ€§å½±éŸ¿
        features[5] = cvss.get('integrity_impact', 0.0)   # å®Œæ•´æ€§å½±éŸ¿
        features[6] = cvss.get('availability_impact', 0.0) # å¯ç”¨æ€§å½±éŸ¿
        
        # å¨è„…æƒ…å ±ç‰¹å¾µ (20ç¶­)
        threat_intel = risk_data.get('threat_intelligence', {})
        features[20] = threat_intel.get('actively_exploited', 0.0)
        features[21] = threat_intel.get('exploit_available', 0.0)
        features[22] = threat_intel.get('in_the_wild', 0.0)
        features[23] = threat_intel.get('threat_actor_interest', 0.0)
        
        # è³‡ç”¢åƒ¹å€¼ç‰¹å¾µ (20ç¶­)
        asset_value = risk_data.get('asset_value', {})
        features[40] = asset_value.get('business_criticality', 0.0)
        features[41] = asset_value.get('data_sensitivity', 0.0)
        features[42] = asset_value.get('regulatory_impact', 0.0)
        features[43] = asset_value.get('financial_impact', 0.0)
        
        return features
    
    def extract_attack_features(self, attack_data: Dict) -> np.ndarray:
        """æå–æ”»æ“Šç‰¹å¾µ (70ç¶­)"""
        features = np.zeros(70)
        
        if not attack_data:
            return features
        
        # æ”»æ“Šé¡å‹ç‰¹å¾µ (25ç¶­)
        attack_types = ['sql_injection', 'xss', 'csrf', 'ssrf', 'xxe',
                       'deserialization', 'command_injection', 'file_inclusion',
                       'directory_traversal', 'authentication_bypass',
                       'authorization_bypass', 'business_logic_bypass',
                       'race_condition', 'timing_attack', 'bruteforce',
                       'enumeration', 'information_disclosure', 'dos',
                       'buffer_overflow', 'format_string', 'integer_overflow',
                       'privilege_escalation', 'lateral_movement', 'persistence',
                       'exfiltration']
        
        for i, attack_type in enumerate(attack_types):
            if attack_type in attack_data.get('attack_vectors', []):
                features[i] = 1.0
        
        # æ”»æ“ŠæˆåŠŸç‡ç‰¹å¾µ (15ç¶­)
        success_rates = attack_data.get('success_rates', {})
        for i, attack_type in enumerate(['sqli', 'xss', 'ssrf', 'rce', 'lfi']):
            features[25 + i] = success_rates.get(attack_type, 0.0)
        
        # æ”»æ“Šè¤‡é›œåº¦ç‰¹å¾µ (15ç¶­)
        complexity = attack_data.get('attack_complexity', {})
        features[40] = complexity.get('skill_level_required', 0.0)
        features[41] = complexity.get('time_required', 0.0)
        features[42] = complexity.get('tools_required', 0.0)
        
        # é˜²ç¦¦æ©Ÿåˆ¶ç‰¹å¾µ (15ç¶­)
        defenses = attack_data.get('defenses_detected', {})
        features[55] = 1.0 if defenses.get('waf') else 0.0
        features[56] = 1.0 if defenses.get('rate_limiting') else 0.0
        features[57] = 1.0 if defenses.get('input_validation') else 0.0
        features[58] = 1.0 if defenses.get('csrf_protection') else 0.0
        
        return features
    
    def extract_intelligence_features(self, intel_data: Dict) -> np.ndarray:
        """æå–æƒ…å ±ç‰¹å¾µ (50ç¶­)"""
        features = np.zeros(50)
        
        if not intel_data:
            return features
        
        # æŠ€è¡“æ£§ç‰¹å¾µ (20ç¶­)
        tech_stack = intel_data.get('technology_stack', {})
        technologies = ['apache', 'nginx', 'iis', 'tomcat', 'nodejs',
                       'php', 'python', 'java', 'dotnet', 'ruby',
                       'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch',
                       'docker', 'kubernetes', 'aws', 'azure', 'gcp']
        
        for i, tech in enumerate(technologies):
            if tech in tech_stack:
                features[i] = tech_stack[tech]
        
        # çµ„ç¹”ç‰¹å¾µ (15ç¶­)
        org_info = intel_data.get('organization', {})
        features[20] = org_info.get('company_size', 0.0)
        features[21] = org_info.get('industry_risk_level', 0.0)
        features[22] = org_info.get('geographic_risk', 0.0)
        features[23] = org_info.get('regulatory_environment', 0.0)
        
        # æ­·å²æ”»æ“Šç‰¹å¾µ (15ç¶­)
        history = intel_data.get('attack_history', {})
        features[35] = history.get('previous_breaches', 0.0)
        features[36] = history.get('vulnerability_disclosure_history', 0.0)
        features[37] = history.get('threat_actor_targeting', 0.0)
        
        return features
    
    def extract_meta_features(self, results: List[CapabilityResult]) -> np.ndarray:
        """æå–å…ƒç‰¹å¾µ (62ç¶­)"""
        features = np.zeros(62)
        
        # èƒ½åŠ›åŸ·è¡Œçµ±è¨ˆ (20ç¶­)
        total_capabilities = len(results)
        successful_capabilities = sum(1 for r in results if r.status == 'success')
        
        features[0] = successful_capabilities / max(total_capabilities, 1)  # æˆåŠŸç‡
        features[1] = total_capabilities / 20.0  # æ­¸ä¸€åŒ–èƒ½åŠ›æ•¸é‡
        
        # å¹³å‡ç½®ä¿¡åº¦å’ŒåŸ·è¡Œæ™‚é–“
        confidences = [r.confidence for r in results if r.confidence > 0]
        exec_times = [r.execution_time for r in results if r.execution_time > 0]
        
        features[2] = np.mean(confidences) if confidences else 0.0
        features[3] = np.mean(exec_times) / 10.0 if exec_times else 0.0  # æ­¸ä¸€åŒ–åˆ°0-1
        
        # å„é¡å‹èƒ½åŠ›çš„åŸ·è¡Œç‹€æ…‹ (7*6=42ç¶­)
        capability_types = list(CapabilityType)
        for i, cap_type in enumerate(capability_types):
            type_results = [r for r in results if r.capability_type == cap_type]
            if type_results:
                # æ¯ç¨®èƒ½åŠ›é¡å‹6å€‹ç‰¹å¾µ
                features[4 + i*6] = len(type_results) / 10.0  # æ•¸é‡
                features[5 + i*6] = sum(1 for r in type_results if r.status == 'success') / len(type_results)  # æˆåŠŸç‡
                features[6 + i*6] = np.mean([r.confidence for r in type_results if r.confidence > 0] or [0])  # å¹³å‡ç½®ä¿¡åº¦
                features[7 + i*6] = np.mean([r.execution_time for r in type_results if r.execution_time > 0] or [0]) / 5.0  # å¹³å‡æ™‚é–“
                features[8 + i*6] = len([r for r in type_results if r.error_message]) / len(type_results)  # éŒ¯èª¤ç‡
                features[9 + i*6] = 1.0  # è©²é¡å‹å·²åŸ·è¡Œæ¨™è¨˜
        
        return features
    
    def combine_features(self, results: List[CapabilityResult]) -> np.ndarray:
        """çµ„åˆæ‰€æœ‰ç‰¹å¾µç‚º512ç¶­å‘é‡"""
        # åˆå§‹åŒ–å„é¡ç‰¹å¾µ
        vuln_features = np.zeros(100)
        network_features = np.zeros(80)
        code_features = np.zeros(90)
        risk_features = np.zeros(60)
        attack_features = np.zeros(70)
        intel_features = np.zeros(50)
        
        # å¾çµæœä¸­æå–å„é¡ç‰¹å¾µ
        for result in results:
            if result.capability_type == CapabilityType.VULNERABILITY_SCANNING:
                vuln_features = np.maximum(vuln_features, self.extract_vulnerability_features(result.data))
            elif result.capability_type == CapabilityType.NETWORK_RECONNAISSANCE:
                network_features = np.maximum(network_features, self.extract_network_features(result.data))
            elif result.capability_type in [CapabilityType.STATIC_ANALYSIS, CapabilityType.CODE_EXPLORATION]:
                code_features = np.maximum(code_features, self.extract_code_features(result.data))
            elif result.capability_type == CapabilityType.RISK_ASSESSMENT:
                risk_features = np.maximum(risk_features, self.extract_risk_features(result.data))
            elif result.capability_type == CapabilityType.WEB_ATTACK:
                attack_features = np.maximum(attack_features, self.extract_attack_features(result.data))
            elif result.capability_type == CapabilityType.INTELLIGENCE_GATHERING:
                intel_features = np.maximum(intel_features, self.extract_intelligence_features(result.data))
        
        # æå–å…ƒç‰¹å¾µ
        meta_features = self.extract_meta_features(results)
        
        # çµ„åˆæ‰€æœ‰ç‰¹å¾µ
        combined_features = np.concatenate([
            vuln_features,      # 100ç¶­
            network_features,   # 80ç¶­
            code_features,      # 90ç¶­
            risk_features,      # 60ç¶­
            attack_features,    # 70ç¶­
            intel_features,     # 50ç¶­
            meta_features       # 62ç¶­
        ])
        
        assert len(combined_features) == 512, f"ç‰¹å¾µå‘é‡é•·åº¦å¿…é ˆç‚º512ï¼Œç•¶å‰ç‚º{len(combined_features)}"
        return combined_features

class AIVACapabilityOrchestrator:
    """AIVAèƒ½åŠ›ç·¨æ’å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰æ ¸å¿ƒèƒ½åŠ›"""
    
    def __init__(self):
        self.feature_extractor = FeatureExtractor()
        self.capabilities = {}
        self.results_cache = {}
        
        # è¼‰å…¥5Mç¥ç¶“ç¶²è·¯
        self.ai_core = None
        self._load_5m_neural_network()
    
    def _load_5m_neural_network(self):
        """è¼‰å…¥5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯ - çµ±ä¸€åŒ¯å…¥è·¯å¾‘ä¿®å¾©"""
        try:
            # å˜—è©¦ç›¸å°è·¯å¾‘åŒ¯å…¥ (æŒ‡å—æ¨è–¦æ–¹å¼)
            from services.core.aiva_core.ai_engine.real_neural_core import RealAICore
            
            self.ai_core = RealAICore(
                use_5m_model=True,
                weights_path="services/core/aiva_core/ai_engine/aiva_5M_weights.pth"
            )
            self.ai_core.load_weights()
            logger.info("âœ… 5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯è¼‰å…¥æˆåŠŸ (ç›¸å°è·¯å¾‘)")
            
        except ImportError:
            try:
                # å‚™ç”¨ï¼šå‹•æ…‹è·¯å¾‘åŒ¯å…¥
                sys.path.insert(0, str(Path(__file__).parent / 'services/core/aiva_core/ai_engine'))
                from real_neural_core import RealAICore
                
                self.ai_core = RealAICore(
                    use_5m_model=True,
                    weights_path="services/core/aiva_core/ai_engine/aiva_5M_weights.pth"
                )
                self.ai_core.load_weights()
                logger.info("âœ… 5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯è¼‰å…¥æˆåŠŸ (å‹•æ…‹è·¯å¾‘)")
                
            except Exception as e:
                logger.error(f"âŒ 5Mç¥ç¶“ç¶²è·¯è¼‰å…¥å¤±æ•—: {e}")
                self.ai_core = None
    
    def register_capability(self, name: str, capability_instance):
        """è¨»å†Šèƒ½åŠ›æ¨¡çµ„"""
        self.capabilities[name] = capability_instance
        logger.info(f"ğŸ“ è¨»å†Šèƒ½åŠ›æ¨¡çµ„: {name}")
    
    def execute_static_analysis(self, **kwargs) -> CapabilityResult:
        """åŸ·è¡Œéœæ…‹åˆ†æ"""
        target_code = kwargs.get('target_code', kwargs.get('target', ''))
        
        try:
            # æ¨¡æ“¬éœæ…‹åˆ†æçµæœ
            analysis_data = {
                'languages': ['python', 'javascript'],
                'complexity': {
                    'cyclomatic_complexity': 15,
                    'halstead_difficulty': 25.5,
                    'lines_of_code': 1250,
                    'maintainability_index': 75.2
                },
                'security_patterns': {
                    'eval': 2, 'exec': 1, 'sql_query': 5,
                    'subprocess.call': 3, 'os.system': 1
                },
                'dependencies': ['requests', 'urllib', 'json', 'sqlite3']
            }
            
            return CapabilityResult(
                capability_type=CapabilityType.STATIC_ANALYSIS,
                status="success",
                confidence=0.85,
                data=analysis_data,
                execution_time=0.15
            )
            
        except Exception as e:
            return CapabilityResult(
                capability_type=CapabilityType.STATIC_ANALYSIS,
                status="error",
                confidence=0.0,
                data={},
                error_message=str(e)
            )
    
    def execute_vulnerability_scanning(self, **kwargs) -> CapabilityResult:
        """åŸ·è¡Œæ¼æ´æƒæ"""
        target_url = kwargs.get('target_url', kwargs.get('target', ''))
        
        try:
            # æ¨¡æ“¬æ¼æ´æƒæçµæœ
            vuln_data = {
                'vulnerabilities': [
                    {
                        'type': 'sqli',
                        'severity': 'high',
                        'cvss_score': 8.5,
                        'location': '/login?id=1',
                        'payload': "1' OR '1'='1"
                    },
                    {
                        'type': 'xss',
                        'severity': 'medium', 
                        'cvss_score': 6.2,
                        'location': '/search?q=<script>',
                        'payload': '<script>alert("XSS")</script>'
                    }
                ],
                'exploit_difficulty': {'easy': 2, 'medium': 1},
                'detection_confidence': [0.95, 0.87, 0.76]
            }
            
            return CapabilityResult(
                capability_type=CapabilityType.VULNERABILITY_SCANNING,
                status="success", 
                confidence=0.92,
                data=vuln_data,
                execution_time=2.5
            )
            
        except Exception as e:
            return CapabilityResult(
                capability_type=CapabilityType.VULNERABILITY_SCANNING,
                status="error",
                confidence=0.0,
                data={},
                error_message=str(e)
            )
    
    def execute_network_reconnaissance(self, **kwargs) -> CapabilityResult:
        """åŸ·è¡Œç¶²è·¯åµå¯Ÿ"""
        target_host = kwargs.get('target_host', kwargs.get('target', ''))
        
        try:
            # æ¨¡æ“¬ç¶²è·¯åµå¯Ÿçµæœ
            network_data = {
                'open_ports': [22, 80, 443, 3306, 8080],
                'services': {
                    '22': 'OpenSSH 7.4',
                    '80': 'Apache httpd 2.4.29',
                    '443': 'Apache httpd 2.4.29 (SSL)',
                    '3306': 'MySQL 5.7.24',
                    '8080': 'Tomcat 9.0.14'
                },
                'os_fingerprint': {
                    'ttl': 64,
                    'window_size': 29200,
                    'os_class': 'Linux 3.X|4.X'
                },
                'waf_detected': True,
                'cdn_detected': False,
                'response_time': 120,
                'bandwidth': 1000000
            }
            
            return CapabilityResult(
                capability_type=CapabilityType.NETWORK_RECONNAISSANCE,
                status="success",
                confidence=0.88,
                data=network_data,
                execution_time=5.2
            )
            
        except Exception as e:
            return CapabilityResult(
                capability_type=CapabilityType.NETWORK_RECONNAISSANCE,
                status="error",
                confidence=0.0,
                data={},
                error_message=str(e)
            )
    
    def execute_risk_assessment(self, **kwargs) -> CapabilityResult:
        """åŸ·è¡Œé¢¨éšªè©•ä¼°"""
        target_info = kwargs.get('target_info', kwargs.get('target', {}))
        
        try:
            # æ¨¡æ“¬é¢¨éšªè©•ä¼°çµæœ
            risk_data = {
                'cvss_v3': {
                    'attack_vector': 0.85,      # Network
                    'attack_complexity': 0.77,  # Low
                    'privileges_required': 0.62, # None
                    'user_interaction': 0.85,   # None
                    'confidentiality_impact': 0.56,  # High
                    'integrity_impact': 0.56,   # High
                    'availability_impact': 0.56  # High
                },
                'threat_intelligence': {
                    'actively_exploited': 0.8,
                    'exploit_available': 1.0,
                    'in_the_wild': 0.6,
                    'threat_actor_interest': 0.7
                },
                'asset_value': {
                    'business_criticality': 0.9,
                    'data_sensitivity': 0.85,
                    'regulatory_impact': 0.7,
                    'financial_impact': 0.8
                }
            }
            
            return CapabilityResult(
                capability_type=CapabilityType.RISK_ASSESSMENT,
                status="success",
                confidence=0.91,
                data=risk_data,
                execution_time=0.8
            )
            
        except Exception as e:
            return CapabilityResult(
                capability_type=CapabilityType.RISK_ASSESSMENT,
                status="error",
                confidence=0.0,
                data={},
                error_message=str(e)
            )
    
    def execute_comprehensive_analysis(self, target: str) -> Tuple[List[CapabilityResult], np.ndarray, Optional[Dict[str, Any]]]:
        """åŸ·è¡Œç¶œåˆåˆ†æ - æ•´åˆæ‰€æœ‰èƒ½åŠ›æ¨¡çµ„"""
        logger.info(f"ğŸ” é–‹å§‹å°ç›®æ¨™ {target} é€²è¡Œç¶œåˆåˆ†æ...")
        
        results = []
        
        # åŒæ­¥åŸ·è¡Œå¤šç¨®èƒ½åŠ›åˆ†æ
        try:
            result1 = self.execute_static_analysis(target=target)
            results.append(result1)
        except Exception as e:
            logger.error(f"éœæ…‹åˆ†æå¤±æ•—: {e}")
        
        try:
            result2 = self.execute_vulnerability_scanning(target=target)
            results.append(result2)
        except Exception as e:
            logger.error(f"æ¼æ´æƒæå¤±æ•—: {e}")
            
        try:
            result3 = self.execute_network_reconnaissance(target=target)
            results.append(result3)
        except Exception as e:
            logger.error(f"ç¶²è·¯åµå¯Ÿå¤±æ•—: {e}")
            
        try:
            result4 = self.execute_risk_assessment(target=target)
            results.append(result4)
        except Exception as e:
            logger.error(f"é¢¨éšªè©•ä¼°å¤±æ•—: {e}")
        
        # æå–ç‰¹å¾µå‘é‡
        feature_vector = self.feature_extractor.combine_features(results)
        logger.info("âœ… æå–512ç¶­ç‰¹å¾µå‘é‡å®Œæˆ")
        
        # ä½¿ç”¨5Mç¥ç¶“ç¶²è·¯é€²è¡Œæ±ºç­–
        ai_decision = None
        if self.ai_core:
            ai_decision = self.make_ai_decision(feature_vector)
        
        return results, feature_vector, ai_decision
    
    def make_ai_decision(self, feature_vector: np.ndarray) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨5Mç¥ç¶“ç¶²è·¯åšæ±ºç­– - ä¿®å¾©asyncå•é¡Œï¼Œæ·»åŠ Noneæª¢æŸ¥"""
        if not self.ai_core:
            logger.warning("AIæ ¸å¿ƒæœªåˆå§‹åŒ–ï¼Œç„¡æ³•é€²è¡Œæ±ºç­–")
            return None
            
        try:
            import torch
            
            # è½‰æ›ç‚ºPyTorchå¼µé‡
            input_tensor = torch.FloatTensor(feature_vector).unsqueeze(0)  # [1, 512]
            
            with torch.no_grad():
                # ç²å¾—ä¸»è¼¸å‡ºå’Œè¼”åŠ©è¼¸å‡º
                main_output, aux_output = self.ai_core.forward_with_aux(input_tensor)
                
                # æ±ºç­–åˆ†æ
                decision_class = torch.argmax(main_output, dim=1).item()
                confidence = torch.max(torch.softmax(main_output, dim=1)).item()
                
                # ç²å¾—å‰5å€‹æ¨è–¦å‹•ä½œ
                top5_actions = torch.topk(torch.softmax(main_output, dim=1), 5, dim=1)
                top5_classes = top5_actions.indices[0].tolist()
                top5_probs = top5_actions.values[0].tolist()
                
                # åˆ†æè¼”åŠ©ç‰¹å¾µ
                aux_features = aux_output[0].tolist()  # 531ç¶­ç‰¹å¾µ
                
                return {
                    'primary_decision': {
                        'class': decision_class,
                        'confidence': confidence,
                        'description': f'æ¨è–¦å‹•ä½œé¡åˆ¥ {decision_class}'
                    },
                    'alternative_actions': [
                        {
                            'class': cls,
                            'probability': prob,
                            'description': f'å‚™é¸å‹•ä½œ {cls}'
                        }
                        for cls, prob in zip(top5_classes, top5_probs)
                    ],
                    'auxiliary_analysis': {
                        'feature_count': len(aux_features),
                        'max_activation': max(aux_features),
                        'min_activation': min(aux_features),
                        'mean_activation': sum(aux_features) / len(aux_features),
                        'active_features': sum(1 for f in aux_features if abs(f) > 0.01)
                    },
                    'reasoning': f'åŸºæ–¼512ç¶­ç‰¹å¾µåˆ†æï¼Œ5Mç¥ç¶“ç¶²è·¯æ¨è–¦åŸ·è¡Œé¡åˆ¥{decision_class}çš„å‹•ä½œï¼Œä¿¡å¿ƒåº¦{confidence:.3f}'
                }
                
        except Exception as e:
            logger.error(f"AIæ±ºç­–å¤±æ•—: {e}")
            return {
                'error': str(e),
                'fallback_decision': 'manual_analysis_required'
            }

def main():
    """æ¼”ç¤ºAIVAèƒ½åŠ›ä¸²æ¥"""
    def run_demo():
        """AIVAæ¼”ç¤ºå‡½æ•¸ - ç§»é™¤ä¸å¿…è¦çš„async"""
        print("ğŸš€ AIVA æ ¸å¿ƒèƒ½åŠ›èˆ‡5Mç¥ç¶“ç¶²è·¯ä¸²æ¥æ¼”ç¤º")
        print("=" * 60)
        
        # åˆå§‹åŒ–ç·¨æ’å™¨
        orchestrator = AIVACapabilityOrchestrator()
        
        # ç›®æ¨™æ¸¬è©¦
        test_target = "https://testphp.vulnweb.com"
        
        # åŸ·è¡Œç¶œåˆåˆ†æ - ç§»é™¤awaitï¼Œå› ç‚ºå‡½æ•¸ä¸æ˜¯async
        results, features, decision = orchestrator.execute_comprehensive_analysis(test_target)
        
        print(f"\nğŸ“Š åˆ†æçµæœç¸½è¦½:")
        print(f"   - åŸ·è¡Œèƒ½åŠ›æ•¸é‡: {len(results)}")
        print(f"   - æˆåŠŸåŸ·è¡Œ: {sum(1 for r in results if r.status == 'success')}")
        print(f"   - ç‰¹å¾µå‘é‡ç¶­åº¦: {len(features)}")
        
        print(f"\nğŸ§  AIæ±ºç­–çµæœ:")
        if decision and 'primary_decision' in decision:
            primary = decision['primary_decision']
            print(f"   - ä¸»è¦æ±ºç­–: é¡åˆ¥ {primary['class']}")
            print(f"   - ä¿¡å¿ƒåº¦: {primary['confidence']:.3f}")
            print(f"   - æ¨ç†: {decision.get('reasoning', 'N/A')}")
            
            print(f"\nğŸ¯ å‚™é¸å‹•ä½œ:")
            for i, alt in enumerate(decision['alternative_actions'][:3]):
                print(f"   {i+1}. é¡åˆ¥ {alt['class']} (æ©Ÿç‡: {alt['probability']:.3f})")
        
        print(f"\nğŸ“ˆ è©³ç´°åˆ†æ:")
        for result in results:
            print(f"   - {result.capability_type.value}: {result.status} (ä¿¡å¿ƒåº¦: {result.confidence:.3f})")
        
        print(f"\nğŸ‰ AIVAæ ¸å¿ƒèƒ½åŠ›ä¸²æ¥æ¼”ç¤ºå®Œæˆ!")
    
    # é‹è¡Œæ¼”ç¤º
    run_demo()  # ç›´æ¥èª¿ç”¨ï¼Œä¸éœ€è¦asyncio.run

if __name__ == "__main__":
    main()