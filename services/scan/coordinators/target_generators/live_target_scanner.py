#!/usr/bin/env python3
"""
AIVA å¯¦éš›é¶å ´æƒæåŸ·è¡Œå™¨
=============================

æ”¯æ´å°å¯¦éš›é¶å ´é€²è¡Œå‹•æ…‹ç›®æ¨™æƒæï¼Œéµå¾ª aiva_common è¦ç¯„
ä¸å¯«æ­»ç›®æ¨™ï¼Œæ”¯æ´å¤šç¨®æƒææ¨¡å¼

ä½¿ç”¨ç¯„ä¾‹:
    python live_target_scanner.py --url http://example.com
    python live_target_scanner.py --urls http://site1.com,http://site2.com --strategy deep
    python live_target_scanner.py --url http://example.com --exclude "/admin,/private" --include-subdomains
"""

import argparse
import json
import os
import time
import sys
from typing import List, Optional
from urllib.parse import urlparse
from uuid import uuid4

import pika
from pydantic import ValidationError

# æ·»åŠ  aiva_common è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from services.aiva_common.schemas.testing.tasks import ScanStartPayload
from services.aiva_common.schemas.base import ScanScope, RateLimit, Authentication

# RabbitMQ é…ç½®
RABBITMQ_URL = os.environ.get('RABBITMQ_URL', 'amqp://aiva:aiva_mq_password@localhost:5672/aiva')
TASK_QUEUE = 'tasks.scan.live_targets'

class LiveTargetScanner:
    """å¯¦éš›é¶å ´æƒæå™¨"""
    
    def __init__(self):
        self.connection = None
        self.channel = None
    
    def connect_rabbitmq(self) -> bool:
        """å»ºç«‹ RabbitMQ é€£æ¥"""
        max_retries = 10
        retry_delay = 5
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”— å˜—è©¦é€£æ¥ RabbitMQ (å˜—è©¦ {attempt + 1}/{max_retries})...")
                parameters = pika.URLParameters(RABBITMQ_URL)
                self.connection = pika.BlockingConnection(parameters)
                self.channel = self.connection.channel()
                
                # è²æ˜éšŠåˆ—
                self.channel.queue_declare(
                    queue=TASK_QUEUE,
                    durable=True,
                    arguments={'x-message-ttl': 3600000}
                )
                
                print("âœ… RabbitMQ é€£æ¥æˆåŠŸ!")
                return True
                
            except Exception as e:
                print(f"âŒ é€£æ¥å¤±æ•—: {e}")
                if attempt < max_retries - 1:
                    print(f"â³ {retry_delay} ç§’å¾Œé‡è©¦...")
                    time.sleep(retry_delay)
                else:
                    print("âŒ ç„¡æ³•é€£æ¥åˆ° RabbitMQ")
                    return False
    
    def validate_targets(self, urls: List[str]) -> List[str]:
        """é©—è­‰å’Œæ¨™æº–åŒ–ç›®æ¨™ URL"""
        validated_urls = []
        
        for url in urls:
            if not url.startswith(('http://', 'https://')):
                url = f"https://{url}"
            
            try:
                parsed = urlparse(url)
                if not parsed.netloc:
                    print(f"âš ï¸ ç„¡æ•ˆçš„ URL: {url}")
                    continue
                validated_urls.append(url)
                
            except Exception as e:
                print(f"âš ï¸ URL è§£æéŒ¯èª¤ {url}: {e}")
                continue
        
        return validated_urls
    
    def create_scan_payload(self, 
                           urls: List[str],
                           strategy: str = "normal",
                           exclusions: List[str] = None,
                           include_subdomains: bool = True,
                           rate_limit_requests: int = 10,
                           rate_limit_delay: float = 1.0,
                           custom_headers: dict = None) -> ScanStartPayload:
        """å‰µå»ºç¬¦åˆ aiva_common è¦ç¯„çš„æƒæè² è¼‰"""
        
        # ç”Ÿæˆæƒæ ID
        scan_id = f"scan_{uuid4().hex[:8]}"
        
        # é…ç½®æƒæç¯„åœ
        scope = ScanScope(
            exclusions=exclusions or [],
            include_subdomains=include_subdomains,
            allowed_hosts=[urlparse(url).netloc for url in urls]
        )
        
        # é…ç½®é€Ÿç‡é™åˆ¶
        rate_limit = RateLimit(
            requests_per_second=rate_limit_requests,
            delay_between_requests=rate_limit_delay
        )
        
        # é…ç½®èº«ä»½é©—è­‰ï¼ˆå¦‚æœéœ€è¦ï¼‰
        authentication = Authentication()
        
        try:
            payload = ScanStartPayload(
                scan_id=scan_id,
                targets=urls,
                scope=scope,
                authentication=authentication,
                strategy=strategy,
                rate_limit=rate_limit,
                custom_headers=custom_headers or {}
            )
            return payload
            
        except ValidationError as e:
            print(f"âŒ è² è¼‰é©—è­‰å¤±æ•—: {e}")
            raise
    
    def send_scan_task(self, payload: ScanStartPayload) -> str:
        """ç™¼é€æƒæä»»å‹™åˆ°éšŠåˆ—"""
        
        if not self.channel:
            raise Exception("RabbitMQ é€£æ¥æœªå»ºç«‹")
        
        message = json.dumps(payload.model_dump(), ensure_ascii=False, indent=2)
        
        self.channel.basic_publish(
            exchange='',
            routing_key=TASK_QUEUE,
            body=message.encode('utf-8'),
            properties=pika.BasicProperties(
                delivery_mode=2,  # æŒä¹…åŒ–
                content_type='application/json',
                headers={
                    'task_type': 'live_scan',
                    'scan_id': payload.scan_id,
                    'target_count': len(payload.targets)
                }
            )
        )
        
        return payload.scan_id
    
    def scan_targets(self, 
                    urls: List[str],
                    strategy: str = "normal",
                    exclusions: List[str] = None,
                    include_subdomains: bool = True,
                    rate_limit_requests: int = 10,
                    rate_limit_delay: float = 1.0,
                    custom_headers: dict = None) -> str:
        """åŸ·è¡Œå°æŒ‡å®šç›®æ¨™çš„æƒæ"""
        
        print("=" * 80)
        print("ğŸ¯ AIVA å¯¦éš›é¶å ´æƒæå™¨")
        print("=" * 80)
        
        # é©—è­‰ç›®æ¨™
        validated_urls = self.validate_targets(urls)
        if not validated_urls:
            raise ValueError("âŒ æ²’æœ‰æœ‰æ•ˆçš„ç›®æ¨™ URL")
        
        print(f"\nğŸ“‹ æƒæé…ç½®:")
        print(f"   ç›®æ¨™æ•¸é‡: {len(validated_urls)}")
        print(f"   æƒæç­–ç•¥: {strategy}")
        print(f"   åŒ…å«å­åŸŸå: {include_subdomains}")
        print(f"   é€Ÿç‡é™åˆ¶: {rate_limit_requests} req/sï¼Œå»¶é² {rate_limit_delay}s")
        if exclusions:
            print(f"   æ’é™¤è·¯å¾‘: {', '.join(exclusions)}")
        
        # é¡¯ç¤ºç›®æ¨™
        print(f"\nğŸ¯ æƒæç›®æ¨™:")
        for i, url in enumerate(validated_urls, 1):
            print(f"   [{i}] {url}")
        
        # å»ºç«‹é€£æ¥
        if not self.connect_rabbitmq():
            raise Exception("âŒ ç„¡æ³•é€£æ¥åˆ° RabbitMQ")
        
        try:
            # å‰µå»ºæƒæè² è¼‰
            payload = self.create_scan_payload(
                urls=validated_urls,
                strategy=strategy,
                exclusions=exclusions,
                include_subdomains=include_subdomains,
                rate_limit_requests=rate_limit_requests,
                rate_limit_delay=rate_limit_delay,
                custom_headers=custom_headers
            )
            
            # ç™¼é€ä»»å‹™
            scan_id = self.send_scan_task(payload)
            
            print(f"\nâœ… æƒæä»»å‹™å·²ç™¼é€!")
            print(f"   æƒæ ID: {scan_id}")
            print(f"   éšŠåˆ—: {TASK_QUEUE}")
            print(f"   RabbitMQ ç®¡ç†ç•Œé¢: http://localhost:15672")
            
            return scan_id
            
        finally:
            if self.connection:
                self.connection.close()
    
    def close(self):
        """é—œé–‰é€£æ¥"""
        if self.connection:
            self.connection.close()


def parse_urls(url_string: str) -> List[str]:
    """è§£æ URL å­—ç¬¦ä¸²"""
    return [url.strip() for url in url_string.split(',') if url.strip()]


def parse_exclusions(exclusion_string: str) -> List[str]:
    """è§£ææ’é™¤è·¯å¾‘å­—ç¬¦ä¸²"""
    return [path.strip() for path in exclusion_string.split(',') if path.strip()]


def parse_headers(header_string: str) -> dict:
    """è§£æè‡ªå®šç¾©æ¨™é ­å­—ç¬¦ä¸²"""
    headers = {}
    if not header_string:
        return headers
    
    for header in header_string.split(','):
        if ':' in header:
            key, value = header.split(':', 1)
            headers[key.strip()] = value.strip()
    
    return headers


def main():
    parser = argparse.ArgumentParser(
        description="AIVA å¯¦éš›é¶å ´æƒæå™¨ - æ”¯æ´å‹•æ…‹ç›®æ¨™é…ç½®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
    # å–®å€‹ç›®æ¨™
    python %(prog)s --url https://example.com
    
    # å¤šå€‹ç›®æ¨™
    python %(prog)s --urls "https://site1.com,https://site2.com"
    
    # æ·±åº¦æƒæä¸¦æ’é™¤ç‰¹å®šè·¯å¾‘
    python %(prog)s --url https://example.com --strategy deep --exclude "/admin,/private"
    
    # ä¸åŒ…å«å­åŸŸåçš„å¿«é€Ÿæƒæ
    python %(prog)s --url https://example.com --strategy quick --no-subdomains
    
    # è‡ªå®šç¾©é€Ÿç‡é™åˆ¶å’Œæ¨™é ­
    python %(prog)s --url https://example.com --rate-limit 5 --delay 2.0 --headers "User-Agent:Custom Bot"

æƒæç­–ç•¥:
    quick  - å¿«é€Ÿæƒæï¼ŒåŸºæœ¬æª¢æŸ¥
    normal - æ¨™æº–æƒæï¼ˆé»˜èªï¼‰
    deep   - æ·±åº¦æƒæï¼Œè©³ç´°æª¢æŸ¥
    full   - å…¨é¢æƒæï¼ŒåŒ…å«æ‰€æœ‰æ¸¬è©¦
    custom - è‡ªå®šç¾©æƒæç­–ç•¥
        """
    )
    
    # URL åƒæ•¸ï¼ˆäº’æ–¥ï¼‰
    url_group = parser.add_mutually_exclusive_group(required=True)
    url_group.add_argument('--url', help='å–®å€‹ç›®æ¨™ URL')
    url_group.add_argument('--urls', help='å¤šå€‹ç›®æ¨™ URLï¼Œç”¨é€—è™Ÿåˆ†éš”')
    
    # æƒæç­–ç•¥
    parser.add_argument('--strategy', 
                      choices=['quick', 'normal', 'deep', 'full', 'custom'],
                      default='normal',
                      help='æƒæç­–ç•¥ (é»˜èª: normal)')
    
    # ç¯„åœé…ç½®
    parser.add_argument('--exclude', help='æ’é™¤çš„è·¯å¾‘ï¼Œç”¨é€—è™Ÿåˆ†éš” (ä¾‹: "/admin,/private")')
    parser.add_argument('--no-subdomains', action='store_true', help='ä¸åŒ…å«å­åŸŸå')
    
    # é€Ÿç‡é™åˆ¶
    parser.add_argument('--rate-limit', type=int, default=10, 
                      help='æ¯ç§’è«‹æ±‚æ•¸ (é»˜èª: 10)')
    parser.add_argument('--delay', type=float, default=1.0,
                      help='è«‹æ±‚é–“å»¶é²ç§’æ•¸ (é»˜èª: 1.0)')
    
    # è‡ªå®šç¾©é…ç½®
    parser.add_argument('--headers', help='è‡ªå®šç¾© HTTP æ¨™é ­ï¼Œæ ¼å¼: "Key1:Value1,Key2:Value2"')
    
    # è¼¸å‡ºé…ç½®
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°è¼¸å‡º')
    parser.add_argument('--dry-run', action='store_true', help='ä¹¾é‹è¡Œï¼Œä¸å¯¦éš›ç™¼é€ä»»å‹™')
    
    args = parser.parse_args()
    
    try:
        # è§£æç›®æ¨™ URL
        if args.url:
            urls = [args.url]
        else:
            urls = parse_urls(args.urls)
        
        if not urls:
            print("âŒ æ²’æœ‰æä¾›æœ‰æ•ˆçš„ç›®æ¨™ URL")
            return 1
        
        # è§£ææ’é™¤è·¯å¾‘
        exclusions = parse_exclusions(args.exclude) if args.exclude else None
        
        # è§£æè‡ªå®šç¾©æ¨™é ­
        custom_headers = parse_headers(args.headers) if args.headers else None
        
        # ä¹¾é‹è¡Œæ¨¡å¼
        if args.dry_run:
            print("ğŸ” ä¹¾é‹è¡Œæ¨¡å¼ - åƒ…é©—è­‰é…ç½®")
            scanner = LiveTargetScanner()
            payload = scanner.create_scan_payload(
                urls=urls,
                strategy=args.strategy,
                exclusions=exclusions,
                include_subdomains=not args.no_subdomains,
                rate_limit_requests=args.rate_limit,
                rate_limit_delay=args.delay,
                custom_headers=custom_headers
            )
            print(f"\nâœ… é…ç½®é©—è­‰æˆåŠŸ!")
            if args.verbose:
                print(f"\nğŸ“„ ç”Ÿæˆçš„è² è¼‰:")
                print(json.dumps(payload.model_dump(), indent=2, ensure_ascii=False))
            return 0
        
        # å¯¦éš›åŸ·è¡Œæƒæ
        scanner = LiveTargetScanner()
        scan_id = scanner.scan_targets(
            urls=urls,
            strategy=args.strategy,
            exclusions=exclusions,
            include_subdomains=not args.no_subdomains,
            rate_limit_requests=args.rate_limit,
            rate_limit_delay=args.delay,
            custom_headers=custom_headers
        )
        
        print(f"\nğŸ” ç›£æ§å»ºè­°:")
        print(f"   1. æŸ¥çœ‹ RabbitMQ éšŠåˆ—ç‹€æ…‹: http://localhost:15672")
        print(f"   2. ç›£æ§æƒæå¼•æ“æ—¥èªŒ:")
        print(f"      docker logs -f aiva-rust-fast-discovery")
        print(f"      docker logs -f aiva-python-scanner")
        print(f"      docker logs -f aiva-typescript-scanner")
        print(f"   3. æŸ¥è©¢æƒæçµæœ:")
        print(f"      python query_scan_results.py --scan-id {scan_id}")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ¶ä¸­æ–·")
        return 130
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())