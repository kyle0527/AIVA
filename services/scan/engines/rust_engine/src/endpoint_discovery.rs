// Endpoint Discovery Module - Phase0 æ ¸å¿ƒåŠŸèƒ½
// HackerOne å¯¦æˆ°: ç™¼ç¾ API ç«¯é»ã€ç®¡ç†ç•Œé¢ã€æ•æ„Ÿè·¯å¾‘

use regex::Regex;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashSet;
use std::time::Duration;
use tracing::{debug, info};

/// ç«¯é»ç™¼ç¾çµæœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DiscoveredEndpoint {
    pub path: String,
    pub method: String,
    pub status_code: u16,
    pub discovered_by: DiscoveryMethod,
    pub risk_level: RiskLevel,
    pub response_size: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum DiscoveryMethod {
    Dictionary,    // å­—å…¸çˆ†ç ´
    JsAnalysis,    // JS æ–‡ä»¶åˆ†æ
    Sitemap,       // Sitemap.xml
    Robots,        // Robots.txt
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Ord)]
#[serde(rename_all = "lowercase")]
pub enum RiskLevel {
    Critical,
    High,
    Medium,
    Low,
    Info,
}

/// ç«¯é»ç™¼ç¾å™¨
pub struct EndpointDiscoverer {
    client: Client,
    common_paths: Vec<&'static str>,
    js_endpoint_regex: Regex,
    timeout: Duration,
}

impl EndpointDiscoverer {
    pub fn new() -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(5))
            .danger_accept_invalid_certs(true)
            .build()
            .expect("Failed to build HTTP client");

        // å¸¸è¦‹è·¯å¾‘ - åŸºæ–¼ SecLists å’Œ HackerOne å¯¦æˆ°ç¶“é©—
        let common_paths = vec![
            // API ç«¯é»
            "/api",
            "/api/v1",
            "/api/v2",
            "/api/users",
            "/api/config",
            "/graphql",
            "/graphiql",
            
            // ç®¡ç†ç•Œé¢
            "/admin",
            "/admin/login",
            "/administrator",
            "/management",
            "/console",
            "/backend",
            
            // èªè­‰ç›¸é—œ
            "/auth",
            "/login",
            "/signin",
            "/logout",
            "/register",
            "/reset-password",
            
            // æ–‡æª”èˆ‡é…ç½®
            "/swagger.json",
            "/swagger-ui",
            "/openapi.json",
            "/api-docs",
            "/.well-known/security.txt",
            "/security.txt",
            
            // é–‹ç™¼ç›¸é—œ
            "/debug",
            "/test",
            "/dev",
            "/_debug",
            
            // æ–‡ä»¶æ“ä½œ
            "/upload",
            "/download",
            "/files",
            
            // æ•æ„Ÿç›®éŒ„ (ä½å„ªå…ˆç´šï¼Œä½†ä¿ç•™æ¥å£)
            "/.env",
            "/.git/config",
            "/config.json",
            "/package.json",
            
            // å…¶ä»–
            "/sitemap.xml",
            "/robots.txt",
            "/crossdomain.xml",
        ];

        // JS ä¸­çš„ API ç«¯é»æå–
        let js_endpoint_regex = Regex::new(
            r#"['"`](/(?:api|admin|auth|upload|download|graphql)[^'"`\s]*?)['"`]"#
        ).expect("Invalid regex");

        Self {
            client,
            common_paths,
            js_endpoint_regex,
            timeout: Duration::from_secs(10),
        }
    }

    /// ç™¼ç¾ç«¯é» (ä¸»å…¥å£)
    pub async fn discover(&self, base_url: &str) -> Vec<DiscoveredEndpoint> {
        info!("ğŸ” é–‹å§‹ç«¯é»ç™¼ç¾: {}", base_url);
        
        let mut all_endpoints = Vec::new();
        let mut seen_paths = HashSet::new();

        // æ–¹æ³• 1: å­—å…¸æƒæ
        let dict_endpoints = self.scan_common_paths(base_url).await;
        for endpoint in dict_endpoints {
            if seen_paths.insert(endpoint.path.clone()) {
                all_endpoints.push(endpoint);
            }
        }

        // æ–¹æ³• 2: Robots.txt åˆ†æ
        if let Some(robots_endpoints) = self.analyze_robots(base_url).await {
            for endpoint in robots_endpoints {
                if seen_paths.insert(endpoint.path.clone()) {
                    all_endpoints.push(endpoint);
                }
            }
        }

        // æ–¹æ³• 3: Sitemap.xml åˆ†æ
        if let Some(sitemap_endpoints) = self.analyze_sitemap(base_url).await {
            for endpoint in sitemap_endpoints {
                if seen_paths.insert(endpoint.path.clone()) {
                    all_endpoints.push(endpoint);
                }
            }
        }

        info!("âœ… ç«¯é»ç™¼ç¾å®Œæˆ: å…± {} å€‹", all_endpoints.len());
        all_endpoints
    }

    /// å­—å…¸æƒæå¸¸è¦‹è·¯å¾‘
    async fn scan_common_paths(&self, base_url: &str) -> Vec<DiscoveredEndpoint> {
        debug!("ğŸ“– å­—å…¸æƒæé–‹å§‹ ({} å€‹è·¯å¾‘)", self.common_paths.len());
        
        let mut endpoints = Vec::new();
        
        for path in &self.common_paths {
            let url = format!("{}{}", base_url.trim_end_matches('/'), path);
            
            match self.client.get(&url).send().await {
                Ok(response) => {
                    let status = response.status().as_u16();
                    let size = response.content_length().unwrap_or(0) as usize;
                    
                    // åªè¨˜éŒ„æœ‰æ•ˆéŸ¿æ‡‰ (æ’é™¤ 404)
                    if status != 404 {
                        let risk = Self::calculate_path_risk(path);
                        
                        debug!("  âœ… {} [{}] ({} bytes)", path, status, size);
                        
                        endpoints.push(DiscoveredEndpoint {
                            path: path.to_string(),
                            method: "GET".to_string(),
                            status_code: status,
                            discovered_by: DiscoveryMethod::Dictionary,
                            risk_level: risk,
                            response_size: size,
                        });
                    }
                }
                Err(e) => {
                    debug!("  âŒ {} - Error: {:?}", path, e);
                }
            }
        }
        
        debug!("ğŸ“– å­—å…¸æƒæå®Œæˆ: {} å€‹æœ‰æ•ˆç«¯é»", endpoints.len());
        endpoints
    }

    /// åˆ†æ robots.txt
    async fn analyze_robots(&self, base_url: &str) -> Option<Vec<DiscoveredEndpoint>> {
        let robots_url = format!("{}/robots.txt", base_url.trim_end_matches('/'));
        
        match self.client.get(&robots_url).send().await {
            Ok(response) if response.status().is_success() => {
                let text = response.text().await.ok()?;
                let mut endpoints = Vec::new();
                
                for line in text.lines() {
                    if let Some(path) = Self::extract_robots_path(line) {
                        // é©—è­‰è·¯å¾‘æ˜¯å¦å­˜åœ¨
                        let url = format!("{}{}", base_url.trim_end_matches('/'), path);
                        if let Ok(resp) = self.client.head(&url).send().await {
                            if resp.status().as_u16() != 404 {
                                endpoints.push(DiscoveredEndpoint {
                                    path: path.to_string(),
                                    method: "GET".to_string(),
                                    status_code: resp.status().as_u16(),
                                    discovered_by: DiscoveryMethod::Robots,
                                    risk_level: Self::calculate_path_risk(&path),
                                    response_size: 0,
                                });
                            }
                        }
                    }
                }
                
                if !endpoints.is_empty() {
                    info!("ğŸ¤– Robots.txt: ç™¼ç¾ {} å€‹è·¯å¾‘", endpoints.len());
                    Some(endpoints)
                } else {
                    None
                }
            }
            _ => None,
        }
    }

    /// åˆ†æ sitemap.xml
    async fn analyze_sitemap(&self, base_url: &str) -> Option<Vec<DiscoveredEndpoint>> {
        let sitemap_url = format!("{}/sitemap.xml", base_url.trim_end_matches('/'));
        
        match self.client.get(&sitemap_url).send().await {
            Ok(response) if response.status().is_success() => {
                let text = response.text().await.ok()?;
                let urls = Self::extract_sitemap_urls(&text);
                
                if !urls.is_empty() {
                    info!("ğŸ—ºï¸  Sitemap.xml: ç™¼ç¾ {} å€‹ URL", urls.len());
                    
                    // è½‰æ›ç‚ºç«¯é» (åªå–è·¯å¾‘)
                    let endpoints = urls.iter()
                        .filter_map(|url| {
                            url.strip_prefix(base_url).map(|path| {
                                DiscoveredEndpoint {
                                    path: path.to_string(),
                                    method: "GET".to_string(),
                                    status_code: 200,
                                    discovered_by: DiscoveryMethod::Sitemap,
                                    risk_level: Self::calculate_path_risk(path),
                                    response_size: 0,
                                }
                            })
                        })
                        .collect();
                    
                    Some(endpoints)
                } else {
                    None
                }
            }
            _ => None,
        }
    }

    /// å¾ JS æ–‡ä»¶æå–ç«¯é» (ä¾› JsAnalyzer èª¿ç”¨)
    pub fn extract_endpoints_from_js(&self, js_content: &str) -> Vec<String> {
        let mut endpoints = HashSet::new();
        
        for cap in self.js_endpoint_regex.captures_iter(js_content) {
            if let Some(path) = cap.get(1) {
                endpoints.insert(path.as_str().to_string());
            }
        }
        
        endpoints.into_iter().collect()
    }

    /// è¨ˆç®—è·¯å¾‘é¢¨éšªç­‰ç´š
    fn calculate_path_risk(path: &str) -> RiskLevel {
        let path_lower = path.to_lowercase();
        
        // é—œéµå­—åŒ¹é…
        if path_lower.contains("/admin") || path_lower.contains("/management") {
            return RiskLevel::Critical;
        }
        
        if path_lower.contains("/upload") || path_lower.contains("/download") {
            return RiskLevel::High;
        }
        
        if path_lower.contains("/api") || path_lower.contains("/auth") {
            return RiskLevel::High;
        }
        
        if path_lower.contains("/graphql") || path_lower.contains("/swagger") {
            return RiskLevel::Medium;
        }
        
        if path_lower.contains("/debug") || path_lower.contains("/test") {
            return RiskLevel::Medium;
        }
        
        if path_lower.ends_with(".json") || path_lower.ends_with(".xml") {
            return RiskLevel::Low;
        }
        
        RiskLevel::Info
    }

    /// å¾ robots.txt è¡Œæå–è·¯å¾‘
    fn extract_robots_path(line: &str) -> Option<String> {
        let line = line.trim();
        
        if line.starts_with("Disallow:") {
            line.strip_prefix("Disallow:")
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty() && s.starts_with('/'))
        } else if line.starts_with("Allow:") {
            line.strip_prefix("Allow:")
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty() && s.starts_with('/'))
        } else {
            None
        }
    }

    /// å¾ sitemap.xml æå– URL
    fn extract_sitemap_urls(xml: &str) -> Vec<String> {
        let url_regex = Regex::new(r"<loc>(.*?)</loc>").unwrap();
        
        url_regex.captures_iter(xml)
            .filter_map(|cap| cap.get(1))
            .map(|m| m.as_str().to_string())
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_calculate_path_risk() {
        assert_eq!(
            EndpointDiscoverer::calculate_path_risk("/admin"),
            RiskLevel::Critical
        );
        assert_eq!(
            EndpointDiscoverer::calculate_path_risk("/api/users"),
            RiskLevel::High
        );
        assert_eq!(
            EndpointDiscoverer::calculate_path_risk("/config.json"),
            RiskLevel::Low
        );
    }

    #[test]
    fn test_extract_robots_path() {
        assert_eq!(
            EndpointDiscoverer::extract_robots_path("Disallow: /admin"),
            Some("/admin".to_string())
        );
        assert_eq!(
            EndpointDiscoverer::extract_robots_path("Allow: /api"),
            Some("/api".to_string())
        );
        assert_eq!(
            EndpointDiscoverer::extract_robots_path("# Comment"),
            None
        );
    }

    #[test]
    fn test_js_endpoint_extraction() {
        let discoverer = EndpointDiscoverer::new();
        let js_code = r#"
            fetch('/api/users')
            axios.get("/admin/config")
            $.ajax({url: '/graphql'})
        "#;
        
        let endpoints = discoverer.extract_endpoints_from_js(js_code);
        assert!(endpoints.contains(&"/api/users".to_string()));
        assert!(endpoints.contains(&"/admin/config".to_string()));
        assert!(endpoints.contains(&"/graphql".to_string()));
    }
}
