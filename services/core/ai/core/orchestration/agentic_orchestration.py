"""
AIVA Agentic Orchestration v2.0
æ™ºèƒ½ä»£ç†ç·¨æ’ç³»çµ± - 2025å¹´AIæ¶æ§‹æ–°è¶¨å‹¢

å¯¦ç¾æ™ºèƒ½ä»£ç†ç·¨æ’ã€ä»»å‹™åˆ†é…ã€å‹•æ…‹èª¿åº¦ç­‰æ ¸å¿ƒåŠŸèƒ½ï¼Œ
åŸºæ–¼äº‹ä»¶é©…å‹•æ¶æ§‹æä¾›è‡ªå‹•åŒ–çš„å¤šæ¨¡çµ„å”èª¿èƒ½åŠ›ã€‚

Author: AIVA Team  
Created: 2025-11-09
Version: 2.0.0
"""

import asyncio
import time
import json
import logging
import uuid
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import heapq
from collections import defaultdict, deque

# å°å…¥äº‹ä»¶ç³»çµ±
from ..event_system.event_bus import AIEvent, AIEventBus, EventPriority
from ..controller.strangler_fig_controller import AIRequest, AIResponse, MessageType
from ..mcp_protocol.mcp_protocol import MCPMessage, MCPManager, AIVAMCPAdapter

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šç¾©
UTC_TIMEZONE_OFFSET = '+00:00'

# ==================== ä»£ç†ç·¨æ’æ ¸å¿ƒå®šç¾© ====================

class TaskPriority(Enum):
    """ä»»å‹™å„ªå…ˆç´š"""
    CRITICAL = 1
    HIGH = 2
    NORMAL = 3
    LOW = 4
    BACKGROUND = 5

class TaskStatus(Enum):
    """ä»»å‹™ç‹€æ…‹"""
    PENDING = "pending"
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    RETRYING = "retrying"

class AgentType(Enum):
    """ä»£ç†é¡å‹"""
    PERCEPTION = "perception"
    COGNITION = "cognition"
    KNOWLEDGE = "knowledge"
    DECISION = "decision"
    EXECUTION = "execution"
    COORDINATOR = "coordinator"

@dataclass
class OrchestrationTask:
    """ç·¨æ’ä»»å‹™å®šç¾©"""
    
    # åŸºç¤è³‡è¨Š
    task_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = ""
    description: str = ""
    
    # ä»»å‹™é…ç½®
    target_agent: str = ""
    operation: str = ""
    payload: Dict[str, Any] = field(default_factory=dict)
    
    # å„ªå…ˆç´šå’Œèª¿åº¦
    priority: TaskPriority = TaskPriority.NORMAL
    estimated_duration: float = 1.0  # ç§’
    max_retries: int = 3
    timeout: float = 30.0  # ç§’
    
    # ä¾è³´é—œä¿‚
    dependencies: List[str] = field(default_factory=list)  # ä¾è³´çš„ä»»å‹™ID
    prerequisites: Dict[str, Any] = field(default_factory=dict)  # å‰ç½®æ¢ä»¶
    
    # ç‹€æ…‹ç®¡ç†
    status: TaskStatus = TaskStatus.PENDING
    created_at: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    
    # åŸ·è¡Œçµæœ
    result: Optional[Dict[str, Any]] = None
    error: Optional[Dict[str, Any]] = None
    retry_count: int = 0
    
    # å…ƒæ•¸æ“š
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'task_id': self.task_id,
            'name': self.name,
            'description': self.description,
            'target_agent': self.target_agent,
            'operation': self.operation,
            'payload': self.payload,
            'priority': self.priority.name,
            'estimated_duration': self.estimated_duration,
            'max_retries': self.max_retries,
            'timeout': self.timeout,
            'dependencies': self.dependencies,
            'prerequisites': self.prerequisites,
            'status': self.status.value,
            'created_at': self.created_at,
            'started_at': self.started_at,
            'completed_at': self.completed_at,
            'result': self.result,
            'error': self.error,
            'retry_count': self.retry_count,
            'metadata': self.metadata
        }

@dataclass
class WorkflowDefinition:
    """å·¥ä½œæµç¨‹å®šç¾©"""
    
    workflow_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = ""
    description: str = ""
    
    # ä»»å‹™åˆ—è¡¨
    tasks: List[OrchestrationTask] = field(default_factory=list)
    
    # å·¥ä½œæµç¨‹é…ç½®
    max_parallel_tasks: int = 3
    total_timeout: float = 300.0  # 5åˆ†é˜
    failure_policy: str = "stop_on_failure"  # stop_on_failure, continue_on_failure
    
    # ç‹€æ…‹
    status: str = "created"
    created_at: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    
    # çµæœçµ±è¨ˆ
    total_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    
    def add_task(self, task: OrchestrationTask) -> None:
        """æ·»åŠ ä»»å‹™"""
        self.tasks.append(task)
        self.total_tasks = len(self.tasks)

# ==================== ä»»å‹™èª¿åº¦å™¨ ====================

class TaskScheduler:
    """ä»»å‹™èª¿åº¦å™¨"""
    
    def __init__(self):
        # ä»»å‹™éšŠåˆ—ï¼ˆå„ªå…ˆç´šéšŠåˆ—ï¼‰
        self.task_queue = []  # heap
        self.running_tasks = {}  # task_id -> task
        self.completed_tasks = {}  # task_id -> task
        
        # ä»£ç†ç‹€æ…‹ç®¡ç†
        self.agent_availability = {}  # agent_name -> is_available
        self.agent_load = defaultdict(int)  # agent_name -> current_load
        
        # ä¾è³´é—œä¿‚åœ–
        self.dependency_graph = defaultdict(set)  # task_id -> {dependent_task_ids}
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total_tasks_scheduled': 0,
            'total_tasks_completed': 0,
            'total_tasks_failed': 0,
            'avg_execution_time': 0.0,
            'avg_queue_time': 0.0
        }
    
    def schedule_task(self, task: OrchestrationTask) -> bool:
        """èª¿åº¦ä»»å‹™"""
        try:
            # æª¢æŸ¥å‰ç½®æ¢ä»¶
            if not self._check_prerequisites(task):
                task.status = TaskStatus.PENDING
                logger.warning(f"ä»»å‹™ {task.task_id} å‰ç½®æ¢ä»¶ä¸æ»¿è¶³ï¼Œæš«ä¸èª¿åº¦")
                return False
            
            # æª¢æŸ¥ä¾è³´é—œä¿‚
            if not self._check_dependencies(task):
                task.status = TaskStatus.PENDING
                logger.warning(f"ä»»å‹™ {task.task_id} ä¾è³´æœªå®Œæˆï¼Œæš«ä¸èª¿åº¦")
                return False
            
            # å°‡ä»»å‹™åŠ å…¥å„ªå…ˆç´šéšŠåˆ—
            priority_value = task.priority.value
            heap_item = (priority_value, time.time(), task.task_id, task)
            heapq.heappush(self.task_queue, heap_item)
            
            task.status = TaskStatus.QUEUED
            self.stats['total_tasks_scheduled'] += 1
            
            logger.info(f"ä»»å‹™å·²èª¿åº¦: {task.name} ({task.task_id})")
            return True
            
        except Exception as e:
            logger.error(f"èª¿åº¦ä»»å‹™å¤±æ•—: {str(e)}")
            return False
    
    def get_next_task(self) -> Optional[OrchestrationTask]:
        """ç²å–ä¸‹ä¸€å€‹å¾…åŸ·è¡Œçš„ä»»å‹™"""
        while self.task_queue:
            priority, queue_time, task_id, task = heapq.heappop(self.task_queue)
            
            # æª¢æŸ¥ä»»å‹™æ˜¯å¦ä»æœ‰æ•ˆ
            if task.status != TaskStatus.QUEUED:
                continue
            
            # æª¢æŸ¥ä»£ç†å¯ç”¨æ€§
            if not self._is_agent_available(task.target_agent):
                # é‡æ–°æ”¾å›éšŠåˆ—
                heapq.heappush(self.task_queue, (priority, queue_time, task_id, task))
                return None
            
            # æ›´æ–°çµ±è¨ˆ
            queue_time = (time.time() - queue_time) * 1000
            self._update_queue_time_stats(queue_time)
            
            return task
        
        return None
    
    def mark_task_running(self, task: OrchestrationTask) -> None:
        """æ¨™è¨˜ä»»å‹™ç‚ºé‹è¡Œä¸­"""
        task.status = TaskStatus.RUNNING
        task.started_at = datetime.now(timezone.utc).isoformat()
        self.running_tasks[task.task_id] = task
        
        # æ›´æ–°ä»£ç†è² è¼‰
        self.agent_load[task.target_agent] += 1
        self._update_agent_availability(task.target_agent)
    
    def mark_task_completed(self, task: OrchestrationTask, result: Dict[str, Any]) -> None:
        """æ¨™è¨˜ä»»å‹™å®Œæˆ"""
        task.status = TaskStatus.COMPLETED
        task.completed_at = datetime.now(timezone.utc).isoformat()
        task.result = result
        
        # å¾é‹è¡Œä¸­ç§»é™¤
        if task.task_id in self.running_tasks:
            del self.running_tasks[task.task_id]
        
        # åŠ å…¥å®Œæˆåˆ—è¡¨
        self.completed_tasks[task.task_id] = task
        
        # æ›´æ–°ä»£ç†è² è¼‰
        self.agent_load[task.target_agent] = max(0, self.agent_load[task.target_agent] - 1)
        self._update_agent_availability(task.target_agent)
        
        # æ›´æ–°çµ±è¨ˆ
        self.stats['total_tasks_completed'] += 1
        execution_time = self._calculate_execution_time(task)
        self._update_execution_time_stats(execution_time)
        
        # æª¢æŸ¥ä¾è³´æ–¼æ­¤ä»»å‹™çš„å…¶ä»–ä»»å‹™
        self._check_dependent_tasks(task.task_id)
        
        logger.info(f"ä»»å‹™å®Œæˆ: {task.name} ({task.task_id})")
    
    def mark_task_failed(self, task: OrchestrationTask, error: Dict[str, Any]) -> None:
        """æ¨™è¨˜ä»»å‹™å¤±æ•—"""
        task.error = error
        task.retry_count += 1
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡è©¦
        if task.retry_count <= task.max_retries:
            task.status = TaskStatus.RETRYING
            # é‡æ–°èª¿åº¦ï¼ˆå»¶é²ä¸€æ®µæ™‚é–“ï¼‰
            retry_task = asyncio.create_task(self._schedule_retry(task))
            # ä¿å­˜ä»»å‹™å¼•ç”¨é¿å…åƒåœ¾å›æ”¶
            self._retry_tasks = getattr(self, '_retry_tasks', [])
            self._retry_tasks.append(retry_task)
            logger.warning(f"ä»»å‹™å¤±æ•—ï¼Œå°‡é‡è©¦: {task.name} (ç¬¬{task.retry_count}æ¬¡é‡è©¦)")
        else:
            task.status = TaskStatus.FAILED
            task.completed_at = datetime.now(timezone.utc).isoformat()
            
            # å¾é‹è¡Œä¸­ç§»é™¤
            if task.task_id in self.running_tasks:
                del self.running_tasks[task.task_id]
            
            # æ›´æ–°ä»£ç†è² è¼‰
            self.agent_load[task.target_agent] = max(0, self.agent_load[task.target_agent] - 1)
            self._update_agent_availability(task.target_agent)
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['total_tasks_failed'] += 1
            
            logger.error(f"ä»»å‹™æœ€çµ‚å¤±æ•—: {task.name} ({task.task_id})")
    
    def _check_prerequisites(self, task: OrchestrationTask) -> bool:
        """æª¢æŸ¥å‰ç½®æ¢ä»¶"""
        if not task.prerequisites:
            return True
        
        # æª¢æŸ¥å…·é«”çš„å‰ç½®æ¢ä»¶
        for prerequisite in task.prerequisites:
            if not self._is_prerequisite_satisfied(prerequisite):
                return False
        return True
    
    def _is_prerequisite_satisfied(self, prerequisite: str) -> bool:
        """æª¢æŸ¥å–®å€‹å‰ç½®æ¢ä»¶æ˜¯å¦æ»¿è¶³"""
        # æ ¹æ“šå‰ç½®æ¢ä»¶é¡å‹é€²è¡Œæª¢æŸ¥
        if prerequisite.startswith('service:'):
            return self._check_service_availability(prerequisite[8:])
        elif prerequisite.startswith('resource:'):
            return self._check_resource_availability(prerequisite[9:])
        else:
            # ç°¡åŒ–å¯¦ç¾ï¼Œå…¶ä»–é¡å‹é»˜èªæ»¿è¶³
            return True
    
    def _check_service_availability(self, service_name: str) -> bool:
        """æª¢æŸ¥æœå‹™å¯ç”¨æ€§"""
        # æª¢æŸ¥æœå‹™ç‹€æ…‹ï¼Œé€™è£¡ç°¡åŒ–å¯¦ç¾
        return len(service_name) > 0  # åŸºæœ¬æœ‰æ•ˆæ€§æª¢æŸ¥
    
    def _check_resource_availability(self, resource_name: str) -> bool:
        """æª¢æŸ¥è³‡æºå¯ç”¨æ€§"""
        # æª¢æŸ¥è³‡æºç‹€æ…‹ï¼Œé€™è£¡ç°¡åŒ–å¯¦ç¾  
        return len(resource_name) > 0  # åŸºæœ¬æœ‰æ•ˆæ€§æª¢æŸ¥
    
    def _check_dependencies(self, task: OrchestrationTask) -> bool:
        """æª¢æŸ¥ä¾è³´é—œä¿‚"""
        for dep_task_id in task.dependencies:
            dep_task = self.completed_tasks.get(dep_task_id)
            if not dep_task or dep_task.status != TaskStatus.COMPLETED:
                return False
        
        return True
    
    def _is_agent_available(self, agent_name: str) -> bool:
        """æª¢æŸ¥ä»£ç†æ˜¯å¦å¯ç”¨"""
        # ç°¡åŒ–å¯¦ç¾ï¼šæª¢æŸ¥è² è¼‰æ˜¯å¦éé«˜
        max_load = 2  # æ¯å€‹ä»£ç†æœ€å¤šåŒæ™‚è™•ç†2å€‹ä»»å‹™
        current_load = self.agent_load.get(agent_name, 0)
        return current_load < max_load
    
    def _update_agent_availability(self, agent_name: str) -> None:
        """æ›´æ–°ä»£ç†å¯ç”¨æ€§"""
        is_available = self._is_agent_available(agent_name)
        self.agent_availability[agent_name] = is_available
    
    def _check_dependent_tasks(self, completed_task_id: str) -> None:
        """æª¢æŸ¥ä¾è³´æ–¼å·²å®Œæˆä»»å‹™çš„å…¶ä»–ä»»å‹™"""
        # å¯¦ç¾ä¾è³´æª¢æŸ¥é‚è¼¯ - é€™è£¡æ˜¯ TaskScheduler çš„æ–¹æ³•
        # éæ­·æ‰€æœ‰å¾…è™•ç†çš„ä»»å‹™ï¼Œæª¢æŸ¥æ˜¯å¦ä¾è³´æ­¤å®Œæˆçš„ä»»å‹™
        tasks_to_update = []
        for task in self.task_queue:
            if completed_task_id in task.dependencies:
                tasks_to_update.append(task)
        
        for task in tasks_to_update:
            task.dependencies.remove(completed_task_id)
            if not task.dependencies and task.status == TaskStatus.PENDING:
                # ä¾è³´å·²æ»¿è¶³ï¼Œå¯ä»¥é–‹å§‹åŸ·è¡Œ
                task.status = TaskStatus.QUEUED
    
    def _calculate_execution_time(self, task: OrchestrationTask) -> float:
        """è¨ˆç®—ä»»å‹™åŸ·è¡Œæ™‚é–“"""
        if not task.started_at or not task.completed_at:
            return 0.0
        
        start_time = datetime.fromisoformat(task.started_at.replace('Z', UTC_TIMEZONE_OFFSET))
        end_time = datetime.fromisoformat(task.completed_at.replace('Z', UTC_TIMEZONE_OFFSET))
        
        return (end_time - start_time).total_seconds()
    
    def _update_execution_time_stats(self, execution_time: float) -> None:
        """æ›´æ–°åŸ·è¡Œæ™‚é–“çµ±è¨ˆ"""
        if self.stats['avg_execution_time'] == 0:
            self.stats['avg_execution_time'] = execution_time
        else:
            # æŒ‡æ•¸ç§»å‹•å¹³å‡
            alpha = 0.1
            self.stats['avg_execution_time'] = (
                alpha * execution_time + 
                (1 - alpha) * self.stats['avg_execution_time']
            )
    
    def _update_queue_time_stats(self, queue_time: float) -> None:
        """æ›´æ–°éšŠåˆ—æ™‚é–“çµ±è¨ˆ"""
        if self.stats['avg_queue_time'] == 0:
            self.stats['avg_queue_time'] = queue_time
        else:
            alpha = 0.1
            self.stats['avg_queue_time'] = (
                alpha * queue_time + 
                (1 - alpha) * self.stats['avg_queue_time']
            )
    
    async def _schedule_retry(self, task: OrchestrationTask) -> None:
        """èª¿åº¦é‡è©¦ä»»å‹™"""
        # æŒ‡æ•¸é€€é¿å»¶é²
        delay = min(2 ** task.retry_count, 30)  # æœ€å¤š30ç§’
        await asyncio.sleep(delay)
        
        task.status = TaskStatus.PENDING
        self.schedule_task(task)
    
    def get_status(self) -> Dict[str, Any]:
        """ç²å–èª¿åº¦å™¨ç‹€æ…‹"""
        return {
            'queue_size': len(self.task_queue),
            'running_tasks': len(self.running_tasks),
            'completed_tasks': len(self.completed_tasks),
            'agent_availability': dict(self.agent_availability),
            'agent_load': dict(self.agent_load),
            'statistics': self.stats
        }

# ==================== ä»£ç†ç·¨æ’å™¨ ====================

class AgenticOrchestrator:
    """æ™ºèƒ½ä»£ç†ç·¨æ’å™¨"""
    
    def __init__(self, event_bus: Optional[AIEventBus] = None, 
                 mcp_manager: Optional[MCPManager] = None):
        self.event_bus = event_bus
        self.mcp_manager = mcp_manager
        
        # æ ¸å¿ƒçµ„ä»¶
        self.scheduler = TaskScheduler()
        
        # ä»£ç†è¨»å†Šè¡¨
        self.registered_agents = {}
        
        # å·¥ä½œæµç¨‹ç®¡ç†
        self.active_workflows = {}
        self.workflow_history = {}
        
        # åŸ·è¡Œå™¨
        self.executor_pool = {}  # agent_name -> executor_count
        self.max_concurrent_tasks = 10
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'workflows_created': 0,
            'workflows_completed': 0,
            'workflows_failed': 0,
            'total_tasks_orchestrated': 0,
            'avg_workflow_duration': 0.0
        }
        
        # é‹è¡Œç‹€æ…‹
        self.is_running = False
        self.orchestration_task = None
        
        logger.info("æ™ºèƒ½ä»£ç†ç·¨æ’å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def register_agent(self, agent_name: str, agent_type: AgentType, 
                      capabilities: List[str], max_concurrent: int = 2) -> bool:
        """è¨»å†Šä»£ç†"""
        try:
            self.registered_agents[agent_name] = {
                'type': agent_type.value,
                'capabilities': capabilities,
                'max_concurrent': max_concurrent,
                'registered_at': datetime.now(timezone.utc).isoformat(),
                'status': 'active'
            }
            
            self.executor_pool[agent_name] = max_concurrent
            
            logger.info(f"è¨»å†Šä»£ç†: {agent_name} ({agent_type.value})")
            return True
            
        except Exception as e:
            logger.error(f"è¨»å†Šä»£ç†å¤±æ•—: {str(e)}")
            return False
    
    def create_workflow(self, workflow_def: WorkflowDefinition) -> str:
        """å‰µå»ºå·¥ä½œæµç¨‹"""
        try:
            # é©—è­‰å·¥ä½œæµç¨‹
            if not self._validate_workflow(workflow_def):
                raise ValueError("å·¥ä½œæµç¨‹é©—è­‰å¤±æ•—")
            
            # æ·»åŠ åˆ°æ´»èºå·¥ä½œæµç¨‹
            self.active_workflows[workflow_def.workflow_id] = workflow_def
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats['workflows_created'] += 1
            self.stats['total_tasks_orchestrated'] += len(workflow_def.tasks)
            
            logger.info(f"å‰µå»ºå·¥ä½œæµç¨‹: {workflow_def.name} ({workflow_def.workflow_id})")
            return workflow_def.workflow_id
            
        except Exception as e:
            logger.error(f"å‰µå»ºå·¥ä½œæµç¨‹å¤±æ•—: {str(e)}")
            raise
    
    async def execute_workflow(self, workflow_id: str) -> Dict[str, Any]:
        """åŸ·è¡Œå·¥ä½œæµç¨‹"""
        workflow = self._get_workflow(workflow_id)
        
        logger.info(f"é–‹å§‹åŸ·è¡Œå·¥ä½œæµç¨‹: {workflow.name}")
        
        workflow.status = "running"
        workflow.started_at = datetime.now(timezone.utc).isoformat()
        
        try:
            await self._start_workflow_execution(workflow_id, workflow)
            completed_tasks, failed_tasks = await self._execute_all_tasks(workflow)
            result = self._finalize_workflow(workflow_id, workflow, completed_tasks, failed_tasks)
            
            logger.info(f"å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆ: {workflow.name} - {workflow.status}")
            return result
            
        except Exception as e:
            return self._handle_workflow_error(workflow_id, workflow, e)
    
    def _get_workflow(self, workflow_id: str):
        """ç²å–å·¥ä½œæµç¨‹"""
        workflow = self.active_workflows.get(workflow_id)
        if not workflow:
            raise ValueError(f"å·¥ä½œæµç¨‹ä¸å­˜åœ¨: {workflow_id}")
        return workflow
    
    async def _start_workflow_execution(self, workflow_id: str, workflow) -> None:
        """é–‹å§‹å·¥ä½œæµç¨‹åŸ·è¡Œ"""
        # ç™¼å¸ƒå·¥ä½œæµç¨‹é–‹å§‹äº‹ä»¶
        if self.event_bus:
            await self._publish_orchestration_event('workflow.started', {
                'workflow_id': workflow_id,
                'workflow_name': workflow.name,
                'total_tasks': workflow.total_tasks
            })
        
        # èª¿åº¦æ‰€æœ‰ä»»å‹™
        for task in workflow.tasks:
            self.scheduler.schedule_task(task)
    
    async def _execute_all_tasks(self, workflow) -> tuple:
        """åŸ·è¡Œæ‰€æœ‰ä»»å‹™ä¸¦ç­‰å¾…å®Œæˆ"""
        completed_tasks = []
        failed_tasks = []
        start_time = time.time()
        
        while True:
            # æª¢æŸ¥è¶…æ™‚
            if time.time() - start_time > workflow.total_timeout:
                logger.error(f"å·¥ä½œæµç¨‹è¶…æ™‚: {workflow.name}")
                break
            
            all_done = self._check_tasks_completion(workflow, completed_tasks, failed_tasks)
            if all_done:
                break
                
            await asyncio.sleep(0.1)  # çŸ­æš«ä¼‘æ¯
        
        return completed_tasks, failed_tasks
    
    def _check_tasks_completion(self, workflow, completed_tasks: list, failed_tasks: list) -> bool:
        """æª¢æŸ¥ä»»å‹™å®Œæˆç‹€æ…‹"""
        all_done = True
        
        for task in workflow.tasks:
            if task.status in [TaskStatus.PENDING, TaskStatus.QUEUED, TaskStatus.RUNNING, TaskStatus.RETRYING]:
                all_done = False
            elif task.status == TaskStatus.COMPLETED:
                if task.task_id not in [t.task_id for t in completed_tasks]:
                    completed_tasks.append(task)
            elif task.status == TaskStatus.FAILED:
                if task.task_id not in [t.task_id for t in failed_tasks]:
                    failed_tasks.append(task)
                    
                    # æª¢æŸ¥å¤±æ•—ç­–ç•¥
                    if workflow.failure_policy == "stop_on_failure":
                        logger.error(f"ä»»å‹™å¤±æ•—ï¼Œåœæ­¢å·¥ä½œæµç¨‹: {task.name}")
                        all_done = True
        
        return all_done
    
    def _finalize_workflow(self, workflow_id: str, workflow, completed_tasks: list, failed_tasks: list) -> dict:
        """å®Œæˆå·¥ä½œæµç¨‹ä¸¦è¿”å›çµæœ"""
        # æ›´æ–°å·¥ä½œæµç¨‹ç‹€æ…‹
        workflow.completed_tasks = len(completed_tasks)
        workflow.failed_tasks = len(failed_tasks)
        workflow.completed_at = datetime.now(timezone.utc).isoformat()
        
        if workflow.failed_tasks == 0:
            workflow.status = "completed"
            self.stats['workflows_completed'] += 1
        else:
            workflow.status = "failed"
            self.stats['workflows_failed'] += 1
        
        # ç§»å‹•åˆ°æ­·å²è¨˜éŒ„
        self.workflow_history[workflow_id] = workflow
        del self.active_workflows[workflow_id]
        
        # è¨ˆç®—æŒçºŒæ™‚é–“
        duration = self._calculate_workflow_duration(workflow)
        self._update_workflow_duration_stats(duration)
        
        # ç™¼å¸ƒå®Œæˆäº‹ä»¶
        completion_task = asyncio.create_task(self._publish_workflow_completion_event(workflow_id, workflow, duration))
        # ä¿å­˜ä»»å‹™å¼•ç”¨é¿å…åƒåœ¾å›æ”¶
        self._completion_tasks = getattr(self, '_completion_tasks', [])
        self._completion_tasks.append(completion_task)
        
        return {
            'workflow_id': workflow_id,
            'status': workflow.status,
            'total_tasks': workflow.total_tasks,
            'completed_tasks': workflow.completed_tasks,
            'failed_tasks': workflow.failed_tasks,
            'duration': duration,
            'task_results': [task.to_dict() for task in workflow.tasks]
        }
    
    async def _publish_workflow_completion_event(self, workflow_id: str, workflow, duration: float) -> None:
        """ç™¼å¸ƒå·¥ä½œæµç¨‹å®Œæˆäº‹ä»¶"""
        if self.event_bus:
            await self._publish_orchestration_event('workflow.completed', {
                'workflow_id': workflow_id,
                'status': workflow.status,
                'completed_tasks': workflow.completed_tasks,
                'failed_tasks': workflow.failed_tasks,
                'duration': duration
            })
    
    def _handle_workflow_error(self, workflow_id: str, workflow, error: Exception) -> dict:
        """è™•ç†å·¥ä½œæµç¨‹éŒ¯èª¤"""
        workflow.status = "error"
        workflow.completed_at = datetime.now(timezone.utc).isoformat()
        
        logger.error(f"å·¥ä½œæµç¨‹åŸ·è¡ŒéŒ¯èª¤: {str(error)}")
        
        return {
            'workflow_id': workflow_id,
            'status': 'error',
            'error': str(error)
        }
    
    async def start_orchestration(self) -> None:
        """é–‹å§‹ç·¨æ’æœå‹™"""
        if self.is_running:
            logger.warning("ç·¨æ’å™¨å·²ç¶“åœ¨é‹è¡Œä¸­")
            return
        
        self.is_running = True
        self.orchestration_task = asyncio.create_task(self._orchestration_loop())
        
        logger.info("ä»£ç†ç·¨æ’å™¨å·²å•Ÿå‹•")
    
    async def stop_orchestration(self) -> None:
        """åœæ­¢ç·¨æ’æœå‹™"""
        self.is_running = False
        
        if self.orchestration_task:
            self.orchestration_task.cancel()
            try:
                await self.orchestration_task
            except asyncio.CancelledError:
                pass
        
        logger.info("ä»£ç†ç·¨æ’å™¨å·²åœæ­¢")
    
    async def _orchestration_loop(self) -> None:
        """ç·¨æ’ä¸»å¾ªç’°"""
        logger.info("é–‹å§‹ç·¨æ’å¾ªç’°")
        
        while self.is_running:
            try:
                # è™•ç†å¾…åŸ·è¡Œä»»å‹™
                task = self.scheduler.get_next_task()
                
                if task:
                    await self._execute_task(task)
                else:
                    await asyncio.sleep(0.1)  # æ²’æœ‰ä»»å‹™æ™‚ä¼‘æ¯ä¸€ä¸‹
                    
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç·¨æ’å¾ªç’°éŒ¯èª¤: {str(e)}")
                await asyncio.sleep(1)  # éŒ¯èª¤å¾Œç¨ä½œä¼‘æ¯
    
    async def _execute_task(self, task: OrchestrationTask) -> None:
        """åŸ·è¡Œå–®å€‹ä»»å‹™"""
        try:
            # æ¨™è¨˜ä»»å‹™é–‹å§‹é‹è¡Œ
            self.scheduler.mark_task_running(task)
            
            # ç™¼å¸ƒä»»å‹™é–‹å§‹äº‹ä»¶
            if self.event_bus:
                await self._publish_orchestration_event('task.started', {
                    'task_id': task.task_id,
                    'task_name': task.name,
                    'target_agent': task.target_agent,
                    'operation': task.operation
                })
            
            # åŸ·è¡Œä»»å‹™
            if self.mcp_manager:
                # ä½¿ç”¨MCPå”è­°åŸ·è¡Œ
                result = await self._execute_task_via_mcp(task)
            else:
                # ç›´æ¥åŸ·è¡Œï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰
                result = await self._execute_task_direct(task)
            
            # æ¨™è¨˜ä»»å‹™å®Œæˆ
            self.scheduler.mark_task_completed(task, result)
            
            # ç™¼å¸ƒä»»å‹™å®Œæˆäº‹ä»¶
            if self.event_bus:
                await self._publish_orchestration_event('task.completed', {
                    'task_id': task.task_id,
                    'task_name': task.name,
                    'target_agent': task.target_agent,
                    'result_summary': self._summarize_task_result(result)
                })
                
        except Exception as e:
            error_info = {
                'type': type(e).__name__,
                'message': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
            
            # æ¨™è¨˜ä»»å‹™å¤±æ•—
            self.scheduler.mark_task_failed(task, error_info)
            
            # ç™¼å¸ƒä»»å‹™å¤±æ•—äº‹ä»¶
            if self.event_bus:
                await self._publish_orchestration_event('task.failed', {
                    'task_id': task.task_id,
                    'task_name': task.name,
                    'target_agent': task.target_agent,
                    'error': error_info,
                    'retry_count': task.retry_count
                })
    
    async def _execute_task_via_mcp(self, task: OrchestrationTask) -> Dict[str, Any]:
        """é€šéMCPå”è­°åŸ·è¡Œä»»å‹™"""
        
        mcp_message = MCPMessage(
            method="tools/call",
            params={
                'name': task.operation,
                'arguments': task.payload
            },
            source_module="orchestrator",
            target_module=task.target_agent
        )
        
        response = await self.mcp_manager.route_mcp_message(mcp_message)
        
        if response and response.result:
            return response.result
        else:
            raise RuntimeError(f"MCPä»»å‹™åŸ·è¡Œå¤±æ•—: {task.operation}")
    
    async def _execute_task_direct(self, task: OrchestrationTask) -> Dict[str, Any]:
        """ç›´æ¥åŸ·è¡Œä»»å‹™ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰"""
        
        # æ¨¡æ“¬ä»»å‹™åŸ·è¡Œ
        execution_time = min(task.estimated_duration, 5.0)  # æœ€å¤š5ç§’
        await asyncio.sleep(execution_time)
        
        return {
            'status': 'success',
            'message': f'Task {task.name} executed successfully',
            'execution_time': execution_time,
            'target_agent': task.target_agent,
            'operation': task.operation,
            'payload': task.payload
        }
    
    def _validate_workflow(self, workflow: WorkflowDefinition) -> bool:
        """é©—è­‰å·¥ä½œæµç¨‹"""
        
        # æª¢æŸ¥ä»»å‹™çš„ç›®æ¨™ä»£ç†æ˜¯å¦å­˜åœ¨
        for task in workflow.tasks:
            if task.target_agent not in self.registered_agents:
                logger.error(f"ä»»å‹™ç›®æ¨™ä»£ç†æœªè¨»å†Š: {task.target_agent}")
                return False
        
        # æª¢æŸ¥ä¾è³´é—œä¿‚æ˜¯å¦æœ‰ç’°
        if self._has_circular_dependencies(workflow.tasks):
            logger.error("æª¢æ¸¬åˆ°å¾ªç’°ä¾è³´")
            return False
        
        return True
    
    def _has_circular_dependencies(self, tasks: List[OrchestrationTask]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¾ªç’°ä¾è³´"""
        graph = self._build_dependency_graph(tasks)
        return self._detect_cycles_in_graph(graph)
    
    def _build_dependency_graph(self, tasks: List[OrchestrationTask]) -> Dict[str, set]:
        """æ§‹å»ºä¾è³´åœ–"""
        graph = {}
        for task in tasks:
            graph[task.task_id] = set(task.dependencies)
        return graph
    
    def _detect_cycles_in_graph(self, graph: Dict[str, set]) -> bool:
        """ä½¿ç”¨DFSæª¢æ¸¬åœ–ä¸­çš„ç’°"""
        visited = set()
        rec_stack = set()
        
        def has_cycle(node):
            visited.add(node)
            rec_stack.add(node)
            
            for neighbor in graph.get(node, set()):
                if neighbor not in visited:
                    if has_cycle(neighbor):
                        return True
                elif neighbor in rec_stack:
                    return True
            
            rec_stack.remove(node)
            return False
        
        return self._check_all_nodes_for_cycles(graph, visited, has_cycle)
    
    def _check_all_nodes_for_cycles(self, graph: Dict[str, set], visited: set, has_cycle_func) -> bool:
        """æª¢æŸ¥æ‰€æœ‰ç¯€é»æ˜¯å¦å­˜åœ¨å¾ªç’°"""
        for task_id in graph:
            if task_id not in visited and has_cycle_func(task_id):
                return True
        return False
    
    def _calculate_workflow_duration(self, workflow: WorkflowDefinition) -> float:
        """è¨ˆç®—å·¥ä½œæµç¨‹æŒçºŒæ™‚é–“"""
        if not workflow.started_at or not workflow.completed_at:
            return 0.0
        
        start_time = datetime.fromisoformat(workflow.started_at.replace('Z', UTC_TIMEZONE_OFFSET))
        end_time = datetime.fromisoformat(workflow.completed_at.replace('Z', UTC_TIMEZONE_OFFSET))
        
        return (end_time - start_time).total_seconds()
    
    def _update_workflow_duration_stats(self, duration: float) -> None:
        """æ›´æ–°å·¥ä½œæµç¨‹æŒçºŒæ™‚é–“çµ±è¨ˆ"""
        if self.stats['avg_workflow_duration'] == 0:
            self.stats['avg_workflow_duration'] = duration
        else:
            alpha = 0.1
            self.stats['avg_workflow_duration'] = (
                alpha * duration + 
                (1 - alpha) * self.stats['avg_workflow_duration']
            )
    
    def _summarize_task_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ç¸½çµä»»å‹™çµæœ"""
        return {
            'status': result.get('status', 'unknown'),
            'execution_time': result.get('execution_time', 0),
            'data_size': len(str(result))
        }
    
    async def _publish_orchestration_event(self, event_type: str, data: Dict[str, Any]):
        """ç™¼å¸ƒç·¨æ’äº‹ä»¶"""
        if not self.event_bus:
            return
        
        event = AIEvent(
            event_type=f"orchestration.{event_type}",
            source_module="orchestrator",
            source_version="v2.0",
            data={
                **data,
                'timestamp': datetime.now(timezone.utc).isoformat()
            },
            priority=EventPriority.NORMAL
        )
        
        await self.event_bus.publish(event)
    
    def get_status(self) -> Dict[str, Any]:
        """ç²å–ç·¨æ’å™¨ç‹€æ…‹"""
        return {
            'orchestrator_status': 'running' if self.is_running else 'stopped',
            'registered_agents': len(self.registered_agents),
            'active_workflows': len(self.active_workflows),
            'workflow_history': len(self.workflow_history),
            'scheduler_status': self.scheduler.get_status(),
            'statistics': self.stats,
            'last_updated': datetime.now(timezone.utc).isoformat()
        }

# ==================== å·¥ä½œæµç¨‹å»ºæ§‹å™¨ ====================

class WorkflowBuilder:
    """å·¥ä½œæµç¨‹å»ºæ§‹å™¨"""
    
    def __init__(self):
        self.workflow = WorkflowDefinition()
        self.task_counter = 0
    
    def create_workflow(self, name: str, description: str = "") -> 'WorkflowBuilder':
        """å‰µå»ºå·¥ä½œæµç¨‹"""
        self.workflow.name = name
        self.workflow.description = description
        return self
    
    def add_task(self, name: str, target_agent: str, operation: str, 
                payload: Optional[Dict[str, Any]] = None, 
                priority: TaskPriority = TaskPriority.NORMAL,
                dependencies: Optional[List[str]] = None) -> 'WorkflowBuilder':
        """æ·»åŠ ä»»å‹™"""
        
        task = OrchestrationTask(
            name=name,
            target_agent=target_agent,
            operation=operation,
            payload=payload or {},
            priority=priority,
            dependencies=dependencies or []
        )
        
        self.workflow.add_task(task)
        self.task_counter += 1
        
        return self
    
    def set_parallel_limit(self, max_parallel: int) -> 'WorkflowBuilder':
        """è¨­ç½®ä¸¦è¡Œé™åˆ¶"""
        self.workflow.max_parallel_tasks = max_parallel
        return self
    
    def set_timeout(self, timeout: float) -> 'WorkflowBuilder':
        """è¨­ç½®è¶…æ™‚æ™‚é–“"""
        self.workflow.total_timeout = timeout
        return self
    
    def set_failure_policy(self, policy: str) -> 'WorkflowBuilder':
        """è¨­ç½®å¤±æ•—ç­–ç•¥"""
        self.workflow.failure_policy = policy
        return self
    
    def build(self) -> WorkflowDefinition:
        """æ§‹å»ºå·¥ä½œæµç¨‹"""
        return self.workflow

# ==================== æ¸¬è©¦å’Œç¤ºä¾‹ ====================

async def test_agentic_orchestration():
    """æ¸¬è©¦æ™ºèƒ½ä»£ç†ç·¨æ’ç³»çµ±"""
    
    print("ğŸ¤– æ¸¬è©¦æ™ºèƒ½ä»£ç†ç·¨æ’ç³»çµ±")
    print("=" * 50)
    
    # å‰µå»ºç·¨æ’å™¨
    orchestrator = AgenticOrchestrator()
    
    # è¨»å†Šä»£ç†
    print("\nğŸ“ è¨»å†Šä»£ç†...")
    
    agents = [
        ("perception", AgentType.PERCEPTION, ["scan_analysis", "context_encoding"]),
        ("cognition", AgentType.COGNITION, ["self_exploration", "capability_assessment"]),
        ("knowledge", AgentType.KNOWLEDGE, ["code_analysis", "semantic_search"]),
        ("decision", AgentType.DECISION, ["strategy_planning", "resource_allocation"]),
        ("execution", AgentType.EXECUTION, ["task_execution", "result_reporting"])
    ]
    
    for agent_name, agent_type, capabilities in agents:
        success = orchestrator.register_agent(agent_name, agent_type, capabilities)
        print(f"   {'âœ…' if success else 'âŒ'} {agent_name} ({agent_type.value})")
    
    # å‰µå»ºæ¸¬è©¦å·¥ä½œæµç¨‹
    print("\nğŸ”§ å‰µå»ºæ¸¬è©¦å·¥ä½œæµç¨‹...")
    
    builder = WorkflowBuilder()
    workflow = (builder
                .create_workflow("AIç³»çµ±åˆ†æå·¥ä½œæµç¨‹", "å®Œæ•´çš„AIç³»çµ±åˆ†æå’Œå„ªåŒ–æµç¨‹")
                .add_task("ç³»çµ±ç‹€æ…‹æƒæ", "perception", "scan_analysis", 
                         {"target": "system_state"}, TaskPriority.HIGH)
                .add_task("èƒ½åŠ›è©•ä¼°", "cognition", "capability_assessment", 
                         {"task": "system_optimization"}, TaskPriority.NORMAL, 
                         dependencies=[])  # ä¾è³´ç¬¬ä¸€å€‹ä»»å‹™
                .add_task("çŸ¥è­˜æª¢ç´¢", "knowledge", "semantic_search", 
                         {"query": "performance optimization techniques"}, TaskPriority.NORMAL)
                .add_task("ç­–ç•¥è¦åŠƒ", "decision", "strategy_planning", 
                         {"context": "optimization"}, TaskPriority.HIGH)
                .add_task("åŸ·è¡Œå„ªåŒ–", "execution", "task_execution", 
                         {"strategy": "auto_optimization"}, TaskPriority.CRITICAL)
                .set_parallel_limit(3)
                .set_timeout(60.0)
                .set_failure_policy("continue_on_failure")
                .build())
    
    # å‰µå»ºå·¥ä½œæµç¨‹
    workflow_id = orchestrator.create_workflow(workflow)
    print(f"âœ… å·¥ä½œæµç¨‹å·²å‰µå»º: {workflow_id}")
    print(f"   ğŸ“‹ ç¸½ä»»å‹™æ•¸: {workflow.total_tasks}")
    
    # å•Ÿå‹•ç·¨æ’å™¨
    print("\nğŸš€ å•Ÿå‹•ç·¨æ’å™¨...")
    await orchestrator.start_orchestration()
    
    # åŸ·è¡Œå·¥ä½œæµç¨‹
    print("\nâ–¶ï¸ åŸ·è¡Œå·¥ä½œæµç¨‹...")
    result = await orchestrator.execute_workflow(workflow_id)
    
    print("âœ… å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆ")
    print(f"   ğŸ“Š ç‹€æ…‹: {result['status']}")
    print(f"   âœ… å®Œæˆä»»å‹™: {result['completed_tasks']}/{result['total_tasks']}")
    print(f"   âŒ å¤±æ•—ä»»å‹™: {result['failed_tasks']}")
    print(f"   â±ï¸ æŒçºŒæ™‚é–“: {result['duration']:.2f}ç§’")
    
    # é¡¯ç¤ºä»»å‹™åŸ·è¡Œè©³æƒ…
    print("\nğŸ“‹ ä»»å‹™åŸ·è¡Œè©³æƒ…:")
    for i, task_result in enumerate(result['task_results']):
        status_icon = "âœ…" if task_result['status'] == 'completed' else "âŒ"
        print(f"   {status_icon} {task_result['name']} - {task_result['status']}")
    
    # åœæ­¢ç·¨æ’å™¨
    print("\nâ¹ï¸ åœæ­¢ç·¨æ’å™¨...")
    await orchestrator.stop_orchestration()
    
    # ç²å–æœ€çµ‚ç‹€æ…‹
    status = orchestrator.get_status()
    print("\nğŸ“Š ç·¨æ’å™¨æœ€çµ‚ç‹€æ…‹:")
    print(f"   ğŸ—ï¸ å·¥ä½œæµç¨‹çµ±è¨ˆ: {status['statistics']['workflows_completed']} å®Œæˆ, {status['statistics']['workflows_failed']} å¤±æ•—")
    print(f"   ğŸ“ˆ ä»»å‹™çµ±è¨ˆ: {status['statistics']['total_tasks_orchestrated']} ç¸½ç·¨æ’ä»»å‹™")
    print(f"   âš¡ å¹³å‡å·¥ä½œæµç¨‹æ™‚é–“: {status['statistics']['avg_workflow_duration']:.2f}ç§’")

if __name__ == "__main__":
    asyncio.run(test_agentic_orchestration())