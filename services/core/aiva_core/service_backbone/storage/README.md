# Storage - å­˜å„²ç®¡ç†å­ç³»çµ±

**å°èˆª**: [â† è¿”å› Service Backbone](../README.md) | [â† è¿”å› AIVA Core](../../README.md) | [â† è¿”å›é …ç›®æ ¹ç›®éŒ„](../../../../../README.md)

## ğŸ“‘ ç›®éŒ„

- [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
- [ğŸ“‚ æ–‡ä»¶çµæ§‹](#-æ–‡ä»¶çµæ§‹)
- [ğŸ¯ æ ¸å¿ƒåŠŸèƒ½](#-æ ¸å¿ƒåŠŸèƒ½)
  - [backends.py](#backendspy-560-è¡Œ-)
  - [storage_manager.py](#storage_managerpy-240-è¡Œ)
  - [models.py](#modelspy-185-è¡Œ)
  - [config.py](#configpy-97-è¡Œ)
- [ğŸ’¾ æ•¸æ“šå­˜å„²ç­–ç•¥](#-æ•¸æ“šå­˜å„²ç­–ç•¥)
- [ğŸ”„ æ•¸æ“šç”Ÿå‘½é€±æœŸ](#-æ•¸æ“šç”Ÿå‘½é€±æœŸ)
- [ğŸ“Š æŸ¥è©¢å„ªåŒ–](#-æŸ¥è©¢å„ªåŒ–)
- [ğŸ”’ æ•¸æ“šå®‰å…¨](#-æ•¸æ“šå®‰å…¨)
- [ğŸ“š ç›¸é—œæ¨¡çµ„](#-ç›¸é—œæ¨¡çµ„)
- [ğŸ”§ é…ç½®æœ€ä½³å¯¦è¸](#-é…ç½®æœ€ä½³å¯¦è¸)

---

## ğŸ“‹ æ¦‚è¿°

**å®šä½**: çµ±ä¸€å­˜å„²æ¥å£å’Œæ•¸æ“šæŒä¹…åŒ–  
**ç‹€æ…‹**: âœ… å·²å¯¦ç¾  
**æ–‡ä»¶æ•¸**: 4 å€‹ Python æ–‡ä»¶ (1,082 è¡Œ)

## ğŸ“‚ æ–‡ä»¶çµæ§‹

```
storage/
â”œâ”€â”€ backends.py (560 è¡Œ) â­ - å­˜å„²å¾Œç«¯å¯¦ç¾
â”œâ”€â”€ storage_manager.py (240 è¡Œ) - å­˜å„²ç®¡ç†å™¨
â”œâ”€â”€ models.py (185 è¡Œ) - æ•¸æ“šæ¨¡å‹
â”œâ”€â”€ config.py (97 è¡Œ) - é…ç½®ç®¡ç†
â”œâ”€â”€ __init__.py
â””â”€â”€ README.md (æœ¬æ–‡æª”)
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### backends.py (560 è¡Œ) â­

**è·è²¬**: å¤šç¨®å­˜å„²å¾Œç«¯çš„çµ±ä¸€å¯¦ç¾

**æ”¯æ´çš„å¾Œç«¯**:
| å¾Œç«¯é¡å‹ | é¡å | ç‰¹é» | é©ç”¨å ´æ™¯ |
|---------|------|------|---------|
| **SQLite** | `SQLiteBackend` | è¼•é‡,å–®æ–‡ä»¶ | é–‹ç™¼æ¸¬è©¦,å°å‹éƒ¨ç½² |
| **PostgreSQL** | `PostgreSQLBackend` | å¼·å¤§,ACID | ç”Ÿç”¢ç’°å¢ƒ |
| **MongoDB** | `MongoDBBackend` | NoSQL,éˆæ´» | éçµæ§‹åŒ–æ•¸æ“š |
| **Redis** | `RedisBackend` | å¿«é€Ÿ,å…§å­˜ | å¿«å–,æœƒè©± |
| **æ–‡ä»¶ç³»çµ±** | `FileSystemBackend` | ç°¡å–®,æœ¬åœ° | æ–‡ä»¶å­˜å„² |

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from aiva_core.service_backbone.storage import backends

# PostgreSQL å¾Œç«¯
db = backends.PostgreSQLBackend(
    host="localhost",
    port=5432,
    database="aiva",
    user="admin",
    password="***"
)

# ä¿å­˜æ•¸æ“š
db.save("scan_results", {
    "scan_id": "123",
    "target": "example.com",
    "findings": [...]
})

# æŸ¥è©¢æ•¸æ“š
results = db.query("scan_results", {
    "target": "example.com",
    "status": "completed"
})
```

**å¾Œç«¯æ¥å£** (çµ±ä¸€ API):
```python
class StorageBackend(ABC):
    def save(self, collection: str, data: dict) -> str: pass
    def query(self, collection: str, filters: dict) -> list: pass
    def update(self, collection: str, id: str, data: dict): pass
    def delete(self, collection: str, id: str): pass
    def get_by_id(self, collection: str, id: str) -> dict: pass
```

---

### storage_manager.py (240 è¡Œ)

**è·è²¬**: é«˜å±¤å­˜å„²ç®¡ç†å’Œæ“ä½œå°è£

**ä¸»è¦åŠŸèƒ½**:
- è‡ªå‹•é¸æ“‡å­˜å„²å¾Œç«¯
- é€£æ¥æ± ç®¡ç†
- äº‹å‹™æ”¯æŒ
- æ•¸æ“šé·ç§»

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from aiva_core.service_backbone.storage import StorageManager

# åˆå§‹åŒ– (è‡ªå‹•é¸æ“‡å¾Œç«¯)
storage = StorageManager.from_config({
    "backend": "postgresql",
    "connection_string": "postgresql://localhost/aiva"
})

# ä½¿ç”¨äº‹å‹™
with storage.transaction():
    storage.save("scans", scan_data)
    storage.save("findings", findings_data)
    # è‡ªå‹•æäº¤æˆ–å›æ»¾

# æ‰¹é‡æ“ä½œ
storage.bulk_save("scans", [scan1, scan2, scan3])
```

**é«˜ç´šåŠŸèƒ½**:
```python
# æ•¸æ“šé·ç§»
storage.migrate_data(
    from_backend="sqlite",
    to_backend="postgresql",
    collections=["scans", "findings"]
)

# æ•¸æ“šå‚™ä»½
storage.backup(
    path="/backups/aiva_backup_20251116.sql",
    format="sql"
)
```

---

### models.py (185 è¡Œ)

**è·è²¬**: æ•¸æ“šæ¨¡å‹å®šç¾©å’Œ ORM æ˜ å°„

**ä¸»è¦æ¨¡å‹**:
```python
from aiva_core.service_backbone.storage import models

# æƒæçµæœæ¨¡å‹
class ScanResult(models.Model):
    scan_id = models.StringField(primary_key=True)
    target = models.StringField(required=True)
    status = models.EnumField(["pending", "running", "completed"])
    findings = models.ListField()
    created_at = models.DateTimeField(auto_now_add=True)

# æ¼æ´ç™¼ç¾æ¨¡å‹
class Finding(models.Model):
    finding_id = models.StringField(primary_key=True)
    scan_id = models.ForeignKey(ScanResult)
    severity = models.EnumField(["low", "medium", "high", "critical"])
    title = models.StringField()
    description = models.TextField()
```

**ä½¿ç”¨ç¯„ä¾‹**:
```python
# å‰µå»ºè¨˜éŒ„
scan = ScanResult(
    scan_id="scan_123",
    target="example.com",
    status="completed"
)
scan.save()

# æŸ¥è©¢è¨˜éŒ„
scans = ScanResult.query(target="example.com")

# æ›´æ–°è¨˜éŒ„
scan.status = "completed"
scan.save()

# é—œè¯æŸ¥è©¢
findings = Finding.query(scan_id=scan.scan_id)
```

---

### config.py (97 è¡Œ)

**è·è²¬**: å­˜å„²é…ç½®ç®¡ç†

**é…ç½®é …**:
```python
from aiva_core.service_backbone.storage import StorageConfig

config = StorageConfig(
    backend="postgresql",
    host="localhost",
    port=5432,
    database="aiva",
    pool_size=20,
    max_overflow=10,
    echo=False,  # SQL æ—¥èªŒ
    timeout=30
)
```

## ğŸ’¾ æ•¸æ“šå­˜å„²ç­–ç•¥

### 1. æƒæçµæœå­˜å„²

```python
# é—œä¿‚å‹æ•¸æ“šåº« (PostgreSQL)
storage.save("scan_results", {
    "scan_id": "123",
    "target": "example.com",
    "scan_type": "full",
    "status": "completed",
    "findings_count": 15
})

# è©³ç´°ç™¼ç¾å­˜å„²åœ¨ MongoDB (éˆæ´»çµæ§‹)
mongo_storage.save("finding_details", {
    "finding_id": "f456",
    "raw_data": {...},  # ä»»æ„çµæ§‹
    "metadata": {...}
})
```

### 2. å¿«å–å±¤

```python
# Redis å¿«å–ç†±é–€æ•¸æ“š
redis_backend = backends.RedisBackend()
redis_backend.save("cache:scan:123", scan_data, ttl=3600)

# å¿«å–å‘½ä¸­é‚è¼¯
def get_scan_result(scan_id):
    # å…ˆæŸ¥å¿«å–
    cached = redis_backend.get(f"cache:scan:{scan_id}")
    if cached:
        return cached
    
    # å¿«å–æœªå‘½ä¸­,æŸ¥æ•¸æ“šåº«
    result = db.get_by_id("scan_results", scan_id)
    redis_backend.save(f"cache:scan:{scan_id}", result, ttl=3600)
    return result
```

### 3. æ–‡ä»¶å­˜å„²

```python
# å¤§æ–‡ä»¶å­˜å„²åœ¨æ–‡ä»¶ç³»çµ±
fs_backend = backends.FileSystemBackend(base_path="/data/aiva")
fs_backend.save_file("reports/scan_123.pdf", pdf_content)

# å…ƒæ•¸æ“šå­˜å„²åœ¨æ•¸æ“šåº«
db.save("reports", {
    "report_id": "r789",
    "scan_id": "123",
    "file_path": "/data/aiva/reports/scan_123.pdf",
    "size_bytes": 1024000
})
```

## ğŸ”„ æ•¸æ“šç”Ÿå‘½é€±æœŸ

```
å‰µå»º
  â†“
å­˜å„²åˆ°ä¸»æ•¸æ“šåº«
  â†“
åŒæ­¥åˆ°å¿«å– (ç†±æ•¸æ“š)
  â†“
å®šæœŸæ­¸æª” (èˆŠæ•¸æ“š)
  â†“
è‡ªå‹•æ¸…ç† (éæœŸæ•¸æ“š)
```

## ğŸ“Š æŸ¥è©¢å„ªåŒ–

### ç´¢å¼•ç­–ç•¥

```python
# å‰µå»ºç´¢å¼•
storage.create_index("scan_results", ["target", "created_at"])
storage.create_index("findings", ["severity", "scan_id"])

# è¤‡åˆç´¢å¼•
storage.create_index("scans", [
    ("target", "asc"),
    ("status", "asc"),
    ("created_at", "desc")
])
```

### æŸ¥è©¢å„ªåŒ–

```python
# åˆ†é æŸ¥è©¢
results = storage.query_paginated(
    collection="scan_results",
    filters={"status": "completed"},
    page=1,
    page_size=50
)

# æŠ•å½±æŸ¥è©¢ (åªè¿”å›éœ€è¦çš„å­—æ®µ)
results = storage.query(
    collection="findings",
    filters={"severity": "critical"},
    projection=["finding_id", "title", "severity"]
)
```

## ğŸ”’ æ•¸æ“šå®‰å…¨

### åŠ å¯†å­˜å„²

```python
# å•Ÿç”¨éœæ…‹åŠ å¯†
storage = StorageManager(
    backend="postgresql",
    encryption_key="your_encryption_key",
    encrypt_at_rest=True
)

# æ•æ„Ÿå­—æ®µåŠ å¯†
storage.encrypt_fields("users", ["password", "api_key"])
```

### å‚™ä»½ç­–ç•¥

```python
# å®šæœŸå‚™ä»½
from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler()
scheduler.add_job(
    func=storage.backup,
    trigger="cron",
    hour=2,  # æ¯å¤©å‡Œæ™¨ 2 é»
    args=["/backups/daily_backup.sql"]
)
scheduler.start()
```

## ğŸ“š ç›¸é—œæ¨¡çµ„

- [state](../state/README.md) - ç‹€æ…‹å­˜å„²
- [messaging](../messaging/README.md) - æ¶ˆæ¯æŒä¹…åŒ–
- [cognitive_core/rag](../../cognitive_core/rag/README.md) - å‘é‡å­˜å„²

## ğŸ”¨ aiva_common ä¿®å¾©è¦ç¯„

> **æ ¸å¿ƒåŸå‰‡**: æœ¬æ¨¡çµ„å¿…é ˆåš´æ ¼éµå¾ª [`services/aiva_common`](../../../../aiva_common/README.md) çš„ä¿®å¾©è¦ç¯„ã€‚

```python
# âœ… æ­£ç¢ºï¼šä½¿ç”¨æ¨™æº–é…ç½®å’Œé¡å‹
from aiva_common import UnifiedConfig, ModuleName, Environment

# ç²å–å­˜å„²é…ç½®
config = UnifiedConfig.get_instance()
storage_config = config.get_module_config(ModuleName.STORAGE)

# ä½¿ç”¨æ¨™æº–ç’°å¢ƒ
if config.environment == Environment.PRODUCTION:
    backend = "postgresql"
else:
    backend = "sqlite"

# âŒ ç¦æ­¢ï¼šè‡ªå®šç¾©å­˜å„²é…ç½®é¡
class StorageConfig:
    def __init__(self, backend):
        self.backend = backend  # ä½¿ç”¨ UnifiedConfig

# âŒ ç¦æ­¢ï¼šç¡¬ç·¨ç¢¼ç’°å¢ƒæª¢æŸ¥
if os.getenv("ENV") == "prod":  # ä½¿ç”¨ Environment æšèˆ‰
    backend = "postgresql"
```

ğŸ“– **å®Œæ•´è¦ç¯„**: [aiva_common ä¿®å¾©æŒ‡å—](../../../../aiva_common/README.md)

---

## ğŸ”§ é…ç½®æœ€ä½³å¯¦è¸

### ç”Ÿç”¢ç’°å¢ƒ

```python
# PostgreSQL ä¸»æ•¸æ“šåº« + Redis å¿«å– + MongoDB æ–‡æª”å­˜å„²
storage_config = {
    "primary": {
        "backend": "postgresql",
        "host": "prod-db.example.com",
        "pool_size": 50,
        "max_overflow": 20
    },
    "cache": {
        "backend": "redis",
        "host": "prod-cache.example.com",
        "ttl": 3600
    },
    "documents": {
        "backend": "mongodb",
        "host": "prod-mongo.example.com"
    }
}
```

### é–‹ç™¼ç’°å¢ƒ

```python
# SQLite å–®æ–‡ä»¶æ•¸æ“šåº«
storage_config = {
    "backend": "sqlite",
    "database": "aiva_dev.db",
    "echo": True  # é¡¯ç¤º SQL æ—¥èªŒ
}
```

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**æœ€å¾Œæ›´æ–°**: 2025-11-16  
**ç¶­è­·è€…**: Service Backbone åœ˜éšŠ
