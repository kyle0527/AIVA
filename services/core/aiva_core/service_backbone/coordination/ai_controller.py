"""
AIVA AI å­ç³»çµ±æ§åˆ¶å™¨ - BioNeuronMasterController çš„å°ˆé–€æ¨¡çµ„
è² è²¬ç‰¹å®š AI åŠŸèƒ½çš„å”èª¿ï¼Œé¿å…èˆ‡ä¸»æ§åˆ¶å™¨è¡çª
æ”¯æ´æ’ä»¶åŒ–çš„æ™ºèƒ½åˆ†æç³»çµ±
"""

import asyncio
from datetime import datetime
import json
import logging
from typing import Any

try:
    from .plugins.ai_summary_plugin import AISummaryPlugin

    SUMMARY_PLUGIN_AVAILABLE = True
except ImportError:
    SUMMARY_PLUGIN_AVAILABLE = False

logger = logging.getLogger(__name__)


class AISubsystemController:
    """AIVA AI å­ç³»çµ±æ§åˆ¶å™¨ - é¿å…èˆ‡ä¸»æ§åˆ¶å™¨è¡çª
    
    é‡è¦ï¼šæ­¤é¡ä¸å†å¯¦ä¾‹åŒ– BioNeuronRAGAgentï¼Œè€Œæ˜¯ä½¿ç”¨ä¸»æ§åˆ¶å™¨å…±äº«çš„å¯¦ä¾‹
    """

    def __init__(self, master_controller=None):
        """åˆå§‹åŒ– AI å­ç³»çµ±æ§åˆ¶å™¨
        
        Args:
            master_controller: ä¸»æ§åˆ¶å™¨å¯¦ä¾‹ï¼Œç”¨æ–¼å…±äº« AI è³‡æº
        """
        logger.info("ğŸ”§ åˆå§‹åŒ– AIVA AI å­ç³»çµ±æ§åˆ¶å™¨...")

        # é‡è¦ï¼šä¸å†å‰µå»ºç¨ç«‹çš„ AI å¯¦ä¾‹ï¼Œé¿å…è³‡æºæµªè²»
        self.master_controller = master_controller
        self._master_ai = None  # å»¶é²ç²å–ä¸»æ§ AI

        # åˆ†æ•£ AI çµ„ä»¶è¨»å†Š
        self.ai_components = {
            "code_fixer": None,  # å»¶é²åˆå§‹åŒ– CodeFixer
            "smart_detectors": {},
            "detection_engines": {},
        }

        # AI æ±ºç­–æ­·å² (èˆ‡ä¸»æ§åˆ¶å™¨å…±äº«)
        self.decision_history = []
        
        # ğŸ”Œ æ’ä»¶ç³»çµ± - æ‘˜è¦åŠŸèƒ½
        self.summary_plugin: AISummaryPlugin | None = None
        if SUMMARY_PLUGIN_AVAILABLE:
            try:
                self.summary_plugin = AISummaryPlugin(enabled=True)
                logger.info("ğŸ”Œ æ‘˜è¦æ’ä»¶å·²è¼‰å…¥")
            except Exception as e:
                logger.warning(f"âš ï¸ æ‘˜è¦æ’ä»¶è¼‰å…¥å¤±æ•—: {e}")
                self.summary_plugin = None
        else:
            logger.info("â„¹ï¸ æ‘˜è¦æ’ä»¶ä¸å¯ç”¨")

        logger.info("âœ… AI å­ç³»çµ±æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @property
    def master_ai(self):
        """ç²å–ä¸»æ§ AIï¼ˆå¾ä¸»æ§åˆ¶å™¨å…±äº«ï¼‰"""
        if self.master_controller and hasattr(self.master_controller, 'bio_neuron_agent'):
            return self.master_controller.bio_neuron_agent
        return None

    async def process_specialized_request(
        self, user_input: str, **context
    ) -> dict[str, Any]:
        """è™•ç†å°ˆé–€çš„ AI è«‹æ±‚ - é€éä¸»æ§åˆ¶å™¨å”èª¿"""
        logger.info(f"ğŸ”§ å­ç³»çµ± AI è™•ç†: {user_input}")

        if not self.master_ai:
            return {
                "status": "error",
                "error": "No master AI controller available",
                "message": "å­ç³»çµ±éœ€è¦ä¸»æ§åˆ¶å™¨æ”¯æ´"
            }

        # 1. åˆ†æä»»å‹™è¤‡é›œåº¦
        task_analysis = self._analyze_task_complexity(user_input, context)

        # 2. é€éä¸»æ§ AI è™•ç†ï¼ˆé¿å…é‡è¤‡å¯¦ä¾‹åŒ–ï¼‰
        try:
            if task_analysis["can_handle_directly"]:
                result = self._direct_processing(user_input, context)
            elif task_analysis["needs_code_fixing"]:
                result = self._coordinated_code_fixing(user_input, context)
            elif task_analysis["needs_specialized_detection"]:
                result = self._coordinated_detection(user_input, context)
            else:
                result = self._multi_ai_coordination(user_input, context)

            # 3. è¨˜éŒ„æ±ºç­–ï¼ˆèˆ‡ä¸»æ§åˆ¶å™¨å…±äº«ï¼‰
            self._record_specialized_decision(user_input, task_analysis, result)

        # 4. ğŸ”Œ æ’ä»¶åŒ–æ‘˜è¦ç”Ÿæˆ
        if self.summary_plugin and self.summary_plugin.is_enabled():
            try:
                summary = await self.summary_plugin.generate_summary(
                    user_input, task_analysis, result, self.master_ai
                )
                if summary:
                    result["ai_summary"] = summary
            except Exception as e:
                logger.error(f"âŒ æ‘˜è¦æ’ä»¶åŸ·è¡Œå¤±æ•—: {e}")

        return result

    def _analyze_task_complexity(
        self, user_input: str, context: dict
    ) -> dict[str, Any]:
        """åˆ†æä»»å‹™è¤‡é›œåº¦ - æ±ºå®šè™•ç†ç­–ç•¥"""
        input_lower = user_input.lower()

        analysis = {
            "can_handle_directly": False,
            "needs_code_fixing": False,
            "needs_specialized_detection": False,
            "complexity_score": 0.0,
            "confidence": 0.0,
        }

        # ç°¡å–®ä»»å‹™åˆ¤æ–·
        simple_patterns = ["è®€å–", "æŸ¥çœ‹", "é¡¯ç¤º", "åˆ—å‡º", "ç‹€æ…‹"]
        if any(pattern in input_lower for pattern in simple_patterns):
            analysis["can_handle_directly"] = True
            analysis["complexity_score"] = 0.2

        # ç¨‹å¼ç¢¼ä¿®å¾©åˆ¤æ–·
        fix_patterns = ["ä¿®å¾©", "ä¿®æ­£", "éŒ¯èª¤", "æ¼æ´ä¿®å¾©", "fix"]
        if any(pattern in input_lower for pattern in fix_patterns):
            analysis["needs_code_fixing"] = True
            analysis["complexity_score"] = 0.7

        # å°ˆé–€æª¢æ¸¬åˆ¤æ–·
        detection_patterns = ["æƒæ", "æª¢æ¸¬", "æ¼æ´", "å®‰å…¨æª¢æŸ¥"]
        if any(pattern in input_lower for pattern in detection_patterns):
            analysis["needs_specialized_detection"] = True
            analysis["complexity_score"] = 0.6

        analysis["confidence"] = min(analysis["complexity_score"] + 0.3, 1.0)
        return analysis

    async def _direct_processing(
        self, user_input: str, context: dict
    ) -> dict[str, Any]:
        """ä¸»æ§ AI ç›´æ¥è™•ç†"""
        logger.info("ğŸ“‹ ä¸»æ§ AI ç›´æ¥è™•ç†ä»»å‹™")

        result = self.master_ai.invoke(user_input, **context)

        return {
            "status": "success",
            "processing_method": "direct_master_ai",
            "result": result,
            "ai_conflicts": 0,
            "unified_control": True,
        }

    async def _coordinated_code_fixing(
        self, user_input: str, context: dict
    ) -> dict[str, Any]:
        """å”èª¿ç¨‹å¼ç¢¼ä¿®å¾© - ä¸»æ§ AI ç›£ç£ä¸‹çš„ä¿®å¾©"""
        logger.info("ğŸ”§ å”èª¿ç¨‹å¼ç¢¼ä¿®å¾© (ä¸»æ§ AI ç›£ç£)")

        # ä¸»æ§ AI é è™•ç†
        preprocessed = self.master_ai.invoke(f"åˆ†æä¿®å¾©éœ€æ±‚: {user_input}", **context)

        # æ¨¡æ“¬ç¨‹å¼ç¢¼ä¿®å¾© (å¯¦éš›æœƒèª¿ç”¨ CodeFixerï¼Œä½†ä¿æŒä¸»æ§ç›£ç£)
        fix_result = {
            "fixed_code": "# ä¿®å¾©å¾Œçš„ç¨‹å¼ç¢¼ (ç”±ä¸»æ§ AI å”èª¿)",
            "explanation": f'åŸºæ–¼ä¸»æ§ AI åˆ†æ: {preprocessed.get("tool_result", {}).get("analysis", "æœªçŸ¥")}',
            "confidence": 0.85,
        }

        # ä¸»æ§ AI é©—è­‰çµæœ
        validation = self.master_ai.invoke(f"é©—è­‰ä¿®å¾©çµæœ: {fix_result}", **context)

        return {
            "status": "success",
            "processing_method": "coordinated_code_fixing",
            "original_analysis": preprocessed,
            "fix_result": fix_result,
            "validation": validation,
            "ai_conflicts": 0,
            "unified_control": True,
        }

    async def _coordinated_detection(
        self, user_input: str, context: dict
    ) -> dict[str, Any]:
        """å”èª¿æ¼æ´æª¢æ¸¬ - çµ±ä¸€èª¿åº¦å¤šæª¢æ¸¬å¼•æ“"""
        logger.info("ğŸ” å”èª¿æ¼æ´æª¢æ¸¬ (çµ±ä¸€èª¿åº¦)")

        # ä¸»æ§ AI åˆ†ææª¢æ¸¬éœ€æ±‚
        detection_plan = self.master_ai.invoke(f"è¦åŠƒæª¢æ¸¬ç­–ç•¥: {user_input}", **context)

        # æ¨¡æ“¬å¤šå¼•æ“æª¢æ¸¬çµæœ
        detection_results = {
            "sqli_results": {"vulnerabilities_found": 0, "confidence": 0.9},
            "xss_results": {"vulnerabilities_found": 1, "confidence": 0.8},
            "ssrf_results": {"vulnerabilities_found": 0, "confidence": 0.95},
        }

        # ä¸»æ§ AI æ•´åˆçµæœ
        integration = self.master_ai.invoke(
            f"æ•´åˆæª¢æ¸¬çµæœ: {detection_results}", **context
        )

        return {
            "status": "success",
            "processing_method": "coordinated_detection",
            "detection_plan": detection_plan,
            "detection_results": detection_results,
            "integration": integration,
            "ai_conflicts": 0,
            "unified_control": True,
        }

    async def _multi_ai_coordination(
        self, user_input: str, context: dict
    ) -> dict[str, Any]:
        """å¤š AI å”åŒ - ä¸»æ§ AI çµ±ç±Œ"""
        logger.info("ğŸ¤ å¤š AI å”åŒè™•ç† (ä¸»æ§çµ±ç±Œ)")

        # ä¸»æ§ AI åˆ¶å®šå”åŒè¨ˆç•«
        coordination_plan = self.master_ai.invoke(
            f"åˆ¶å®šå”åŒè¨ˆç•«: {user_input}", **context
        )

        # æ¨¡æ“¬å¤š AI å”åŒåŸ·è¡Œ
        coordination_results = {
            "master_ai_role": "ç¸½é«”è¦åŠƒèˆ‡æœ€çµ‚æ±ºç­–",
            "code_fixer_role": "ç¨‹å¼ç¢¼å•é¡Œä¿®å¾©",
            "detectors_role": "å®‰å…¨æ¼æ´æª¢æ¸¬",
            "coordination_efficiency": 0.92,
        }

        # ä¸»æ§ AI æœ€çµ‚æ•´åˆ
        final_result = self.master_ai.invoke(
            f"æ•´åˆå”åŒçµæœ: {coordination_results}", **context
        )

        return {
            "status": "success",
            "processing_method": "multi_ai_coordination",
            "coordination_plan": coordination_plan,
            "coordination_results": coordination_results,
            "final_result": final_result,
            "ai_conflicts": 0,
            "unified_control": True,
        }

    # ğŸ”Œ æ’ä»¶ç®¡ç†æ–¹æ³•
    def get_summary_plugin_status(self) -> dict[str, Any]:
        """ç²å–æ‘˜è¦æ’ä»¶ç‹€æ…‹"""
        if self.summary_plugin:
            return self.summary_plugin.get_status()
        return {
            "plugin_name": "AI Summary Plugin",
            "enabled": False,
            "available": SUMMARY_PLUGIN_AVAILABLE,
            "message": "æ’ä»¶ä¸å¯ç”¨" if not SUMMARY_PLUGIN_AVAILABLE else "æ’ä»¶æœªè¼‰å…¥",
        }

    def enable_summary_plugin(self) -> dict[str, Any]:
        """å•Ÿç”¨æ‘˜è¦æ’ä»¶"""
        if not SUMMARY_PLUGIN_AVAILABLE:
            return {"error": "æ‘˜è¦æ’ä»¶ä¸å¯ç”¨"}

        if not self.summary_plugin:
            try:
                self.summary_plugin = AISummaryPlugin(enabled=True)
                return {"status": "success", "message": "æ‘˜è¦æ’ä»¶å·²å•Ÿç”¨"}
            except Exception as e:
                return {"error": f"æ‘˜è¦æ’ä»¶å•Ÿç”¨å¤±æ•—: {e}"}
        else:
            self.summary_plugin.enable()
            return {"status": "success", "message": "æ‘˜è¦æ’ä»¶å·²å•Ÿç”¨"}

    def disable_summary_plugin(self) -> dict[str, Any]:
        """ç¦ç”¨æ‘˜è¦æ’ä»¶"""
        if self.summary_plugin:
            self.summary_plugin.disable()
            return {"status": "success", "message": "æ‘˜è¦æ’ä»¶å·²ç¦ç”¨"}
        return {"message": "æ‘˜è¦æ’ä»¶æœªè¼‰å…¥"}

    def configure_summary_plugin(self, **settings) -> dict[str, Any]:
        """é…ç½®æ‘˜è¦æ’ä»¶"""
        if not self.summary_plugin or not self.summary_plugin.is_enabled():
            return {"error": "æ‘˜è¦æ’ä»¶ä¸å¯ç”¨æˆ–æœªå•Ÿç”¨"}
        return self.summary_plugin.configure(**settings)

    def get_summary_statistics(self) -> dict[str, Any]:
        """ç²å–æ‘˜è¦çµ±è¨ˆ - é€šéæ’ä»¶"""
        if self.summary_plugin:
            return self.summary_plugin.get_statistics()
        return {"error": "æ‘˜è¦æ’ä»¶ä¸å¯ç”¨"}

    def reset_summary_plugin(self) -> dict[str, Any]:
        """é‡ç½®æ‘˜è¦æ’ä»¶æ•¸æ“š"""
        if self.summary_plugin and self.summary_plugin.is_enabled():
            self.summary_plugin.reset()
            return {"status": "success", "message": "æ‘˜è¦æ’ä»¶æ•¸æ“šå·²é‡ç½®"}
        return {"error": "æ‘˜è¦æ’ä»¶ä¸å¯ç”¨æˆ–æœªå•Ÿç”¨"}

    def unload_summary_plugin(self) -> dict[str, Any]:
        """å¸è¼‰æ‘˜è¦æ’ä»¶"""
        if self.summary_plugin:
            self.summary_plugin.unload()
            self.summary_plugin = None
            return {"status": "success", "message": "æ‘˜è¦æ’ä»¶å·²å¸è¼‰"}
        return {"message": "æ‘˜è¦æ’ä»¶æœªè¼‰å…¥"}

    def _record_unified_decision(self, user_input: str, analysis: dict, result: dict):
        """è¨˜éŒ„çµ±ä¸€æ±ºç­–æ­·å²"""
        decision_record = {
            "timestamp": asyncio.get_event_loop().time(),
            "user_input": user_input,
            "task_analysis": analysis,
            "processing_method": result.get("processing_method"),
            "ai_conflicts_avoided": result.get("ai_conflicts", 0) == 0,
            "unified_control_maintained": result.get("unified_control", False),
        }

        self.decision_history.append(decision_record)

        if len(self.decision_history) > 100:  # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœ
            self.decision_history.pop(0)

    def get_control_statistics(self) -> dict[str, Any]:
        """ç²å–çµ±ä¸€æ§åˆ¶çµ±è¨ˆ"""
        if not self.decision_history:
            return {"no_decisions": True}

        total_decisions = len(self.decision_history)
        unified_decisions = sum(
            1 for d in self.decision_history if d["unified_control_maintained"]
        )
        conflict_free_decisions = sum(
            1 for d in self.decision_history if d["ai_conflicts_avoided"]
        )

        return {
            "total_decisions": total_decisions,
            "unified_control_rate": unified_decisions / total_decisions,
            "conflict_free_rate": conflict_free_decisions / total_decisions,
            "processing_methods": {
                method: sum(
                    1 for d in self.decision_history if d["processing_method"] == method
                )
                for method in {d["processing_method"] for d in self.decision_history}
            },
            "recommendation": (
                "çµ±ä¸€æ§åˆ¶æ•ˆæœè‰¯å¥½"
                if unified_decisions / total_decisions > 0.9
                else "éœ€è¦å„ªåŒ–çµ±ä¸€æ§åˆ¶"
            ),
        }

    def _classify_request_type(self, user_input: str) -> str:
        """åˆ†é¡è«‹æ±‚é¡å‹"""
        input_lower = user_input.lower()

        if any(word in input_lower for word in ["è®€å–", "æŸ¥çœ‹", "é¡¯ç¤º", "åˆ—å‡º"]):
            return "è³‡è¨ŠæŸ¥è©¢"
        elif any(word in input_lower for word in ["ä¿®å¾©", "ä¿®æ­£", "éŒ¯èª¤"]):
            return "ç¨‹å¼ç¢¼ä¿®å¾©"
        elif any(word in input_lower for word in ["æƒæ", "æª¢æ¸¬", "æ¼æ´"]):
            return "å®‰å…¨æª¢æ¸¬"
        elif any(word in input_lower for word in ["å”èª¿", "æ•´åˆ", "çµ±ä¸€"]):
            return "ç³»çµ±å”èª¿"
        elif any(word in input_lower for word in ["åˆ†æ", "å„ªåŒ–", "æ”¹å–„"]):
            return "ç³»çµ±å„ªåŒ–"
        else:
            return "ç¶œåˆè™•ç†"

    def _get_complexity_level(self, score: float) -> str:
        """ç²å–è¤‡é›œåº¦ç­‰ç´š"""
        if score < 0.3:
            return "ç°¡å–®"
        elif score < 0.6:
            return "ä¸­ç­‰"
        elif score < 0.8:
            return "è¤‡é›œ"
        else:
            return "é«˜åº¦è¤‡é›œ"

    def _calculate_efficiency_score(self, task_analysis: dict, result: dict) -> float:
        """è¨ˆç®—è™•ç†æ•ˆç‡åˆ†æ•¸"""
        base_score = 0.7

        # æ ¹æ“šçµ±ä¸€æ§åˆ¶åŠ åˆ†
        if result.get("unified_control", False):
            base_score += 0.15

        # æ ¹æ“šç„¡è¡çªåŠ åˆ†
        if result.get("ai_conflicts", 0) == 0:
            base_score += 0.1

        # æ ¹æ“šæˆåŠŸç‹€æ…‹åŠ åˆ†
        if result.get("status") == "success":
            base_score += 0.05

        return min(base_score, 1.0)

    def _extract_recommendations(self, ai_analysis: dict) -> list[str]:
        """å¾ AI åˆ†æä¸­æå–å»ºè­°"""
        try:
            analysis_text = ai_analysis.get("tool_result", {}).get("analysis", "")

            # ç°¡å–®çš„å»ºè­°æå–é‚è¼¯
            recommendations = []
            if "å»ºè­°" in analysis_text:
                recommendations.append("åƒè€ƒ AI åˆ†æå»ºè­°é€²è¡Œå„ªåŒ–")
            if "æ”¹å–„" in analysis_text:
                recommendations.append("è€ƒæ…®å¯¦æ–½æ”¹å–„æªæ–½")
            if "å„ªåŒ–" in analysis_text:
                recommendations.append("æ¢ç´¢é€²ä¸€æ­¥å„ªåŒ–æ–¹æ¡ˆ")

            return recommendations if recommendations else ["ç¹¼çºŒä¿æŒç•¶å‰è™•ç†æ–¹å¼"]

        except Exception:
            return ["è«‹äººå·¥æª¢æŸ¥è™•ç†çµæœ"]

    def _identify_learning_points(
        self, user_input: str, task_analysis: dict, result: dict
    ) -> list[str]:
        """è­˜åˆ¥å­¸ç¿’è¦é»"""
        learning_points = []

        # æ ¹æ“šè™•ç†æ–¹å¼è­˜åˆ¥å­¸ç¿’é»
        method = result.get("processing_method", "")
        if "direct" in method:
            learning_points.append("ä¸»æ§ AI èƒ½å¤ ç¨ç«‹è™•ç†æ­¤é¡ç°¡å–®ä»»å‹™")
        elif "coordinated" in method:
            learning_points.append("å”èª¿è™•ç†æ¨¡å¼åœ¨å¾©é›œä»»å‹™ä¸­æ•ˆæœè‰¯å¥½")
        elif "multi_ai" in method:
            learning_points.append("å¤š AI å”åŒèƒ½è™•ç†é«˜è¤‡é›œåº¦ä»»å‹™")

        # æ ¹æ“šè¤‡é›œåº¦è­˜åˆ¥å­¸ç¿’é»
        complexity = task_analysis.get("complexity_score", 0)
        if complexity > 0.7:
            learning_points.append("é«˜è¤‡é›œåº¦ä»»å‹™éœ€è¦æ›´ç²¾ç´°çš„åˆ†æ")
        elif complexity < 0.3:
            learning_points.append("ç°¡å–®ä»»å‹™å¯ä»¥é€²ä¸€æ­¥è‡ªå‹•åŒ–")

        return learning_points

    def _create_brief_summary(self, summary: dict) -> dict:
        """å‰µå»ºç°¡è¦æ‘˜è¦"""
        return {
            "type": "ç°¡è¦æ‘˜è¦",
            "status": summary["basic_info"].get("success_rate", 0) > 0.5,
            "method": summary["processing_summary"]["method_used"],
            "efficiency": summary["processing_summary"]["efficiency_score"],
        }

    def _enhance_detailed_summary(self, summary: dict, result: dict) -> dict:
        """å¢å¼·è©³ç´°æ‘˜è¦"""
        summary["detailed_analysis"] = {
            "processing_steps": self._extract_processing_steps(result),
            "resource_usage": self._estimate_resource_usage(result),
            "improvement_potential": self._assess_improvement_potential(summary),
            "technical_details": {
                "ai_components_used": list(self.ai_components.keys()),
                "coordination_method": result.get("processing_method", "unknown"),
                "decision_confidence": summary["ai_insights"]["confidence"],
            },
        }
        return summary

    def _extract_processing_steps(self, result: dict) -> list[str]:
        """æå–è™•ç†æ­¥é©Ÿ"""
        method = result.get("processing_method", "")

        if method == "direct_master_ai":
            return ["æ¥æ”¶è«‹æ±‚", "ä¸»æ§ AI ç›´æ¥åˆ†æ", "ç”Ÿæˆçµæœ", "è¿”å›ç­”æ¡ˆ"]
        elif method == "coordinated_code_fixing":
            return [
                "æ¥æ”¶è«‹æ±‚",
                "ä¸»æ§ AI é è™•ç†",
                "å”èª¿ä¿®å¾©çµ„ä»¶",
                "é©—è­‰çµæœ",
                "è¿”å›ä¿®å¾©æ–¹æ¡ˆ",
            ]
        elif method == "coordinated_detection":
            return [
                "æ¥æ”¶è«‹æ±‚",
                "è¦åŠƒæª¢æ¸¬ç­–ç•¥",
                "åŸ·è¡Œå¤šå¼•æ“æª¢æ¸¬",
                "æ•´åˆçµæœ",
                "è¿”å›æª¢æ¸¬å ±å‘Š",
            ]
        elif method == "multi_ai_coordination":
            return [
                "æ¥æ”¶è«‹æ±‚",
                "åˆ¶å®šå”åŒè¨ˆç•«",
                "å¤š AI å”åŒåŸ·è¡Œ",
                "æœ€çµ‚æ•´åˆ",
                "è¿”å›ç¶œåˆçµæœ",
            ]
        else:
            return ["æ¥æ”¶è«‹æ±‚", "åˆ†æè™•ç†", "ç”Ÿæˆçµæœ"]

    def _estimate_resource_usage(self, result: dict) -> dict:
        """ä¼°ç®—è³‡æºä½¿ç”¨æƒ…æ³"""
        method = result.get("processing_method", "")

        usage_map = {
            "direct_master_ai": {"cpu": "low", "memory": "low", "ai_calls": 1},
            "coordinated_code_fixing": {
                "cpu": "medium",
                "memory": "medium",
                "ai_calls": 3,
            },
            "coordinated_detection": {"cpu": "high", "memory": "medium", "ai_calls": 4},
            "multi_ai_coordination": {"cpu": "high", "memory": "high", "ai_calls": 5},
        }

        return usage_map.get(
            method, {"cpu": "unknown", "memory": "unknown", "ai_calls": 1}
        )

    def _assess_improvement_potential(self, summary: dict) -> str:
        """è©•ä¼°æ”¹å–„æ½›åŠ›"""
        efficiency = summary["processing_summary"]["efficiency_score"]

        if efficiency >= 0.9:
            return "å„ªç§€ï¼Œå¾®èª¿å³å¯"
        elif efficiency >= 0.7:
            return "è‰¯å¥½ï¼Œæœ‰å°å¹…æ”¹å–„ç©ºé–“"
        elif efficiency >= 0.5:
            return "å¯æ¥å—ï¼Œéœ€è¦å„ªåŒ–"
        else:
            return "éœ€è¦é‡å¤§æ”¹å–„"

    def _record_summary_history(self, summary: dict):
        """è¨˜éŒ„æ‘˜è¦æ­·å²"""
        self.summary_history.append(summary)

        # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœ
        if len(self.summary_history) > 50:
            self.summary_history.pop(0)

    def _record_unified_decision(self, user_input: str, analysis: dict, result: dict):
        """è¨˜éŒ„çµ±ä¸€æ±ºç­–æ­·å²"""
        decision_record = {
            "timestamp": asyncio.get_event_loop().time(),
            "user_input": user_input,
            "task_analysis": analysis,
            "processing_method": result.get("processing_method"),
            "ai_conflicts_avoided": result.get("ai_conflicts", 0) == 0,
            "unified_control_maintained": result.get("unified_control", False),
        }

        self.decision_history.append(decision_record)

        if len(self.decision_history) > 100:  # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœ
            self.decision_history.pop(0)

    def get_ai_summary_statistics(self) -> dict[str, Any]:
        """ç²å– AI æ‘˜è¦çµ±è¨ˆ"""
        if not self.summary_history:
            return {"no_summaries": True}

        total_summaries = len(self.summary_history)
        success_summaries = sum(
            1
            for s in self.summary_history
            if s.get("basic_info", {}).get("success_rate", 0) > 0.5
        )

        # çµ±è¨ˆè«‹æ±‚é¡å‹åˆ†å¸ƒ
        request_types = {}
        efficiency_scores = []

        for summary in self.summary_history:
            req_type = summary.get("basic_info", {}).get("request_type", "unknown")
            request_types[req_type] = request_types.get(req_type, 0) + 1

            efficiency = summary.get("processing_summary", {}).get(
                "efficiency_score", 0
            )
            if efficiency > 0:
                efficiency_scores.append(efficiency)

        avg_efficiency = (
            sum(efficiency_scores) / len(efficiency_scores) if efficiency_scores else 0
        )

        return {
            "summary_statistics": {
                "total_summaries": total_summaries,
                "success_rate": (
                    success_summaries / total_summaries if total_summaries > 0 else 0
                ),
                "average_efficiency": round(avg_efficiency, 3),
            },
            "request_type_distribution": request_types,
            "efficiency_analysis": {
                "min_efficiency": min(efficiency_scores) if efficiency_scores else 0,
                "max_efficiency": max(efficiency_scores) if efficiency_scores else 0,
                "avg_efficiency": avg_efficiency,
            },
            "recommendations": self._generate_summary_recommendations(
                avg_efficiency, request_types
            ),
        }

    def _generate_summary_recommendations(
        self, avg_efficiency: float, request_types: dict
    ) -> list[str]:
        """ç”Ÿæˆæ‘˜è¦åˆ†æå»ºè­°"""
        recommendations = []

        if avg_efficiency < 0.6:
            recommendations.append("å»ºè­°å„ªåŒ–è™•ç†æ•ˆç‡ï¼Œç›®æ¨™æå‡è‡³ 70% ä»¥ä¸Š")
        elif avg_efficiency < 0.8:
            recommendations.append("è™•ç†æ•ˆç‡è‰¯å¥½ï¼Œå¯é€²ä¸€æ­¥å¾®èª¿è‡³ 85% ä»¥ä¸Š")
        else:
            recommendations.append("è™•ç†æ•ˆç‡å„ªç§€ï¼Œä¿æŒç•¶å‰æ°´æº–")

        # åˆ†ææœ€å¸¸è¦‹çš„è«‹æ±‚é¡å‹
        if request_types:
            most_common = max(request_types, key=request_types.get)
            recommendations.append(f"æœ€å¸¸è™•ç†ã€Œ{most_common}ã€é¡å‹è«‹æ±‚ï¼Œå¯é‡å°æ€§å„ªåŒ–")

        return recommendations

    def configure_summary_settings(self, **settings) -> dict[str, Any]:
        """é…ç½®æ‘˜è¦ç”Ÿæˆè¨­å®š"""
        old_config = self.summary_config.copy()

        # æ›´æ–°é…ç½®
        for key, value in settings.items():
            if key in self.summary_config:
                self.summary_config[key] = value

        logger.info(f"ğŸ“‹ æ‘˜è¦é…ç½®å·²æ›´æ–°: {settings}")

        return {
            "status": "success",
            "old_config": old_config,
            "new_config": self.summary_config,
            "changes_applied": list(settings.keys()),
        }

    def get_latest_summaries(self, count: int = 5) -> list[dict]:
        """ç²å–æœ€è¿‘çš„æ‘˜è¦è¨˜éŒ„"""
        return self.summary_history[-count:] if self.summary_history else []

    def export_summary_report(self, format_type: str = "json") -> dict[str, Any]:
        """åŒ¯å‡ºæ‘˜è¦å ±å‘Š"""
        report_data = {
            "report_metadata": {
                "generated_at": datetime.now().isoformat(),
                "total_summaries": len(self.summary_history),
                "summary_period": "å…¨éƒ¨æ­·å²è¨˜éŒ„",
                "format": format_type,
            },
            "summary_statistics": self.get_ai_summary_statistics(),
            "control_statistics": self.get_control_statistics(),
            "recent_summaries": self.get_latest_summaries(10),
            "configuration": {
                "summary_config": self.summary_config,
                "ai_components": list(self.ai_components.keys()),
            },
        }

        logger.info(f"ğŸ“Š æ‘˜è¦å ±å‘Šå·²ç”Ÿæˆ ({format_type} æ ¼å¼)")

        return {
            "status": "success",
            "report_data": report_data,
            "export_format": format_type,
            "file_suggestion": f"aiva_summary_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{format_type}",
        }

    async def generate_comprehensive_summary(
        self, time_period: str = "recent"
    ) -> dict[str, Any]:
        """ç”Ÿæˆç¶œåˆæ‘˜è¦åˆ†æ"""
        logger.info(f"ğŸ“ˆ ç”Ÿæˆç¶œåˆæ‘˜è¦åˆ†æ (æœŸé–“: {time_period})")

        # é¸æ“‡åˆ†ææ™‚é–“ç¯„åœ
        if time_period == "recent":
            data_to_analyze = (
                self.summary_history[-10:]
                if len(self.summary_history) >= 10
                else self.summary_history
            )
        elif time_period == "all":
            data_to_analyze = self.summary_history
        else:
            data_to_analyze = self.summary_history[-5:]  # é»˜èªæœ€è¿‘5å€‹

        if not data_to_analyze:
            return {"error": "æ²’æœ‰å¯åˆ†æçš„æ‘˜è¦æ•¸æ“š"}

        # ä½¿ç”¨ä¸»æ§ AI é€²è¡Œç¶œåˆåˆ†æ
        analysis_prompt = f"""
        è«‹å°ä»¥ä¸‹ AIVA AI ç³»çµ±çš„è™•ç†æ‘˜è¦é€²è¡Œç¶œåˆåˆ†æ:
        
        åˆ†ææ•¸æ“šé‡: {len(data_to_analyze)} æ¢è¨˜éŒ„
        æ™‚é–“æœŸé–“: {time_period}
        
        æ‘˜è¦æ•¸æ“š: {json.dumps(data_to_analyze, ensure_ascii=False, indent=2)}
        
        è«‹æä¾›:
        1. ç³»çµ±æ€§èƒ½è¶¨å‹¢åˆ†æ
        2. è™•ç†æ•ˆç‡è©•ä¼°
        3. å¸¸è¦‹å•é¡Œæ¨¡å¼
        4. æ”¹å–„å»ºè­°
        5. æœªä¾†ç™¼å±•æ–¹å‘
        """

        try:
            ai_comprehensive_analysis = self.master_ai.invoke(analysis_prompt)

            comprehensive_summary = {
                "analysis_metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "data_points": len(data_to_analyze),
                    "time_period": time_period,
                    "analysis_depth": "comprehensive",
                },
                "ai_insights": ai_comprehensive_analysis,
                "quantitative_analysis": self._perform_quantitative_analysis(
                    data_to_analyze
                ),
                "trend_analysis": self._analyze_trends(data_to_analyze),
                "recommendations": self._generate_comprehensive_recommendations(
                    data_to_analyze
                ),
            }

            # è¨˜éŒ„ç¶œåˆåˆ†æ
            self.summary_history.append(
                {
                    "type": "comprehensive_analysis",
                    "timestamp": datetime.now().isoformat(),
                    "analysis_result": comprehensive_summary,
                }
            )

            logger.info("âœ… ç¶œåˆæ‘˜è¦åˆ†æå®Œæˆ")
            return comprehensive_summary

        except Exception as e:
            logger.error(f"âŒ ç¶œåˆæ‘˜è¦åˆ†æå¤±æ•—: {e}")
            return {"error": f"ç¶œåˆåˆ†æå¤±æ•—: {str(e)}"}

    def _perform_quantitative_analysis(self, summaries: list[dict]) -> dict:
        """åŸ·è¡Œå®šé‡åˆ†æ"""
        if not summaries:
            return {}

        efficiency_scores = []
        success_rates = []
        complexity_levels = []

        for summary in summaries:
            if "processing_summary" in summary:
                eff = summary["processing_summary"].get("efficiency_score", 0)
                if eff > 0:
                    efficiency_scores.append(eff)

            if "basic_info" in summary:
                sr = summary["basic_info"].get("success_rate", 0)
                success_rates.append(sr)

                cl = summary["basic_info"].get("complexity_level", "")
                if cl:
                    complexity_levels.append(cl)

        return {
            "efficiency": {
                "average": (
                    sum(efficiency_scores) / len(efficiency_scores)
                    if efficiency_scores
                    else 0
                ),
                "min": min(efficiency_scores) if efficiency_scores else 0,
                "max": max(efficiency_scores) if efficiency_scores else 0,
                "trend": (
                    "improving"
                    if len(efficiency_scores) > 2
                    and efficiency_scores[-1] > efficiency_scores[0]
                    else "stable"
                ),
            },
            "success_rate": {
                "average": (
                    sum(success_rates) / len(success_rates) if success_rates else 0
                ),
                "total_attempts": len(success_rates),
            },
            "complexity_distribution": {
                level: complexity_levels.count(level)
                for level in set(complexity_levels)
            },
        }

    def _analyze_trends(self, summaries: list[dict]) -> dict:
        """åˆ†æè¶¨å‹¢"""
        if len(summaries) < 3:
            return {"insufficient_data": True}

        recent = summaries[-3:]
        older = summaries[:-3] if len(summaries) > 3 else []

        # æ¯”è¼ƒæœ€è¿‘å’Œè¼ƒæ—©æœŸçš„è¡¨ç¾
        recent_avg_eff = sum(
            s.get("processing_summary", {}).get("efficiency_score", 0) for s in recent
        ) / len(recent)
        older_avg_eff = (
            sum(
                s.get("processing_summary", {}).get("efficiency_score", 0)
                for s in older
            )
            / len(older)
            if older
            else recent_avg_eff
        )

        trend_direction = (
            "improving"
            if recent_avg_eff > older_avg_eff
            else "declining" if recent_avg_eff < older_avg_eff else "stable"
        )

        return {
            "performance_trend": trend_direction,
            "recent_efficiency": recent_avg_eff,
            "historical_efficiency": older_avg_eff,
            "improvement_rate": abs(recent_avg_eff - older_avg_eff),
        }

    def _generate_comprehensive_recommendations(
        self, summaries: list[dict]
    ) -> list[str]:
        """ç”Ÿæˆç¶œåˆå»ºè­°"""
        recommendations = []

        # åˆ†ææ•ˆç‡åˆ†å¸ƒ
        efficiency_scores = [
            s.get("processing_summary", {}).get("efficiency_score", 0)
            for s in summaries
        ]
        avg_efficiency = (
            sum(efficiency_scores) / len(efficiency_scores) if efficiency_scores else 0
        )

        if avg_efficiency < 0.6:
            recommendations.append("ğŸ”§ ç³»çµ±æ•ˆç‡åä½ï¼Œå»ºè­°æª¢æŸ¥å’Œå„ªåŒ– AI çµ„ä»¶å”èª¿æ©Ÿåˆ¶")
        elif avg_efficiency > 0.85:
            recommendations.append("âœ¨ ç³»çµ±æ•ˆç‡å„ªç§€ï¼Œå¯è€ƒæ…®è™•ç†æ›´è¤‡é›œçš„ä»»å‹™")

        # åˆ†æè«‹æ±‚é¡å‹å¤šæ¨£æ€§
        request_types = [
            s.get("basic_info", {}).get("request_type", "") for s in summaries
        ]
        unique_types = len(set(request_types))

        if unique_types < 3:
            recommendations.append("ğŸ“ˆ å»ºè­°æ“´å±•è™•ç†æ›´å¤šé¡å‹çš„ä»»å‹™ä»¥æå‡ç³»çµ±é©æ‡‰æ€§")
        elif unique_types > 5:
            recommendations.append("ğŸ¯ ç³»çµ±è™•ç†å¤šæ¨£åŒ–ä»»å‹™èƒ½åŠ›å¼·ï¼Œå¯å°ˆæ³¨æ–¼æ·±åº¦å„ªåŒ–")

        return recommendations

    def get_control_statistics(self) -> dict[str, Any]:
        """ç²å–çµ±ä¸€æ§åˆ¶çµ±è¨ˆ"""
        if not self.decision_history:
            return {"no_decisions": True}

        total_decisions = len(self.decision_history)
        unified_decisions = sum(
            1 for d in self.decision_history if d["unified_control_maintained"]
        )
        conflict_free_decisions = sum(
            1 for d in self.decision_history if d["ai_conflicts_avoided"]
        )

        return {
            "total_decisions": total_decisions,
            "unified_control_rate": unified_decisions / total_decisions,
            "conflict_free_rate": conflict_free_decisions / total_decisions,
            "processing_methods": {
                method: sum(
                    1 for d in self.decision_history if d["processing_method"] == method
                )
                for method in {d["processing_method"] for d in self.decision_history}
            },
            "recommendation": (
                "çµ±ä¸€æ§åˆ¶æ•ˆæœè‰¯å¥½"
                if unified_decisions / total_decisions > 0.9
                else "éœ€è¦å„ªåŒ–çµ±ä¸€æ§åˆ¶"
            ),
        }


# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_unified_control():
    """å±•ç¤ºçµ±ä¸€ AI æ§åˆ¶çš„æ•ˆæœ"""
    print("ğŸ¯ AIVA çµ±ä¸€ AI æ§åˆ¶å±•ç¤º")
    print("=" * 40)

    controller = UnifiedAIController()

    test_requests = [
        "è®€å– app.py æª”æ¡ˆ",
        "ä¿®å¾© SQL æ³¨å…¥æ¼æ´",
        "åŸ·è¡Œå…¨é¢å®‰å…¨æƒæ",
        "å”èª¿ Go å’Œ Rust æ¨¡çµ„",
        "åˆ†æä¸¦å„ªåŒ–ç³»çµ±æ¶æ§‹",
    ]

    for request in test_requests:
        print(f"\nğŸ‘¤ ç”¨æˆ¶è«‹æ±‚: {request}")
        result = await controller.process_unified_request(request)
        print(f"ğŸ¤– è™•ç†æ–¹å¼: {result['processing_method']}")
        print(f"âœ… çµ±ä¸€æ§åˆ¶: {result['unified_control']}")
        print(f"ğŸ”„ AI è¡çª: {result['ai_conflicts']}")

        # é¡¯ç¤º AI æ‘˜è¦
        if "ai_summary" in result:
            summary = result["ai_summary"]
            print(
                f"ğŸ“‹ AI æ‘˜è¦: {summary.get('basic_info', {}).get('request_type', 'N/A')}"
            )
            print(
                f"âš¡ æ•ˆç‡åˆ†æ•¸: {summary.get('processing_summary', {}).get('efficiency_score', 0):.2f}"
            )

    print("\nğŸ“Š çµ±ä¸€æ§åˆ¶çµ±è¨ˆ:")
    stats = controller.get_control_statistics()
    print(f"çµ±ä¸€æ§åˆ¶ç‡: {stats['unified_control_rate']:.1%}")
    print(f"ç„¡è¡çªç‡: {stats['conflict_free_rate']:.1%}")
    print(f"å»ºè­°: {stats['recommendation']}")

    print("\nğŸ“ˆ æ‘˜è¦çµ±è¨ˆ:")
    summary_stats = controller.get_ai_summary_statistics()
    if "no_summaries" not in summary_stats:
        print(f"æ‘˜è¦ç¸½æ•¸: {summary_stats['summary_statistics']['total_summaries']}")
        print(
            f"å¹³å‡æ•ˆç‡: {summary_stats['summary_statistics']['average_efficiency']:.2f}"
        )
        print(f"æˆåŠŸç‡: {summary_stats['summary_statistics']['success_rate']:.1%}")


if __name__ == "__main__":
    asyncio.run(demonstrate_unified_control())
