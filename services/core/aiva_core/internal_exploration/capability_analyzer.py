"""Capability Analyzer - ËÉΩÂäõÂàÜÊûêÂô® (Â¢ûÂº∑Áâà)

Ë≠òÂà•ÂíåÂàÜÊûê AIVA Á≥ªÁµ±ÁöÑÂäüËÉΩËÉΩÂäõ,ÊîØÊè¥Â§öË™ûË®ÄÂàÜÊûê:
- Python: AST Ëß£Êûê @register_capability Ë£ùÈ£æÂô®
- Go/Rust/TypeScript: ‰ΩøÁî® language_extractors Ê≠£ÂâáÊèêÂèñ

Â¢ûÂº∑ÂäüËÉΩ:
- ÂÆåÂñÑÁöÑÈåØË™§ËôïÁêÜÂíåËøΩËπ§
- Ë©≥Á¥∞ÁöÑÊèêÂèñÂ†±Âëä
- Êñá‰ª∂Â§ßÂ∞èÈ©óË≠â
- Á∑®Á¢ºÈåØË™§ËôïÁêÜ

ÈÅµÂæ™ aiva_common ‰øÆÂæ©Ë¶èÁØÑ:
- ‰ΩøÁî®Ê®ôÊ∫ñË£ùÈ£æÂô®Ê®°Âºè
- Áµ±‰∏ÄÁöÑËÉΩÂäõÂÖÉÊï∏ÊìöÊ†ºÂºè
"""

import ast
import logging
from pathlib import Path
from typing import Any
from dataclasses import dataclass
from datetime import datetime, timezone

from .language_extractors import get_extractor

logger = logging.getLogger(__name__)


@dataclass
class ExtractionError:
    """ÊèêÂèñÈåØË™§Ë®òÈåÑ"""
    file_path: str
    language: str
    error_type: str
    error_message: str
    timestamp: str


class CapabilityAnalyzer:
    """ËÉΩÂäõÂàÜÊûêÂô®
    
    ËÅ∑Ë≤¨ÔºöË≠òÂà•Á≥ªÁµ±‰∏≠ÊâÄÊúâË®ªÂÜäÁöÑËÉΩÂäõÂáΩÊï∏ÔºåÊèêÂèñÂÖ∂ÂÖÉÊï∏Êìö
    
    Ë≠òÂà•ÁõÆÊ®ôÔºö
    - @register_capability Ë£ùÈ£æÁöÑÂáΩÊï∏
    - @capability Ë£ùÈ£æÁöÑÂáΩÊï∏
    - ÂåÖÂê´ 'capability' ÈóúÈçµÂ≠óÁöÑË£ùÈ£æÂô®
    """
    
    def __init__(self):
        """ÂàùÂßãÂåñËÉΩÂäõÂàÜÊûêÂô® (Â¢ûÂº∑Áâà)"""
        self.capabilities_cache: dict[str, list[dict]] = {}
        self.extraction_errors: list[ExtractionError] = []  # ‚úÖ ÈåØË™§ËøΩËπ§
        self.stats = {
            "total_files": 0,
            "successful_files": 0,
            "failed_files": 0,
            "skipped_files": 0
        }
        logger.info("CapabilityAnalyzer initialized (Enhanced Mode)")
    
    async def analyze_capabilities(self, modules_info: dict) -> list[dict[str, Any]]:
        """ÂàÜÊûêÊ®°ÁµÑ‰∏≠ÁöÑËÉΩÂäõÂáΩÊï∏
        
        Args:
            modules_info: ModuleExplorer ËøîÂõûÁöÑÊ®°ÁµÑË≥áË®ä
            
        Returns:
            ËÉΩÂäõÂàóË°®:
            [
                {
                    "name": str,
                    "module": str,
                    "description": str,
                    "parameters": list,
                    "file_path": str,
                    "return_type": str | None,
                    "is_async": bool,
                    "decorators": list
                }
            ]
        """
        logger.info(f"üîç Starting capability analysis for {len(modules_info)} modules...")
        capabilities = []
        
        for module_name, module_data in modules_info.items():
            logger.info(f"  Analyzing module: {module_name}")
            module_path = Path(module_data["path"])
            
            for file_info in module_data["files"]:
                file_path = module_path / file_info["path"]
                
                # Ë∑≥ÈÅé __init__.py
                if file_path.name == "__init__.py":
                    continue
                
                caps = await self._extract_capabilities_from_file(file_path, module_name)
                capabilities.extend(caps)
        
        logger.info(f"‚úÖ Capability analysis completed: {len(capabilities)} capabilities found")
        return capabilities
    
    async def _extract_capabilities_from_file(self, file_path: Path, module: str) -> list[dict]:
        """ÂæûÊñá‰ª∂‰∏≠ÊèêÂèñËÉΩÂäõ (Â¢ûÂº∑ÈåØË™§ËôïÁêÜÁâà)
        
        Args:
            file_path: Êñá‰ª∂Ë∑ØÂæë (.py/.go/.rs/.ts/.js)
            module: ÊâÄÂ±¨Ê®°ÁµÑÂêçÁ®±
            
        Returns:
            ËÉΩÂäõÂàóË°®
        """
        self.stats["total_files"] += 1
        language = "unknown"
        
        try:
            # ‚úÖ È©óË≠âÊñá‰ª∂Â≠òÂú®
            if not file_path.exists():
                logger.error(f"  ‚ùå File not found: {file_path}")
                self._record_error(
                    file_path, "unknown", "FileNotFoundError",
                    f"File does not exist: {file_path}"
                )
                self.stats["failed_files"] += 1
                return []
            
            # ‚úÖ È©óË≠âÊñá‰ª∂Â§ßÂ∞è (Ë∑≥ÈÅéÈÅéÂ§ßÊñá‰ª∂)
            file_size = file_path.stat().st_size
            if file_size > 5 * 1024 * 1024:  # 5MB
                logger.warning(f"  ‚ö†Ô∏è  Skipping large file: {file_path.name} ({file_size / 1024 / 1024:.1f}MB)")
                self.stats["skipped_files"] += 1
                return []
            
            # Ê™¢Ê∏¨Ë™ûË®Ä
            language = self._detect_language(file_path)
            if language == "unknown":
                logger.warning(f"  ‚ö†Ô∏è  Unknown file type: {file_path.suffix}")
                self.stats["skipped_files"] += 1
                return []
            
            # ÊèêÂèñËÉΩÂäõ
            if language == "python":
                capabilities = self._extract_python_capabilities(file_path, module)
            else:
                capabilities = self._extract_non_python_capabilities(file_path, module, language)
            
            self.stats["successful_files"] += 1
            return capabilities
            
        except PermissionError as e:
            logger.error(f"  ‚ùå Permission denied: {file_path.name}")
            self._record_error(file_path, language, "PermissionError", str(e))
            self.stats["failed_files"] += 1
            return []
        
        except UnicodeDecodeError as e:
            logger.error(f"  ‚ùå Encoding error: {file_path.name}")
            self._record_error(file_path, language, "UnicodeDecodeError", str(e))
            self.stats["failed_files"] += 1
            return []
        
        except Exception as e:
            logger.exception(f"  ‚ùå Unexpected error extracting from {file_path.name}: {e}")
            self._record_error(file_path, language, type(e).__name__, str(e))
            self.stats["failed_files"] += 1
            return []
    
    def _detect_language(self, file_path: Path) -> str:
        """Ê™¢Ê∏¨Êñá‰ª∂Ë™ûË®Ä
        
        Args:
            file_path: Êñá‰ª∂Ë∑ØÂæë
            
        Returns:
            Ë™ûË®ÄÂêçÁ®±: python, go, rust, typescript, javascript
        """
        suffix = file_path.suffix.lower()
        language_map = {
            ".py": "python",
            ".go": "go",
            ".rs": "rust",
            ".ts": "typescript",
            ".js": "javascript"
        }
        return language_map.get(suffix, "unknown")
    
    def _extract_python_capabilities(self, file_path: Path, module: str) -> list[dict]:
        """Âæû Python Êñá‰ª∂ÊèêÂèñËÉΩÂäõ (‰ΩøÁî® AST)
        
        Args:
            file_path: Python Êñá‰ª∂Ë∑ØÂæë
            module: ÊâÄÂ±¨Ê®°ÁµÑÂêçÁ®±
            
        Returns:
            ËÉΩÂäõÂàóË°®
        """
        capabilities = []
        
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
                tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # Ê™¢Êü•ÊòØÂê¶ÊúâËÉΩÂäõË£ùÈ£æÂô®
                    if self._has_capability_decorator(node):
                        cap = self._extract_capability_info(node, file_path, module)
                        capabilities.append(cap)
            
            if capabilities:
                logger.debug(f"  Found {len(capabilities)} Python capabilities in {file_path.name}")
            
        except SyntaxError as e:
            logger.warning(f"  Syntax error in {file_path}: {e}")
        except Exception as e:
            logger.error(f"  Failed to parse {file_path}: {e}")
        
        return capabilities
    
    def _extract_non_python_capabilities(
        self, 
        file_path: Path, 
        module: str,
        language: str
    ) -> list[dict]:
        """ÂæûÈùû Python Êñá‰ª∂ÊèêÂèñËÉΩÂäõ (‰ΩøÁî® language_extractors)
        
        Args:
            file_path: Êñá‰ª∂Ë∑ØÂæë
            module: ÊâÄÂ±¨Ê®°ÁµÑÂêçÁ®±
            language: Ë™ûË®ÄÂêçÁ®±
            
        Returns:
            ËÉΩÂäõÂàóË°®
        """
        try:
            # Áç≤ÂèñÂ∞çÊáâË™ûË®ÄÁöÑÊèêÂèñÂô®
            extractor = get_extractor(language)
            if not extractor:
                logger.warning(f"  No extractor available for language: {language}")
                return []
            
            # ËÆÄÂèñÊñá‰ª∂ÂÖßÂÆπ
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
            
            # ‰ΩøÁî®ÊèêÂèñÂô®ÊèêÂèñËÉΩÂäõ
            capabilities = extractor.extract_capabilities(content, str(file_path))
            
            # Ê∑ªÂä† module ‰ø°ÊÅØ (extractor ÂèØËÉΩÊ≤íÊúâË®≠ÁΩÆ)
            for cap in capabilities:
                if "module" not in cap or not cap["module"]:
                    cap["module"] = module
            
            if capabilities:
                logger.debug(f"  Found {len(capabilities)} {language} capabilities in {file_path.name}")
            
            return capabilities
            
        except Exception as e:
            logger.error(f"  Failed to extract from {file_path}: {e}")
            return []
    
    def _has_capability_decorator(self, node: ast.FunctionDef) -> bool:
        """Ê™¢Êü•ÂáΩÊï∏ÊòØÂê¶ÁÇ∫ËÉΩÂäõÂáΩÊï∏
        
        Á≠ñÁï•Ôºö
        1. Êúâ @capability Ë£ùÈ£æÂô®ÁöÑÂáΩÊï∏ÔºàÊòéÁ¢∫Ê®ôË®òÔºâ
        2. async def ÂáΩÊï∏ÔºàÁï∞Ê≠•ËÉΩÂäõÔºâ
        3. ÂÖ¨ÈñãÂáΩÊï∏ÔºàÈùû _ ÈñãÈ†≠Ôºâ‰∏îÊúâÊñáÊ™îÂ≠ó‰∏≤
        
        Args:
            node: AST ÂáΩÊï∏ÂÆöÁæ©ÁØÄÈªû
            
        Returns:
            ÊòØÂê¶ÁÇ∫ËÉΩÂäõÂáΩÊï∏
        """
        # Á≠ñÁï• 1: Ê™¢Êü•Ë£ùÈ£æÂô®
        if self._check_decorator_for_capability(node):
            return True
        
        # Á≠ñÁï• 2 & 3: ÂÖ¨ÈñãÁöÑÁï∞Ê≠•ÂáΩÊï∏ÊàñÊúâÊñáÊ™îÁöÑÂáΩÊï∏
        if node.name.startswith('_'):
            return False
            
        # Áï∞Ê≠•ÂáΩÊï∏
        if isinstance(node, ast.AsyncFunctionDef):
            return True
        
        # ÊúâÂØ¶Ë≥™ÊÄßÊñáÊ™îÁöÑÂáΩÊï∏
        docstring = ast.get_docstring(node)
        return bool(docstring and len(docstring) > 20)
    
    def _check_decorator_for_capability(self, node: ast.FunctionDef) -> bool:
        """Ê™¢Êü•Ë£ùÈ£æÂô®ÊòØÂê¶ÂåÖÂê´ capability
        
        Args:
            node: AST ÂáΩÊï∏ÂÆöÁæ©ÁØÄÈªû
            
        Returns:
            ÊòØÂê¶Êúâ capability Áõ∏ÈóúË£ùÈ£æÂô®
        """
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Name):
                if "capability" in decorator.id.lower():
                    return True
            elif isinstance(decorator, ast.Call):
                if isinstance(decorator.func, ast.Name):
                    if "capability" in decorator.func.id.lower():
                        return True
                elif isinstance(decorator.func, ast.Attribute):
                    if "capability" in decorator.func.attr.lower():
                        return True
        return False
    
    def _extract_capability_info(
        self, 
        node: ast.FunctionDef, 
        file_path: Path,
        module: str
    ) -> dict[str, Any]:
        """ÊèêÂèñËÉΩÂäõË©≥Á¥∞Ë≥áË®ä
        
        Args:
            node: AST ÂáΩÊï∏ÂÆöÁæ©ÁØÄÈªû
            file_path: Êñá‰ª∂Ë∑ØÂæë
            module: Ê®°ÁµÑÂêçÁ®±
            
        Returns:
            ËÉΩÂäõË≥áË®äÂ≠óÂÖ∏
        """
        # ÊèêÂèñÂèÉÊï∏
        parameters = []
        for arg in node.args.args:
            param_info = {
                "name": arg.arg,
                "annotation": ast.unparse(arg.annotation) if arg.annotation else None
            }
            parameters.append(param_info)
        
        # ÊèêÂèñËøîÂõûÈ°ûÂûã
        return_type = None
        if node.returns:
            try:
                return_type = ast.unparse(node.returns)
            except Exception:
                return_type = "Unknown"
        
        # ÊèêÂèñË£ùÈ£æÂô®ÂêçÁ®±
        decorators = []
        for decorator in node.decorator_list:
            try:
                decorators.append(ast.unparse(decorator))
            except Exception:
                decorators.append("Unknown")
        
        # ÊèêÂèñÊñáÊ™îÂ≠ó‰∏≤
        docstring = ast.get_docstring(node) or ""
        description = docstring.split("\n")[0] if docstring else f"Function: {node.name}"
        
        return {
            "name": node.name,
            "language": "python",  # ‚úÖ Ê∑ªÂä†Ë™ûË®ÄÊ¨Ñ‰Ωç
            "module": module,
            "description": description,
            "parameters": parameters,
            "file_path": str(file_path),
            "return_type": return_type,
            "is_async": isinstance(node, ast.AsyncFunctionDef) or any(
                isinstance(n, ast.AsyncFunctionDef) for n in ast.walk(node)
            ),
            "decorators": decorators,
            "docstring": docstring,
            "line_number": node.lineno
        }
    
    def get_capabilities_by_module(self, capabilities: list[dict]) -> dict[str, list[dict]]:
        """ÊåâÊ®°ÁµÑÂàÜÁµÑËÉΩÂäõ
        
        Args:
            capabilities: ËÉΩÂäõÂàóË°®
            
        Returns:
            ÊåâÊ®°ÁµÑÂàÜÁµÑÁöÑÂ≠óÂÖ∏
        """
        grouped = {}
        
        for cap in capabilities:
            module = cap["module"]
            if module not in grouped:
                grouped[module] = []
            grouped[module].append(cap)
        
        return grouped
    
    def generate_capability_summary(self, capabilities: list[dict]) -> str:
        """ÁîüÊàêËÉΩÂäõÊëòË¶ÅÂ†±Âëä
        
        Args:
            capabilities: ËÉΩÂäõÂàóË°®
            
        Returns:
            ÂèØËÆÄÁöÑÊëòË¶ÅÂ≠ó‰∏≤
        """
        if not capabilities:
            return "No capabilities found"
        
        grouped = self.get_capabilities_by_module(capabilities)
        
        lines = [f"Total Capabilities: {len(capabilities)}\n"]
        
        for module, caps in grouped.items():
            lines.append(f"\nModule: {module} ({len(caps)} capabilities)")
            for cap in caps:
                params = ", ".join(p["name"] for p in cap["parameters"])
                lines.append(f"  - {cap['name']}({params})")
                if cap["description"]:
                    lines.append(f"    {cap['description'][:80]}")
        
        return "\n".join(lines)
    
    def _record_error(
        self,
        file_path: Path,
        language: str,
        error_type: str,
        error_message: str
    ):
        """Ë®òÈåÑÊèêÂèñÈåØË™§
        
        Args:
            file_path: Êñá‰ª∂Ë∑ØÂæë
            language: Ë™ûË®ÄÂêçÁ®±
            error_type: ÈåØË™§È°ûÂûã
            error_message: ÈåØË™§Ë®äÊÅØ
        """
        error = ExtractionError(
            file_path=str(file_path),
            language=language,
            error_type=error_type,
            error_message=error_message,
            timestamp=datetime.now(timezone.utc).isoformat()
        )
        self.extraction_errors.append(error)
    
    def get_extraction_report(self) -> dict:
        """Áç≤ÂèñË©≥Á¥∞ÁöÑÊèêÂèñÂ†±Âëä
        
        Returns:
            ÂåÖÂê´Áµ±Ë®àÂíåÈåØË™§Ë©≥ÊÉÖÁöÑÂ†±Âëä
        """
        return {
            "statistics": self.stats,
            "success_rate": (
                self.stats["successful_files"] / self.stats["total_files"] * 100
                if self.stats["total_files"] > 0 else 0
            ),
            "total_errors": len(self.extraction_errors),
            "errors_by_type": self._group_errors_by_type(),
            "errors_by_language": self._group_errors_by_language(),
            "recent_errors": [
                {
                    "file": err.file_path,
                    "language": err.language,
                    "type": err.error_type,
                    "message": err.error_message[:100]  # Êà™Êñ∑Èï∑Ë®äÊÅØ
                }
                for err in self.extraction_errors[:10]  # Ââç 10 ÂÄãÈåØË™§
            ]
        }
    
    def _group_errors_by_type(self) -> dict[str, int]:
        """ÊåâÈåØË™§È°ûÂûãÂàÜÁµÑ
        
        Returns:
            ÈåØË™§È°ûÂûãÁµ±Ë®àÂ≠óÂÖ∏
        """
        error_counts = {}
        for err in self.extraction_errors:
            error_counts[err.error_type] = error_counts.get(err.error_type, 0) + 1
        return error_counts
    
    def _group_errors_by_language(self) -> dict[str, int]:
        """ÊåâË™ûË®ÄÂàÜÁµÑÈåØË™§
        
        Returns:
            Ë™ûË®ÄÈåØË™§Áµ±Ë®àÂ≠óÂÖ∏
        """
        lang_counts = {}
        for err in self.extraction_errors:
            lang_counts[err.language] = lang_counts.get(err.language, 0) + 1
        return lang_counts
    
    def print_extraction_report(self):
        """ÊâìÂç∞ÊèêÂèñÂ†±Âëä (ÁæéÂåñËº∏Âá∫)"""
        report = self.get_extraction_report()
        
        logger.info("\n" + "=" * 60)
        logger.info("üìä Capability Extraction Report")
        logger.info("=" * 60)
        
        stats = report["statistics"]
        logger.info("\nüìÅ Files Processed:")
        logger.info(f"  Total:      {stats['total_files']}")
        logger.info(f"  ‚úÖ Success:  {stats['successful_files']}")
        logger.info(f"  ‚ùå Failed:   {stats['failed_files']}")
        logger.info(f"  ‚ö†Ô∏è  Skipped:  {stats['skipped_files']}")
        logger.info(f"  Success Rate: {report['success_rate']:.1f}%")
        
        if report["total_errors"] > 0:
            logger.warning(f"\n‚ö†Ô∏è  Errors: {report['total_errors']}")
            logger.warning("\nBy Type:")
            for err_type, count in report["errors_by_type"].items():
                logger.warning(f"  - {err_type}: {count}")
            
            if report["errors_by_language"]:
                logger.warning("\nBy Language:")
                for lang, count in report["errors_by_language"].items():
                    logger.warning(f"  - {lang}: {count}")
        
        logger.info("=" * 60 + "\n")
