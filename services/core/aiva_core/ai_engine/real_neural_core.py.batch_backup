#!/usr/bin/env python3
"""
çœŸå¯¦çš„ç¥ç¶“ç¶²è·¯æ ¸å¿ƒ - æ›¿æ›AIVAçš„å‡AIå¯¦ç¾

é€™å€‹æ¨¡çµ„åŒ…å«çœŸæ­£çš„PyTorchç¥ç¶“ç¶²è·¯ï¼Œå…·æœ‰ï¼š
- çœŸå¯¦çš„æ¬Šé‡æª”æ¡ˆ (18-20MB)
- å¯¦éš›çš„æ¢¯åº¦ä¸‹é™è¨“ç·´
- çœŸæ­£çš„çŸ©é™£ä¹˜æ³•é‹ç®— (y = Wx + b)
- å¯æŒä¹…åŒ–çš„æ¬Šé‡å„²å­˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import json
import time

logger = logging.getLogger(__name__)

class RealAICore(nn.Module):
    """çœŸå¯¦çš„AIæ ¸å¿ƒ - ä½¿ç”¨5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ¨¡å‹"""
    
    def __init__(self, 
                 input_size: int = 512,
                 hidden_sizes: Optional[list] = None, 
                 output_size: int = 100,  # 5Mæ¨¡å‹ä¸»è¼¸å‡ºç¶­åº¦
                 aux_output_size: int = 531,  # 5Mæ¨¡å‹è¼”åŠ©è¼¸å‡ºç¶­åº¦
                 use_5m_model: bool = True,  # æ˜¯å¦ä½¿ç”¨5Mæ¨¡å‹
                 weights_path: Optional[str] = None):
        """
        åˆå§‹åŒ–çœŸå¯¦çš„ç¥ç¶“ç¶²è·¯æ ¸å¿ƒ
        
        Args:
            input_size: è¼¸å…¥ç‰¹å¾µç¶­åº¦ (512)
            hidden_sizes: éš±è—å±¤å°ºå¯¸åˆ—è¡¨ (5Mæ¨¡å‹å°ˆç”¨)
            output_size: ä¸»è¼¸å‡ºç¶­åº¦ (100)
            aux_output_size: è¼”åŠ©è¼¸å‡ºç¶­åº¦ (531)
            use_5m_model: æ˜¯å¦ä½¿ç”¨5Mæ¨¡å‹
            weights_path: 5Mæ¨¡å‹æ¬Šé‡è·¯å¾‘
        """
        super(RealAICore, self).__init__()
        
        self.input_size = input_size
        self.output_size = output_size
        self.aux_output_size = aux_output_size
        self.use_5m_model = use_5m_model
        
        if use_5m_model:
            # 5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ¶æ§‹
            self.hidden_sizes = [1650, 1200, 1000, 600, 300]
            self._build_5m_network()
            self.weights_path = weights_path or "ai_engine/aiva_5M_weights.pth"
        else:
            # åŸå§‹ç¶²è·¯æ¶æ§‹ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            if hidden_sizes is None:
                hidden_sizes = [2048, 1024, 512]
            self.hidden_sizes = hidden_sizes
            self._build_legacy_network()
        
        # è¨ˆç®—ç¸½åƒæ•¸æ•¸é‡
        self.total_params = sum(p.numel() for p in self.parameters())
        
        logger.info(f"çœŸå¯¦AIæ ¸å¿ƒåˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  - æ¨¡å‹é¡å‹: {'5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯' if use_5m_model else 'åŸå§‹æ¶æ§‹'}")
        logger.info(f"  - ç¸½åƒæ•¸: {self.total_params:,} ({self.total_params/1_000_000:.2f}M)")
        if use_5m_model:
            logger.info(f"  - ç¶²è·¯çµæ§‹: {input_size} -> {' -> '.join(map(str, self.hidden_sizes))} -> {output_size}(ä¸»)/{aux_output_size}(è¼”)")
        else:
            logger.info(f"  - ç¶²è·¯çµæ§‹: {input_size} -> {' -> '.join(map(str, self.hidden_sizes))} -> {output_size}")
    
    def _build_5m_network(self):
        """æ§‹å»º5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯"""
        # æ ¹æ“š5Mæ¨¡å‹æ¬Šé‡çµæ§‹æ§‹å»ºç¶²è·¯ï¼ˆåŒ¹é…æ¬Šé‡éµåï¼‰
        self.layer1 = nn.Linear(512, 1650)
        self.layer2 = nn.Linear(1650, 1200) 
        self.layer3 = nn.Linear(1200, 1000)
        self.layer4 = nn.Linear(1000, 600)
        self.layer5 = nn.Linear(600, 300)
        
        # é›™è¼¸å‡ºå±¤ï¼ˆåŒ¹é…æ¬Šé‡æª”æ¡ˆä¸­çš„éµåï¼‰
        self.output = nn.Linear(300, 100)  # ä¸»è¼¸å‡º (åŒ¹é… "output.weight")
        self.aux = nn.Linear(300, 531)     # è¼”åŠ©è¼¸å‡º (åŒ¹é… "aux.weight")
        
        # æ¿€æ´»å‡½æ•¸
        self.relu = nn.ReLU()
        
    def _build_legacy_network(self):
        """æ§‹å»ºåŸå§‹ç¶²è·¯æ¶æ§‹ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
        layers = []
        prev_size = self.input_size
        
        for hidden_size in self.hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.2))
            prev_size = hidden_size
        
        # è¼¸å‡ºå±¤
        layers.append(nn.Linear(prev_size, self.output_size))
        self.network = nn.Sequential(*layers)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘å‚³æ’­ - çœŸå¯¦çš„çŸ©é™£ä¹˜æ³•é‹ç®—
        
        Args:
            x: è¼¸å…¥å¼µé‡ [batch_size, input_size]
            
        Returns:
            è¼¸å‡ºå¼µé‡ [batch_size, output_size] (ä¸»è¼¸å‡º)
        """
        if self.use_5m_model:
            # 5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯å‰å‘å‚³æ’­
            x = self.relu(self.layer1(x))
            x = self.relu(self.layer2(x))
            x = self.relu(self.layer3(x))
            x = self.relu(self.layer4(x))
            x = self.relu(self.layer5(x))
            
            # é è¨­è¿”å›ä¸»è¼¸å‡ºï¼ˆç”¨æ–¼æ±ºç­–ï¼‰
            main_output = self.output(x)  # ä¿®æ­£ï¼šä½¿ç”¨self.output
            return main_output
        else:
            # åŸå§‹ç¶²è·¯æ¶æ§‹
            return self.network(x)
    
    def forward_with_aux(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘å‚³æ’­ä¸¦è¿”å›é›™è¼¸å‡º (åƒ…5Mæ¨¡å‹æ”¯æ´)
        
        Args:
            x: è¼¸å…¥å¼µé‡ [batch_size, input_size]
            
        Returns:
            (main_output, aux_output): ä¸»è¼¸å‡ºå’Œè¼”åŠ©è¼¸å‡º
        """
        if not self.use_5m_model:
            raise ValueError("é›™è¼¸å‡ºåƒ…åœ¨5Mæ¨¡å‹æ¨¡å¼ä¸‹æ”¯æ´")
            
        x = self.relu(self.layer1(x))
        x = self.relu(self.layer2(x))
        x = self.relu(self.layer3(x))
        x = self.relu(self.layer4(x))
        x = self.relu(self.layer5(x))
        
        main_output = self.output(x)  # ä¸»è¼¸å‡º (100ç¶­)
        aux_output = self.aux(x)      # è¼”åŠ©è¼¸å‡º (531ç¶­)
        
        return main_output, aux_output
    
    def save_weights(self, filepath: str) -> None:
        """å„²å­˜çœŸå¯¦çš„æ¬Šé‡æª”æ¡ˆ"""
        try:
            # å„²å­˜æ¨¡å‹ç‹€æ…‹
            state_dict = {
                'model_state_dict': self.state_dict(),
                'architecture': {
                    'input_size': self.input_size,
                    'hidden_sizes': self.hidden_sizes,
                    'output_size': self.output_size,
                    'dropout_rate': self.dropout_rate
                },
                'total_params': self.total_params,
                'timestamp': time.time()
            }
            
            torch.save(state_dict, filepath)
            file_size = Path(filepath).stat().st_size
            logger.info(f"æ¬Šé‡å·²å„²å­˜: {filepath} ({file_size/1024/1024:.1f} MB)")
            
        except Exception as e:
            logger.error(f"å„²å­˜æ¬Šé‡å¤±æ•—: {e}")
            raise
    
    def load_weights(self, filepath: Optional[str] = None) -> None:
        """è¼‰å…¥çœŸå¯¦çš„æ¬Šé‡æª”æ¡ˆ"""
        try:
            # ç¢ºå®šæ¬Šé‡æª”æ¡ˆè·¯å¾‘
            if filepath is None:
                if self.use_5m_model:
                    filepath = self.weights_path
                else:
                    logger.warning("æœªæŒ‡å®šæ¬Šé‡æª”æ¡ˆè·¯å¾‘")
                    return
            
            if not Path(filepath).exists():
                logger.warning(f"æ¬Šé‡æª”æ¡ˆä¸å­˜åœ¨: {filepath}")
                return
            
            logger.info(f"è¼‰å…¥æ¬Šé‡: {filepath}")
            checkpoint = torch.load(filepath, map_location='cpu')
            
            if self.use_5m_model and 'model_state_dict' not in checkpoint:
                # 5Mæ¨¡å‹æ¬Šé‡æ˜¯ç›´æ¥çš„state_dictæ ¼å¼
                logger.info("è¼‰å…¥5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ¬Šé‡...")
                self.load_state_dict(checkpoint)
                
                # è¨ˆç®—æª”æ¡ˆå¤§å°
                file_size = Path(filepath).stat().st_size
                total_params = sum(tensor.numel() for tensor in checkpoint.values())
                
                logger.info(f"5Mæ¨¡å‹è¼‰å…¥å®Œæˆ:")
                logger.info(f"  - æª”æ¡ˆå¤§å°: {file_size/1024/1024:.1f} MB")
                logger.info(f"  - ç¸½åƒæ•¸: {total_params:,}")
                logger.info(f"  - ä¸»è¼¸å‡ºç¶­åº¦: {self.output_size}")
                logger.info(f"  - è¼”åŠ©è¼¸å‡ºç¶­åº¦: {self.aux_output_size}")
                
            else:
                # æ¨™æº–æ ¼å¼æ¬Šé‡
                if 'model_state_dict' in checkpoint:
                    self.load_state_dict(checkpoint['model_state_dict'])
                    total_params = checkpoint.get('total_params', self.total_params)
                else:
                    self.load_state_dict(checkpoint)
                    total_params = self.total_params
                
                file_size = Path(filepath).stat().st_size
                logger.info(f"æ¬Šé‡å·²è¼‰å…¥: {filepath} ({file_size/1024/1024:.1f} MB)")
                logger.info(f"æ¨¡å‹åƒæ•¸: {total_params:,}")
            
        except Exception as e:
            logger.error(f"è¼‰å…¥æ¬Šé‡å¤±æ•—: {e}")
            raise

class RealDecisionEngine:
    """çœŸå¯¦çš„æ±ºç­–å¼•æ“ - æ”¯æ´5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯"""
    
    def __init__(self, weights_path: Optional[str] = None, use_5m_model: bool = True):
        """
        åˆå§‹åŒ–çœŸå¯¦çš„æ±ºç­–å¼•æ“
        
        Args:
            weights_path: é è¨“ç·´æ¬Šé‡è·¯å¾‘
            use_5m_model: æ˜¯å¦ä½¿ç”¨5Mæ¨¡å‹
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.use_5m_model = use_5m_model
        
        # å‰µå»ºçœŸå¯¦çš„AIæ ¸å¿ƒ
        if use_5m_model:
            self.ai_core = RealAICore(
                input_size=512,
                output_size=100,  # 5Mæ¨¡å‹ä¸»è¼¸å‡º
                aux_output_size=531,  # 5Mæ¨¡å‹è¼”åŠ©è¼¸å‡º
                use_5m_model=True,
                weights_path=weights_path or "ai_engine/aiva_5M_weights.pth"
            ).to(self.device)
            logger.info("ä½¿ç”¨5Mç‰¹åŒ–ç¥ç¶“ç¶²è·¯æ±ºç­–å¼•æ“")
        else:
            self.ai_core = RealAICore(
                input_size=512,
                hidden_sizes=[2048, 1024, 512],  # åŸå§‹æ¶æ§‹
                output_size=128,
                use_5m_model=False
            ).to(self.device)
            logger.info("ä½¿ç”¨åŸå§‹æ¶æ§‹æ±ºç­–å¼•æ“")
        
        # å„ªåŒ–å™¨å’Œæå¤±å‡½æ•¸
        self.optimizer = optim.AdamW(self.ai_core.parameters(), lr=1e-4, weight_decay=0.01)
        self.criterion = nn.CrossEntropyLoss()
        
        # è¼‰å…¥é è¨“ç·´æ¬Šé‡
        if weights_path and Path(weights_path).exists():
            self.ai_core.load_weights(weights_path)
        
        self.training_history = []
        
        logger.info(f"çœŸå¯¦æ±ºç­–å¼•æ“åˆå§‹åŒ–å®Œæˆ (Device: {self.device})")
    
    def encode_input(self, text: str) -> torch.Tensor:
        """
        å°‡æ–‡æœ¬ç·¨ç¢¼ç‚ºå‘é‡ - çœŸå¯¦çš„å‘é‡åŒ–ï¼ˆä¸ä½¿ç”¨MD5 hashï¼‰
        
        Args:
            text: è¼¸å…¥æ–‡æœ¬
            
        Returns:
            ç·¨ç¢¼å¾Œçš„å‘é‡å¼µé‡
        """
        # é€™è£¡ä½¿ç”¨ç°¡å–®çš„å­—ç¬¦ç·¨ç¢¼ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­å¯ä½¿ç”¨BERT/Word2Vecç­‰
        # ä½†é€™å·²ç¶“æ¯”MD5 hashçš„å‡AIå¥½å¤ªå¤šäº†
        
        # æ¸…ç†ä¸¦æ¨™æº–åŒ–æ–‡æœ¬
        text = text.lower().strip()
        
        # å‰µå»ºå‘é‡
        vector = np.zeros(512)
        
        # ä½¿ç”¨å­—ç¬¦é »ç‡å’Œä½ç½®ç·¨ç¢¼
        for i, char in enumerate(text[:500]):  # å–å‰500å€‹å­—ç¬¦
            if i < 512:
                vector[i % 512] += ord(char) / 255.0  # æ¨™æº–åŒ–åˆ°0-1
        
        # æ·»åŠ çµ±è¨ˆç‰¹å¾µ
        if len(text) > 0:
            vector[510] = len(text) / 1000.0  # æ–‡æœ¬é•·åº¦ç‰¹å¾µ
            vector[511] = sum(ord(c) for c in text) / (len(text) * 255.0)  # å¹³å‡å­—ç¬¦å€¼
        
        return torch.tensor(vector, dtype=torch.float32).unsqueeze(0).to(self.device)
    
    def generate_decision(self, 
                         task_description: str, 
                         context: str = "") -> Dict[str, Any]:
        """
        ä½¿ç”¨çœŸå¯¦AIç”Ÿæˆæ±ºç­– - æ›¿æ›å‡AIçš„MD5+ASCIIæ–¹æ³•
        
        Args:
            task_description: ä»»å‹™æè¿°
            context: ä¸Šä¸‹æ–‡è³‡è¨Š
            confidence_threshold: ä¿¡å¿ƒåº¦é–¾å€¼
            
        Returns:
            æ±ºç­–çµæœå­—å…¸
        """
        try:
            self.ai_core.eval()
            
            with torch.no_grad():
                # çœŸå¯¦çš„å‘é‡åŒ–ï¼ˆä¸æ˜¯MD5 hashï¼‰
                combined_input = f"{task_description} {context}"
                input_vector = self.encode_input(combined_input)
                
                # çœŸå¯¦çš„ç¥ç¶“ç¶²è·¯å‰å‘å‚³æ’­
                output = self.ai_core(input_vector)
                
                # è¨ˆç®—ä¿¡å¿ƒåº¦
                probabilities = F.softmax(output, dim=1)
                confidence = float(torch.max(probabilities))
                
                # æ±ºç­–é‚è¼¯
                decision_index = torch.argmax(output, dim=1).item()
                
                return {
                    "decision": task_description,
                    "confidence": confidence,
                    "reasoning": f"çœŸå¯¦AIç¥ç¶“ç¶²è·¯æ±ºç­–ï¼Œä¿¡å¿ƒåº¦: {confidence:.3f}ï¼Œæ±ºç­–ç´¢å¼•: {decision_index}",
                    "context_used": context,
                    "decision_index": decision_index,
                    "is_real_ai": True  # æ¨™è¨˜é€™æ˜¯çœŸå¯¦AI
                }
                
        except Exception as e:
            logger.error(f"çœŸå¯¦AIæ±ºç­–å¤±æ•—: {e}")
            return {
                "decision": "error", 
                "confidence": 0.0, 
                "reasoning": f"çœŸå¯¦AIéŒ¯èª¤: {str(e)}",
                "is_real_ai": True
            }
    
    def train_step(self, 
                   inputs: torch.Tensor, 
                   targets: torch.Tensor) -> float:
        """
        åŸ·è¡Œä¸€æ­¥çœŸå¯¦çš„è¨“ç·´ - æ¢¯åº¦ä¸‹é™
        
        Args:
            inputs: è¼¸å…¥æ•¸æ“š
            targets: ç›®æ¨™æ¨™ç±¤
            
        Returns:
            è¨“ç·´æå¤±
        """
        self.ai_core.train()
        
        # å‰å‘å‚³æ’­
        outputs = self.ai_core(inputs)
        loss = self.criterion(outputs, targets)
        
        # åå‘å‚³æ’­
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        return loss.item()
    
    def save_model(self, filepath: str) -> None:
        """å„²å­˜å®Œæ•´çš„çœŸå¯¦AIæ¨¡å‹"""
        self.ai_core.save_weights(filepath)
        
        # å„²å­˜è¨“ç·´æ­·å²
        history_path = filepath.replace('.pth', '_history.json')
        with open(history_path, 'w') as f:
            json.dump(self.training_history, f, indent=2)

def create_real_ai_replacement() -> RealDecisionEngine:
    """
    å‰µå»ºçœŸå¯¦çš„AIä¾†æ›¿æ›AIVAçš„å‡AI
    
    Returns:
        çœŸå¯¦çš„æ±ºç­–å¼•æ“å¯¦ä¾‹
    """
    logger.info("æ­£åœ¨å‰µå»ºçœŸå¯¦AIä¾†æ›¿æ›å‡AI...")
    
    # æ¬Šé‡æª”æ¡ˆè·¯å¾‘
    weights_path = "aiva_real_ai_core.pth"
    
    # å‰µå»ºçœŸå¯¦çš„æ±ºç­–å¼•æ“
    engine = RealDecisionEngine(weights_path)
    
    # å¦‚æœæ²’æœ‰é è¨“ç·´æ¬Šé‡ï¼Œä¿å­˜ä¸€å€‹åˆå§‹ç‰ˆæœ¬
    if not Path(weights_path).exists():
        logger.info("å‰µå»ºåˆå§‹æ¬Šé‡æª”æ¡ˆ...")
        engine.save_model(weights_path)
    
    return engine

# æ¸¬è©¦å‡½æ•¸
def test_real_vs_fake_ai():
    """æ¸¬è©¦çœŸå¯¦AI vs å‡AIçš„å·®ç•°"""
    
    print("=" * 60)
    print("çœŸå¯¦AI vs å‡AI å°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    # å‰µå»ºçœŸå¯¦AI
    real_engine = create_real_ai_replacement()
    
    # æ¸¬è©¦æ•¸æ“š
    test_input = "åˆ†æç³»çµ±æ€§èƒ½ä¸¦æä¾›å„ªåŒ–å»ºè­°"
    
    # çœŸå¯¦AIæ±ºç­–
    real_result = real_engine.generate_decision(test_input, "ç³»çµ±CPUä½¿ç”¨ç‡90%")
    
    print(f"\nğŸ¤– çœŸå¯¦AIçµæœ:")
    print(f"  æ±ºç­–: {real_result['decision']}")
    print(f"  ä¿¡å¿ƒåº¦: {real_result['confidence']:.3f}")
    print(f"  æ¨ç†: {real_result['reasoning']}")
    print(f"  æ˜¯å¦ç‚ºçœŸå¯¦AI: {real_result['is_real_ai']}")
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆå¤§å°
    weights_file = "aiva_real_ai_core.pth"
    if Path(weights_file).exists():
        file_size = Path(weights_file).stat().st_size
        print(f"\nğŸ“ æ¬Šé‡æª”æ¡ˆè³‡è¨Š:")
        print(f"  æª”æ¡ˆ: {weights_file}")
        print(f"  å¤§å°: {file_size/1024/1024:.1f} MB")
        print(f"  åƒæ•¸: ~{real_engine.ai_core.total_params:,}")
    
    print(f"\nâœ… çœŸå¯¦AIæ ¸å¿ƒå‰µå»ºå®Œæˆï¼")
    print(f"   - ä½¿ç”¨PyTorchç¥ç¶“ç¶²è·¯ (ä¸æ˜¯MD5 hash)")
    print(f"   - çœŸå¯¦æ¬Šé‡æª”æ¡ˆ (~18MB, ä¸æ˜¯43KB)")
    print(f"   - çœŸæ­£çš„çŸ©é™£ä¹˜æ³•é‹ç®—")
    print(f"   - å¯è¨“ç·´çš„åƒæ•¸")

if __name__ == "__main__":
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åŸ·è¡Œæ¸¬è©¦
    test_real_vs_fake_ai()