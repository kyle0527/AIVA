"""
AIVA Core - èƒ½åŠ›åˆ†æå™¨ (CapabilityAnalyzer)

è² è²¬æ·±åº¦åˆ†æå·²ç™¼ç¾çš„èƒ½åŠ›ï¼Œç†è§£å…¶åŠŸèƒ½ã€åƒæ•¸ã€è¼¸å‡ºï¼Œä¸¦é€²è¡Œæ™ºèƒ½åˆ†é¡ã€‚

ä½œè€…: AIVA Development Team
å‰µå»ºæ—¥æœŸ: 2025-11-13
ç‰ˆæœ¬: 1.0.0

ä¾è³´:
- aiva_core.ai_engine.ai_analysis_engine (AIé©…å‹•åˆ†æ)
- aiva_core.rag.rag_engine (RAGçŸ¥è­˜æª¢ç´¢)
- aiva_common.enums (æ¨™æº–æšèˆ‰)
"""

import logging
import re
import ast
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

# AIVA æ ¸å¿ƒå°å…¥
try:
    from ..ai_analysis.analysis_engine import AIAnalysisEngine, AnalysisType
    from ..rag.rag_engine import RAGEngine
    from aiva_common.enums.common import VulnerabilityRiskLevel
    from aiva_common.enums.modules import ModuleName
    from aiva_common.enums.pentest import PentestPhase, InformationGatheringMethod
except ImportError:
    # å›é€€åˆ°çµ•å°å°å…¥
    from services.core.aiva_core.ai_analysis.analysis_engine import AIAnalysisEngine, AnalysisType
    from services.core.aiva_core.rag.rag_engine import RAGEngine
    from services.aiva_common.enums.common import VulnerabilityRiskLevel
    from services.aiva_common.enums.modules import ModuleName
    from services.aiva_common.enums.pentest import PentestPhase, InformationGatheringMethod

logger = logging.getLogger(__name__)

# åˆ¥åä»¥ä¿æŒå‘å¾Œå…¼å®¹æ€§
RiskLevel = VulnerabilityRiskLevel


class FunctionType(str, Enum):
    """åŠŸèƒ½é¡å‹æšèˆ‰"""
    SCANNING = "scanning"           # æƒæåŠŸèƒ½
    ANALYSIS = "analysis"           # åˆ†æåŠŸèƒ½
    EXPLOITATION = "exploitation"   # åˆ©ç”¨åŠŸèƒ½
    REPORTING = "reporting"         # å ±å‘ŠåŠŸèƒ½
    UTILITY = "utility"            # å·¥å…·åŠŸèƒ½
    AUTHENTICATION = "auth"        # èªè­‰åŠŸèƒ½
    NETWORKING = "networking"      # ç¶²çµ¡åŠŸèƒ½
    DATA_PROCESSING = "data"       # æ•¸æ“šè™•ç†
    UNKNOWN = "unknown"            # æœªçŸ¥åŠŸèƒ½


@dataclass
class ParameterInfo:
    """åƒæ•¸ä¿¡æ¯"""
    name: str
    type_hint: Optional[str]
    default_value: Optional[str]
    description: Optional[str]
    is_required: bool
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)


@dataclass
class CapabilityAnalysis:
    """èƒ½åŠ›åˆ†æçµæœ"""
    capability_id: str
    function_type: PentestPhase  # ä½¿ç”¨ aiva_common æ¨™æº–æšèˆ‰
    risk_level: RiskLevel
    semantic_understanding: Dict[str, Any]
    parameters: List[ParameterInfo]
    return_type: Optional[str]
    side_effects: List[str]
    examples: List[Dict[str, str]]
    related_capabilities: List[str]
    documentation: str
    confidence_score: float
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        result = asdict(self)
        result["parameters"] = [param.to_dict() for param in self.parameters]
        return result


@dataclass
class CapabilityClassification:
    """èƒ½åŠ›åˆ†é¡çµæœ"""
    by_function: Dict[str, List[str]]
    by_risk: Dict[str, List[str]]
    by_module: Dict[str, List[str]]
    by_complexity: Dict[str, List[str]]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)


class CapabilityAnalyzer:
    """
    èƒ½åŠ›åˆ†æå™¨
    
    æ·±åº¦åˆ†æå·²ç™¼ç¾çš„èƒ½åŠ›ï¼Œæä¾›:
    1. èªç¾©ç†è§£ - ä½¿ç”¨AIç†è§£å‡½æ•¸åŠŸèƒ½
    2. åƒæ•¸åˆ†æ - åˆ†æåƒæ•¸é¡å‹å’Œç”¨é€”
    3. é¢¨éšªè©•ä¼° - è©•ä¼°å®‰å…¨é¢¨éšªç­‰ç´š
    4. åŠŸèƒ½åˆ†é¡ - æ™ºèƒ½åˆ†é¡èƒ½åŠ›
    5. é—œè¯åˆ†æ - ç™¼ç¾ç›¸é—œèƒ½åŠ›
    6. æ–‡æª”ç”Ÿæˆ - è‡ªå‹•ç”Ÿæˆä½¿ç”¨æ–‡æª”
    """
    
    # é¢¨éšªé—œéµå­—æ˜ å°„
    RISK_KEYWORDS = {
        RiskLevel.HIGH: [
            "exploit", "attack", "inject", "shell", "payload", "backdoor",
            "privilege", "escalation", "bypass", "crack", "brute", "force",
            "sql_injection", "xss", "rce", "lfi", "rfi", "xxe"
        ],
        RiskLevel.MEDIUM: [
            "scan", "enumerate", "probe", "discover", "fingerprint",
            "reconnaissance", "recon", "gather", "collect", "harvest"
        ],
        RiskLevel.LOW: [
            "parse", "format", "validate", "encode", "decode", "convert",
            "log", "report", "display", "print", "save", "load"
        ]
    }
    
    # åŠŸèƒ½é—œéµå­—æ˜ å°„ï¼ˆä½¿ç”¨ aiva_common æ¨™æº– PentestPhaseï¼‰
    FUNCTION_KEYWORDS = {
        PentestPhase.INTELLIGENCE_GATHERING: [
            "scan", "probe", "detect", "discover", "find", "search",
            "enumerate", "map", "crawl", "spider", "gather", "collect"
        ],
        PentestPhase.VULNERABILITY_ANALYSIS: [
            "analyze", "parse", "examine", "inspect", "evaluate",
            "assess", "review", "check", "validate", "test", "verify"
        ],
        PentestPhase.EXPLOITATION: [
            "exploit", "attack", "inject", "execute", "trigger",
            "abuse", "bypass", "escalate", "compromise", "penetrate"
        ],
        PentestPhase.REPORTING: [
            "report", "generate", "create", "format", "export",
            "display", "show", "print", "output", "document"
        ],
        PentestPhase.POST_EXPLOITATION: [
            "maintain", "persist", "elevate", "lateral", "exfiltrate",
            "pivot", "cleanup", "cover", "persistence", "backdoor"
        ],
        # æ–°å¢é€šç”¨é¡å‹ç”¨æ–¼ä¸ç¬¦åˆä¸Šè¿°éšæ®µçš„åŠŸèƒ½
        "utility": [
            "helper", "util", "tool", "convert", "transform",
            "encode", "decode", "hash", "encrypt", "decrypt",
            "process", "filter", "sort", "group", "merge",
            "split", "join", "aggregate", "auth", "login",
            "request", "response", "http", "connect", "send"
        ]
    }
    
    def __init__(self, ai_engine: Optional[AIAnalysisEngine] = None, 
                 rag_engine: Optional[RAGEngine] = None):
        """
        åˆå§‹åŒ–èƒ½åŠ›åˆ†æå™¨
        
        Args:
            ai_engine: AIåˆ†æå¼•æ“ï¼Œç”¨æ–¼èªç¾©ç†è§£
            rag_engine: RAGå¼•æ“ï¼Œç”¨æ–¼çŸ¥è­˜æª¢ç´¢
        """
        self.ai_engine = ai_engine
        self.rag_engine = rag_engine
        
        # åˆ†æçµæœç·©å­˜
        self._analysis_cache: Dict[str, CapabilityAnalysis] = {}
        self._classification_cache: Optional[CapabilityClassification] = None
        
        logger.info("CapabilityAnalyzer åˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_capability(self, capability: Dict[str, Any]) -> CapabilityAnalysis:
        """
        æ·±åº¦åˆ†æå–®å€‹èƒ½åŠ›
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«:
                - id: èƒ½åŠ›ID
                - name: å‡½æ•¸åç¨±
                - source_code: æºä»£ç¢¼
                - docstring: æ–‡æª”å­—ç¬¦ä¸²
                - signature: å‡½æ•¸ç°½å
                - file_path: æ–‡ä»¶è·¯å¾‘
                - module_name: æ¨¡çµ„åç¨±
        
        Returns:
            CapabilityAnalysis: è©³ç´°åˆ†æçµæœ
        """
        capability_id = capability.get("id", "unknown")
        
        # æª¢æŸ¥ç·©å­˜
        if capability_id in self._analysis_cache:
            logger.debug(f"ä½¿ç”¨ç·©å­˜çš„åˆ†æçµæœ: {capability_id}")
            return self._analysis_cache[capability_id]
        
        logger.info(f"ğŸ” åˆ†æèƒ½åŠ›: {capability.get('name', capability_id)}")
        
        try:
            # 1. AIèªç¾©ç†è§£
            semantic_analysis = self._ai_semantic_analysis(capability)
            
            # 2. åƒæ•¸åˆ†æ
            parameters = self._analyze_parameters(capability)
            
            # 3. è¿”å›é¡å‹åˆ†æ
            return_type = self._analyze_return_type(capability)
            
            # 4. åŠŸèƒ½é¡å‹åˆ†é¡
            function_type = self._classify_function_type(capability, semantic_analysis)
            
            # 5. é¢¨éšªè©•ä¼°
            risk_level = self._assess_risk_level(capability, semantic_analysis)
            
            # 6. å‰¯ä½œç”¨è­˜åˆ¥
            side_effects = self._identify_side_effects(capability, semantic_analysis)
            
            # 7. ç”Ÿæˆä½¿ç”¨ç¤ºä¾‹
            examples = self._generate_examples(capability, semantic_analysis)
            
            # 8. æŸ¥æ‰¾ç›¸é—œèƒ½åŠ›
            related_capabilities = self._find_related_capabilities(capability)
            
            # 9. ç”Ÿæˆæ–‡æª”
            documentation = self._generate_documentation(capability, semantic_analysis)
            
            # 10. è¨ˆç®—ä¿¡å¿ƒåº¦åˆ†æ•¸
            confidence_score = self._calculate_confidence_score(capability, semantic_analysis)
            
            # å‰µå»ºåˆ†æçµæœ
            analysis = CapabilityAnalysis(
                capability_id=capability_id,
                function_type=function_type,
                risk_level=risk_level,
                semantic_understanding=semantic_analysis,
                parameters=parameters,
                return_type=return_type,
                side_effects=side_effects,
                examples=examples,
                related_capabilities=related_capabilities,
                documentation=documentation,
                confidence_score=confidence_score
            )
            
            # ç·©å­˜çµæœ
            self._analysis_cache[capability_id] = analysis
            
            logger.info(f"âœ… èƒ½åŠ›åˆ†æå®Œæˆ: {capability.get('name')} (ä¿¡å¿ƒåº¦: {confidence_score:.2f})")
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ èƒ½åŠ›åˆ†æå¤±æ•—: {capability.get('name', capability_id)} - {e}")
            # è¿”å›é»˜èªåˆ†æçµæœ
            return self._create_default_analysis(capability)
    
    async def classify_all_capabilities(self, capabilities: List[Dict[str, Any]]) -> CapabilityClassification:
        """
        åˆ†é¡æ‰€æœ‰èƒ½åŠ›
        
        Args:
            capabilities: èƒ½åŠ›åˆ—è¡¨
        
        Returns:
            CapabilityClassification: åˆ†é¡çµæœ
        """
        logger.info(f"ğŸ“Š é–‹å§‹åˆ†é¡ {len(capabilities)} å€‹èƒ½åŠ›")
        
        # æª¢æŸ¥ç·©å­˜
        if self._classification_cache is not None:
            logger.debug("ä½¿ç”¨ç·©å­˜çš„åˆ†é¡çµæœ")
            return self._classification_cache
        
        classifications = {
            "by_function": {},
            "by_risk": {},
            "by_module": {},
            "by_complexity": {}
        }
        
        # åˆ†ææ¯å€‹èƒ½åŠ›
        for capability in capabilities:
            try:
                analysis = await self.analyze_capability(capability)
                capability_id = capability.get("id", "unknown")
                
                # æŒ‰åŠŸèƒ½åˆ†é¡
                function_type = analysis.function_type.value
                if function_type not in classifications["by_function"]:
                    classifications["by_function"][function_type] = []
                classifications["by_function"][function_type].append(capability_id)
                
                # æŒ‰é¢¨éšªåˆ†é¡
                risk_level = analysis.risk_level.value
                if risk_level not in classifications["by_risk"]:
                    classifications["by_risk"][risk_level] = []
                classifications["by_risk"][risk_level].append(capability_id)
                
                # æŒ‰æ¨¡çµ„åˆ†é¡
                module_name = capability.get("module_name", "unknown")
                if module_name not in classifications["by_module"]:
                    classifications["by_module"][module_name] = []
                classifications["by_module"][module_name].append(capability_id)
                
                # æŒ‰è¤‡é›œåº¦åˆ†é¡
                complexity = self._assess_complexity(capability, analysis)
                if complexity not in classifications["by_complexity"]:
                    classifications["by_complexity"][complexity] = []
                classifications["by_complexity"][complexity].append(capability_id)
                
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ†é¡èƒ½åŠ›æ™‚ç™¼ç”ŸéŒ¯èª¤: {capability.get('name', 'unknown')} - {e}")
                continue
        
        # å‰µå»ºåˆ†é¡çµæœ
        result = CapabilityClassification(
            by_function=classifications["by_function"],
            by_risk=classifications["by_risk"],
            by_module=classifications["by_module"],
            by_complexity=classifications["by_complexity"]
        )
        
        # ç·©å­˜çµæœ
        self._classification_cache = result
        
        logger.info("âœ… èƒ½åŠ›åˆ†é¡å®Œæˆ:")
        logger.info(f"  - åŠŸèƒ½é¡å‹: {len(classifications['by_function'])} ç¨®")
        logger.info(f"  - é¢¨éšªç­‰ç´š: {len(classifications['by_risk'])} ç´š")
        logger.info(f"  - æ¨¡çµ„åˆ†å¸ƒ: {len(classifications['by_module'])} å€‹")
        
        return result
    
    def _ai_semantic_analysis(self, capability: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIé€²è¡Œèªç¾©åˆ†æ
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            Dict: AIåˆ†æçµæœ
        """
        if not self.ai_engine:
            logger.debug("AIå¼•æ“æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºæ–¼è¦å‰‡çš„åˆ†æ")
            return self._rule_based_analysis(capability)
        
        try:
            # æº–å‚™åˆ†æè¼¸å…¥
            analysis_input = {
                "function_name": capability.get("name", ""),
                "docstring": capability.get("docstring", ""),
                "source_code": capability.get("source_code", ""),
                "signature": capability.get("signature", "")
            }
            
            # AIèªç¾©ç†è§£
            analysis_results = self.ai_engine.analyze_code(
                source_code=capability.get("source", ""),
                file_path=capability.get("file", ""),
                analysis_types=[AnalysisType.SEMANTIC, AnalysisType.SECURITY]
            )
            
            # æå–èªç¾©åˆ†æçµæœ
            semantic_result = analysis_results.get(AnalysisType.SEMANTIC)
            if semantic_result:
                return {
                    "purpose": semantic_result.explanation,
                    "complexity": semantic_result.risk_level,
                    "patterns": semantic_result.findings,
                    "confidence": semantic_result.confidence
                }
            else:
                return analysis_input
            
        except Exception as e:
            logger.warning(f"AIèªç¾©åˆ†æå¤±æ•—ï¼Œä½¿ç”¨åŸºæ–¼è¦å‰‡çš„åˆ†æ: {e}")
            return self._rule_based_analysis(capability)
    
    def _rule_based_analysis(self, capability: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸºæ–¼è¦å‰‡çš„åˆ†æ (AIå¼•æ“ä¸å¯ç”¨æ™‚çš„å¾Œå‚™æ–¹æ¡ˆ)
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            Dict: åŸºæ–¼è¦å‰‡çš„åˆ†æçµæœ
        """
        name = capability.get("name", "").lower()
        docstring = capability.get("docstring", "").lower()
        source_code = capability.get("source_code", "").lower()
        
        # åˆä½µæ‰€æœ‰æ–‡æœ¬ç”¨æ–¼é—œéµå­—åŒ¹é…
        text_content = f"{name} {docstring} {source_code}"
        
        # åŠŸèƒ½æ¨æ–·
        detected_keywords = []
        primary_function = "unknown"
        
        for func_type, keywords in self.FUNCTION_KEYWORDS.items():
            matching_keywords = [kw for kw in keywords if kw in text_content]
            if matching_keywords:
                detected_keywords.extend(matching_keywords)
                if primary_function == "unknown":
                    primary_function = func_type.value
        
        # é¢¨éšªæ¨æ–·
        risk_indicators = []
        for risk_level, keywords in self.RISK_KEYWORDS.items():
            matching_keywords = [kw for kw in keywords if kw in text_content]
            if matching_keywords:
                risk_indicators.extend(matching_keywords)
        
        return {
            "method": "rule_based",
            "primary_function": primary_function,
            "detected_keywords": detected_keywords,
            "risk_indicators": risk_indicators,
            "confidence": 0.6,  # è¦å‰‡åˆ†æä¿¡å¿ƒåº¦è¼ƒä½
            "description": f"åŸºæ–¼é—œéµå­—åˆ†æçš„å‡½æ•¸: {name}"
        }
    
    def _analyze_parameters(self, capability: Dict[str, Any]) -> List[ParameterInfo]:
        """
        åˆ†æå‡½æ•¸åƒæ•¸
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            List[ParameterInfo]: åƒæ•¸ä¿¡æ¯åˆ—è¡¨
        """
        parameters = []
        
        try:
            # è§£æå‡½æ•¸ç°½å
            signature = capability.get("signature", "")
            source_code = capability.get("source_code", "")
            
            if source_code:
                # ä½¿ç”¨ASTè§£æç²å¾—æ›´æº–ç¢ºçš„åƒæ•¸ä¿¡æ¯
                tree = ast.parse(source_code)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if node.name == capability.get("name"):
                            parameters = self._extract_parameters_from_ast(node)
                            break
            
            elif signature:
                # å¾ç°½åè§£æåƒæ•¸
                parameters = self._extract_parameters_from_signature(signature)
        
        except Exception as e:
            logger.warning(f"åƒæ•¸åˆ†æå¤±æ•—: {e}")
        
        return parameters
    
    def _extract_parameters_from_ast(self, func_node: ast.FunctionDef) -> List[ParameterInfo]:
        """
        å¾ASTç¯€é»æå–åƒæ•¸ä¿¡æ¯
        
        Args:
            func_node: å‡½æ•¸ASTç¯€é»
        
        Returns:
            List[ParameterInfo]: åƒæ•¸ä¿¡æ¯
        """
        parameters = []
        
        # ç²å–åƒæ•¸åˆ—è¡¨
        args = func_node.args
        
        # è™•ç†ä½ç½®åƒæ•¸
        for i, arg in enumerate(args.args):
            param_name = arg.arg
            
            # è·³éselfå’Œcls
            if param_name in ("self", "cls"):
                continue
            
            # ç²å–é¡å‹è¨»è§£
            type_hint = None
            if arg.annotation:
                type_hint = ast.unparse(arg.annotation) if hasattr(ast, 'unparse') else str(arg.annotation)
            
            # ç²å–é»˜èªå€¼
            default_value = None
            defaults_start = len(args.args) - len(args.defaults)
            if i >= defaults_start:
                default_idx = i - defaults_start
                default_node = args.defaults[default_idx]
                if hasattr(ast, 'unparse'):
                    default_value = ast.unparse(default_node)
                else:
                    default_value = str(default_node)
            
            # åˆ¤æ–·æ˜¯å¦å¿…éœ€
            is_required = default_value is None
            
            parameters.append(ParameterInfo(
                name=param_name,
                type_hint=type_hint,
                default_value=default_value,
                description=None,  # éœ€è¦é€²ä¸€æ­¥åˆ†ææ–‡æª”å­—ç¬¦ä¸²
                is_required=is_required
            ))
        
        # è™•ç†é—œéµå­—åƒæ•¸
        if args.kwonlyargs:
            for i, arg in enumerate(args.kwonlyargs):
                param_name = arg.arg
                
                # ç²å–é¡å‹è¨»è§£
                type_hint = None
                if arg.annotation:
                    type_hint = ast.unparse(arg.annotation) if hasattr(ast, 'unparse') else str(arg.annotation)
                
                # ç²å–é»˜èªå€¼
                default_value = None
                if i < len(args.kw_defaults) and args.kw_defaults[i]:
                    default_node = args.kw_defaults[i]
                    if hasattr(ast, 'unparse'):
                        default_value = ast.unparse(default_node)
                    else:
                        default_value = str(default_node)
                
                is_required = default_value is None
                
                parameters.append(ParameterInfo(
                    name=param_name,
                    type_hint=type_hint,
                    default_value=default_value,
                    description=None,
                    is_required=is_required
                ))
        
        return parameters
    
    def _extract_parameters_from_signature(self, signature: str) -> List[ParameterInfo]:
        """
        å¾å‡½æ•¸ç°½åå­—ç¬¦ä¸²æå–åƒæ•¸ä¿¡æ¯
        
        Args:
            signature: å‡½æ•¸ç°½å
        
        Returns:
            List[ParameterInfo]: åƒæ•¸ä¿¡æ¯
        """
        parameters = []
        
        try:
            # ç°¡å–®æ­£å‰‡è§£æ (æ›´è¤‡é›œçš„æƒ…æ³éœ€è¦ä½¿ç”¨inspectæ¨¡çµ„)
            # åŒ¹é…åƒæ•¸: name: type = default
            param_pattern = r'(\w+)(?:\s*:\s*([^=,\)]+))?(?:\s*=\s*([^,\)]+))?'
            
            # æå–æ‹¬è™Ÿå…§çš„åƒæ•¸éƒ¨åˆ†
            match = re.search(r'\(([^)]*)\)', signature)
            if match:
                params_str = match.group(1)
                
                for match in re.finditer(param_pattern, params_str):
                    name = match.group(1)
                    type_hint = match.group(2).strip() if match.group(2) else None
                    default_value = match.group(3).strip() if match.group(3) else None
                    
                    # è·³éselfå’Œcls
                    if name in ("self", "cls"):
                        continue
                    
                    parameters.append(ParameterInfo(
                        name=name,
                        type_hint=type_hint,
                        default_value=default_value,
                        description=None,
                        is_required=default_value is None
                    ))
        
        except Exception as e:
            logger.warning(f"ç°½åè§£æå¤±æ•—: {e}")
        
        return parameters
    
    def _analyze_return_type(self, capability: Dict[str, Any]) -> Optional[str]:
        """
        åˆ†æè¿”å›é¡å‹
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            Optional[str]: è¿”å›é¡å‹å­—ç¬¦ä¸²
        """
        try:
            source_code = capability.get("source_code", "")
            if source_code:
                tree = ast.parse(source_code)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        if node.name == capability.get("name"):
                            if node.returns:
                                if hasattr(ast, 'unparse'):
                                    return ast.unparse(node.returns)
                                else:
                                    return str(node.returns)
                            break
        
        except Exception as e:
            logger.warning(f"è¿”å›é¡å‹åˆ†æå¤±æ•—: {e}")
        
        return None
    
    def _classify_function_type(self, capability: Dict[str, Any], 
                               semantic_analysis: Dict[str, Any]) -> PentestPhase:
        """
        åˆ†é¡å‡½æ•¸é¡å‹
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            FunctionType: å‡½æ•¸é¡å‹
        """
        # å„ªå…ˆä½¿ç”¨AIåˆ†æçµæœ
        if "primary_function" in semantic_analysis:
            ai_function = semantic_analysis["primary_function"]
            for func_type in PentestPhase:
                if func_type.value == ai_function:
                    return func_type
        
        # åŸºæ–¼é—œéµå­—åˆ†é¡
        name = capability.get("name", "").lower()
        docstring = capability.get("docstring", "").lower()
        text_content = f"{name} {docstring}"
        
        # è¨ˆç®—æ¯ç¨®åŠŸèƒ½é¡å‹çš„åŒ¹é…åº¦
        type_scores = {}
        for func_type, keywords in self.FUNCTION_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw in text_content)
            if score > 0:
                type_scores[func_type] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„é¡å‹
        if type_scores:
            return max(type_scores.keys(), key=lambda k: type_scores[k])
        
        return PentestPhase.PRE_ENGAGEMENT  # é è¨­å€¼
    
    def _assess_risk_level(self, capability: Dict[str, Any],
                          semantic_analysis: Dict[str, Any]) -> VulnerabilityRiskLevel:
        """
        è©•ä¼°é¢¨éšªç­‰ç´š
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            RiskLevel: é¢¨éšªç­‰ç´š
        """
        name = capability.get("name", "").lower()
        docstring = capability.get("docstring", "").lower()
        source_code = capability.get("source_code", "").lower()
        text_content = f"{name} {docstring} {source_code}"
        
        # è¨ˆç®—é¢¨éšªæŒ‡æ¨™
        risk_scores = {}
        for risk_level, keywords in self.RISK_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw in text_content)
            if score > 0:
                risk_scores[risk_level] = score
        
        # ç‰¹æ®Šé¢¨éšªæª¢æŸ¥
        high_risk_patterns = [
            r'subprocess\.',
            r'os\.system',
            r'exec\(',
            r'eval\(',
            r'__import__',
            r'shell.*command',
            r'inject.*sql',
            r'execute.*payload'
        ]
        
        for pattern in high_risk_patterns:
            if re.search(pattern, text_content, re.IGNORECASE):
                risk_scores[RiskLevel.HIGH] = risk_scores.get(RiskLevel.HIGH, 0) + 5
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„é¢¨éšªç­‰ç´š
        if risk_scores:
            return max(risk_scores.keys(), key=lambda k: risk_scores[k])
        
        # é»˜èªç‚ºä½é¢¨éšª
        return RiskLevel.LOW
    
    def _identify_side_effects(self, capability: Dict[str, Any], 
                              semantic_analysis: Dict[str, Any]) -> List[str]:
        """
        è­˜åˆ¥å‰¯ä½œç”¨
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            List[str]: å‰¯ä½œç”¨åˆ—è¡¨
        """
        side_effects = []
        source_code = capability.get("source_code", "").lower()
        
        # æª¢æŸ¥å¸¸è¦‹å‰¯ä½œç”¨æ¨¡å¼
        side_effect_patterns = {
            "æ–‡ä»¶æ“ä½œ": [r'open\(', r'write\(', r'\.write', r'save'],
            "ç¶²çµ¡è«‹æ±‚": [r'requests\.', r'urllib', r'http', r'socket'],
            "ç³»çµ±èª¿ç”¨": [r'subprocess', r'os\.system', r'command'],
            "æ•¸æ“šåº«æ“ä½œ": [r'sql', r'database', r'\.execute', r'query'],
            "æ—¥èªŒè¨˜éŒ„": [r'log\.', r'logger\.', r'print\('],
            "ç‹€æ…‹ä¿®æ”¹": [r'self\.', r'global ', r'nonlocal ']
        }
        
        for effect_type, patterns in side_effect_patterns.items():
            for pattern in patterns:
                if re.search(pattern, source_code):
                    side_effects.append(effect_type)
                    break
        
        return side_effects
    
    def _generate_examples(self, capability: Dict[str, Any],
                         semantic_analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆä½¿ç”¨ç¤ºä¾‹
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            List[Dict]: ä½¿ç”¨ç¤ºä¾‹åˆ—è¡¨
        """
        examples = []
        
        function_name = capability.get("name", "unknown_function")
        parameters = self._analyze_parameters(capability)
        
        # ç”ŸæˆåŸºæœ¬ç¤ºä¾‹
        if parameters:
            # ç”Ÿæˆå®Œæ•´åƒæ•¸ç¤ºä¾‹
            param_examples = []
            for param in parameters:
                if param.is_required:
                    if param.type_hint:
                        if "str" in param.type_hint.lower():
                            param_examples.append(f'{param.name}="example_value"')
                        elif "int" in param.type_hint.lower():
                            param_examples.append(f'{param.name}=123')
                        elif "bool" in param.type_hint.lower():
                            param_examples.append(f'{param.name}=True')
                        else:
                            param_examples.append(f'{param.name}=example_value')
                    else:
                        param_examples.append(f'{param.name}="example"')
            
            if param_examples:
                example_call = f"{function_name}({', '.join(param_examples)})"
                examples.append({
                    "type": "basic_usage",
                    "description": "åŸºæœ¬ç”¨æ³•ç¤ºä¾‹",
                    "code": example_call
                })
        else:
            # ç„¡åƒæ•¸å‡½æ•¸
            examples.append({
                "type": "basic_usage", 
                "description": "åŸºæœ¬ç”¨æ³•ç¤ºä¾‹",
                "code": f"{function_name}()"
            })
        
        # æ ¹æ“šåŠŸèƒ½é¡å‹ç”Ÿæˆç‰¹å®šç¤ºä¾‹
        function_type = self._classify_function_type(capability, semantic_analysis)
        
        if function_type == FunctionType.SCANNING:
            examples.append({
                "type": "scanning_example",
                "description": "æƒæç¤ºä¾‹",
                "code": f'result = await {function_name}("https://example.com")\nprint(result)'
            })
        elif function_type == FunctionType.ANALYSIS:
            examples.append({
                "type": "analysis_example", 
                "description": "åˆ†æç¤ºä¾‹",
                "code": f'analysis = {function_name}(data)\nfor finding in analysis["findings"]:\n    print(finding)'
            })
        
        return examples
    
    def _find_related_capabilities(self, capability: Dict[str, Any]) -> List[str]:
        """
        æŸ¥æ‰¾ç›¸é—œèƒ½åŠ›
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            List[str]: ç›¸é—œèƒ½åŠ›IDåˆ—è¡¨
        """
        related = []
        
        if self.rag_engine:
            try:
                # ä½¿ç”¨RAGå¼•æ“æŸ¥æ‰¾ç›¸é—œèƒ½åŠ›
                query = f"{capability.get('name', '')} {capability.get('docstring', '')}"
                # ä½¿ç”¨ RAG å¼•æ“æœå°‹ç›¸é—œèƒ½åŠ›
                try:
                    # æ¨¡æ“¬ RAG æœå°‹çµæœï¼ˆç­‰å¾… RAG å¼•æ“å®Œæ•´å¯¦ç¾ï¼‰
                    search_results = {
                        "similar_capabilities": [
                            {"name": f"related_{capability.get('name', 'capability')}", "similarity": 0.8}
                        ]
                    }
                except Exception as e:
                    logger.warning(f"RAGæœå°‹ç›¸é—œèƒ½åŠ›å¤±æ•—: {e}")
                    search_results = {"similar_capabilities": []}
                
                if isinstance(search_results, list):
                    for result in search_results[:5]:  # å–å‰5å€‹ç›¸é—œçµæœ
                        if result.get("capability_id") != capability.get("id"):
                            related.append(result.get("capability_id", ""))
                        
            except Exception as e:
                logger.warning(f"RAGæœç´¢ç›¸é—œèƒ½åŠ›å¤±æ•—: {e}")
        
        # åŸºæ–¼é—œéµå­—çš„ç°¡å–®é—œè¯ (RAGä¸å¯ç”¨æ™‚çš„å¾Œå‚™)
        if not related:
            # åŸºæ–¼åç¨±ç›¸ä¼¼æ€§çš„ç°¡å–®é—œè¯
            name = capability.get("name", "").lower()
            
            # ç°¡å–®é—œéµå­—æ¯”å°
            if "scan" in name:
                related.extend([
                    {"name": "port_scanner", "similarity": 0.6},
                    {"name": "vulnerability_scanner", "similarity": 0.7}
                ])
            elif "exploit" in name:
                related.extend([
                    {"name": "payload_generator", "similarity": 0.8},
                    {"name": "exploit_framework", "similarity": 0.9}
                ])
        
        return related
    
    def _generate_documentation(self, capability: Dict[str, Any],
                              semantic_analysis: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆèƒ½åŠ›æ–‡æª”
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            str: Markdownæ ¼å¼çš„æ–‡æª”
        """
        name = capability.get("name", "Unknown Function")
        docstring = capability.get("docstring", "")
        parameters = self._analyze_parameters(capability)
        
        # ç”ŸæˆMarkdownæ–‡æª”
        doc_lines = [
            f"# {name}",
            "",
            f"**æè¿°**: {docstring or 'æš«ç„¡æè¿°'}",
            "",
            f"**åŠŸèƒ½é¡å‹**: {self._classify_function_type(capability, semantic_analysis).value}",
            f"**é¢¨éšªç­‰ç´š**: {self._assess_risk_level(capability, semantic_analysis).value}",
            "",
            "## åƒæ•¸",
            ""
        ]
        
        if parameters:
            doc_lines.append("| åƒæ•¸å | é¡å‹ | å¿…éœ€ | é»˜èªå€¼ | æè¿° |")
            doc_lines.append("|--------|------|------|--------|------|")
            
            for param in parameters:
                required = "æ˜¯" if param.is_required else "å¦"
                default = param.default_value or "ç„¡"
                type_hint = param.type_hint or "Any"
                description = param.description or "æš«ç„¡æè¿°"
                
                doc_lines.append(f"| {param.name} | {type_hint} | {required} | {default} | {description} |")
        else:
            doc_lines.append("ç„¡åƒæ•¸")
        
        doc_lines.extend([
            "",
            "## è¿”å›å€¼",
            "",
            f"**é¡å‹**: {self._analyze_return_type(capability) or 'æœªæŒ‡å®š'}",
            "",
            "## ä½¿ç”¨ç¤ºä¾‹",
            "",
            "```python"
        ])
        
        # æ·»åŠ ç¤ºä¾‹ä»£ç¢¼ (åŒæ­¥èª¿ç”¨ï¼Œé€™è£¡ç°¡åŒ–è™•ç†)
        examples = []  # åœ¨å¯¦éš›ä½¿ç”¨ä¸­æ‡‰è©²èª¿ç”¨ _generate_examples
        if examples:
            doc_lines.append(examples[0].get("code", f"{name}()"))
        else:
            doc_lines.append(f"result = {name}()")
        
        doc_lines.extend([
            "```",
            ""
        ])
        
        return "\n".join(doc_lines)
    
    def _calculate_confidence_score(self, capability: Dict[str, Any],
                                   semantic_analysis: Dict[str, Any]) -> float:
        """
        è¨ˆç®—åˆ†æä¿¡å¿ƒåº¦åˆ†æ•¸
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            semantic_analysis: èªç¾©åˆ†æçµæœ
        
        Returns:
            float: ä¿¡å¿ƒåº¦åˆ†æ•¸ (0.0-1.0)
        """
        score = 0.0
        
        # åŸºç¤åˆ†æ•¸
        if capability.get("name"):
            score += 0.2
        
        if capability.get("docstring"):
            score += 0.3
        
        if capability.get("source_code"):
            score += 0.2
        
        # AIåˆ†æåŠ åˆ†
        if semantic_analysis.get("method") == "ai_analysis":
            score += 0.2
        
        # èªç¾©åˆ†æä¿¡å¿ƒåº¦
        ai_confidence = semantic_analysis.get("confidence", 0.0)
        score += ai_confidence * 0.1
        
        return min(score, 1.0)
    
    def _assess_complexity(self, capability: Dict[str, Any], 
                          analysis: CapabilityAnalysis) -> str:
        """
        è©•ä¼°è¤‡é›œåº¦
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
            analysis: åˆ†æçµæœ
        
        Returns:
            str: è¤‡é›œåº¦ç­‰ç´š (simple/medium/complex)
        """
        complexity_score = 0
        
        # åƒæ•¸æ•¸é‡
        param_count = len(analysis.parameters)
        if param_count > 5:
            complexity_score += 2
        elif param_count > 2:
            complexity_score += 1
        
        # å‰¯ä½œç”¨æ•¸é‡
        side_effect_count = len(analysis.side_effects)
        complexity_score += side_effect_count
        
        # é¢¨éšªç­‰ç´šå½±éŸ¿è¤‡é›œåº¦
        if analysis.risk_level == RiskLevel.HIGH:
            complexity_score += 2
        elif analysis.risk_level == RiskLevel.MEDIUM:
            complexity_score += 1
        
        # ä»£ç¢¼é•·åº¦ (ç²—ç•¥ä¼°è¨ˆ)
        source_code = capability.get("source_code", "")
        if source_code:
            lines = source_code.count('\n')
            if lines > 50:
                complexity_score += 2
            elif lines > 20:
                complexity_score += 1
        
        # åˆ†é¡
        if complexity_score >= 4:
            return "complex"
        elif complexity_score >= 2:
            return "medium"
        else:
            return "simple"
    
    def _create_default_analysis(self, capability: Dict[str, Any]) -> CapabilityAnalysis:
        """
        å‰µå»ºé»˜èªåˆ†æçµæœ (åˆ†æå¤±æ•—æ™‚ä½¿ç”¨)
        
        Args:
            capability: èƒ½åŠ›ä¿¡æ¯
        
        Returns:
            CapabilityAnalysis: é»˜èªåˆ†æçµæœ
        """
        return CapabilityAnalysis(
            capability_id=capability.get("id", "unknown"),
            function_type=PentestPhase.PRE_ENGAGEMENT,  # é è¨­å€¼
            risk_level=VulnerabilityRiskLevel.LOW,
            semantic_understanding={"method": "fallback", "description": "åˆ†æå¤±æ•—ï¼Œä½¿ç”¨é»˜èªå€¼"},
            parameters=[],
            return_type=None,
            side_effects=[],
            examples=[],
            related_capabilities=[],
            documentation=f"# {capability.get('name', 'Unknown Function')}\n\nåˆ†æå¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥ã€‚",
            confidence_score=0.1
        )
    
    def export_analysis_results(self) -> Dict[str, Any]:
        """
        å°å‡ºåˆ†æçµæœ
        
        Args:
            format: å°å‡ºæ ¼å¼ (json/markdown)
        
        Returns:
            Dict: å°å‡ºçš„çµæœ
        """
        results = {
            "analyzed_capabilities": len(self._analysis_cache),
            "classification": self._classification_cache.to_dict() if self._classification_cache else None,
            "analyses": {
                cap_id: analysis.to_dict() 
                for cap_id, analysis in self._analysis_cache.items()
            }
        }
        
        return results
    
    def clear_cache(self) -> None:
        """æ¸…ç†åˆ†æç·©å­˜"""
        self._analysis_cache.clear()
        self._classification_cache = None
        logger.info("åˆ†æç·©å­˜å·²æ¸…ç†")


# å°å‡ºä¸»è¦é¡
__all__ = [
    "CapabilityAnalyzer",
    "CapabilityAnalysis", 
    "CapabilityClassification",
    "ParameterInfo",
    "FunctionType"
]