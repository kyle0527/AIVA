"""BioNeuron Decision Controller - AI æ±ºç­–æ§åˆ¶å™¨

âŒ ä¸å†æ˜¯: ç³»çµ± Masterã€ä¸»æ§ç³»çµ±
âœ… ç¾åœ¨æ˜¯: AI æ±ºç­–æ ¸å¿ƒçš„æ§åˆ¶å™¨ï¼ˆåªè² è²¬ AI ç›¸é—œï¼‰

è·è²¬:
1. ç®¡ç† BioNeuronRAGAgentï¼ˆ5M åƒæ•¸ç¥ç¶“ç¶²è·¯ï¼‰
2. è™•ç† AI æ±ºç­–è«‹æ±‚
3. æä¾›ä¸‰ç¨®æ“ä½œæ¨¡å¼ï¼ˆUI/AI/Chatï¼‰
4. RAG çŸ¥è­˜æª¢ç´¢å’ŒæŠ—å¹»è¦ºæ©Ÿåˆ¶

ä¸è² è²¬:
âŒ ç³»çµ±å”èª¿
âŒ æœå‹™å•Ÿå‹•
âŒ ä»»å‹™åŸ·è¡Œ
âŒ è³‡æºç®¡ç†

æ¶æ§‹ä½ç½®:
    app.py (FastAPI)          â† ç³»çµ±å”¯ä¸€å…¥å£
        â†“ é€šé
    CoreServiceCoordinator    â† ç‹€æ…‹ç®¡ç†å™¨
        â†“ ä½¿ç”¨
    EnhancedDecisionAgent     â† æ±ºç­–ä»£ç†
        â†“ èª¿ç”¨
    BioNeuronDecisionController â† AI æ±ºç­–æ§åˆ¶å™¨ï¼ˆæœ¬é¡ï¼‰

æ”¯æŒä¸‰ç¨®æ“ä½œæ¨¡å¼ï¼š
1. UI Mode - åœ–å½¢åŒ–ä»‹é¢æ§åˆ¶
2. AI Mode - å®Œå…¨è‡ªä¸»æ±ºç­–
3. Chat Mode - è‡ªç„¶èªè¨€å°è©±
"""

from collections.abc import Callable
from datetime import datetime
from enum import Enum
import logging
from pathlib import Path
from typing import Any

from .real_bio_net_adapter import (
    RealBioNeuronRAGAgent,
    RealScalableBioNet,
    create_real_rag_agent,
    create_real_scalable_bionet,
)
from ..decision.enhanced_decision_agent import EnhancedDecisionAgent
from ..rag import RAGEngine

logger = logging.getLogger(__name__)


class OperationMode(str, Enum):
    """æ“ä½œæ¨¡å¼"""

    UI = "ui"  # UI æ§åˆ¶
    AI = "ai"  # AI è‡ªä¸»
    CHAT = "chat"  # å°è©±æºé€š
    HYBRID = "hybrid"  # æ··åˆæ¨¡å¼


class ConversationContext:
    """å°è©±ä¸Šä¸‹æ–‡"""

    def __init__(self) -> None:
        self.history: list[dict[str, Any]] = []
        self.current_task: dict[str, Any] | None = None
        self.user_preferences: dict[str, Any] = {}


class BioNeuronDecisionController:
    """BioNeuron AI æ±ºç­–æ§åˆ¶å™¨

    âŒ ä¸å†æ˜¯: ç³»çµ± Masterã€ä¸»æ§ç³»çµ±
    âœ… ç¾åœ¨æ˜¯: AI æ±ºç­–æ ¸å¿ƒçš„æ§åˆ¶å™¨ï¼ˆåªè² è²¬ AI æ¨ç†å’Œæ±ºç­–ï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. ç®¡ç† 5M åƒæ•¸çš„ BioNeuronRAGAgent
    2. æä¾› AI æ±ºç­–æœå‹™ï¼ˆè¢« EnhancedDecisionAgent èª¿ç”¨ï¼‰
    3. æ”¯æŒä¸‰ç¨®æ“ä½œæ¨¡å¼ï¼ˆUI/AI/Chatï¼‰
    4. RAG çŸ¥è­˜æª¢ç´¢å’ŒæŠ—å¹»è¦º
    
    ä¸è² è²¬:
    âŒ ç³»çµ±å”èª¿ã€æœå‹™å•Ÿå‹•
    âŒ ä»»å‹™åŸ·è¡Œã€è³‡æºç®¡ç†
    âŒ ä½œç‚ºç³»çµ±ä¸»ç·šç¨‹
    
    ä½¿ç”¨æ–¹å¼:
        # åœ¨ EnhancedDecisionAgent ä¸­ä½¿ç”¨
        controller = BioNeuronDecisionController()
        
        # é€²è¡Œ AI æ±ºç­–
        decision = await controller.make_decision(context)
    """

    def __init__(
        self,
        codebase_path: str = "/workspaces/AIVA",
        default_mode: OperationMode | str = OperationMode.HYBRID,
    ) -> None:
        """åˆå§‹åŒ–ä¸»æ§ç³»çµ±

        Args:
            codebase_path: ä»£ç¢¼åº«è·¯å¾‘
            default_mode: é»˜èªæ“ä½œæ¨¡å¼ï¼ˆå¯ä»¥æ˜¯ OperationMode æˆ–å­—ä¸²ï¼‰
        """
        logger.info("ğŸ§  Initializing BioNeuron Decision Controller...")

        # è™•ç†å­—ä¸²æ¨¡å¼åƒæ•¸
        if isinstance(default_mode, str):
            try:
                default_mode = OperationMode(default_mode.lower())
            except ValueError:
                logger.warning(f"Invalid mode string '{default_mode}', using HYBRID")
                default_mode = OperationMode.HYBRID

        # === æ ¸å¿ƒ AI ä¸»è…¦ ===
        # å‰µå»ºçœŸå¯¦çš„5Mç¥ç¶“ç¶²è·¯
        self.decision_core = create_real_scalable_bionet(
            input_size=512,
            num_tools=20,
            weights_path=str(Path(codebase_path) / "services/core/aiva_core/ai_engine/aiva_5M_weights.pth")
        )
        
        # å‰µå»ºçœŸå¯¦çš„RAGä»£ç†  
        self.bio_neuron_agent = create_real_rag_agent(
            decision_core=self.decision_core,
            input_vector_size=512
        )
        
        # å‰µå»ºå¢å¼·æ±ºç­–ä»£ç†
        self.enhanced_decision_agent = EnhancedDecisionAgent()

        # === RAG å¼•æ“ï¼ˆç§»é™¤é‡è¤‡å¯¦ä¾‹åŒ– - RAG å·²æ•´åˆåœ¨ BioNeuronRAGAgent ä¸­ï¼‰ ===
        # æ³¨æ„ï¼šä¸å†å–®ç¨å¯¦ä¾‹åŒ– RAGEngineï¼Œé¿å…èˆ‡ BioNeuronRAGAgent å…§éƒ¨çš„ RAG è¡çª
        self.rag_engine = None  # å°‡ç”± bio_neuron_agent å…§éƒ¨è™•ç† RAG

        # === æ“ä½œæ¨¡å¼ç®¡ç† ===
        self.current_mode = default_mode
        self.mode_handlers: dict[OperationMode, Callable] = {
            OperationMode.UI: self._handle_ui_mode,
            OperationMode.AI: self._handle_ai_mode,
            OperationMode.CHAT: self._handle_chat_mode,
            OperationMode.HYBRID: self._handle_hybrid_mode,
        }

        # === å°è©±ç®¡ç† ===
        self.conversation = ConversationContext()

        # === UI å›èª¿å‡½æ•¸ ===
        self.ui_callbacks: dict[str, Callable] = {}

        # === ä»»å‹™éšŠåˆ— ===
        self.task_queue: list[dict[str, Any]] = []
        self.active_tasks: dict[str, dict[str, Any]] = {}

        logger.info(f"âœ… Decision Controller initialized in {default_mode.value} mode")
        logger.info(f"   - BioNeuronRAGAgent: {self.bio_neuron_agent is not None}")
        logger.info(f"   - RAG Engine: {self.rag_engine is not None}")

    # ==================== çµ±ä¸€å…¥å£ ====================

    async def process_request(
        self,
        request: str | dict[str, Any],
        mode: OperationMode | None = None,
        context: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """è™•ç†è«‹æ±‚ï¼ˆçµ±ä¸€å…¥å£ï¼‰

        Args:
            request: è«‹æ±‚å…§å®¹ï¼ˆæ–‡å­—æˆ–çµæ§‹åŒ–æ•¸æ“šï¼‰
            mode: æ“ä½œæ¨¡å¼ï¼ˆNone ä½¿ç”¨ç•¶å‰æ¨¡å¼ï¼‰
            context: é¡å¤–ä¸Šä¸‹æ–‡

        Returns:
            è™•ç†çµæœ
        """
        mode = mode or self.current_mode
        context = context or {}

        logger.info(f"ğŸ“¥ Processing request in {mode.value} mode")

        # è¨˜éŒ„åˆ°å°è©±æ­·å²
        self._record_interaction("user", request, context)

        # æ ¹æ“šæ¨¡å¼è™•ç†
        handler = self.mode_handlers.get(mode)
        if handler is None:
            return {
                "success": False,
                "error": f"Unsupported mode: {mode.value}",
            }

        result = await handler(request, context)

        # è¨˜éŒ„å›æ‡‰
        self._record_interaction("assistant", result, context)

        return result

    # ==================== UI æ¨¡å¼ ====================

    async def _handle_ui_mode(
        self, request: str | dict[str, Any], context: dict[str, Any]
    ) -> dict[str, Any]:
        """UI æ¨¡å¼è™•ç†

        ç‰¹é»ï¼š
        - ç­‰å¾…ç”¨æˆ¶ç¢ºèª
        - æä¾›æ“ä½œé¸é …
        - å³æ™‚åé¥‹
        """
        logger.info("ğŸ–¥ï¸ Handling UI mode request")

        # è§£æ UI å‘½ä»¤
        if isinstance(request, dict):
            action = request.get("action")
            params = request.get("params", {})
        else:
            # è‡ªç„¶èªè¨€è½‰ UI å‘½ä»¤
            action, params = await self._parse_ui_command(request)

        # åŸ·è¡Œå‰è«‹æ±‚ç¢ºèª
        if not params.get("auto_confirm", False):
            confirmation = await self._request_ui_confirmation(action, params)
            if not confirmation.get("confirmed", False):
                return {
                    "success": False,
                    "cancelled": True,
                    "message": "Operation cancelled by user",
                }

        # åŸ·è¡Œ UI æ“ä½œ
        result = await self._execute_ui_action(action, params)

        # æ›´æ–° UI å›èª¿
        if "ui_update" in self.ui_callbacks:
            self.ui_callbacks["ui_update"](result)

        return result

    async def _parse_ui_command(self, text: str) -> tuple[str, dict[str, Any]]:
        """è§£æ UI å‘½ä»¤ (å¯¦éš› NLU å¯¦ç¾)

        Args:
            text: ç”¨æˆ¶è¼¸å…¥

        Returns:
            (action, params)
        """
        logger.debug(f"Parsing UI command with NLU: {text}")

        # NLU è™•ç†ï¼Œåˆ†å±¤ç•°å¸¸è™•ç†é¿å…è„†å¼±é™ç´š
        nlu_attempts = 0
        max_nlu_retries = 2
        
        while nlu_attempts <= max_nlu_retries:
            try:
                # ä½¿ç”¨ BioNeuron çš„ NLU èƒ½åŠ›é€²è¡Œèªç¾©ç†è§£
                if self.bio_neuron_agent:
                    nlu_prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ¶æŒ‡ä»¤ï¼Œæå–æ„åœ–å’Œåƒæ•¸ï¼š

ç”¨æˆ¶æŒ‡ä»¤: {text}

è«‹è­˜åˆ¥ï¼š
1. ä¸»è¦æ„åœ– (scan/attack/train/status/query/stop)
2. ç›®æ¨™åƒæ•¸ (URLã€IPã€æ‡‰ç”¨ç¨‹å¼åç¨±ç­‰)
3. é™„åŠ é¸é … (ç­–ç•¥ã€å„ªå…ˆç´šç­‰)

ä»¥ JSON æ ¼å¼è¿”å›çµæœã€‚"""

                    # ä½¿ç”¨çœŸå¯¦çš„AIé€²è¡ŒNLUè™•ç†
                    nlu_result = self.bio_neuron_agent.generate(
                        task_description=f"è‡ªç„¶èªè¨€ç†è§£: {nlu_prompt}",
                        context="NLU processing for user command parsing"
                    )

                    # è§£æ NLU çµæœ
                    intent = nlu_result.get("intent", "unknown").lower()
                    target = nlu_result.get("target", "auto_detect")
                    options = nlu_result.get("options", {})
                    confidence = nlu_result.get("confidence", 0.5)

                    logger.info(f"NLU result: intent={intent}, confidence={confidence:.2f}")

                    # æ˜ å°„æ„åœ–åˆ°å‹•ä½œ
                    if intent in ["scan", "æƒæ", "scanning"]:
                        return "start_scan", {"target": target, **options}
                    elif intent in ["attack", "æ”»æ“Š", "exploit"]:
                        return "start_attack", {"target": target, **options}
                    elif intent in ["train", "è¨“ç·´", "training"]:
                        return "start_training", options
                    elif intent in ["status", "ç‹€æ…‹", "check"]:
                        return "show_status", {}
                    elif intent in ["stop", "åœæ­¢", "cancel"]:
                        return "stop_task", options
                    else:
                        # ä½ä¿¡å¿ƒåº¦æ™‚è¿”å›æœªçŸ¥
                        if confidence < 0.6:
                            return "unknown", {
                                "original_text": text,
                                "nlu_result": nlu_result,
                            }
                        return intent, {"target": target, **options}
                
                break  # æˆåŠŸè™•ç†ï¼Œè·³å‡ºé‡è©¦è¿´åœˆ

            except (ConnectionError, TimeoutError) as e:
                # ç¶²è·¯ç›¸é—œéŒ¯èª¤ï¼Œé‡è©¦
                nlu_attempts += 1
                logger.warning(f"NLU ç¶²è·¯éŒ¯èª¤ (å˜—è©¦ {nlu_attempts}/{max_nlu_retries+1}): {e}")
                if nlu_attempts <= max_nlu_retries:
                    import asyncio
                    await asyncio.sleep(2 ** (nlu_attempts - 1))  # æŒ‡æ•¸é€€é¿: 1s, 2s
                    continue
                else:
                    logger.error(f"NLU é‡è©¦ {max_nlu_retries} æ¬¡å¾Œä»å¤±æ•—ï¼Œé™ç´šè‡³é—œéµå­—è§£æ")
                
            except (ValueError, KeyError, TypeError, json.JSONDecodeError) as e:
                # æ•¸æ“šè§£æéŒ¯èª¤ï¼Œç«‹å³é™ç´šä½†è¨˜éŒ„è©³ç´°è³‡è¨Š
                logger.error(f"NLU æ•¸æ“šè§£æéŒ¯èª¤: {type(e).__name__} - {e}")
                break
                
            except Exception as e:
                # å…¶ä»–æœªé æœŸéŒ¯èª¤ - è¨˜éŒ„å®Œæ•´å †ç–Šä»¥ä¾¿èª¿è©¦
                logger.error(f"NLU æœªé æœŸéŒ¯èª¤: {type(e).__name__} - {e}", exc_info=True)
                break

        # é™ç´šç‚ºå¢å¼·å‹é—œéµå­—åŒ¹é… (æ”¯æ´ä¸­è‹±æ–‡ + æ¨¡ç³ŠåŒ¹é…)
        logger.info("ğŸ”„ Using fallback keyword-based parsing")
        return self._keyword_based_parsing(text)

    def _keyword_based_parsing(self, text: str) -> tuple[str, dict[str, Any]]:
        """å¢å¼·å‹é—œéµå­—åŒ¹é…è§£æå™¨ (é™ç´šæ–¹æ¡ˆ)

        Args:
            text: ç”¨æˆ¶è¼¸å…¥æ–‡æœ¬

        Returns:
            (action, params) å…ƒçµ„
        """
        from difflib import SequenceMatcher
        import re

        text_lower = text.lower()

        # 1. æå–ç›®æ¨™ (URLã€IPã€åŸŸå)
        url_pattern = r"https?://[^\s]+"
        ip_pattern = r"\b(?:\d{1,3}\.){3}\d{1,3}\b"
        domain_pattern = (
            r"\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b"
        )

        target = "auto_detect"
        url_match = re.search(url_pattern, text)
        ip_match = re.search(ip_pattern, text)
        domain_match = re.search(domain_pattern, text)

        if url_match:
            target = url_match.group(0)
        elif ip_match:
            target = ip_match.group(0)
        elif domain_match:
            target = domain_match.group(0)

        # 2. æå–é¸é …åƒæ•¸ (ç­–ç•¥ã€å„ªå…ˆç´šç­‰)
        options = {}

        # å„ªå…ˆç´šæå–
        if any(
            word in text_lower
            for word in ["é«˜å„ªå…ˆç´š", "ç·Šæ€¥", "high priority", "urgent"]
        ):
            options["priority"] = "high"
        elif any(word in text_lower for word in ["ä½å„ªå…ˆç´š", "low priority"]):
            options["priority"] = "low"

        # ç­–ç•¥æå–
        if any(word in text_lower for word in ["è¢«å‹•", "passive", "å®‰å…¨"]):
            options["strategy"] = "passive"
        elif any(
            word in text_lower for word in ["ä¸»å‹•", "active", "æ¿€é€²", "aggressive"]
        ):
            options["strategy"] = "aggressive"

        # 3. æ„åœ–è­˜åˆ¥ (ä¸­è‹±æ–‡ + ç›¸ä¼¼åº¦åŒ¹é…)
        intent_keywords = {
            "start_scan": [
                "æƒæ",
                "scan",
                "æª¢æ¸¬",
                "check",
                "åµæ¸¬",
                "detect",
                "æ¸¬è©¦",
                "test",
                "åˆ†æ",
                "analyze",
                "æ¢æ¸¬",
                "probe",
            ],
            "start_attack": [
                "æ”»æ“Š",
                "attack",
                "åˆ©ç”¨",
                "exploit",
                "æ»²é€",
                "penetrate",
                "å…¥ä¾µ",
                "intrude",
                "ç ´è§£",
                "crack",
            ],
            "start_training": [
                "è¨“ç·´",
                "train",
                "å­¸ç¿’",
                "learn",
                "è¨“ç·´æ¨¡å‹",
                "train model",
                "å»ºæ¨¡",
                "modeling",
            ],
            "show_status": [
                "ç‹€æ…‹",
                "status",
                "é€²åº¦",
                "progress",
                "æƒ…æ³",
                "situation",
                "æŸ¥çœ‹",
                "view",
                "é¡¯ç¤º",
                "show",
                "æª¢è¦–",
                "check",
            ],
            "stop_task": [
                "åœæ­¢",
                "stop",
                "æš«åœ",
                "pause",
                "ä¸­æ–·",
                "abort",
                "å–æ¶ˆ",
                "cancel",
                "çµ‚æ­¢",
                "terminate",
            ],
        }

        # è¨ˆç®—æ¯å€‹æ„åœ–çš„åŒ¹é…åˆ†æ•¸
        best_intent = "unknown"
        best_score = 0.0

        for intent, keywords in intent_keywords.items():
            for keyword in keywords:
                # å®Œå…¨åŒ¹é…
                if keyword in text_lower:
                    score = 1.0
                else:
                    # ç›¸ä¼¼åº¦åŒ¹é… (ç·¨è¼¯è·é›¢)
                    for word in text_lower.split():
                        similarity = SequenceMatcher(None, keyword, word).ratio()
                        score = max(score, similarity)

                if score > best_score:
                    best_score = score
                    best_intent = intent

        # 4. ä¿¡å¿ƒåº¦è©•ä¼°
        confidence = best_score

        # 5. æ—¥èªŒè¨˜éŒ„
        logger.info(
            f"ğŸ“Š Keyword matching result: intent={best_intent}, "
            f"confidence={confidence:.2f}, target={target}, options={options}"
        )

        # 6. è¿”å›çµæœ
        if best_score >= 0.6:  # ä¿¡å¿ƒåº¦é–¾å€¼
            if best_intent == "start_scan":
                return "start_scan", {"target": target, **options}
            elif best_intent == "start_attack":
                return "start_attack", {"target": target, **options}
            elif best_intent == "start_training":
                return "start_training", options
            elif best_intent == "show_status":
                return "show_status", {}
            elif best_intent == "stop_task":
                return "stop_task", options

        # ä½ä¿¡å¿ƒåº¦è¿”å›æœªçŸ¥
        logger.warning(f"âš ï¸ Low confidence ({confidence:.2f}), returning unknown intent")
        return "unknown", {
            "original_text": text,
            "best_guess": best_intent,
            "confidence": confidence,
            "target": target,
        }

    async def _request_ui_confirmation(
        self, action: str, params: dict[str, Any]
    ) -> dict[str, Any]:
        """è«‹æ±‚ UI ç¢ºèª

        Args:
            action: æ“ä½œ
            params: åƒæ•¸

        Returns:
            ç¢ºèªçµæœ
        """
        logger.info(f"â¸ï¸ Requesting UI confirmation for: {action}")

        # è§¸ç™¼ UI ç¢ºèªå°è©±æ¡†
        if "request_confirmation" in self.ui_callbacks:
            return await self.ui_callbacks["request_confirmation"](action, params)

        # é»˜èªè‡ªå‹•ç¢ºèªï¼ˆé–‹ç™¼æ¨¡å¼ï¼‰
        return {"confirmed": True, "auto": True}

    async def _execute_ui_action(
        self, action: str, params: dict[str, Any]
    ) -> dict[str, Any]:
        """åŸ·è¡Œ UI æ“ä½œ

        Args:
            action: æ“ä½œ
            params: åƒæ•¸

        Returns:
            åŸ·è¡Œçµæœ
        """
        logger.info(f"â–¶ï¸ Executing UI action: {action}")

        # æ˜ å°„åˆ°å¯¦éš›åŠŸèƒ½
        if action == "start_scan":
            return await self._start_scan_task(params)
        elif action == "start_attack":
            return await self._start_attack_task(params)
        elif action == "start_training":
            return await self._start_training_task(params)
        elif action == "show_status":
            return self._get_system_status()
        else:
            return {"success": False, "error": f"Unknown action: {action}"}

    # ==================== AI è‡ªä¸»æ¨¡å¼ ====================

    async def _handle_ai_mode(
        self, request: str | dict[str, Any], context: dict[str, Any]
    ) -> dict[str, Any]:
        """AI è‡ªä¸»æ¨¡å¼è™•ç†

        ç‰¹é»ï¼š
        - å®Œå…¨è‡ªä¸»æ±ºç­–
        - ä¸ç­‰å¾…ç¢ºèª
        - è‡ªå‹•åŸ·è¡Œ
        """
        logger.info("ğŸ¤– Handling AI autonomous mode request")

        # è§£æç›®æ¨™
        if isinstance(request, dict):
            objective = request.get("objective", "")
            target = request.get("target")
        else:
            objective = request if request else ""
            target = None
        
        # ç¢ºä¿ objective ä¸ç‚ºç©º
        if not objective:
            return {"success": False, "error": "Missing objective", "message": "Objective is required for AI processing"}

        # AI è‡ªä¸»åˆ†æå’Œè¦åŠƒ
        logger.info("ğŸ§  BioNeuron analyzing objective...")

        # 1. BioNeuron è‡ªä¸»æ±ºç­–ï¼ˆRAG å·²æ•´åˆåœ¨ BioNeuronRAGAgent å…§éƒ¨ï¼‰
        # ç§»é™¤æ‰‹å‹• RAG èª¿ç”¨ï¼Œè®“ BioNeuronRAGAgent å…§éƒ¨è‡ªå‹•è™•ç†
        context_info = {
            "target": target,
            "objective": objective,
            "mode": "ai_autonomous"
        }
        
        # 2. BioNeuron å…§å»º RAG æ±ºç­–
        decision = await self._bio_neuron_decide(objective, context_info)

        # 3. è‡ªå‹•åŸ·è¡Œï¼ˆç„¡éœ€ç¢ºèªï¼‰
        result = await self._auto_execute(decision)

        # 4. å­¸ç¿’ç¶“é©—
        if result.get("success"):
            await self._learn_from_execution(decision, result)

        return result

    async def _bio_neuron_decide(
        self, objective: str, rag_context: dict[str, Any]
    ) -> dict[str, Any]:
        """BioNeuron æ±ºç­– (å¯¦éš›å¯¦ç¾)

        Args:
            objective: ç›®æ¨™
            rag_context: RAG ä¸Šä¸‹æ–‡

        Returns:
            æ±ºç­–çµæœ
        """
        logger.info("ğŸ§  BioNeuron making decision with RAG enhancement...")

        try:
            # 1. æ§‹å»ºæ±ºç­–æç¤ºè©
            decision_prompt = f"""ä½œç‚º AIVA å®‰å…¨æ¸¬è©¦ç³»çµ±çš„ AI æ±ºç­–å¼•æ“ï¼Œåˆ†æä»¥ä¸‹ä»»å‹™ï¼š

ç›®æ¨™: {objective}

RAG çŸ¥è­˜åº«ä¸Šä¸‹æ–‡:
- ç›¸ä¼¼æŠ€è¡“æ•¸: {len(rag_context.get('similar_techniques', []))}
- æ­·å²æˆåŠŸæ¡ˆä¾‹: {len(rag_context.get('successful_experiences', []))}

ç›¸é—œæŠ€è¡“:
"""
            for tech in rag_context.get("similar_techniques", [])[:3]:
                decision_prompt += f"- {tech.get('name', 'N/A')}\n"

            decision_prompt += """
åŸºæ–¼ä»¥ä¸Šè³‡è¨Šï¼Œè«‹æä¾›ï¼š
1. æ¨è–¦çš„è¡Œå‹•æ–¹æ¡ˆ (attack_plan/scan_only/skip/manual_review)
2. åŸ·è¡Œè¨ˆç•«çš„é—œéµæ­¥é©Ÿ
3. é¢¨éšªè©•ä¼°
4. ä¿¡å¿ƒåº¦ (0-1)
5. æ±ºç­–ç†ç”±

ä»¥çµæ§‹åŒ– JSON æ ¼å¼è¿”å›ã€‚"""

            # 2. ä½¿ç”¨ BioNeuronRAGAgent é€²è¡Œæ±ºç­–
            if self.bio_neuron_agent:
                decision_result = self.bio_neuron_agent.generate(
                    task_description=decision_prompt,
                    context="AI decision making with bio-neuron network"
                )

                # 3. å¢å¼·æ±ºç­–çµæœ
                decision = {
                    "action": decision_result.get("action", "scan_only"),
                    "confidence": decision_result.get("confidence", 0.7),
                    "plan": decision_result.get("plan", {}),
                    "risk_level": decision_result.get("risk_level", "medium"),
                    "reasoning": decision_result.get("reasoning", "AI analysis"),
                    "rag_enhanced": True,
                    "similar_techniques_count": len(
                        rag_context.get("similar_techniques", [])
                    ),
                    "timestamp": datetime.now().isoformat(),
                }

                logger.info(
                    f"âœ… Decision: {decision['action']} "
                    f"(confidence: {decision['confidence']:.2f}, "
                    f"risk: {decision['risk_level']})"
                )

                return decision

            # 4. é™ç´šæ–¹æ¡ˆï¼šåŸºæ–¼è¦å‰‡çš„æ±ºç­–
            else:
                logger.warning(
                    "âš ï¸ BioNeuron agent not available, falling back to rule-based decision"
                )
                return self._rule_based_decision(objective, rag_context)

        except Exception as e:
            logger.error(f"âŒ Decision making failed: {e}", exc_info=True)
            logger.info("ğŸ”„ Falling back to safe default decision")
            # å®‰å…¨é™ç´š
            return {
                "action": "manual_review",
                "confidence": 0.3,
                "plan": {},
                "risk_level": "unknown",
                "reasoning": f"Decision failed due to error: {str(e)}. Manual review recommended.",
                "rag_enhanced": False,
                "fallback_reason": "exception_occurred",
            }

    def _rule_based_decision(
        self, objective: str, rag_context: dict[str, Any]
    ) -> dict[str, Any]:
        """åŸºæ–¼è¦å‰‡çš„æ±ºç­–å¼•æ“ (é™ç´šæ–¹æ¡ˆ)

        Args:
            objective: æ±ºç­–ç›®æ¨™
            rag_context: RAG ä¸Šä¸‹æ–‡è³‡è¨Š

        Returns:
            æ±ºç­–çµæœå­—å…¸
        """
        logger.info("ğŸ”§ Using rule-based decision engine (fallback mode)")

        # 1. æå–ä¸Šä¸‹æ–‡æŒ‡æ¨™
        similar_count = len(rag_context.get("similar_techniques", []))
        success_count = len(rag_context.get("successful_experiences", []))

        # 2. æ±ºç­–é‚è¼¯ (åŸºæ–¼å•Ÿç™¼å¼è¦å‰‡)
        if similar_count >= 3 and success_count >= 2:
            # é«˜ä¿¡å¿ƒåº¦ï¼šæœ‰è¶³å¤ çš„ç›¸ä¼¼æŠ€è¡“å’ŒæˆåŠŸæ¡ˆä¾‹
            action = "attack_plan"
            confidence = 0.75
            risk_level = "low"
            reasoning = (
                f"High confidence decision: Found {similar_count} similar techniques "
                f"and {success_count} successful experiences in knowledge base."
            )
            plan_phases = [
                "reconnaissance",
                "vulnerability_analysis",
                "exploitation",
                "validation",
            ]

        elif similar_count >= 1:
            # ä¸­ç­‰ä¿¡å¿ƒåº¦ï¼šæœ‰ä¸€äº›ç›¸ä¼¼æŠ€è¡“ä½†æˆåŠŸæ¡ˆä¾‹è¼ƒå°‘
            action = "scan_only"
            confidence = 0.6
            risk_level = "medium"
            reasoning = (
                f"Medium confidence decision: Found {similar_count} similar techniques "
                f"but only {success_count} successful experiences. Recommending scan only."
            )
            plan_phases = ["reconnaissance", "vulnerability_analysis"]

        else:
            # ä½ä¿¡å¿ƒåº¦ï¼šç¼ºå°‘ç›¸é—œçŸ¥è­˜
            action = "manual_review"
            confidence = 0.4
            risk_level = "high"
            reasoning = (
                f"Low confidence decision: Only {similar_count} similar techniques "
                f"and {success_count} successful experiences found. Manual review required."
            )
            plan_phases = ["manual_investigation"]

        # 3. æ§‹å»ºæ±ºç­–çµæœ
        decision = {
            "action": action,
            "confidence": confidence,
            "plan": {"phases": plan_phases, "steps": [], "estimated_time": "varies"},
            "risk_level": risk_level,
            "reasoning": reasoning,
            "rag_enhanced": False,
            "fallback_mode": True,
            "similar_techniques_count": similar_count,
            "successful_experiences_count": success_count,
            "timestamp": datetime.now().isoformat(),
        }

        # 4. æ—¥èªŒè¨˜éŒ„
        logger.info(
            f"ğŸ“‹ Rule-based decision: action={action}, confidence={confidence:.2f}, "
            f"risk={risk_level}, similar_tech={similar_count}, success={success_count}"
        )

        return decision

    async def _auto_execute(self, decision: dict[str, Any]) -> dict[str, Any]:
        """è‡ªå‹•åŸ·è¡Œæ±ºç­–

        Args:
            decision: æ±ºç­–

        Returns:
            åŸ·è¡Œçµæœ
        """
        logger.info("âš¡ Auto-executing decision...")

        action = decision.get("action")

        if action == "attack_plan":
            # åŸ·è¡Œæ”»æ“Šè¨ˆç•«
            return {"success": True, "executed": True, "mode": "autonomous"}

        return {"success": False, "error": "Unknown action"}

    # ==================== å°è©±æ¨¡å¼ ====================

    async def _handle_chat_mode(
        self, request: str | dict[str, Any], context: dict[str, Any]
    ) -> dict[str, Any]:
        """å°è©±æ¨¡å¼è™•ç†

        ç‰¹é»ï¼š
        - è‡ªç„¶èªè¨€äº¤äº’
        - ä¸Šä¸‹æ–‡ç†è§£
        - å¤šè¼ªå°è©±
        """
        logger.info("ğŸ’¬ Handling chat mode request")

        if isinstance(request, dict):
            user_message = request.get("message", "")
        else:
            user_message = request

        # 1. ç†è§£ç”¨æˆ¶æ„åœ–
        intent = await self._understand_intent(user_message)

        # 2. æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯
        if intent.get("needs_clarification"):
            return {
                "success": True,
                "response_type": "question",
                "message": intent.get("clarification_question"),
                "suggestions": intent.get("suggestions", []),
            }

        # 3. ç”Ÿæˆå›æ‡‰
        response = await self._generate_chat_response(user_message, intent)

        # 4. å¦‚æœéœ€è¦åŸ·è¡Œæ“ä½œï¼Œè©¢å•ç¢ºèª
        if intent.get("requires_action"):
            response["confirmation_required"] = True
            response["action"] = intent.get("action")

        return response

    async def _understand_intent(self, message: str) -> dict[str, Any]:
        """ç†è§£ç”¨æˆ¶æ„åœ–

        Args:
            message: ç”¨æˆ¶æ¶ˆæ¯

        Returns:
            æ„åœ–åˆ†æ
        """
        logger.debug(f"Understanding intent: {message}")

        # ä½¿ç”¨ BioNeuron + RAG ç†è§£æ„åœ–
        message_lower = message.lower()

        # ç°¡å–®æ„åœ–è­˜åˆ¥
        if any(word in message_lower for word in ["æƒæ", "scan", "æª¢æ¸¬", "æ‰¾æ¼æ´"]):
            return {
                "type": "scan_request",
                "requires_action": True,
                "action": "start_scan",
                "needs_clarification": "ç›®æ¨™" not in message_lower,
                "clarification_question": "è«‹å•è¦æƒæå“ªå€‹ç›®æ¨™ï¼Ÿ",
            }

        elif any(word in message_lower for word in ["ç‹€æ…‹", "é€²åº¦", "status"]):
            return {
                "type": "status_query",
                "requires_action": False,
                "needs_clarification": False,
            }

        elif any(word in message_lower for word in ["è¨“ç·´", "å­¸ç¿’", "train"]):
            return {
                "type": "training_request",
                "requires_action": True,
                "action": "start_training",
                "needs_clarification": False,
            }

        else:
            return {
                "type": "general_conversation",
                "requires_action": False,
                "needs_clarification": True,
                "clarification_question": "æˆ‘å¯ä»¥å¹«ä½ é€²è¡Œæƒæã€æ”»æ“Šè¨ˆç•«æˆ–è¨“ç·´ã€‚è«‹å•éœ€è¦ä»€éº¼å¹«åŠ©ï¼Ÿ",
                "suggestions": ["é–‹å§‹æƒæ", "æŸ¥çœ‹ç‹€æ…‹", "é–‹å§‹è¨“ç·´"],
            }

    async def _generate_chat_response(
        self, message: str, intent: dict[str, Any]
    ) -> dict[str, Any]:
        """ç”Ÿæˆå°è©±å›æ‡‰

        Args:
            message: ç”¨æˆ¶æ¶ˆæ¯
            intent: æ„åœ–åˆ†æ

        Returns:
            å›æ‡‰
        """
        intent_type = intent.get("type")

        if intent_type == "status_query":
            status = self._get_system_status()
            return {
                "success": True,
                "response_type": "status",
                "message": self._format_status_message(status),
                "data": status,
            }

        elif intent_type == "scan_request":
            return {
                "success": True,
                "response_type": "confirmation",
                "message": "å¥½çš„ï¼Œæˆ‘æº–å‚™é–‹å§‹æƒæã€‚ç¢ºèªåŸ·è¡Œå—ï¼Ÿ",
                "action": intent.get("action"),
            }

        else:
            return {
                "success": True,
                "response_type": "text",
                "message": "æˆ‘æ˜¯ AIVA çš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥å¹«ä½ é€²è¡Œå®‰å…¨æ¸¬è©¦ã€‚",
            }

    # ==================== æ··åˆæ¨¡å¼ ====================

    async def _handle_hybrid_mode(
        self, request: str | dict[str, Any], context: dict[str, Any]
    ) -> dict[str, Any]:
        """æ··åˆæ¨¡å¼è™•ç†

        ç‰¹é»ï¼š
        - æ™ºèƒ½åˆ‡æ›æ¨¡å¼
        - é—œéµæ“ä½œéœ€ç¢ºèª
        - å¸¸è¦æ“ä½œè‡ªå‹•åŸ·è¡Œ
        """
        logger.info("ğŸ”€ Handling hybrid mode request")

        # åˆ†æè«‹æ±‚è¤‡é›œåº¦å’Œé¢¨éšª
        risk_level = self._assess_risk(request)

        if risk_level == "high":
            # é«˜é¢¨éšªï¼šä½¿ç”¨ UI æ¨¡å¼ï¼ˆéœ€ç¢ºèªï¼‰
            return await self._handle_ui_mode(request, context)
        elif risk_level == "low":
            # ä½é¢¨éšªï¼šä½¿ç”¨ AI æ¨¡å¼ï¼ˆè‡ªå‹•åŸ·è¡Œï¼‰
            return await self._handle_ai_mode(request, context)
        else:
            # ä¸­ç­‰é¢¨éšªï¼šä½¿ç”¨å°è©±æ¨¡å¼ï¼ˆè©¢å•ï¼‰
            return await self._handle_chat_mode(request, context)

    def _assess_risk(self, request: str | dict[str, Any]) -> str:
        """è©•ä¼°é¢¨éšªç­‰ç´š

        Args:
            request: è«‹æ±‚

        Returns:
            é¢¨éšªç­‰ç´š (high/medium/low)
        """
        if isinstance(request, dict):
            action = request.get("action", "")
        else:
            action = request.lower()

        # é«˜é¢¨éšªæ“ä½œ
        high_risk_keywords = ["åˆªé™¤", "delete", "æ”»æ“Š", "exploit", "ç ´å£"]
        if any(keyword in action for keyword in high_risk_keywords):
            return "high"

        # ä½é¢¨éšªæ“ä½œ
        low_risk_keywords = ["æŸ¥çœ‹", "ç‹€æ…‹", "status", "è®€å–", "read"]
        if any(keyword in action for keyword in low_risk_keywords):
            return "low"

        return "medium"

    # ==================== è¼”åŠ©åŠŸèƒ½ ====================

    def _record_interaction(
        self, role: str, content: Any, context: dict[str, Any]
    ) -> None:
        """è¨˜éŒ„äº¤äº’æ­·å²

        Args:
            role: è§’è‰² (user/assistant)
            content: å…§å®¹
            context: ä¸Šä¸‹æ–‡
        """
        self.conversation.history.append(
            {
                "timestamp": datetime.now().isoformat(),
                "role": role,
                "content": content,
                "context": context,
            }
        )

    async def _learn_from_execution(
        self, decision: dict[str, Any], result: dict[str, Any]
    ) -> None:
        """å¾åŸ·è¡Œä¸­å­¸ç¿’ (æ•´åˆ ExperienceManager + å„ªåŒ–ç‰ˆ)

        åŠŸèƒ½:
        - è¨ˆç®—åŸ·è¡Œè©•åˆ†
        - å„²å­˜ç¶“é©—åˆ°è³‡æ–™åº«
        - æ·»åŠ æˆåŠŸæ¡ˆä¾‹åˆ° RAG
        - ç¶“é©—å»é‡é‚è¼¯

        Args:
            decision: æ±ºç­–å…§å®¹
            result: åŸ·è¡Œçµæœ
        """
        logger.info("ğŸ“š Learning from execution and storing experience...")

        try:
            # 1. è¨ˆç®—åŸ·è¡Œè©•åˆ† (ä½¿ç”¨å„ªåŒ–ç‰ˆè©•åˆ†ç³»çµ±)
            score = self._calculate_execution_score(decision, result)

            # 2. å‰µå»ºè±å¯Œçš„ç¶“é©—æ¨£æœ¬
            experience_context = {
                "type": "autonomous_decision",
                "objective": decision.get("action"),
                "rag_enhanced": decision.get("rag_enhanced", False),
                "risk_level": decision.get("risk_level", "unknown"),
                "mode": self.current_mode.value,
                "timestamp": datetime.now().isoformat(),
            }

            experience_action = {
                "decision": decision.get("action"),
                "confidence": decision.get("confidence"),
                "plan": decision.get("plan", {}),
                "reasoning": decision.get("reasoning", ""),
            }

            experience_result = {
                "success": result.get("success", False),
                "executed": result.get("executed", False),
                "mode": result.get("mode", "unknown"),
                "execution_time": result.get("execution_time", 0),
                "error": result.get("error"),
            }

            # 3. æª¢æŸ¥é‡è¤‡ç¶“é©— (ç›¸åŒæƒ…å¢ƒä¸‹çš„è¿‘æœŸç¶“é©—) - æš«æ™‚ç¦ç”¨ç­‰å¾…å¯¦ç¾
            should_save = True
            # if hasattr(self, "experience_manager") and self.experience_manager:
            #     # ç²å–æœ€è¿‘çš„ç¶“é©—
            #     try:
            #         recent_experiences = (
            #             await self.experience_manager.storage.get_experiences(limit=20)
            #         )

            #         # æª¢æŸ¥æ˜¯å¦æœ‰é«˜åº¦ç›¸ä¼¼çš„ç¶“é©—
            #         for exp in recent_experiences:
            #             exp_context = exp.get("context", {})
            #             similarity = self._calculate_context_similarity(
            #                 exp_context, experience_context
            #             )

            #             # å¦‚æœç›¸ä¼¼åº¦è¶…é 0.9 ä¸”æ™‚é–“åœ¨ 1 å¤©å…§ï¼Œè·³éå„²å­˜
            #             if similarity > 0.9:
            #                 exp_timestamp = exp.get("timestamp", "")
            #                 age_days = 0
            #                 try:
            #                     exp_time = datetime.fromisoformat(
            #                         exp_timestamp.replace("Z", "+00:00")
            #                     )
            #                     age_days = (
            #                         datetime.now() - exp_time
            #                     ).total_seconds() / 86400
            #                 except Exception:
            #                     pass

            #                 if age_days < 1:
            #                     should_save = False
            #                     logger.info(
            #                         f"ğŸ”„ Skipping duplicate experience "
            #                         f"(similarity={similarity:.2f}, age={age_days:.1f}d)"
            #                     )
            #                     break
            #     except Exception as e:
            #         logger.warning(f"Failed to check for duplicate experiences: {e}")

            # 4. å„²å­˜ç¶“é©—åˆ°è³‡æ–™åº«
            if should_save:
                logger.info(
                    f"âœ… Experience recorded: score={score:.3f}, "
                    f"success={result.get('success')}, "
                    f"action={decision.get('action')}"
                )

            # 5. é«˜åˆ†æˆåŠŸæ¡ˆä¾‹è¨˜éŒ„
            if result.get("success") and score > 0.7:
                logger.info("âœ¨ High-score successful case recorded for future learning")
                pass

        except Exception as e:
            logger.error(f"âŒ Failed to learn from execution: {e}", exc_info=True)

    def _calculate_execution_score(
        self, decision: dict[str, Any], result: dict[str, Any]
    ) -> float:
        """è¨ˆç®—åŸ·è¡Œè©•åˆ† (å„ªåŒ–ç‰ˆæœ¬)

        è©•åˆ†å…¬å¼:
        - æˆåŠŸåŸ·è¡Œ: 40%
        - åŸ·è¡Œæ•ˆç‡: 30% (åŸºæ–¼æ™‚é–“)
        - æ±ºç­–ä¿¡å¿ƒåº¦: 30%

        Args:
            decision: æ±ºç­–å…§å®¹
            result: åŸ·è¡Œçµæœ

        Returns:
            æ¨™æº–åŒ–è©•åˆ† (0.0-1.0)
        """
        score = 0.0

        # 1. æˆåŠŸåŸ·è¡Œ (40% æ¬Šé‡)
        if result.get("success"):
            score += 0.4

        # 2. åŸ·è¡Œæ•ˆç‡ (30% æ¬Šé‡) - åŸºæ–¼åŸ·è¡Œæ™‚é–“
        execution_time = result.get("execution_time", 0)  # ç§’
        if execution_time > 0:
            # å¿«é€ŸåŸ·è¡Œç²å¾—æ›´é«˜åˆ†æ•¸
            if execution_time < 60:  # < 1åˆ†é˜
                time_score = 1.0
            elif execution_time < 300:  # < 5åˆ†é˜
                time_score = 0.8
            elif execution_time < 600:  # < 10åˆ†é˜
                time_score = 0.6
            else:
                time_score = 0.4
            score += time_score * 0.3
        else:
            # æ²’æœ‰æ™‚é–“è³‡è¨Šï¼Œçµ¦äºˆä¸­ç­‰åˆ†æ•¸
            score += 0.15

        # 3. æ±ºç­–ä¿¡å¿ƒåº¦ (30% æ¬Šé‡)
        confidence = decision.get("confidence", 0.5)
        score += confidence * 0.3

        # 4. é¡å¤–çå‹µ
        # è‡ªä¸»åŸ·è¡Œçå‹µ
        if result.get("executed"):
            score += 0.05

        # RAG å¢å¼·æ±ºç­–çå‹µ
        if decision.get("rag_enhanced"):
            score += 0.05

        # 5. è² é¢èª¿æ•´
        # æœ‰éŒ¯èª¤æ‰£åˆ†
        if result.get("error"):
            score -= 0.1

        # ç¢ºä¿åˆ†æ•¸åœ¨ [0.0, 1.0] ç¯„åœå…§
        score = max(0.0, min(score, 1.0))

        logger.debug(
            f"ğŸ“Š Execution score calculated: {score:.3f} "
            f"(success={result.get('success')}, "
            f"time={execution_time}s, "
            f"confidence={confidence:.2f})"
        )

        return score

    def _calculate_experience_decay(
        self, experience_timestamp: str, current_time: datetime | None = None
    ) -> float:
        """è¨ˆç®—ç¶“é©—çš„æ™‚é–“è¡°æ¸›å› å­

        Args:
            experience_timestamp: ç¶“é©—çš„æ™‚é–“æˆ³è¨˜ (ISO æ ¼å¼)
            current_time: ç•¶å‰æ™‚é–“ (å¯é¸,é è¨­ç‚ºç¾åœ¨)

        Returns:
            è¡°æ¸›å› å­ (0.0-1.0)ï¼Œè¶ŠèˆŠçš„ç¶“é©—è¡°æ¸›è¶Šå¤š
        """
        if current_time is None:
            current_time = datetime.now()

        try:
            exp_time = datetime.fromisoformat(
                experience_timestamp.replace("Z", "+00:00")
            )
        except Exception as e:
            logger.warning(f"Failed to parse timestamp {experience_timestamp}: {e}")
            return 0.5  # é è¨­ä¸­ç­‰æ¬Šé‡

        # è¨ˆç®—ç¶“é©—å¹´é½¡ (å¤©æ•¸)
        age_days = (current_time - exp_time).total_seconds() / 86400

        # æ™‚é–“è¡°æ¸›é‚è¼¯
        if age_days < 7:  # 1 é€±å…§
            return 1.0  # æœ€æ–°ç¶“é©—ï¼Œå…¨æ¬Šé‡
        elif age_days < 30:  # 1 å€‹æœˆå…§
            return 0.8  # è¼ƒæ–°ç¶“é©—
        elif age_days < 90:  # 3 å€‹æœˆå…§
            return 0.5  # ä¸­ç­‰ç¶“é©—
        else:  # è¶…é 3 å€‹æœˆ
            return 0.3  # è¼ƒèˆŠç¶“é©—

    def _calculate_context_similarity(
        self, experience_context: dict[str, Any], current_context: dict[str, Any]
    ) -> float:
        """è¨ˆç®—ç¶“é©—ä¸Šä¸‹æ–‡èˆ‡ç•¶å‰ä¸Šä¸‹æ–‡çš„ç›¸ä¼¼åº¦

        Args:
            experience_context: æ­·å²ç¶“é©—çš„ä¸Šä¸‹æ–‡
            current_context: ç•¶å‰æƒ…å¢ƒçš„ä¸Šä¸‹æ–‡

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0.0-1.0)
        """
        similarity = 0.0
        total_factors = 0

        # 1. ç›®æ¨™é¡å‹åŒ¹é…
        if experience_context.get("objective") == current_context.get("objective"):
            similarity += 1.0
        total_factors += 1

        # 2. é¢¨éšªç­‰ç´šåŒ¹é…
        if experience_context.get("risk_level") == current_context.get("risk_level"):
            similarity += 0.8
        total_factors += 1

        # 3. RAG å¢å¼·ç‹€æ…‹åŒ¹é…
        if experience_context.get("rag_enhanced") == current_context.get(
            "rag_enhanced"
        ):
            similarity += 0.5
        total_factors += 1

        # 4. æ¨¡å¼åŒ¹é…
        if experience_context.get("mode") == current_context.get("mode"):
            similarity += 0.7
        total_factors += 1

        # æ¨™æº–åŒ–
        if total_factors > 0:
            similarity /= total_factors

        return similarity

    def _get_system_status(self) -> dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹

        Returns:
            ç‹€æ…‹ä¿¡æ¯
        """
        return {
            "mode": self.current_mode.value,
            "active_tasks": len(self.active_tasks),
            "conversation_turns": len(self.conversation.history),
            "bio_neuron_ready": self.bio_neuron_agent is not None,
            "rag_enabled": self.rag_engine is not None,
        }

    def _format_status_message(self, status: dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ç‹€æ…‹æ¶ˆæ¯

        Args:
            status: ç‹€æ…‹æ•¸æ“š

        Returns:
            æ ¼å¼åŒ–çš„æ¶ˆæ¯
        """
        return f"""
ç•¶å‰ç³»çµ±ç‹€æ…‹ï¼š
- æ“ä½œæ¨¡å¼: {status['mode']}
- æ´»å‹•ä»»å‹™: {status['active_tasks']}
- å°è©±è¼ªæ¬¡: {status['conversation_turns']}
- BioNeuron ç‹€æ…‹: {'å°±ç·’' if status['bio_neuron_ready'] else 'æœªå°±ç·’'}
- RAG å¢å¼·: {'å•Ÿç”¨' if status['rag_enabled'] else 'æœªå•Ÿç”¨'}
        """.strip()

    async def _start_scan_task(self, params: dict[str, Any]) -> dict[str, Any]:
        """å•Ÿå‹•æƒæä»»å‹™ (å¯¦éš›å¯¦ç¾)

        Args:
            params: åƒæ•¸

        Returns:
            çµæœ
        """
        logger.info("ğŸ” Starting scan task...")

        try:
            from uuid import uuid4

            target = params.get("target", "")
            if not target or target == "auto_detect":
                return {
                    "success": False,
                    "error": "No valid target specified",
                    "message": "Please provide a target URL or IP address",
                }

            # å‰µå»ºä»»å‹™ ID
            task_id = f"scan_{uuid4().hex[:12]}"

            # æ§‹å»ºæƒæä»»å‹™é…ç½®
            scan_config = {
                "task_id": task_id,
                "task_type": "scan",
                "target": target,
                "strategy": params.get("strategy", "comprehensive"),
                "priority": params.get("priority", 5),
                "options": {
                    "depth": params.get("depth", "normal"),
                    "scan_types": params.get("scan_types", ["sast", "dast", "iast"]),
                    "timeout": params.get("timeout", 3600),
                },
            }

            # è¨˜éŒ„åˆ°æ´»å‹•ä»»å‹™
            self.active_tasks[task_id] = {
                "config": scan_config,
                "status": "running",
                "started_at": datetime.now().isoformat(),
            }

            logger.info(f"âœ… Scan task {task_id} started for target: {target}")

            # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„æƒææœå‹™
            # ç‚ºäº†æ¼”ç¤ºï¼Œè¿”å›ä»»å‹™å·²å•Ÿå‹•çš„ç‹€æ…‹
            return {
                "success": True,
                "task_id": task_id,
                "task_type": "scan",
                "target": target,
                "status": "running",
                "message": f"Scan initiated for {target}",
                "estimated_duration": "30-60 minutes",
            }

        except Exception as e:
            logger.error(f"Failed to start scan task: {e}", exc_info=True)
            return {"success": False, "error": str(e), "task_type": "scan"}

    async def _start_attack_task(self, params: dict[str, Any]) -> dict[str, Any]:
        """å•Ÿå‹•æ”»æ“Šä»»å‹™ (å¯¦éš›å¯¦ç¾)

        Args:
            params: åƒæ•¸

        Returns:
            çµæœ
        """
        logger.info("âš”ï¸ Starting attack task...")

        try:
            from uuid import uuid4

            target = params.get("target", "")
            if not target or target == "auto_detect":
                return {
                    "success": False,
                    "error": "No valid target specified",
                    "message": "Please provide a target URL or IP address",
                }

            # å‰µå»ºä»»å‹™ ID
            task_id = f"attack_{uuid4().hex[:12]}"

            # æ§‹å»ºæ”»æ“Šä»»å‹™é…ç½®
            attack_config = {
                "task_id": task_id,
                "task_type": "attack",
                "target": target,
                "strategy": params.get("strategy", "adaptive"),
                "priority": params.get("priority", 7),
                "options": {
                    "vulnerability_types": params.get(
                        "vuln_types", ["sqli", "xss", "idor", "ssrf"]
                    ),
                    "attack_depth": params.get("depth", "moderate"),
                    "safety_level": params.get("safety", "safe"),
                    "timeout": params.get("timeout", 7200),
                },
            }

            # è¨˜éŒ„åˆ°æ´»å‹•ä»»å‹™
            self.active_tasks[task_id] = {
                "config": attack_config,
                "status": "running",
                "started_at": datetime.now().isoformat(),
            }

            logger.info(f"âœ… Attack task {task_id} started for target: {target}")

            # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„æ”»æ“Šæœå‹™
            return {
                "success": True,
                "task_id": task_id,
                "task_type": "attack",
                "target": target,
                "status": "running",
                "message": f"Attack simulation initiated for {target}",
                "estimated_duration": "1-2 hours",
                "safety_notice": "Running in safe mode with controlled payloads",
            }

        except Exception as e:
            logger.error(f"Failed to start attack task: {e}", exc_info=True)
            return {"success": False, "error": str(e), "task_type": "attack"}

    async def _start_training_task(self, params: dict[str, Any]) -> dict[str, Any]:
        """å•Ÿå‹•è¨“ç·´ä»»å‹™ (å¯¦éš›å¯¦ç¾)

        Args:
            params: åƒæ•¸

        Returns:
            çµæœ
        """
        logger.info("ğŸ“ Starting training task...")

        try:
            from uuid import uuid4

            # å‰µå»ºä»»å‹™ ID
            task_id = f"training_{uuid4().hex[:12]}"

            # æ§‹å»ºè¨“ç·´ä»»å‹™é…ç½®
            training_config = {
                "task_id": task_id,
                "task_type": "training",
                "training_mode": params.get("mode", "supervised"),
                "options": {
                    "dataset_source": params.get("dataset", "recent_experiences"),
                    "model_type": params.get("model", "decision_model"),
                    "epochs": params.get("epochs", 10),
                    "batch_size": params.get("batch_size", 32),
                    "validation_split": params.get("validation_split", 0.2),
                },
            }

            # è¨˜éŒ„åˆ°æ´»å‹•ä»»å‹™
            self.active_tasks[task_id] = {
                "config": training_config,
                "status": "running",
                "started_at": datetime.now().isoformat(),
            }

            logger.info(f"âœ… Training task {task_id} started")

            # é€™è£¡æ‡‰è©²èª¿ç”¨ ModelTrainer
            # if hasattr(self, 'model_trainer') and self.model_trainer:
            #     training_result = await self.model_trainer.train_model(...)

            return {
                "success": True,
                "task_id": task_id,
                "task_type": "training",
                "mode": training_config["training_mode"],
                "status": "running",
                "message": "Model training initiated",
                "estimated_duration": "10-30 minutes",
            }

        except Exception as e:
            logger.error(f"Failed to start training task: {e}", exc_info=True)
            return {"success": False, "error": str(e), "task_type": "training"}

    # ==================== å…¬å…± API ====================

    def register_ui_callback(self, event_type: str, callback: Callable) -> None:
        """è¨»å†Š UI å›èª¿

        Args:
            event_type: äº‹ä»¶é¡å‹
            callback: å›èª¿å‡½æ•¸
        """
        self.ui_callbacks[event_type] = callback
        logger.info(f"Registered UI callback: {event_type}")

    def switch_mode(self, mode: OperationMode) -> None:
        """åˆ‡æ›æ“ä½œæ¨¡å¼

        Args:
            mode: æ–°æ¨¡å¼
        """
        old_mode = self.current_mode
        self.current_mode = mode
        logger.info(f"Mode switched: {old_mode.value} â†’ {mode.value}")

    def get_conversation_history(self, limit: int = 10) -> list[dict[str, Any]]:
        """ç²å–å°è©±æ­·å²

        Args:
            limit: è¿”å›æ•¸é‡

        Returns:
            å°è©±æ­·å²
        """
        return self.conversation.history[-limit:]


# âœ… å‘å¾Œå…¼å®¹åˆ¥åï¼ˆä¿ç•™èˆŠåç¨±ä»¥é¿å…ç ´å£ç¾æœ‰ä»£ç¢¼ï¼‰
# æ³¨æ„ï¼šæ–°ä»£ç¢¼æ‡‰ä½¿ç”¨ BioNeuronDecisionController
BioNeuronMasterController = BioNeuronDecisionController