"""
AI Commander - AIVA ä¸­å¤® AI æŒ‡æ®ç³»çµ±

çµ±ä¸€æŒ‡æ®æ‰€æœ‰ AI çµ„ä»¶ï¼š
1. BioNeuronRAGAgentï¼ˆPython ä¸»æ§ AIï¼‰
2. RAG Engineï¼ˆçŸ¥è­˜æª¢ç´¢å¢å¼·ï¼‰
3. Training Orchestratorï¼ˆè¨“ç·´ç³»çµ±ï¼‰
4. Multi-Language AI Modulesï¼ˆGo/Rust/TypeScript AIï¼‰

æ¶æ§‹è¨­è¨ˆï¼š
- AI Commander ä½œç‚ºæœ€é«˜æŒ‡æ®å±¤
- å„èªè¨€ AI ä½œç‚ºå°ˆæ¥­åŸ·è¡Œå±¤
- RAG æä¾›çŸ¥è­˜æ”¯æŒ
- Training æä¾›æŒçºŒå­¸ç¿’
"""

from datetime import datetime
from enum import Enum
import logging
from pathlib import Path
from typing import Any
import logging

# åœ¨try-exceptä¹‹å‰å…ˆå®šç¾©logger
logger = logging.getLogger(__name__)

try:
    from services.aiva_common.ai import AIVAExperienceManager as ExperienceManager
    from services.aiva_common.ai.interfaces import IExperienceManager
    
    from .ai_engine import BioNeuronRAGAgent
    from .learning.model_trainer import ModelTrainer
    from .multilang_coordinator import MultiLanguageAICoordinator
    from .rag import KnowledgeBase, RAGEngine, VectorStore
    from .training.training_orchestrator import TrainingOrchestrator
except ImportError as e:
    logger.warning(f"Failed to import AI components: {e}")
    # å›é€€åˆ°æ ¸å¿ƒæ¨¡çµ„
    try:
        from services.core.aiva_core.ai_engine import BioNeuronRAGAgent
        from services.core.aiva_core.learning.model_trainer import ModelTrainer
        from services.core.aiva_core.multilang_coordinator import MultiLanguageAICoordinator
        from services.core.aiva_core.rag import KnowledgeBase, RAGEngine, VectorStore
        from services.core.aiva_core.training.training_orchestrator import (
            TrainingOrchestrator,
        )
        # ä½¿ç”¨ä»‹é¢çš„é è¨­å¯¦ç¾
        ExperienceManager = None
        IExperienceManager = None
    except ImportError:
        logger.error("Unable to import core AI components")
        # è¨­å®šé è¨­å€¼
        ExperienceManager = None
        IExperienceManager = None

logger = logging.getLogger(__name__)


class AITaskType(str, Enum):
    """AI ä»»å‹™é¡å‹"""

    # æ±ºç­–é¡
    ATTACK_PLANNING = "attack_planning"  # æ”»æ“Šè¨ˆç•«ç”Ÿæˆ
    STRATEGY_DECISION = "strategy_decision"  # ç­–ç•¥æ±ºç­–
    RISK_ASSESSMENT = "risk_assessment"  # é¢¨éšªè©•ä¼°

    # åŸ·è¡Œé¡
    VULNERABILITY_DETECTION = "vulnerability_detection"  # æ¼æ´æª¢æ¸¬
    EXPLOIT_EXECUTION = "exploit_execution"  # æ¼æ´åˆ©ç”¨
    CODE_ANALYSIS = "code_analysis"  # ä»£ç¢¼åˆ†æ

    # å­¸ç¿’é¡
    EXPERIENCE_LEARNING = "experience_learning"  # ç¶“é©—å­¸ç¿’
    MODEL_TRAINING = "model_training"  # æ¨¡å‹è¨“ç·´
    KNOWLEDGE_RETRIEVAL = "knowledge_retrieval"  # çŸ¥è­˜æª¢ç´¢

    # å”èª¿é¡
    MULTI_LANG_COORDINATION = "multi_lang_coordination"  # å¤šèªè¨€å”èª¿
    TASK_DELEGATION = "task_delegation"  # ä»»å‹™å§”æ´¾


class AIComponent(str, Enum):
    """AI çµ„ä»¶é¡å‹"""

    BIO_NEURON_AGENT = "bio_neuron_agent"  # Python ä¸»æ§ AI
    RAG_ENGINE = "rag_engine"  # RAG å¼•æ“
    TRAINING_SYSTEM = "training_system"  # è¨“ç·´ç³»çµ±
    MULTILANG_COORDINATOR = "multilang_coordinator"  # å¤šèªè¨€å”èª¿å™¨

    # èªè¨€å°ˆå±¬ AI
    GO_AI_MODULE = "go_ai_module"  # Go AI æ¨¡çµ„
    RUST_AI_MODULE = "rust_ai_module"  # Rust AI æ¨¡çµ„
    TS_AI_MODULE = "ts_ai_module"  # TypeScript AI æ¨¡çµ„


class AICommander:
    """AI æŒ‡æ®å®˜

    çµ±ä¸€ç®¡ç†å’Œå”èª¿æ‰€æœ‰ AI çµ„ä»¶ï¼Œè² è²¬ï¼š
    1. ä»»å‹™åˆ†æå’Œåˆ†é…
    2. AI çµ„ä»¶å”èª¿
    3. æ±ºç­–æ•´åˆ
    4. ç¶“é©—ç©ç´¯
    5. æŒçºŒå­¸ç¿’
    """

    def __init__(
        self,
        codebase_path: str = "/workspaces/AIVA",
        data_directory: Path | None = None,
    ) -> None:
        """åˆå§‹åŒ– AI æŒ‡æ®å®˜

        Args:
            codebase_path: ä»£ç¢¼åº«è·¯å¾‘
            data_directory: æ•¸æ“šç›®éŒ„
        """
        logger.info("ğŸ–ï¸ Initializing AI Commander...")

        self.data_directory = data_directory or Path("./data/ai_commander")
        self.data_directory.mkdir(parents=True, exist_ok=True)

        # === æ ¸å¿ƒ AI çµ„ä»¶ ===

        # 1. Python ä¸»æ§ AIï¼ˆBioNeuronRAGAgentï¼‰
        logger.info("  Loading BioNeuronRAGAgent...")
        self.bio_neuron_agent = BioNeuronRAGAgent(codebase_path)

        # 2. RAG ç³»çµ±ï¼ˆçŸ¥è­˜å¢å¼·ï¼‰
        logger.info("  Loading RAG Engine...")
        vector_store = VectorStore(
            backend="memory",  # å¯é…ç½®ç‚º chroma/faiss
            persist_directory=self.data_directory / "vectors",
        )
        knowledge_base = KnowledgeBase(
            vector_store=vector_store,
            data_directory=self.data_directory / "knowledge",
        )
        self.rag_engine = RAGEngine(knowledge_base=knowledge_base)

        # 3. ç¶“é©—ç®¡ç†å’Œæ¨¡å‹è¨“ç·´
        logger.info("  Loading Training System...")

        # æ•´åˆ ExperienceManager èˆ‡è³‡æ–™åº«å¾Œç«¯
        experience_db_path = self.data_directory / "experience_db"
        experience_db_path.mkdir(parents=True, exist_ok=True)

        # ä½¿ç”¨ç°¡å–®çš„ JSON æª”æ¡ˆå„²å­˜å¾Œç«¯ï¼ˆå¯æ“´å±•ç‚ºè³‡æ–™åº«ï¼‰
        class SimpleStorageBackend:
            """ç°¡å–®çš„æª”æ¡ˆå„²å­˜å¾Œç«¯"""

            def __init__(self, storage_path: Path):
                self.storage_path = storage_path
                self.experiences_file = storage_path / "experiences.json"
                if not self.experiences_file.exists():
                    import json

                    with open(self.experiences_file, "w", encoding="utf-8") as f:
                        json.dump([], f)

            async def add_experience(self, experience_data: dict):
                """æ·»åŠ ç¶“é©—è¨˜éŒ„"""
                import json

                try:
                    with open(self.experiences_file, encoding="utf-8") as f:
                        experiences = json.load(f)
                    experiences.append(experience_data)
                    with open(self.experiences_file, "w", encoding="utf-8") as f:
                        json.dump(experiences, f, indent=2, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"Failed to save experience: {e}")

            async def get_experiences(self, limit: int = 100) -> list[dict]:
                """ç²å–ç¶“é©—è¨˜éŒ„"""
                import json

                try:
                    with open(self.experiences_file, encoding="utf-8") as f:
                        experiences = json.load(f)
                    return experiences[-limit:]  # è¿”å›æœ€è¿‘çš„è¨˜éŒ„
                except Exception as e:
                    logger.error(f"Failed to load experiences: {e}")
                    return []

        storage_backend = SimpleStorageBackend(experience_db_path)
        self.experience_manager = ExperienceManager(
            storage_backend=storage_backend,
        )
        self.model_trainer = ModelTrainer(
            # ç§»é™¤ model_config åƒæ•¸é¿å…èˆ‡ Pydantic è¡çª
            # é…ç½®å°‡åœ¨å¾ŒçºŒé€šéæ–¹æ³•è¨­ç½®
        )

        # 4. è¨“ç·´ç·¨æ’å™¨ï¼ˆæ•´åˆ RAG å’Œè¨“ç·´ï¼‰
        try:
            from .execution.plan_executor import PlanExecutor
            from .messaging.message_broker import MessageBroker
            from .training.scenario_manager import ScenarioManager
        except ImportError:
            from services.core.aiva_core.execution.plan_executor import PlanExecutor
            from services.core.aiva_core.messaging.message_broker import MessageBroker
            from services.core.aiva_core.training.scenario_manager import (
                ScenarioManager,
            )

        scenario_manager = ScenarioManager()

        try:
            message_broker = MessageBroker()
            plan_executor = PlanExecutor(message_broker=message_broker)
        except TypeError:
            # å¦‚æœ PlanExecutor ä¸æ¥å— message_broker åƒæ•¸ï¼Œä½¿ç”¨ç„¡åƒæ•¸åˆå§‹åŒ–
            plan_executor = PlanExecutor()

        self.training_orchestrator = TrainingOrchestrator(
            scenario_manager=scenario_manager,
            rag_engine=self.rag_engine,
            plan_executor=plan_executor,
            experience_manager=self.experience_manager,
            model_trainer=self.model_trainer,
        )

        # 5. å¤šèªè¨€å”èª¿å™¨
        logger.info("  Loading Multi-Language Coordinator...")
        self.multilang_coordinator = MultiLanguageAICoordinator()

        # === æŒ‡æ®ç‹€æ…‹ ===
        self.command_history: list[dict[str, Any]] = []
        self.active_tasks: dict[str, dict[str, Any]] = {}
        self.component_status: dict[str, bool] = {
            component.value: True for component in AIComponent
        }

        logger.info("âœ… AI Commander initialized successfully")
        logger.info(f"   - BioNeuronRAGAgent: {self.bio_neuron_agent is not None}")
        logger.info(f"   - RAG Engine: {self.rag_engine is not None}")
        logger.info(f"   - Training System: {self.training_orchestrator is not None}")
        logger.info(
            f"   - Multi-Language Coordinator: {self.multilang_coordinator is not None}"
        )

    async def execute_command(
        self,
        task_type: AITaskType,
        context: dict[str, Any],
    ) -> dict[str, Any]:
        """åŸ·è¡Œ AI æŒ‡ä»¤

        Args:
            task_type: ä»»å‹™é¡å‹
            context: ä»»å‹™ä¸Šä¸‹æ–‡

        Returns:
            åŸ·è¡Œçµæœ
        """
        logger.info(f"ğŸ¯ Executing AI Command: {task_type.value}")

        # è¨˜éŒ„æŒ‡ä»¤
        command_id = f"cmd_{datetime.now().strftime('%Y%m%d_%H%M%S%f')}"
        command_record = {
            "command_id": command_id,
            "task_type": task_type.value,
            "context": context,
            "timestamp": datetime.now().isoformat(),
            "status": "started",
        }
        self.command_history.append(command_record)
        self.active_tasks[command_id] = command_record

        try:
            # æ ¹æ“šä»»å‹™é¡å‹åˆ†æ´¾
            if task_type == AITaskType.ATTACK_PLANNING:
                result = await self._plan_attack(context)

            elif task_type == AITaskType.STRATEGY_DECISION:
                result = await self._make_strategy_decision(context)

            elif task_type == AITaskType.VULNERABILITY_DETECTION:
                result = await self._detect_vulnerabilities(context)

            elif task_type == AITaskType.EXPERIENCE_LEARNING:
                result = await self._learn_from_experience(context)

            elif task_type == AITaskType.MODEL_TRAINING:
                result = await self._train_model(context)

            elif task_type == AITaskType.KNOWLEDGE_RETRIEVAL:
                result = await self._retrieve_knowledge(context)

            elif task_type == AITaskType.MULTI_LANG_COORDINATION:
                result = await self._coordinate_multilang(context)

            else:
                result = {
                    "success": False,
                    "error": f"Unsupported task type: {task_type.value}",
                }

            # æ›´æ–°ç‹€æ…‹
            command_record["status"] = "completed"
            command_record["result"] = result
            command_record["end_time"] = datetime.now().isoformat()

            logger.info(
                f"âœ… Command {command_id} completed: "
                f"success={result.get('success', False)}"
            )

        except Exception as e:
            logger.error(f"âŒ Command {command_id} failed: {e}", exc_info=True)
            command_record["status"] = "failed"
            command_record["error"] = str(e)
            result = {"success": False, "error": str(e)}

        finally:
            del self.active_tasks[command_id]

        return result

    async def _plan_attack(self, context: dict[str, Any]) -> dict[str, Any]:
        """ç”Ÿæˆæ”»æ“Šè¨ˆç•«ï¼ˆRAG å¢å¼·ï¼‰

        Args:
            context: åŒ…å« target, objective ç­‰

        Returns:
            æ”»æ“Šè¨ˆç•«çµæœ
        """
        logger.info("ğŸ“‹ Generating attack plan with RAG enhancement...")

        target = context.get("target")
        objective = context.get("objective", "Comprehensive security assessment")
        constraints = context.get("constraints", {})

        if not target:
            return {"success": False, "error": "Target not specified"}

        try:
            # 1. ä½¿ç”¨ RAG æª¢ç´¢ç›¸é—œçŸ¥è­˜
            rag_context = self.rag_engine.enhance_attack_plan(
                target=target,
                objective=objective,
            )

            # 2. å¾ç¶“é©—åº«ç²å–æ­·å²æˆåŠŸæ¡ˆä¾‹
            historical_experiences = (
                await self.experience_manager.storage.get_experiences(limit=50)
                if self.experience_manager.storage
                else []
            )

            # 3. ä½¿ç”¨ BioNeuronRAGAgent ç”Ÿæˆè¨ˆç•«
            plan_prompt = self._build_plan_generation_prompt(
                target=target,
                objective=objective,
                rag_context=rag_context,
                historical_experiences=historical_experiences,
                constraints=constraints,
            )

            # èª¿ç”¨ BioNeuron ç”Ÿæˆè¨ˆç•«
            plan_response = await self.bio_neuron_agent.generate_structured_output(
                prompt=plan_prompt,
                output_schema={
                    "type": "object",
                    "properties": {
                        "plan_id": {"type": "string"},
                        "target": {"type": "string"},
                        "objective": {"type": "string"},
                        "phases": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "name": {"type": "string"},
                                    "description": {"type": "string"},
                                    "steps": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                    },
                                    "expected_duration": {"type": "string"},
                                },
                            },
                        },
                        "risk_assessment": {"type": "string"},
                        "success_criteria": {
                            "type": "array",
                            "items": {"type": "string"},
                        },
                    },
                },
            )

            # 4. æ§‹å»ºå®Œæ•´çš„æ”»æ“Šè¨ˆç•«
            from uuid import uuid4

            plan_id = f"plan_{uuid4().hex[:12]}"

            attack_plan = {
                "plan_id": plan_id,
                "target": target,
                "objective": objective,
                "phases": plan_response.get("phases", []),
                "risk_assessment": plan_response.get("risk_assessment", ""),
                "success_criteria": plan_response.get("success_criteria", []),
                "rag_context": {
                    "similar_techniques": rag_context.get("similar_techniques", []),
                    "successful_experiences_count": len(historical_experiences),
                },
                "confidence": self._calculate_plan_confidence(
                    rag_context, historical_experiences
                ),
                "created_at": datetime.now().isoformat(),
            }

            logger.info(
                f"âœ… Generated plan {plan_id} with {len(attack_plan['phases'])} phases, "
                f"confidence: {attack_plan['confidence']:.2f}"
            )

            return {
                "success": True,
                "plan": attack_plan,
                "confidence": attack_plan["confidence"],
            }

        except Exception as e:
            logger.error(f"Failed to generate attack plan: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "fallback_message": "Plan generation failed, using basic strategy",
            }

    def _build_plan_generation_prompt(
        self,
        target: str,
        objective: str,
        rag_context: dict[str, Any],
        historical_experiences: list[dict],
        constraints: dict[str, Any],
    ) -> str:
        """æ§‹å»ºè¨ˆç•«ç”Ÿæˆæç¤ºè© (å„ªåŒ–ç‰ˆ)

        å„ªåŒ–é‡é»:
        - æ›´è©³ç´°çš„æŠ€è¡“æè¿°
        - æˆåŠŸæ¡ˆä¾‹å¼•ç”¨
        - å¤±æ•—ç¶“é©—è­¦ç¤º
        - å‹•æ…‹ç­–ç•¥å»ºè­°
        """
        # 1. åŸºæœ¬è³‡è¨Š
        prompt = f"""Generate a comprehensive security testing attack plan for:

ğŸ¯ Target: {target}
ğŸ“‹ Objective: {objective}

"""

        # 2. RAG çŸ¥è­˜åº«ç›¸ä¼¼æŠ€è¡“ (è©³ç´°ç‰ˆ)
        similar_techs = rag_context.get("similar_techniques", [])
        if similar_techs:
            prompt += "ğŸ” Similar Techniques from Knowledge Base:\n"
            for idx, tech in enumerate(similar_techs[:5], 1):  # å¢åŠ åˆ° 5 å€‹
                prompt += f"{idx}. {tech.get('name', 'N/A')}\n"
                prompt += f"   - Description: {tech.get('description', 'N/A')}\n"
                prompt += f"   - Relevance Score: {tech.get('score', 0):.2f}\n"
                if tech.get("tags"):
                    prompt += f"   - Tags: {', '.join(tech.get('tags', []))}\n"
            prompt += "\n"

        # 3. æ­·å²ç¶“é©—çµ±è¨ˆ
        if historical_experiences:
            success_exps = [
                e for e in historical_experiences if e.get("score", 0) > 0.7
            ]
            medium_exps = [
                e for e in historical_experiences if 0.4 <= e.get("score", 0) <= 0.7
            ]
            failed_exps = [e for e in historical_experiences if e.get("score", 0) < 0.4]

            prompt += "ğŸ“Š Historical Performance Analysis:\n"
            prompt += f"   - Total Experiences: {len(historical_experiences)}\n"
            prompt += f"   - âœ… Success Rate: {len(success_exps)/len(historical_experiences)*100:.1f}%\n"
            prompt += f"   - âš ï¸ Partial Success: {len(medium_exps)/len(historical_experiences)*100:.1f}%\n"
            prompt += f"   - âŒ Failure Rate: {len(failed_exps)/len(historical_experiences)*100:.1f}%\n"

            # å¼•ç”¨æˆåŠŸæ¡ˆä¾‹
            if success_exps:
                prompt += "\nğŸŒŸ Top Successful Cases:\n"
                for exp in success_exps[:2]:
                    context = exp.get("context", {})
                    action = exp.get("action", {})
                    prompt += f"   - Strategy: {action.get('decision', 'N/A')}\n"
                    prompt += f"     Score: {exp.get('score', 0):.2f}, Type: {context.get('objective', 'N/A')}\n"

            # è­¦ç¤ºå¤±æ•—ç¶“é©—
            if failed_exps:
                prompt += "\nâš ï¸ Lessons from Failed Attempts:\n"
                for exp in failed_exps[:2]:
                    result = exp.get("result", {})
                    prompt += f"   - Avoid: {result.get('error', 'Unknown error')}\n"

            prompt += "\n"

        # 4. ç´„æŸæ¢ä»¶
        if constraints:
            prompt += "ğŸš§ Constraints:\n"
            for key, value in constraints.items():
                prompt += f"   - {key}: {value}\n"
            prompt += "\n"

        # 5. å‹•æ…‹ç­–ç•¥å»ºè­°
        prompt += """ğŸ¯ Required Output Structure:
1. **Multi-Phase Plan**:
   - Phase 1: Reconnaissance (information gathering)
   - Phase 2: Vulnerability Analysis (identify weaknesses)
   - Phase 3: Exploitation Planning (prepare attack vectors)
   - Phase 4: Validation & Reporting (verify findings)

2. **Risk Assessment**:
   - Identify potential risks for each phase
   - Categorize as Low/Medium/High/Critical
   - Suggest mitigation strategies

3. **Success Criteria**:
   - Measurable objectives for each phase
   - Clear indicators of completion
   - Fallback plans if primary approach fails

4. **Dynamic Adaptation**:
   - Conditional steps based on intermediate results
   - Alternative paths if obstacles encountered
   - Real-time adjustment triggers

âš–ï¸ Focus on: Practical, safe, authorized security testing approaches.
ğŸ”’ Ensure: Compliance with ethical hacking standards and legal boundaries.
"""
        return prompt

    def _calculate_plan_confidence(
        self, rag_context: dict[str, Any], historical_experiences: list[dict]
    ) -> float:
        """è¨ˆç®—è¨ˆç•«ä¿¡å¿ƒåº¦ (å„ªåŒ–ç‰ˆ)

        è€ƒæ…®å› ç´ :
        - RAG ç›¸ä¼¼æŠ€è¡“æ•¸é‡å’Œåˆ†æ•¸
        - æ­·å²æˆåŠŸç‡
        - ç¶“é©—æ•¸é‡å……è¶³åº¦
        - æ™‚é–“æ–°é®®åº¦

        Returns:
            ä¿¡å¿ƒåº¦åˆ†æ•¸ (0.3-0.95 ç¯„åœ)
        """
        confidence = 0.3  # æœ€ä½åŸºç¤ä¿¡å¿ƒåº¦

        # 1. RAG ç›¸ä¼¼æŠ€è¡“åŠ æˆ (æœ€é«˜ +0.25)
        similar_techs = rag_context.get("similar_techniques", [])
        if similar_techs:
            # è€ƒæ…®æŠ€è¡“æ•¸é‡
            tech_count_bonus = min(len(similar_techs) * 0.03, 0.15)

            # è€ƒæ…®æŠ€è¡“ç›¸é—œæ€§åˆ†æ•¸
            avg_score = (
                sum(t.get("score", 0) for t in similar_techs) / len(similar_techs)
                if similar_techs
                else 0
            )
            score_bonus = avg_score * 0.1

            confidence += tech_count_bonus + score_bonus

        # 2. æ­·å²ç¶“é©—åŠ æˆ (æœ€é«˜ +0.35)
        if historical_experiences:
            # ç¶“é©—æ•¸é‡å……è¶³åº¦ (è‡³å°‘ 10 å€‹ç¶“é©—æ‰æœ‰å……åˆ†åƒè€ƒåƒ¹å€¼)
            exp_count = len(historical_experiences)
            count_factor = min(exp_count / 10, 1.0)

            # æˆåŠŸç‡è¨ˆç®—
            success_exps = [
                e for e in historical_experiences if e.get("score", 0) > 0.7
            ]
            success_rate = len(success_exps) / exp_count if exp_count > 0 else 0

            # æ™‚é–“æ–°é®®åº¦ (æœ€è¿‘çš„ç¶“é©—æ¬Šé‡æ›´é«˜)
            recent_bonus = 0
            if exp_count > 0:
                # æª¢æŸ¥æœ€è¿‘ 7 å¤©å…§çš„ç¶“é©—
                from datetime import timedelta

                recent_threshold = (datetime.now() - timedelta(days=7)).isoformat()
                recent_count = len(
                    [
                        e
                        for e in historical_experiences
                        if e.get("timestamp", "") > recent_threshold
                    ]
                )
                recent_bonus = min(recent_count / exp_count * 0.05, 0.05)

            # ç¶œåˆæ­·å²å› ç´ 
            historical_bonus = (success_rate * count_factor * 0.3) + recent_bonus
            confidence += historical_bonus

        # 3. çµ„åˆæ•ˆæ‡‰åŠ æˆ (RAG + æ­·å²éƒ½å¼·æ™‚é¡å¤–çå‹µ)
        if len(similar_techs) >= 3 and len(historical_experiences) >= 5:
            success_rate = len(
                [e for e in historical_experiences if e.get("score", 0) > 0.7]
            ) / len(historical_experiences)
            if success_rate > 0.7:
                confidence += 0.05  # é«˜è³ªé‡çŸ¥è­˜åº«åŠ æˆ

        # 4. ç¢ºä¿ç¯„åœåœ¨ 0.3-0.95 ä¹‹é–“
        confidence = max(0.3, min(confidence, 0.95))

        logger.debug(
            f"Plan confidence calculated: {confidence:.3f} "
            f"(techs={len(similar_techs)}, exps={len(historical_experiences)})"
        )

        return confidence

    async def _make_strategy_decision(self, context: dict[str, Any]) -> dict[str, Any]:
        """ç­–ç•¥æ±ºç­– (å„ªåŒ–ç‰ˆ)

        å¢å¼·åŠŸèƒ½:
        - æ›´è©³ç´°çš„é¢¨éšªè©•ä¼°
        - å¤šç¶­åº¦ä¿¡å¿ƒåº¦è¨ˆç®—
        - æ±ºç­–è¿½è¹¤å’Œå¯©è¨ˆ
        - å‹•æ…‹èª¿æ•´å»ºè­°

        Args:
            context: æ±ºç­–ä¸Šä¸‹æ–‡

        Returns:
            æ±ºç­–çµæœ
        """
        logger.info("ğŸ¤” Making strategic decision with enhanced risk assessment...")

        try:
            situation = context.get("situation", {})
            options = context.get("options", [])
            constraints = context.get("constraints", {})

            # 1. å¾ç¶“é©—åº«ç²å–ç›¸ä¼¼æƒ…æ³çš„æ­·å²æ±ºç­–
            historical_decisions = await self._get_similar_decisions(situation)

            # 2. é¢¨éšªé è©•ä¼°
            risk_factors = self._assess_risk_factors(situation, constraints)

            # 3. æ§‹å»ºå¢å¼·å‹æ±ºç­–æç¤ºè©
            decision_prompt = self._build_strategy_decision_prompt(
                situation, options, constraints, historical_decisions, risk_factors
            )

            # 4. ä½¿ç”¨ BioNeuronRAGAgent é€²è¡Œæ±ºç­–
            decision_response = await self.bio_neuron_agent.generate_structured_output(
                prompt=decision_prompt,
                output_schema={
                    "type": "object",
                    "properties": {
                        "decision": {"type": "string"},
                        "reasoning": {"type": "string"},
                        "confidence": {"type": "number"},
                        "alternative_options": {
                            "type": "array",
                            "items": {"type": "string"},
                        },
                        "risks": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "description": {"type": "string"},
                                    "severity": {"type": "string"},
                                    "mitigation": {"type": "string"},
                                },
                            },
                        },
                        "success_indicators": {
                            "type": "array",
                            "items": {"type": "string"},
                        },
                        "fallback_plan": {"type": "string"},
                    },
                },
            )

            # 5. å¤šç¶­åº¦ä¿¡å¿ƒåº¦è¨ˆç®—
            ai_confidence = decision_response.get("confidence", 0.5)
            historical_confidence = self._calculate_historical_confidence(
                historical_decisions
            )
            risk_adjusted_confidence = self._adjust_confidence_by_risk(
                base_confidence=(ai_confidence * 0.6) + (historical_confidence * 0.4),
                risk_factors=risk_factors,
            )

            # 6. æ§‹å»ºå®Œæ•´æ±ºç­–çµæœ
            result = {
                "success": True,
                "decision": decision_response.get("decision", "proceed_with_caution"),
                "confidence": risk_adjusted_confidence,
                "reasoning": decision_response.get("reasoning", "Based on AI analysis"),
                "alternative_options": decision_response.get("alternative_options", []),
                "risks": decision_response.get("risks", []),
                "success_indicators": decision_response.get("success_indicators", []),
                "fallback_plan": decision_response.get(
                    "fallback_plan", "Abort and reassess"
                ),
                "risk_assessment": {
                    "overall_risk": risk_factors.get("overall_risk", "medium"),
                    "key_factors": risk_factors.get("factors", []),
                    "mitigation_required": risk_factors.get(
                        "mitigation_required", False
                    ),
                },
                "historical_reference_count": len(historical_decisions),
                "decision_metadata": {
                    "ai_confidence": ai_confidence,
                    "historical_confidence": historical_confidence,
                    "risk_adjustment": risk_adjusted_confidence
                    - ((ai_confidence * 0.6) + (historical_confidence * 0.4)),
                    "timestamp": datetime.now().isoformat(),
                },
            }

            logger.info(
                f"âœ… Decision made: {result['decision']} "
                f"(confidence: {result['confidence']:.2f}, "
                f"risk: {risk_factors.get('overall_risk', 'unknown')})"
            )

            return result

        except Exception as e:
            logger.error(f"âŒ Decision making failed: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "decision": "abort",
                "confidence": 0.0,
                "reasoning": "Decision process encountered an error. Aborting for safety.",
                "fallback_plan": "Manual review required",
            }

    def _assess_risk_factors(
        self, situation: dict[str, Any], constraints: dict[str, Any]
    ) -> dict[str, Any]:
        """è©•ä¼°é¢¨éšªå› ç´ 

        Returns:
            é¢¨éšªè©•ä¼°çµæœ
        """
        factors = []
        risk_score = 0

        # 1. ç›®æ¨™ç’°å¢ƒé¢¨éšª
        if situation.get("target_type") == "production":
            factors.append("Production environment - High impact potential")
            risk_score += 3
        elif situation.get("target_type") == "staging":
            factors.append("Staging environment - Medium impact")
            risk_score += 1

        # 2. æ™‚é–“ç´„æŸé¢¨éšª
        if constraints.get("time_limit"):
            factors.append("Time-constrained operation - Reduced testing window")
            risk_score += 2

        # 3. æˆæ¬Šç¯„åœé¢¨éšª
        if not constraints.get("authorized"):
            factors.append("âš ï¸ CRITICAL: Unauthorized testing - Legal risk")
            risk_score += 5

        # 4. è³‡æ–™æ•æ„Ÿåº¦é¢¨éšª
        if situation.get("contains_sensitive_data"):
            factors.append("Sensitive data present - Privacy concerns")
            risk_score += 2

        # 5. ç³»çµ±é—œéµåº¦é¢¨éšª
        if situation.get("system_criticality") == "high":
            factors.append("Critical system - Service disruption risk")
            risk_score += 3

        # è¨ˆç®—ç¸½é«”é¢¨éšªç­‰ç´š
        if risk_score >= 7:
            overall_risk = "critical"
            mitigation_required = True
        elif risk_score >= 4:
            overall_risk = "high"
            mitigation_required = True
        elif risk_score >= 2:
            overall_risk = "medium"
            mitigation_required = False
        else:
            overall_risk = "low"
            mitigation_required = False

        return {
            "overall_risk": overall_risk,
            "risk_score": risk_score,
            "factors": factors,
            "mitigation_required": mitigation_required,
        }

    def _build_strategy_decision_prompt(
        self,
        situation: dict[str, Any],
        options: list[str],
        constraints: dict[str, Any],
        historical_decisions: list[dict],
        risk_factors: dict[str, Any],
    ) -> str:
        """æ§‹å»ºç­–ç•¥æ±ºç­–æç¤ºè©"""
        prompt = f"""Analyze the following situation and make a strategic decision:

ğŸ“‹ **Situation Analysis**:
{situation}

âš–ï¸ **Available Options**:
"""
        for idx, option in enumerate(options, 1):
            prompt += f"{idx}. {option}\n"

        if constraints:
            prompt += "\nğŸš§ **Constraints**:\n"
            for key, value in constraints.items():
                prompt += f"   - {key}: {value}\n"

        # é¢¨éšªè©•ä¼°
        prompt += "\nâš ï¸ **Risk Assessment**:\n"
        prompt += f"   - Overall Risk Level: {risk_factors.get('overall_risk', 'unknown').upper()}\n"
        prompt += f"   - Risk Score: {risk_factors.get('risk_score', 0)}/10\n"
        if risk_factors.get("factors"):
            prompt += "   - Key Risk Factors:\n"
            for factor in risk_factors["factors"]:
                prompt += f"     â€¢ {factor}\n"

        # æ­·å²æ±ºç­–
        if historical_decisions:
            success_rate = (
                len([d for d in historical_decisions if d.get("score", 0) > 0.7])
                / len(historical_decisions)
                * 100
            )
            prompt += "\nğŸ“Š **Historical Decisions** (similar situations):\n"
            prompt += f"   - Total References: {len(historical_decisions)}\n"
            prompt += f"   - Success Rate: {success_rate:.1f}%\n"
            prompt += "   - Top Cases:\n"
            for hist in historical_decisions[:2]:
                prompt += f"     â€¢ Decision: {hist.get('action', {}).get('decision', 'N/A')}\n"
                prompt += f"       Outcome: {'âœ… Success' if hist.get('score', 0) > 0.7 else 'âš ï¸ Partial'}\n"

        prompt += """
ğŸ¯ **Required Output**:
Please provide a comprehensive decisionåŒ…å«:
1. **Primary Decision**: Clear, actionable choice
2. **Reasoning**: Detailed explanation of decision logic
3. **Confidence Level**: 0.0-1.0 based on available information
4. **Alternative Options**: Backup choices if primary fails
5. **Risk Analysis**: Specific risks with severity (Low/Medium/High/Critical) and mitigation strategies
6. **Success Indicators**: Measurable criteria to validate decision effectiveness
7. **Fallback Plan**: What to do if decision leads to negative outcomes

âš–ï¸ **Decision Criteria**:
- Prioritize safety and authorization compliance
- Balance effectiveness with risk level
- Consider time and resource constraints
- Learn from historical outcomes
"""
        return prompt

    def _adjust_confidence_by_risk(
        self, base_confidence: float, risk_factors: dict[str, Any]
    ) -> float:
        """æ ¹æ“šé¢¨éšªå› ç´ èª¿æ•´ä¿¡å¿ƒåº¦

        é«˜é¢¨éšªæƒ…æ³ä¸‹é™ä½ä¿¡å¿ƒåº¦,ç¢ºä¿è¬¹æ…æ±ºç­–
        """
        overall_risk = risk_factors.get("overall_risk", "medium")

        if overall_risk == "critical":
            # é—œéµé¢¨éšªï¼šå¤§å¹…é™ä½ä¿¡å¿ƒåº¦
            adjustment = -0.2
        elif overall_risk == "high":
            # é«˜é¢¨éšªï¼šä¸­åº¦é™ä½ä¿¡å¿ƒåº¦
            adjustment = -0.1
        elif overall_risk == "medium":
            # ä¸­ç­‰é¢¨éšªï¼šç•¥å¾®é™ä½
            adjustment = -0.05
        else:
            # ä½é¢¨éšªï¼šä¸èª¿æ•´æˆ–ç•¥å¾®æå‡
            adjustment = 0.0

        adjusted = base_confidence + adjustment
        return max(0.1, min(adjusted, 0.95))  # ç¢ºä¿åœ¨åˆç†ç¯„åœå…§

    async def _get_similar_decisions(self, situation: dict[str, Any]) -> list[dict]:
        """ç²å–ç›¸ä¼¼æƒ…æ³çš„æ­·å²æ±ºç­–"""
        if not self.experience_manager.storage:
            return []

        try:
            all_experiences = await self.experience_manager.storage.get_experiences(
                limit=100
            )
            # ç°¡å–®çš„ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆå¯ä»¥ä½¿ç”¨æ›´è¤‡é›œçš„èªç¾©ç›¸ä¼¼åº¦ï¼‰
            similar_decisions = [
                exp
                for exp in all_experiences
                if exp.get("context", {}).get("type") == situation.get("type")
            ]
            return similar_decisions[:10]  # è¿”å›å‰ 10 å€‹æœ€ç›¸ä¼¼çš„
        except Exception as e:
            logger.error(f"Failed to retrieve similar decisions: {e}")
            return []

    def _calculate_historical_confidence(
        self, historical_decisions: list[dict]
    ) -> float:
        """æ ¹æ“šæ­·å²æ±ºç­–è¨ˆç®—ä¿¡å¿ƒåº¦"""
        if not historical_decisions:
            return 0.5  # ç„¡æ­·å²æ•¸æ“šæ™‚çš„åŸºæº–å€¼

        # è¨ˆç®—æ­·å²æ±ºç­–çš„å¹³å‡æˆåŠŸç‡
        success_count = len(
            [d for d in historical_decisions if d.get("score", 0) > 0.7]
        )
        return (
            success_count / len(historical_decisions) if historical_decisions else 0.5
        )

    async def _detect_vulnerabilities(self, context: dict[str, Any]) -> dict[str, Any]:
        """æª¢æ¸¬æ¼æ´ï¼ˆå”èª¿å¤šèªè¨€æ¨¡çµ„ï¼‰

        Args:
            context: æª¢æ¸¬ä¸Šä¸‹æ–‡

        Returns:
            æª¢æ¸¬çµæœ
        """
        logger.info("ğŸ” Detecting vulnerabilities across languages...")

        # å”èª¿å¤šèªè¨€ AI æ¨¡çµ„
        target = context.get("target")
        vuln_types = context.get("vulnerability_types", [])

        # TODO: å¯¦éš›å”èª¿é‚è¼¯
        # results = await self.multilang_coordinator.coordinate_detection(
        #     target=target,
        #     vuln_types=vuln_types
        # )

        return {
            "success": True,
            "vulnerabilities_found": 0,
            "languages_coordinated": ["python", "go", "rust"],
        }

    async def _learn_from_experience(self, context: dict[str, Any]) -> dict[str, Any]:
        """å¾ç¶“é©—ä¸­å­¸ç¿’

        Args:
            context: åŒ…å« experience_sample

        Returns:
            å­¸ç¿’çµæœ
        """
        logger.info("ğŸ“š Learning from experience...")

        sample = context.get("experience_sample")
        if not sample:
            return {"success": False, "error": "No experience sample provided"}

        # 1. æ·»åŠ åˆ°ç¶“é©—ç®¡ç†å™¨
        self.experience_manager.add_sample(sample)

        # 2. æ·»åŠ åˆ° RAG çŸ¥è­˜åº«
        self.rag_engine.learn_from_experience(sample)

        return {
            "success": True,
            "sample_quality": sample.quality_score,
            "knowledge_updated": True,
        }

    async def _train_model(self, context: dict[str, Any]) -> dict[str, Any]:
        """è¨“ç·´æ¨¡å‹

        Args:
            context: è¨“ç·´é…ç½®

        Returns:
            è¨“ç·´çµæœ
        """
        logger.info("ğŸ“ Training AI model...")

        # ä½¿ç”¨è¨“ç·´ç·¨æ’å™¨
        result = await self.training_orchestrator.train_model(
            min_samples=context.get("min_samples", 100),
            model_type=context.get("model_type", "supervised"),
        )

        return result

    async def _retrieve_knowledge(self, context: dict[str, Any]) -> dict[str, Any]:
        """æª¢ç´¢çŸ¥è­˜

        Args:
            context: åŒ…å« query

        Returns:
            æª¢ç´¢çµæœ
        """
        logger.info("ğŸ” Retrieving knowledge from RAG...")

        query = context.get("query", "")
        top_k = context.get("top_k", 5)

        results = self.rag_engine.knowledge_base.search(
            query=query,
            top_k=top_k,
        )

        return {
            "success": True,
            "results_count": len(results),
            "results": [
                {
                    "title": entry.title,
                    "type": entry.type.value,
                    "content": entry.content[:200],
                    "success_rate": entry.success_rate,
                }
                for entry in results
            ],
        }

    async def _coordinate_multilang(self, context: dict[str, Any]) -> dict[str, Any]:
        """å”èª¿å¤šèªè¨€ AI æ¨¡çµ„

        Args:
            context: å”èª¿ä¸Šä¸‹æ–‡

        Returns:
            å”èª¿çµæœ
        """
        logger.info("ğŸŒ Coordinating multi-language AI modules...")

        # ä½¿ç”¨å¤šèªè¨€å”èª¿å™¨
        # TODO: å¯¦éš›å”èª¿é‚è¼¯

        return {
            "success": True,
            "modules_coordinated": ["go", "rust", "typescript"],
            "tasks_distributed": 0,
        }

    async def run_training_session(
        self,
        scenario_ids: list[str] | None = None,
        episodes_per_scenario: int = 10,
    ) -> dict[str, Any]:
        """é‹è¡Œè¨“ç·´æœƒè©±

        Args:
            scenario_ids: å ´æ™¯ ID åˆ—è¡¨
            episodes_per_scenario: æ¯å€‹å ´æ™¯çš„å›åˆæ•¸

        Returns:
            è¨“ç·´çµæœ
        """
        logger.info("ğŸ“ Starting training session...")

        result = await self.training_orchestrator.run_training_batch(
            scenario_ids=scenario_ids,
            episodes_per_scenario=episodes_per_scenario,
            use_rag=True,  # ä½¿ç”¨ RAG å¢å¼·
        )

        return result

    def get_status(self) -> dict[str, Any]:
        """ç²å– AI æŒ‡æ®å®˜ç‹€æ…‹

        Returns:
            ç‹€æ…‹ä¿¡æ¯
        """
        return {
            "component_status": self.component_status,
            "active_tasks": len(self.active_tasks),
            "total_commands": len(self.command_history),
            "successful_commands": sum(
                1 for cmd in self.command_history if cmd.get("status") == "completed"
            ),
            "training_stats": self.training_orchestrator.get_training_statistics(),
            "knowledge_stats": self.rag_engine.get_statistics(),
            "experience_stats": self.experience_manager.get_statistics(),
        }

    def save_state(self) -> None:
        """ä¿å­˜ AI æŒ‡æ®å®˜ç‹€æ…‹"""
        logger.info("ğŸ’¾ Saving AI Commander state...")

        # ä¿å­˜ RAG çŸ¥è­˜åº«
        self.rag_engine.save_knowledge()

        # ä¿å­˜ç¶“é©—æ•¸æ“š
        self.experience_manager.export_to_jsonl(
            self.data_directory / "experiences.jsonl"
        )

        # ä¿å­˜è¨“ç·´æœƒè©±
        self.training_orchestrator.save_session()

        logger.info("âœ… AI Commander state saved")
