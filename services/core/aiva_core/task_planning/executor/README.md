# âš™ï¸ Executor - ä»»å‹™åŸ·è¡Œå™¨

**å°èˆª**: [â† è¿”å› Task Planning](../README.md) | [â† è¿”å› AIVA Core](../../README.md)

> **ç‰ˆæœ¬**: 3.0.0-alpha  
> **ç‹€æ…‹**: ç”Ÿç”¢å°±ç·’  
> **è§’è‰²**: ä»»å‹™åŸ·è¡Œå’Œç‹€æ…‹ç›£æ§

---

## ğŸ“‹ ç›®éŒ„

- [æ¨¡çµ„æ¦‚è¿°](#æ¨¡çµ„æ¦‚è¿°)
- [æª”æ¡ˆåˆ—è¡¨](#æª”æ¡ˆåˆ—è¡¨)
- [æ ¸å¿ƒçµ„ä»¶](#æ ¸å¿ƒçµ„ä»¶)
- [ä½¿ç”¨ç¯„ä¾‹](#ä½¿ç”¨ç¯„ä¾‹)

---

## ğŸ¯ æ¨¡çµ„æ¦‚è¿°

Executor å­æ¨¡çµ„è² è²¬å¯¦éš›åŸ·è¡Œä»»å‹™ã€ç®¡ç†ä»»å‹™ä½‡åˆ—ã€ç›£æ§åŸ·è¡Œç‹€æ…‹ï¼Œç¢ºä¿ä»»å‹™æŒ‰è¨ˆåŠƒé †åˆ©åŸ·è¡Œã€‚

### æ ¸å¿ƒåŠŸèƒ½
- **ä»»å‹™åŸ·è¡Œ** - å¯¦éš›åŸ·è¡Œå„é¡æ¸¬è©¦ä»»å‹™
- **ä½‡åˆ—ç®¡ç†** - ç®¡ç†ä»»å‹™å„ªå…ˆç´šä½‡åˆ—
- **ç‹€æ…‹ç›£æ§** - è¿½è¹¤ä»»å‹™åŸ·è¡Œç‹€æ…‹å’Œå¥åº·åº¦
- **çµæœæ”¶é›†** - æ”¶é›†å’ŒèšåˆåŸ·è¡Œçµæœ
- **éŒ¯èª¤è™•ç†** - è™•ç†åŸ·è¡Œéç¨‹ä¸­çš„ç•°å¸¸

---

## ğŸ“‚ æª”æ¡ˆåˆ—è¡¨

| æª”æ¡ˆ | è¡Œæ•¸ | åŠŸèƒ½ | ç‹€æ…‹ |
|------|------|------|------|
| `task_executor.py` | 279 | ä»»å‹™åŸ·è¡Œå™¨ | âœ… |
| `task_queue_manager.py` | ~400 | ä»»å‹™ä½‡åˆ—ç®¡ç†å™¨ | âœ… |
| `execution_status_monitor.py` | ~500 | åŸ·è¡Œç‹€æ…‹ç›£æ§å™¨ | âœ… |
| `plan_executor.py` | ~350 | è¨ˆç•«åŸ·è¡Œå™¨ | âœ… |
| `attack_plan_mapper.py` | ~300 | æ”»æ“Šè¨ˆç•«æ˜ å°„å™¨ï¼ˆèˆŠç‰ˆï¼‰ | ğŸ”§ |
| `__init__.py` | ~50 | æ¨¡çµ„å…¥å£ | âœ… |

**ç¸½è¨ˆ**: 6 å€‹ Python æª”æ¡ˆï¼Œç´„ 1880+ è¡Œä»£ç¢¼

---

## ğŸ”§ æ ¸å¿ƒçµ„ä»¶

### 1. `task_executor.py` - ä»»å‹™åŸ·è¡Œå™¨

**åŠŸèƒ½**: å¯¦éš›åŸ·è¡Œä»»å‹™ä¸¦èˆ‡å„ç¨®æœå‹™æ•´åˆ

**åŸ·è¡Œæµç¨‹**:
```python
æ¥æ”¶ä»»å‹™ â†’ é©—è­‰åƒæ•¸ â†’ é¸æ“‡æœå‹™ â†’ åŸ·è¡Œä»»å‹™ â†’ æ”¶é›†çµæœ â†’ éŒ¯èª¤è™•ç†
```

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from task_planning.executor import TaskExecutor, ExecutionResult

executor = TaskExecutor()

# åŸ·è¡Œä»»å‹™
result = await executor.execute(
    task={
        "task_id": "task_001",
        "type": "sql_injection_test",
        "target": "https://example.com/api",
        "params": {
            "payload": "' OR '1'='1",
            "method": "POST"
        }
    }
)

# è™•ç†çµæœ
if result.success:
    print(f"ä»»å‹™å®Œæˆ: {result.output}")
else:
    print(f"åŸ·è¡Œå¤±æ•—: {result.error}")

# åŸ·è¡Œçµæœçµæ§‹
@dataclass
class ExecutionResult:
    task_id: str
    success: bool
    output: dict[str, Any]
    error: str | None = None
    trace_session_id: str | None = None
    execution_time: float = 0.0
    resource_usage: dict = field(default_factory=dict)
```

**æ”¯æ´çš„ä»»å‹™é¡å‹**:
- `vulnerability_scan` - æ¼æ´æƒæ
- `sql_injection_test` - SQL æ³¨å…¥æ¸¬è©¦
- `xss_test` - XSS æ¸¬è©¦
- `business_logic_test` - æ¥­å‹™é‚è¼¯æ¸¬è©¦
- `custom_function` - è‡ªå®šç¾©å‡½æ•¸åŸ·è¡Œ

**æœå‹™æ•´åˆ**:
```python
# èˆ‡ä¸åŒæœå‹™æ•´åˆ
executor = TaskExecutor(
    scan_service=scan_service,
    function_registry=function_registry,
    integration_service=integration_service
)

# è‡ªå‹•è·¯ç”±åˆ°æ­£ç¢ºçš„æœå‹™
result = await executor.execute(task)
```

---

### 2. `task_queue_manager.py` - ä»»å‹™ä½‡åˆ—ç®¡ç†å™¨

**åŠŸèƒ½**: ç®¡ç†ä»»å‹™å„ªå…ˆç´šä½‡åˆ—å’Œèª¿åº¦

**ä½‡åˆ—æ¶æ§‹**:
```python
TaskQueueManager
â”œâ”€â”€ High Priority Queue (é«˜å„ªå…ˆç´š)
â”œâ”€â”€ Normal Priority Queue (æ­£å¸¸å„ªå…ˆç´š)
â”œâ”€â”€ Low Priority Queue (ä½å„ªå…ˆç´š)
â””â”€â”€ Dead Letter Queue (å¤±æ•—ä»»å‹™)
```

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from task_planning.executor import TaskQueueManager

queue_manager = TaskQueueManager()

# æ·»åŠ ä»»å‹™åˆ°ä½‡åˆ—
queue_manager.enqueue_task(
    topic="vulnerability_scan",
    task_payload={
        "task_id": "task_001",
        "target": "https://example.com",
        "priority": "high"
    }
)

# å¾ä½‡åˆ—ç²å–ä»»å‹™
task = await queue_manager.dequeue_task(
    topic="vulnerability_scan",
    worker_id="worker_001"
)

# ç¢ºèªä»»å‹™å®Œæˆ
queue_manager.acknowledge_task(
    task_id="task_001",
    success=True
)

# é‡è©¦å¤±æ•—ä»»å‹™
queue_manager.retry_task(
    task_id="task_001",
    delay_seconds=60
)

# ç²å–ä½‡åˆ—çµ±è¨ˆ
stats = queue_manager.get_queue_stats(topic="vulnerability_scan")
print(f"å¾…è™•ç†: {stats.pending}")
print(f"åŸ·è¡Œä¸­: {stats.processing}")
print(f"å·²å®Œæˆ: {stats.completed}")
print(f"å¤±æ•—: {stats.failed}")
```

**ä½‡åˆ—ç‰¹æ€§**:
- âœ… å„ªå…ˆç´šèª¿åº¦
- âœ… ä»»å‹™å»é‡
- âœ… è‡ªå‹•é‡è©¦
- âœ… æ­»ä¿¡ä½‡åˆ—
- âœ… è² è¼‰å¹³è¡¡
- âœ… æŒä¹…åŒ–ï¼ˆå¯é¸ï¼‰

**ä½‡åˆ—é…ç½®**:
```python
queue_manager = TaskQueueManager(
    config={
        "max_retries": 3,
        "retry_delay": 60,
        "enable_persistence": True,
        "max_queue_size": 10000,
        "worker_timeout": 300
    }
)
```

---

### 3. `execution_status_monitor.py` - åŸ·è¡Œç‹€æ…‹ç›£æ§å™¨

**åŠŸèƒ½**: è¿½è¹¤å’Œç›£æ§ä»»å‹™åŸ·è¡Œç‹€æ…‹

**ç›£æ§ç¶­åº¦**:
```python
ExecutionStatusMonitor
â”œâ”€â”€ Task Status (ä»»å‹™ç‹€æ…‹)
â”‚   â”œâ”€â”€ Pending
â”‚   â”œâ”€â”€ Running
â”‚   â”œâ”€â”€ Completed
â”‚   â”œâ”€â”€ Failed
â”‚   â””â”€â”€ Cancelled
â”‚
â”œâ”€â”€ Worker Health (Worker å¥åº·åº¦)
â”‚   â”œâ”€â”€ Heartbeat
â”‚   â”œâ”€â”€ Resource Usage
â”‚   â””â”€â”€ Performance Metrics
â”‚
â””â”€â”€ System Metrics (ç³»çµ±æŒ‡æ¨™)
    â”œâ”€â”€ Throughput
    â”œâ”€â”€ Latency
    â””â”€â”€ Error Rate
```

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from task_planning.executor import ExecutionStatusMonitor, ExecutionContext

monitor = ExecutionStatusMonitor()

# è¨˜éŒ„ä»»å‹™é–‹å§‹
monitor.record_task_start(
    task_id="task_001",
    worker_id="worker_001",
    context=ExecutionContext(
        task_type="sql_injection_test",
        target="https://example.com"
    )
)

# æ›´æ–°ä»»å‹™é€²åº¦
monitor.update_progress(
    task_id="task_001",
    progress=50,  # 0-100
    message="æ­£åœ¨æ¸¬è©¦ SQL æ³¨å…¥é»..."
)

# è¨˜éŒ„ä»»å‹™å®Œæˆ
monitor.record_task_completion(
    task_id="task_001",
    success=True,
    result={"vulnerabilities_found": 3}
)

# ç²å–ä»»å‹™ç‹€æ…‹
status = monitor.get_task_status("task_001")
print(f"ç‹€æ…‹: {status.state}")
print(f"é€²åº¦: {status.progress}%")
print(f"åŸ·è¡Œæ™‚é–“: {status.execution_time}s")

# Worker å¿ƒè·³
monitor.record_worker_heartbeat(
    worker_id="worker_001",
    metrics={
        "cpu_usage": 45.2,
        "memory_usage": 1024,
        "active_tasks": 3
    }
)

# ç²å–ç³»çµ±ç›£æ§æ•¸æ“š
system_metrics = monitor.get_system_metrics()
print(f"ç¸½ä»»å‹™æ•¸: {system_metrics.total_tasks}")
print(f"å®Œæˆç‡: {system_metrics.completion_rate}%")
print(f"å¹³å‡åŸ·è¡Œæ™‚é–“: {system_metrics.avg_execution_time}s")
print(f"éŒ¯èª¤ç‡: {system_metrics.error_rate}%")
```

**ç›£æ§å‘Šè­¦**:
```python
# è¨­å®šå‘Šè­¦è¦å‰‡
monitor.set_alert_rule(
    name="high_error_rate",
    condition="error_rate > 10",
    action=lambda: send_notification("éŒ¯èª¤ç‡éé«˜ï¼")
)

monitor.set_alert_rule(
    name="worker_timeout",
    condition="worker_heartbeat_missing > 300",
    action=lambda worker_id: restart_worker(worker_id)
)
```

**åŸ·è¡Œä¸Šä¸‹æ–‡**:
```python
@dataclass
class ExecutionContext:
    task_id: str
    task_type: str
    worker_id: str
    start_time: datetime
    target: str
    params: dict[str, Any]
    parent_task_id: str | None = None
    retry_count: int = 0
```

---

### 4. `plan_executor.py` - è¨ˆç•«åŸ·è¡Œå™¨

**åŠŸèƒ½**: åŸ·è¡Œå®Œæ•´çš„å¤šä»»å‹™åŸ·è¡Œè¨ˆåŠƒ

**åŸ·è¡Œæ¨¡å¼**:
- **é †åºåŸ·è¡Œ** - ä¾åºåŸ·è¡Œæ‰€æœ‰ä»»å‹™
- **ä¸¦è¡ŒåŸ·è¡Œ** - åŒæ™‚åŸ·è¡Œç„¡ä¾è³´ä»»å‹™
- **æµå¼åŸ·è¡Œ** - é‚ŠåŸ·è¡Œé‚Šè™•ç†çµæœ
- **è‡ªé©æ‡‰åŸ·è¡Œ** - æ ¹æ“šçµæœå‹•æ…‹èª¿æ•´

**ä½¿ç”¨ç¯„ä¾‹**:
```python
from task_planning.executor import PlanExecutor

plan_executor = PlanExecutor()

# åŸ·è¡Œè¨ˆåŠƒ
result = await plan_executor.execute_plan(
    plan=execution_plan,
    mode="parallel",  # sequential, parallel, streaming
    config={
        "max_parallel": 5,
        "timeout": 3600,
        "stop_on_error": False
    }
)

# ç²å–åŸ·è¡Œæ‘˜è¦
print(f"ç¸½ä»»å‹™: {result.total_tasks}")
print(f"æˆåŠŸ: {result.successful_tasks}")
print(f"å¤±æ•—: {result.failed_tasks}")
print(f"åŸ·è¡Œæ™‚é–“: {result.execution_time}s")

# ç²å–è©³ç´°çµæœ
for task_result in result.task_results:
    print(f"ä»»å‹™ {task_result.task_id}: {task_result.status}")
```

**è‡ªé©æ‡‰åŸ·è¡Œ**:
```python
# æ ¹æ“šåŸ·è¡Œçµæœå‹•æ…‹èª¿æ•´
async def adaptive_execution(plan):
    executor = PlanExecutor()
    
    for stage in plan.stages:
        # åŸ·è¡Œç•¶å‰éšæ®µ
        stage_result = await executor.execute_stage(stage)
        
        # æ ¹æ“šçµæœèª¿æ•´å¾ŒçºŒè¨ˆåŠƒ
        if stage_result.success_rate < 0.5:
            # é™ä½ä¸¦è¡Œåº¦
            plan.max_parallel = max(1, plan.max_parallel // 2)
        elif stage_result.success_rate > 0.9:
            # æé«˜ä¸¦è¡Œåº¦
            plan.max_parallel = min(10, plan.max_parallel * 2)
        
        # å¦‚æœç™¼ç¾é«˜å±æ¼æ´ï¼Œèª¿æ•´å„ªå…ˆç´š
        if stage_result.critical_findings:
            plan.reorder_by_priority()
    
    return executor.get_summary()
```

---

## ğŸš€ å®Œæ•´ä½¿ç”¨æµç¨‹

### ä»»å‹™åŸ·è¡Œæµç¨‹
```python
from task_planning.executor import (
    TaskQueueManager,
    TaskExecutor,
    ExecutionStatusMonitor
)

# 1. åˆå§‹åŒ–çµ„ä»¶
queue_manager = TaskQueueManager()
executor = TaskExecutor()
monitor = ExecutionStatusMonitor()

# 2. æ·»åŠ ä»»å‹™åˆ°ä½‡åˆ—
queue_manager.enqueue_task(
    topic="vulnerability_scan",
    task_payload={
        "task_id": "task_001",
        "type": "sql_injection_test",
        "target": "https://example.com"
    }
)

# 3. Worker å¾ä½‡åˆ—ç²å–ä»»å‹™
task = await queue_manager.dequeue_task(
    topic="vulnerability_scan",
    worker_id="worker_001"
)

# 4. è¨˜éŒ„é–‹å§‹åŸ·è¡Œ
monitor.record_task_start(
    task_id=task["task_id"],
    worker_id="worker_001"
)

# 5. åŸ·è¡Œä»»å‹™
try:
    result = await executor.execute(task)
    
    # 6. è¨˜éŒ„å®Œæˆ
    monitor.record_task_completion(
        task_id=task["task_id"],
        success=result.success,
        result=result.output
    )
    
    # 7. ç¢ºèªä»»å‹™
    queue_manager.acknowledge_task(
        task_id=task["task_id"],
        success=result.success
    )
    
except Exception as e:
    # è¨˜éŒ„å¤±æ•—
    monitor.record_task_failure(
        task_id=task["task_id"],
        error=str(e)
    )
    
    # é‡è©¦ä»»å‹™
    queue_manager.retry_task(
        task_id=task["task_id"],
        delay_seconds=60
    )
```

### è¨ˆç•«åŸ·è¡Œæµç¨‹
```python
from task_planning.executor import PlanExecutor
from task_planning.planner import AttackOrchestrator

# 1. å‰µå»ºåŸ·è¡Œè¨ˆåŠƒ
orchestrator = AttackOrchestrator()
plan = orchestrator.create_execution_plan(ast_input)

# 2. åŸ·è¡Œè¨ˆåŠƒ
plan_executor = PlanExecutor(
    queue_manager=queue_manager,
    task_executor=executor,
    status_monitor=monitor
)

result = await plan_executor.execute_plan(
    plan=plan,
    mode="parallel",
    config={"max_parallel": 5}
)

# 3. åˆ†æçµæœ
print(f"åŸ·è¡Œæ‘˜è¦:")
print(f"  ç¸½ä»»å‹™: {result.total_tasks}")
print(f"  æˆåŠŸ: {result.successful_tasks}")
print(f"  å¤±æ•—: {result.failed_tasks}")
print(f"  æˆåŠŸç‡: {result.success_rate}%")
print(f"  åŸ·è¡Œæ™‚é–“: {result.execution_time}s")
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ¨™

| æŒ‡æ¨™ | æ•¸å€¼ | å‚™è¨» |
|------|------|------|
| ä»»å‹™åŸ·è¡Œ | 10-100 ms | ä¾ä»»å‹™è¤‡é›œåº¦ |
| ä½‡åˆ—åå | 1000+ tasks/s | å–®å¯¦ä¾‹ |
| ç›£æ§é–‹éŠ· | < 5% CPU | é‹è¡Œæ™‚ |
| ä¸¦è¡Œåº¦ | 100+ tasks | åŒæ™‚åŸ·è¡Œ |
| é‡è©¦å»¶é² | å¯é…ç½® | é è¨­ 60s |

---

**æœ€å¾Œæ›´æ–°**: 2025-11-16  
**ç¶­è­·è€…**: AIVA Development Team
