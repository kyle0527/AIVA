#!/usr/bin/env python3#!/usr/bin/env python3#!/usr/bin/env python3

"""

Legacy import bridge - moved to plugins/aiva_converters/core/schema_codegen_tool.py""""""

"""

Schema Code Generator - Legacy Import BridgeAIVA Schema Code Generation Tool - Legacy Bridge

try:

    from plugins.aiva_converters.core.schema_codegen_tool import *==========================================================================================

except ImportError:

    from schema_codegen_tool_backup import *



if __name__ == "__main__":âš ï¸  DEPRECATION NOTICE âš ï¸âš ï¸  DEPRECATION NOTICE âš ï¸

    print("Redirected to plugins/aiva_converters/core/schema_codegen_tool.py")
æ­¤æª”æ¡ˆå·²ç§»è‡³ AIVA Converters Pluginã€‚æ­¤æª”æ¡ˆå·²ç§»è‡³ AIVA Converters Pluginã€‚

è«‹ä½¿ç”¨æ–°çš„æ’ä»¶ä½ç½®ï¼šplugins/aiva_converters/core/schema_codegen_tool.py

Original Location: services/aiva_common/tools/schema_codegen_tool.py

New Location: plugins/aiva_converters/core/schema_codegen_tool.pyThis file provides backward compatibility for existing imports.

The actual implementation has been moved to the AIVA Converters Plugin.

This file provides backward compatibility for existing imports.

"""Original Location: services/aiva_common/tools/schema_codegen_tool.py  

New Location: plugins/aiva_converters/core/schema_codegen_tool.py

import sys

import warningsLegacy Usage (still works):

import importlib.util    python services/aiva_common/tools/schema_codegen_tool.py --generate-all

from pathlib import Path    

New Usage (recommended):

# Issue deprecation warning    python plugins/aiva_converters/core/schema_codegen_tool.py --generate-all

warnings.warn("""

    "Importing from 'services.aiva_common.tools.schema_codegen_tool' is deprecated. "

    "Please use 'plugins.aiva_converters.core.schema_codegen_tool' instead.",import argparse

    DeprecationWarning,import logging

    stacklevel=2

)# è¨­å®šæ—¥èªŒ - æ”¯æ´ Unicode

import sys

# Try to import from the new plugin locationfrom datetime import datetime

try:from pathlib import Path

    plugin_path = Path(__file__).parent.parent.parent.parent / "plugins"from typing import Any

    sys.path.insert(0, str(plugin_path))

    import yaml

    from aiva_converters.core.schema_codegen_tool import SchemaCodeGeneratorfrom jinja2 import Environment, FileSystemLoader, Template

    from aiva_converters.core.schema_codegen_tool import *

    # sys.stdout.reconfigure(encoding='utf-8')  # åƒ…åœ¨æ”¯æŒçš„ Python ç‰ˆæœ¬ä¸­å¯ç”¨

    print("âœ… Successfully loaded SchemaCodeGenerator from AIVA Converters Plugin")# sys.stderr.reconfigure(encoding='utf-8')  # åƒ…åœ¨æ”¯æŒçš„ Python ç‰ˆæœ¬ä¸­å¯ç”¨

    

except ImportError as e:logging.basicConfig(

    print(f"âŒ Plugin import failed: {e}")    level=logging.INFO,

    print("ğŸ”„ Trying backup implementation...")    format="%(asctime)s - %(levelname)s - %(message)s",

        handlers=[

    # Load backup if plugin fails        logging.StreamHandler(),

    backup_file = Path(__file__).parent / "schema_codegen_tool_backup.py"        logging.FileHandler("schema_codegen.log", encoding="utf-8"),

    if backup_file.exists():    ],

        try:)

            spec = importlib.util.spec_from_file_location("schema_codegen_backup", backup_file)logger = logging.getLogger(__name__)

            backup_module = importlib.util.module_from_spec(spec)

            spec.loader.exec_module(backup_module)

            SchemaCodeGenerator = backup_module.SchemaCodeGeneratorclass SchemaCodeGenerator:

            print("âš ï¸  Using backup implementation")    """Schema ä»£ç¢¼ç”Ÿæˆå™¨ - æ”¯æ´å¤šèªè¨€è‡ªå‹•ç”Ÿæˆ"""

        except Exception as backup_error:

            print(f"âŒ Backup import also failed: {backup_error}")    def __init__(self, sot_file: str = "services/aiva_common/core_schema_sot.yaml"):

            raise ImportError(        """åˆå§‹åŒ–ä»£ç¢¼ç”Ÿæˆå™¨

                "Cannot import SchemaCodeGenerator from plugin or backup. "

                "Please ensure the AIVA Converters Plugin is properly installed."        Args:

            ) from e            sot_file: Schema SOT YAML æª”æ¡ˆè·¯å¾‘

    else:        """

        raise ImportError(        self.sot_file = Path(sot_file)

            "No backup implementation available. "        self.sot_data: dict[str, Any] = {}

            "Please ensure the AIVA Converters Plugin is properly installed."        self.jinja_env = Environment(

        ) from e            loader=FileSystemLoader(Path(__file__).parent / "templates"),

            trim_blocks=True,

if __name__ == "__main__":            lstrip_blocks=True,

    print("ğŸ”„ Schema Code Generator - Legacy Bridge")        )

    print("ğŸ“‚ Original location: services/aiva_common/tools/schema_codegen_tool.py")

    print("ğŸ“¦ New location: plugins/aiva_converters/core/schema_codegen_tool.py")        # è¼‰å…¥ SOT è³‡æ–™

    print("")        self._load_sot_data()

    print("To use the new plugin directly:")

    print("python plugins/aiva_converters/core/schema_codegen_tool.py [args]")    def _load_sot_data(self) -> None:

            """è¼‰å…¥ Schema SOT è³‡æ–™"""

    # Try to run the main function if available        try:

    try:            with open(self.sot_file, encoding="utf-8") as f:

        if hasattr(sys.modules.get(__name__), 'main'):                self.sot_data = yaml.safe_load(f)

            main()            logger.info(f"âœ… æˆåŠŸè¼‰å…¥ SOT æª”æ¡ˆ: {self.sot_file}")

        else:        except FileNotFoundError:

            print("No main function available in current module")            logger.error(f"âŒ SOT æª”æ¡ˆä¸å­˜åœ¨: {self.sot_file}")

    except Exception as e:            sys.exit(1)

        print(f"Error running main: {e}")        except yaml.YAMLError as e:
            logger.error(f"âŒ YAML è§£æéŒ¯èª¤: {e}")
            sys.exit(1)

    def generate_python_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Python Pydantic v2 Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["python"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”ŸæˆåŸºç¤é¡å‹
        if "base_types" in self.sot_data:
            base_file = target_dir / "base_types.py"
            content = self._render_python_base_types()
            with open(base_file, "w", encoding="utf-8") as f:
                f.write(content)
            generated_files.append(str(base_file))  # type: ignore
            logger.info(f"âœ… ç”Ÿæˆ Python åŸºç¤é¡å‹: {base_file}")

        # ç”Ÿæˆå„æ¨¡çµ„ Schema - åŒ…å«æ‰€æœ‰æ–°å¢çš„åˆ†é¡
        categories = ["messaging", "tasks", "findings", "async_utils", "plugins", "cli"]
        for category in categories:
            if category in self.sot_data:
                module_file = target_dir / f"{category}.py"
                content = self._render_python_category(category)
                with open(module_file, "w", encoding="utf-8") as f:
                    f.write(content)
                generated_files.append(str(module_file))  # type: ignore
                logger.info(f"âœ… ç”Ÿæˆ Python {category} Schema: {module_file}")

        # ç”Ÿæˆ __init__.py
        init_file = target_dir / "__init__.py"
        content = self._render_python_init()
        with open(init_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(init_file))  # type: ignore

        return generated_files

    def generate_go_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Go struct Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["go"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”Ÿæˆçµ±ä¸€çš„ schemas.go æª”æ¡ˆ
        schema_file = target_dir / "schemas.go"
        content = self._render_go_schemas()
        with open(schema_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(schema_file))  # type: ignore
        logger.info(f"âœ… ç”Ÿæˆ Go Schema: {schema_file}")

        return generated_files

    def generate_rust_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ Rust Serde Schema

        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„

        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        config = self.sot_data["generation_config"]["rust"]
        target_dir = Path(output_dir) if output_dir else Path(config["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)

        generated_files = []

        # ç”Ÿæˆ mod.rs
        mod_file = target_dir / "mod.rs"
        content = self._render_rust_schemas()
        with open(mod_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(mod_file))  # type: ignore
        logger.info(f"âœ… ç”Ÿæˆ Rust Schema: {mod_file}")

        return generated_files

    def _render_python_base_types(self) -> str:
        """æ¸²æŸ“ Python åŸºç¤é¡å‹"""
        content = []
        content.append('"""')  # type: ignore
        content.append("AIVA åŸºç¤é¡å‹ Schema - è‡ªå‹•ç”Ÿæˆ")  # type: ignore
        content.append("=====================================")  # type: ignore
        content.append("")  # type: ignore
        content.append(self.sot_data["metadata"]["description"])  # type: ignore
        content.append("")  # type: ignore
        content.append(f"âš ï¸  {self.sot_data['metadata']['generated_note']}")  # type: ignore
        content.append(f"ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}")  # type: ignore
        content.append(f"ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}")  # type: ignore
        content.append('"""')  # type: ignore
        content.append("")  # type: ignore

        # æ·»åŠ imports
        for imp in self.sot_data["generation_config"]["python"]["base_imports"]:
            content.append(imp)  # type: ignore
        content.append("")  # type: ignore
        content.append("")  # type: ignore

        # ç”Ÿæˆé¡åˆ¥
        for class_name, class_info in self.sot_data["base_types"].items():
            content.append(f"class {class_name}(BaseModel):")  # type: ignore
            content.append(f'    """{class_info["description"]}"""')  # type: ignore
            content.append("")  # type: ignore

            for field_name, field_info in class_info["fields"].items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            content.append("")  # type: ignore

        return "\n".join(content)

    def _render_python_category(self, category: str) -> str:
        """æ¸²æŸ“ Python åˆ†é¡ Schema"""
        content = []
        content.append('"""')  # type: ignore
        content.append(f"AIVA {category.title()} Schema - è‡ªå‹•ç”Ÿæˆ")  # type: ignore
        content.append("=====================================")  # type: ignore
        content.append("")  # type: ignore
        content.append(self.sot_data["metadata"]["description"])  # type: ignore
        content.append("")  # type: ignore
        content.append(f"âš ï¸  {self.sot_data['metadata']['generated_note']}")  # type: ignore
        content.append(f"ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}")  # type: ignore
        content.append(f"ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}")  # type: ignore
        content.append('"""')  # type: ignore
        content.append("")  # type: ignore

        # æ·»åŠ imports
        for imp in self.sot_data["generation_config"]["python"]["base_imports"]:
            content.append(imp)  # type: ignore
        content.append("")  # type: ignore
        content.append("from .base_types import *")  # type: ignore
        content.append("")  # type: ignore
        content.append("")  # type: ignore

        # ç”Ÿæˆé¡åˆ¥
        for class_name, class_info in self.sot_data[category].items():
            content.append(f"class {class_name}(BaseModel):")  # type: ignore
            content.append(f'    """{class_info["description"]}"""')  # type: ignore
            content.append("")  # type: ignore

            # æª¢æŸ¥æ˜¯å¦æœ‰extends
            if "extends" in class_info:
                content.append(f'    # ç¹¼æ‰¿è‡ª: {class_info["extends"]}')  # type: ignore
                content.append("")  # type: ignore

            # è™•ç†fields
            for field_name, field_info in class_info.get("fields", {}).items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            # è™•ç†additional_fields
            for field_name, field_info in class_info.get(
                "additional_fields", {}
            ).items():
                field_line = self._generate_python_field(field_name, field_info)
                content.append(f"    {field_line}")  # type: ignore
                content.append(f'    """{field_info["description"]}"""')  # type: ignore
                content.append("")  # type: ignore

            content.append("")  # type: ignore

        return "\n".join(content)

    def _render_python_init(self) -> str:
        """æ¸²æŸ“ Python __init__.py"""
        template = Template(
            '''"""
AIVA Schema è‡ªå‹•ç”Ÿæˆæ¨¡çµ„
======================

æ­¤æ¨¡çµ„åŒ…å«æ‰€æœ‰ç”± core_schema_sot.yaml è‡ªå‹•ç”Ÿæˆçš„ Schema å®šç¾©

âš ï¸  è«‹å‹¿æ‰‹å‹•ä¿®æ”¹æ­¤æ¨¡çµ„ä¸­çš„æª”æ¡ˆ
ğŸ”„  å¦‚éœ€æ›´æ–°ï¼Œè«‹ä¿®æ”¹ core_schema_sot.yaml å¾Œé‡æ–°ç”Ÿæˆ
"""

# åŸºç¤é¡å‹
from .base_types import *

# è¨Šæ¯é€šè¨Š
from .messaging import *

# ä»»å‹™ç®¡ç†
from .tasks import *

# ç™¼ç¾çµæœ
from .findings import *

__version__ = "{{ version }}"
__generated_at__ = "{{ generated_at }}"

__all__ = [
    # åŸºç¤é¡å‹
    "MessageHeader",
    "Target", 
    "Vulnerability",
    
    # è¨Šæ¯é€šè¨Š
    "AivaMessage",
    "AIVARequest",
    "AIVAResponse",
    
    # ä»»å‹™ç®¡ç†
    "FunctionTaskPayload",
    "FunctionTaskTarget", 
    "FunctionTaskContext",
    "FunctionTaskTestConfig",
    "ScanTaskPayload",
    
    # ç™¼ç¾çµæœ
    "FindingPayload",
    "FindingEvidence",
    "FindingImpact", 
    "FindingRecommendation",
]
'''
        )

        return template.render(
            version=self.sot_data["version"], generated_at=datetime.now().isoformat()
        )

    def _render_go_schemas(self) -> str:
        """æ¸²æŸ“ Go çµ±ä¸€ Schema"""
        content = []
        content.append("// AIVA Go Schema - è‡ªå‹•ç”Ÿæˆ")  # type: ignore
        content.append("// ===========================")  # type: ignore
        content.append("//")  # type: ignore
        content.append(f'// {self.sot_data["metadata"]["description"]}')  # type: ignore
        content.append("//")  # type: ignore
        content.append(f'// âš ï¸  {self.sot_data["metadata"]["generated_note"]}')  # type: ignore
        content.append(f'// ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data["metadata"]["last_updated"]}')  # type: ignore
        content.append(f'// ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data["version"]}')  # type: ignore
        content.append("")  # type: ignore

        # æ·»åŠ imports
        for imp in self.sot_data["generation_config"]["go"]["base_imports"]:
            content.append(imp)  # type: ignore
        content.append("")  # type: ignore

        # æšèˆ‰é¡å‹
        if "enums" in self.sot_data:
            content.append("// ==================== æšèˆ‰é¡å‹ ====================")  # type: ignore
            content.append("")  # type: ignore

            for enum_name, enum_info in self.sot_data["enums"].items():
                content.append(f'// {enum_name} {enum_info.get("description", "")}')  # type: ignore
                content.append(f"type {enum_name} string")  # type: ignore
                content.append("")  # type: ignore
                content.append("const (")  # type: ignore

                for value_key, value_desc in enum_info.get("values", {}).items():
                    const_name = f"{enum_name}{value_key.title()}"
                    content.append(f'    {const_name:<30} {enum_name} = "{value_key}"  // {value_desc}')  # type: ignore

                content.append(")")  # type: ignore
                content.append("")  # type: ignore

        # åŸºç¤é¡å‹
        content.append("// ==================== åŸºç¤é¡å‹ ====================")  # type: ignore
        content.append("")  # type: ignore

        for class_name, class_info in self.sot_data["base_types"].items():
            content.append(f'// {class_name} {class_info["description"]}')  # type: ignore
            content.append(f"type {class_name} struct {{")  # type: ignore

            for field_name, field_info in class_info["fields"].items():
                go_name = self._to_go_field_name(field_name)
                go_type = self._get_go_type(field_info["type"])
                json_tag = self._get_go_json_tag(field_info.get("required", True))
                content.append(f'    {go_name:<20} {go_type:<25} `json:"{field_name}{json_tag}"`  // {field_info["description"]}')  # type: ignore

            content.append("}")  # type: ignore
            content.append("")  # type: ignore

        # å…¶ä»–é¡åˆ¥ - åŒ…å«æ‰€æœ‰æ–°å¢çš„ Schema åˆ†é¡
        sections = [
            ("messaging", "è¨Šæ¯é€šè¨Š"),
            ("tasks", "ä»»å‹™ç®¡ç†"),
            ("findings", "ç™¼ç¾çµæœ"),
            ("async_utils", "ç•°æ­¥å·¥å…·"),
            ("plugins", "æ’ä»¶ç®¡ç†"),
            ("cli", "CLI ç•Œé¢"),
        ]

        for section, title in sections:
            if section in self.sot_data:
                content.append(f"// ==================== {title} ====================")  # type: ignore
                content.append("")  # type: ignore

                for class_name, class_info in self.sot_data[section].items():
                    content.append(f'// {class_name} {class_info["description"]}')  # type: ignore
                    content.append(f"type {class_name} struct {{")  # type: ignore

                    # ç²å–æ‰€æœ‰å­—æ®µï¼ˆåŒ…æ‹¬ç¹¼æ‰¿çš„å­—æ®µï¼‰
                    all_fields = self._get_all_fields(class_info, section)

                    # ç”Ÿæˆæ‰€æœ‰å­—æ®µ
                    for field_name, field_info in all_fields.items():
                        go_name = self._to_go_field_name(field_name)
                        go_type = self._get_go_type(field_info["type"])
                        json_tag = self._get_go_json_tag(
                            field_info.get("required", True)
                        )
                        content.append(f'    {go_name:<20} {go_type:<25} `json:"{field_name}{json_tag}"`  // {field_info["description"]}')  # type: ignore

                    content.append("}")  # type: ignore
                    content.append("")  # type: ignore

        return "\n".join(content)

    def _render_rust_schemas(self) -> str:
        """
        æ¸²æŸ“å®Œæ•´çš„ Rust Schema

        ç”ŸæˆåŒ…å«æ‰€æœ‰çµæ§‹é«”ã€æšèˆ‰å’Œåºåˆ—åŒ–æ”¯æŒçš„ Rust ä»£ç¢¼
        """
        rust_code = f"""// AIVA Rust Schema - è‡ªå‹•ç”Ÿæˆ
// ç‰ˆæœ¬: {self.sot_data['version']}
// ç”Ÿæˆæ™‚é–“: {self.sot_data.get('generated_at', 'N/A')}
// 
// å®Œæ•´çš„ Rust Schema å¯¦ç¾ï¼ŒåŒ…å«åºåˆ—åŒ–/ååºåˆ—åŒ–æ”¯æŒ

use serde::{{Serialize, Deserialize}};
use std::collections::HashMap;
use chrono::{{DateTime, Utc}};

// å¯é¸ä¾è³´ - æ ¹æ“šå¯¦éš›ä½¿ç”¨æƒ…æ³å•Ÿç”¨
#[cfg(feature = "uuid")]
use uuid::Uuid;

#[cfg(feature = "url")]
use url::Url;

"""

        # ç”Ÿæˆæšèˆ‰
        for enum_name, enum_data in self.sot_data.get("enums", {}).items():
            rust_code += self._render_rust_enum(enum_name, enum_data)
            rust_code += "\n\n"

        # ç”Ÿæˆçµæ§‹é«” - è™•ç†æ‰€æœ‰é ‚å±¤åˆ†é¡
        all_schemas = {}

        # æ”¶é›†æ‰€æœ‰schemaå®šç¾© - åŒ…å«æ‰€æœ‰æ–°å¢çš„åˆ†é¡
        categories = [
            "base_types",
            "messaging",
            "tasks",
            "findings",
            "async_utils",
            "plugins",
            "cli",
        ]
        for category in categories:
            category_schemas = self.sot_data.get(category, {})
            if isinstance(category_schemas, dict):
                all_schemas.update(category_schemas)

        for schema_name, schema_data in all_schemas.items():
            rust_code += self._render_rust_struct(schema_name, schema_data)
            rust_code += "\n\n"

        return rust_code

    def _render_rust_enum(self, enum_name: str, enum_data: dict) -> str:
        """æ¸²æŸ“ Rust æšèˆ‰"""
        description = enum_data.get("description", f"{enum_name} æšèˆ‰")
        values = enum_data.get("values", {})

        rust_enum = f"""/// {description}
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum {enum_name} {{"""

        for value, desc in values.items():
            rust_enum += f"""
    /// {desc}
    {value.replace('-', '_').upper()},"""

        rust_enum += (
            """
}

impl std::fmt::Display for """
            + enum_name
            + """ {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {"""
        )

        for value in values.keys():
            rust_value = value.replace("-", "_").upper()
            rust_enum += f"""
            {enum_name}::{rust_value} => write!(f, "{value}"),"""

        rust_enum += (
            """
        }
    }
}

impl std::str::FromStr for """
            + enum_name
            + """ {
    type Err = String;
    
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_uppercase().as_str() {"""
        )

        for value in values.keys():
            rust_value = value.replace("-", "_").upper()
            rust_enum += f"""
            "{value.upper()}" => Ok({enum_name}::{rust_value}),"""

        rust_enum += f"""
            _ => Err(format!("Invalid {enum_name}: {{}}", s)),
        }}
    }}
}}"""

        return rust_enum

    def _render_rust_struct(self, struct_name: str, struct_data: dict) -> str:
        """æ¸²æŸ“ Rust çµæ§‹é«”"""
        description = struct_data.get("description", f"{struct_name} çµæ§‹é«”")
        # æ”¯æŒå…©ç¨®å­—æ®µå®šç¾©æ ¼å¼ï¼šproperties (æ¨™æº–) å’Œ fields (AIVAç‰¹æœ‰)
        properties = struct_data.get("properties", struct_data.get("fields", {}))
        required = struct_data.get("required", [])

        rust_struct = f"""/// {description}
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct {struct_name} {{"""

        for field_name, field_data in properties.items():
            field_desc = field_data.get("description", f"{field_name} æ¬„ä½")
            original_type = field_data.get("type")
            field_required = field_data.get(
                "required", True
            )  # AIVA schema ä¸­ required å¯èƒ½åœ¨ field ç´šåˆ¥
            is_required_in_struct = field_name in required or field_required

            # å¦‚æœé¡å‹å·²ç¶“æ˜¯ Optionalï¼Œä¸éœ€è¦å†åŒ…è£
            if original_type and original_type.startswith("Optional["):
                field_type = self._convert_to_rust_type(original_type, field_data)
                is_optional = True
            elif not is_required_in_struct:
                # éå¿…å¡«æ¬„ä½ï¼ŒåŒ…è£ç‚º Option
                base_type = self._convert_to_rust_type(original_type, field_data)
                field_type = f"Option<{base_type}>"
                is_optional = True
            else:
                # å¿…å¡«æ¬„ä½
                field_type = self._convert_to_rust_type(original_type, field_data)
                is_optional = False

            rust_struct += f"""
    /// {field_desc}"""

            if is_optional:
                rust_struct += f"""
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub {field_name}: {field_type},"""
            else:
                rust_struct += f"""
    pub {field_name}: {field_type},"""

        rust_struct += (
            """
}

impl """
            + struct_name
            + """ {
    /// å‰µå»ºæ–°çš„å¯¦ä¾‹
    pub fn new() -> Self {
        Self {"""
        )

        for field_name, field_data in properties.items():
            original_type = field_data.get("type")
            field_required = field_data.get("required", True)
            is_required_in_struct = field_name in required or field_required

            if original_type and original_type.startswith("Optional["):
                rust_struct += f"""
            {field_name}: None,"""
            elif not is_required_in_struct:
                rust_struct += f"""
            {field_name}: None,"""
            else:
                # éœ€è¦é‡æ–°è¨ˆç®— field_type ä»¥ç²å¾—æ­£ç¢ºçš„é è¨­å€¼
                if original_type and original_type.startswith("Optional["):
                    converted_type = self._convert_to_rust_type(
                        original_type, field_data
                    )
                elif not is_required_in_struct:
                    base_type = self._convert_to_rust_type(original_type, field_data)
                    converted_type = f"Option<{base_type}>"
                else:
                    converted_type = self._convert_to_rust_type(
                        original_type, field_data
                    )

                default_value = self._get_rust_default_value(converted_type, field_data)
                rust_struct += f"""
            {field_name}: {default_value},"""

        rust_struct += """
        }
    }
    
    /// é©—è­‰çµæ§‹é«”æ•¸æ“š
    pub fn validate(&self) -> Result<(), String> {"""

        # æ·»åŠ å¿…å¡«æ¬„ä½é©—è­‰
        for field_name in required:
            if field_name in properties:
                field_type = properties[field_name].get("type")
                if field_type == "string":
                    rust_struct += f"""
        if self.{field_name}.is_empty() {{
            return Err("Field '{field_name}' is required and cannot be empty".to_string());
        }}"""

        rust_struct += (
            """
        Ok(())
    }
}

impl Default for """
            + struct_name
            + """ {
    fn default() -> Self {
        Self::new()
    }
}"""
        )

        return rust_struct

    def _convert_to_rust_type(
        self, json_type: str, field_data: dict[str, Any] | None = None
    ) -> str:
        """å°‡ JSON Schema é¡å‹è½‰æ›ç‚º Rust é¡å‹"""
        if field_data is None:
            field_data = {}

        # è™•ç† Optional é¡å‹
        if json_type and json_type.startswith("Optional["):
            inner_type = json_type[9:-1]  # ç§»é™¤ 'Optional[' å’Œ ']'
            return f"Option<{self._convert_to_rust_type(inner_type, field_data)}>"

        # è™•ç† List é¡å‹
        if json_type and json_type.startswith("List["):
            inner_type = json_type[5:-1]  # ç§»é™¤ 'List[' å’Œ ']'
            return f"Vec<{self._convert_to_rust_type(inner_type, field_data)}>"

        # è™•ç† Dict é¡å‹
        if json_type and json_type.startswith("Dict["):
            # Dict[str, str] -> HashMap<String, String>
            # Dict[str, Any] -> HashMap<String, serde_json::Value>
            dict_content = json_type[5:-1]  # ç§»é™¤ 'Dict[' å’Œ ']'
            if dict_content == "str, str":
                return "std::collections::HashMap<String, String>"
            elif dict_content == "str, Any":
                return "std::collections::HashMap<String, serde_json::Value>"
            else:
                return "std::collections::HashMap<String, serde_json::Value>"

        # åŸºæœ¬é¡å‹æ˜ å°„
        type_mapping = {
            "str": "String",
            "string": "String",
            "int": "i32",
            "integer": "i32",
            "float": "f64",
            "number": "f64",
            "bool": "bool",
            "boolean": "bool",
            "datetime": "chrono::DateTime<chrono::Utc>",
            "Any": "serde_json::Value",
        }

        # æª¢æŸ¥æ˜¯å¦ç‚ºè‡ªå®šç¾©é¡å‹ï¼ˆå­˜åœ¨æ–¼ SOT ä¸­çš„çµæ§‹é«”ï¼‰
        all_types = set()
        for category in ["base_types", "messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_types.update(self.sot_data[category].keys())

        if json_type in all_types:
            return json_type  # è‡ªå®šç¾©é¡å‹ä¿æŒåŸå

        # è™•ç†æšèˆ‰é¡å‹
        if "enum" in field_data:
            return "String"  # Serde æœƒè™•ç†æšèˆ‰é©—è­‰

        # è™•ç†æ ¼å¼åŒ–é¡å‹
        format_type = field_data.get("format")
        if format_type == "date-time":
            return "chrono::DateTime<chrono::Utc>"
        elif format_type == "uuid":
            return "uuid::Uuid"
        elif format_type == "uri" or format_type == "url":
            return "url::Url"

        return type_mapping.get(json_type, "String")

    def _get_rust_default_value(
        self, json_type: str, field_data: dict[str, Any] | None = None
    ) -> str:
        """ç²å– Rust é¡å‹çš„é»˜èªå€¼"""
        if field_data is None:
            field_data = {}

        # æª¢æŸ¥æ˜¯å¦æœ‰é è¨­å€¼å®šç¾©
        if "default" in field_data:
            default_val = field_data["default"]
            if isinstance(default_val, str):
                return f'"{default_val}".to_string()'
            elif isinstance(default_val, bool):
                return str(default_val).lower()
            elif isinstance(default_val, (int, float)):
                return str(default_val)
            elif isinstance(default_val, list):
                return "Vec::new()"
            elif isinstance(default_val, dict):
                return "std::collections::HashMap::new()"

        # è™•ç† Optional é¡å‹ (å·²ç¶“ç”±ä¸Šå±¤è™•ç†ç‚º Option<T>)
        if json_type and json_type.startswith("Option<"):
            return "None"

        # è™•ç† Vec é¡å‹
        if json_type and json_type.startswith("Vec<"):
            return "Vec::new()"

        # è™•ç† HashMap é¡å‹
        if json_type and json_type.startswith("std::collections::HashMap<"):
            return "std::collections::HashMap::new()"

        # åŸºæœ¬é¡å‹é è¨­å€¼
        defaults = {
            "String": "String::new()",
            "str": "String::new()",
            "string": "String::new()",
            "i32": "0",
            "int": "0",
            "integer": "0",
            "f64": "0.0",
            "float": "0.0",
            "number": "0.0",
            "bool": "false",
            "boolean": "false",
            "chrono::DateTime<chrono::Utc>": "chrono::Utc::now()",
            "serde_json::Value": "serde_json::Value::Null",
            "uuid::Uuid": "uuid::Uuid::new_v4()",
            "url::Url": 'url::Url::parse("https://example.com").unwrap()',
        }

        # æª¢æŸ¥æ˜¯å¦ç‚ºè‡ªå®šç¾©é¡å‹
        all_types = set()
        for category in ["base_types", "messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_types.update(self.sot_data[category].keys())

        if json_type in all_types:
            return f"{json_type}::default()"

        return defaults.get(json_type, "String::new()")

    def _get_python_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º Python é¡å‹"""
        mapping = self.sot_data["generation_config"]["python"]["field_mapping"]
        return mapping.get(type_str, type_str)

    def _get_python_default(self, default_value: Any, type_str: str) -> str:
        """ç²å– Python é è¨­å€¼"""
        if isinstance(default_value, str):
            return f'"{default_value}"'
        elif isinstance(default_value, bool):
            return str(default_value)
        elif isinstance(default_value, dict):
            return "Field(default_factory=dict)"
        elif isinstance(default_value, list):
            return "Field(default_factory=list)"
        return str(default_value)

    def _get_python_validation(self, key: str, value: Any) -> str:
        """ç²å– Python é©—è­‰åƒæ•¸"""
        if isinstance(value, str):
            return f'"{value}"'
        elif isinstance(value, list):
            return f"{value}"
        return str(value)

    def generate_typescript_schemas(self, output_dir: str | None = None) -> list[str]:
        """ç”Ÿæˆ TypeScript Schema
        
        Args:
            output_dir: è‡ªè¨‚è¼¸å‡ºç›®éŒ„
            
        Returns:
            ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        # TypeScript ç”Ÿæˆé…ç½®
        if output_dir:
            target_dir = Path(output_dir)
        else:
            target_dir = Path("services/features/common/typescript/aiva_common_ts/schemas/generated")
        
        target_dir.mkdir(parents=True, exist_ok=True)
        generated_files = []

        # ç”Ÿæˆä¸»è¦çš„ schemas.ts æ–‡ä»¶
        schema_file = target_dir / "schemas.ts"
        content = self._render_typescript_schemas()
        with open(schema_file, "w", encoding="utf-8") as f:
            f.write(content)
        generated_files.append(str(schema_file))
        logger.info(f"âœ… ç”Ÿæˆ TypeScript Schema: {schema_file}")

        # ç”Ÿæˆ index.ts å°å‡ºæ–‡ä»¶
        index_file = target_dir / "index.ts"
        index_content = self._render_typescript_index()
        with open(index_file, "w", encoding="utf-8") as f:
            f.write(index_content)
        generated_files.append(str(index_file))
        logger.info(f"âœ… ç”Ÿæˆ TypeScript Index: {index_file}")

        return generated_files

    def _render_typescript_schemas(self) -> str:
        """æ¸²æŸ“ TypeScript schemas"""
        content = []
        
        # æ–‡ä»¶é ­éƒ¨
        content.extend([
            "/**",
            " * AIVA Common TypeScript Schemas - è‡ªå‹•ç”Ÿæˆ",
            " * ==========================================",
            " * ",
            f" * {self.sot_data['metadata']['description']}",
            " * ",
            f" * âš ï¸  {self.sot_data['metadata']['generated_note']}",
            f" * ğŸ“… æœ€å¾Œæ›´æ–°: {self.sot_data['metadata']['last_updated']}",
            f" * ğŸ”„ Schema ç‰ˆæœ¬: {self.sot_data['version']}",
            " * ",
            " * éµå¾ªå–®ä¸€äº‹å¯¦åŸå‰‡ï¼Œèˆ‡ Python aiva_common.schemas ä¿æŒå®Œå…¨ä¸€è‡´",
            " */",
            "",
            "// ==================== æšèˆ‰é¡å‹å®šç¾© ====================",
            ""
        ])

        # ç”Ÿæˆæšèˆ‰ (å¾ Python enums æ˜ å°„)
        content.extend([
            "export enum Severity {",
            "  CRITICAL = \"critical\",",
            "  HIGH = \"high\",",
            "  MEDIUM = \"medium\",",
            "  LOW = \"low\",",
            "  INFORMATIONAL = \"info\"",
            "}",
            "",
            "export enum Confidence {",
            "  CERTAIN = \"certain\",",
            "  FIRM = \"firm\",", 
            "  POSSIBLE = \"possible\"",
            "}",
            "",
            "export enum VulnerabilityType {",
            "  XSS = \"XSS\",",
            "  SQLI = \"SQL Injection\",",
            "  SSRF = \"SSRF\",",
            "  IDOR = \"IDOR\",",
            "  BOLA = \"BOLA\",",
            "  INFO_LEAK = \"Information Leak\",",
            "  WEAK_AUTH = \"Weak Authentication\",",
            "  RCE = \"Remote Code Execution\",",
            "  AUTHENTICATION_BYPASS = \"Authentication Bypass\"",
            "}",
            "",
            "// ==================== åŸºç¤ä»‹é¢å®šç¾© ====================",
            ""
        ])

        # ç”ŸæˆåŸºç¤é¡å‹
        for class_name, class_info in self.sot_data["base_types"].items():
            content.extend(self._render_typescript_interface(class_name, class_info))
            content.append("")

        # ç”Ÿæˆ messaging é¡å‹
        if "messaging" in self.sot_data:
            content.append("// ==================== è¨Šæ¯é€šè¨Šé¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["messaging"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        # ç”Ÿæˆ findings é¡å‹  
        if "findings" in self.sot_data:
            content.append("// ==================== æ¼æ´ç™¼ç¾é¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["findings"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        # ç”Ÿæˆ tasks é¡å‹
        if "tasks" in self.sot_data:
            content.append("// ==================== ä»»å‹™ç®¡ç†é¡å‹ ====================")
            content.append("")
            for class_name, class_info in self.sot_data["tasks"].items():
                content.extend(self._render_typescript_interface(class_name, class_info))
                content.append("")

        return "\n".join(content)

    def _render_typescript_interface(self, interface_name: str, interface_info: dict) -> list[str]:
        """æ¸²æŸ“ TypeScript ä»‹é¢"""
        lines = []
        lines.append(f"/**")
        lines.append(f" * {interface_info['description']}")
        lines.append(f" */")
        lines.append(f"export interface {interface_name} {{")
        
        # ç”Ÿæˆå­—æ®µ
        for field_name, field_info in interface_info.get("fields", {}).items():
            ts_type = self._get_typescript_type(field_info["type"])
            optional_marker = "?" if not field_info.get("required", True) else ""
            description = field_info.get("description", "")
            
            if description:
                lines.append(f"  /** {description} */")
            lines.append(f"  {field_name}{optional_marker}: {ts_type};")
        
        lines.append("}")
        return lines

    def _get_typescript_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º TypeScript é¡å‹"""
        import re
        
        # è™•ç† Optional[T]
        if type_str.startswith("Optional["):
            inner = type_str[9:-1]
            return f"{self._get_typescript_type(inner)} | null"
        
        # è™•ç† List[T]
        if type_str.startswith("List["):
            inner = type_str[5:-1]
            return f"{self._get_typescript_type(inner)}[]"
        
        # è™•ç† Dict[str, T]
        dict_match = re.match(r"Dict\[str,\s*(.+)\]", type_str)
        if dict_match:
            value_type = dict_match.group(1).strip()
            return f"Record<string, {self._get_typescript_type(value_type)}>"
        
        # åŸºæœ¬é¡å‹æ˜ å°„
        type_mapping = {
            "str": "string",
            "int": "number", 
            "float": "number",
            "bool": "boolean",
            "datetime": "string",  # ISO 8601 æ ¼å¼
            "Any": "any",
            "VulnerabilityType": "VulnerabilityType",
            "Severity": "Severity", 
            "Confidence": "Confidence"
        }
        
        return type_mapping.get(type_str, type_str)

    def _render_typescript_index(self) -> str:
        """æ¸²æŸ“ TypeScript index.ts"""
        content = []
        content.extend([
            "/**",
            " * AIVA TypeScript Schemas - çµ±ä¸€å°å‡º",
            " * ==================================",
            " * ",
            " * æ­¤æ–‡ä»¶å°å‡ºæ‰€æœ‰æ¨™æº–ç”Ÿæˆçš„ Schema å®šç¾©",
            " * éµå¾ªå–®ä¸€äº‹å¯¦åŸå‰‡ï¼Œç¢ºä¿èˆ‡ Python ç‰ˆæœ¬ä¸€è‡´",
            " */",
            "",
            "// å°å‡ºæ‰€æœ‰ schemas",
            "export * from './schemas';",
            "",
            "// ç‰ˆæœ¬ä¿¡æ¯",
            f"export const SCHEMA_VERSION = '{self.sot_data['version']}';",
            f"export const GENERATED_AT = '{datetime.now().isoformat()}';",
            ""
        ])
        
        return "\n".join(content)

    def _generate_python_field(self, field_name: str, field_info: dict) -> str:
        """ç”ŸæˆPythonå­—æ®µå®šç¾©"""
        field_type = self._get_python_type(field_info["type"])
        parts = [f"{field_name}: {field_type}"]

        # è™•ç†é è¨­å€¼å’ŒFieldåƒæ•¸
        field_params = []

        # æ·»åŠ é©—è­‰åƒæ•¸
        if "validation" in field_info:
            for key, value in field_info["validation"].items():
                if key == "enum":
                    field_params.append(f"values={value}")  # type: ignore
                elif key == "pattern":
                    field_params.append(f'pattern=r"{value}"')  # type: ignore
                elif key == "format":
                    # Pydantic v2 format handling
                    if value == "url":
                        field_params.append("url=True")  # type: ignore
                elif key == "max_length":
                    field_params.append(f"max_length={value}")  # type: ignore
                elif key == "minimum":
                    field_params.append(f"ge={value}")  # type: ignore
                elif key == "maximum":
                    field_params.append(f"le={value}")  # type: ignore

        # è™•ç†é è¨­å€¼
        if not field_info.get("required", True):
            if "default" in field_info:
                default_val = self._get_python_default(
                    field_info["default"], field_info["type"]
                )
                if field_params:
                    field_params.append(f"default={default_val}")  # type: ignore
                    parts.append(f" = Field({', '.join(field_params)})")  # type: ignore
                else:
                    parts.append(f" = {default_val}")  # type: ignore
            else:
                if field_params:
                    field_params.append("default=None")  # type: ignore
                    parts.append(f" = Field({', '.join(field_params)})")  # type: ignore
                else:
                    parts.append(" = None")  # type: ignore
        elif "default" in field_info:
            default_val = self._get_python_default(
                field_info["default"], field_info["type"]
            )
            field_params.append(f"default={default_val}")  # type: ignore
            parts.append(f" = Field({', '.join(field_params)})")  # type: ignore
        elif field_params:
            parts.append(f" = Field({', '.join(field_params)})")  # type: ignore

        return "".join(parts)

    def _get_go_type(self, type_str: str) -> str:
        """è½‰æ›ç‚º Go é¡å‹ - æ”¯æ´åµŒå¥—é¡å‹æ˜ å°„"""
        import re

        # è™•ç† Optional[T] - è½‰æ›ç‚º *T
        if type_str.startswith("Optional["):
            inner = type_str[9:-1]  # æå–å…§éƒ¨é¡å‹
            mapped = self._get_go_type(inner)  # éæ­¸æ˜ å°„
            # å¦‚æœå…§éƒ¨é¡å‹å·²ç¶“æ˜¯æŒ‡é‡æˆ–map/slice,ä¸å†æ·»åŠ *
            if (
                mapped.startswith("*")
                or mapped.startswith("map[")
                or mapped.startswith("[]")
            ):
                return mapped
            return f"*{mapped}"

        # è™•ç† Dict[K, V] - è½‰æ›ç‚º map[K]V
        dict_match = re.match(r"Dict\[(.+?),\s*(.+)\]", type_str)
        if dict_match:
            key_type_raw = dict_match.group(1).strip()
            val_type_raw = dict_match.group(2).strip()
            key_type = self._get_go_type(key_type_raw)
            val_type = self._get_go_type(val_type_raw)
            return f"map[{key_type}]{val_type}"

        # è™•ç† List[T] - è½‰æ›ç‚º []T
        if type_str.startswith("List["):
            inner = type_str[5:-1]
            mapped = self._get_go_type(inner)
            return f"[]{mapped}"

        # åŸºæœ¬é¡å‹æ˜ å°„
        mapping = self.sot_data["generation_config"]["go"]["field_mapping"]
        return mapping.get(type_str, type_str)

    def _to_go_field_name(self, field_name: str) -> str:
        """
        è½‰æ›ç‚º Go æ¬„ä½åç¨±ï¼ˆPascalCaseï¼‰ï¼Œç¬¦åˆ Go Initialisms æ¨™æº–
        åƒè€ƒ: https://go.dev/wiki/CodeReviewComments#initialisms
        """
        # Go å®˜æ–¹ç¸®å¯«æ¨™æº– - å¿…é ˆçµ±ä¸€å¤§å°å¯«
        initialisms = {
            "url": "URL",
            "http": "HTTP",
            "https": "HTTPS",
            "id": "ID",
            "api": "API",
            "json": "JSON",
            "xml": "XML",
            "html": "HTML",
            "css": "CSS",
            "js": "JS",
            "sql": "SQL",
            "cwe": "CWE",
            "cve": "CVE",
            "owasp": "OWASP",
            "uuid": "UUID",
            "uri": "URI",
            "tcp": "TCP",
            "udp": "UDP",
            "ip": "IP",
            "os": "OS",
            "cpu": "CPU",
            "ram": "RAM",
            "db": "DB",
        }

        # åˆ†å‰²å­—æ®µåä¸¦è™•ç†æ¯å€‹éƒ¨åˆ†
        parts = field_name.split("_")
        go_parts = []

        for part in parts:
            lower_part = part.lower()
            if lower_part in initialisms:
                go_parts.append(initialisms[lower_part])
            else:
                go_parts.append(part.capitalize())

        return "".join(go_parts)

    def _get_go_json_tag(self, required: bool) -> str:
        """ç²å– Go JSON æ¨™ç±¤"""
        return "" if required else ",omitempty"

    def _get_all_fields(self, class_info: dict, current_section: str) -> dict:
        """
        ç²å–é¡çš„æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬ç¹¼æ‰¿çš„å­—æ®µ

        Args:
            class_info: é¡å®šç¾©ä¿¡æ¯
            current_section: ç•¶å‰æ‰€åœ¨çš„ section (base_types, findings, etc.)

        Returns:
            åŒ…å«æ‰€æœ‰å­—æ®µçš„å­—å…¸
        """
        all_fields = {}

        # é¦–å…ˆè™•ç†ç¹¼æ‰¿
        if "extends" in class_info:
            base_class_name = class_info["extends"]
            base_class_info = None

            # åœ¨æ‰€æœ‰å¯èƒ½çš„ section ä¸­æŸ¥æ‰¾åŸºé¡
            for section_name in [
                "base_types",
                "findings",
                "messaging",
                "tasks",
                "plugins",
                "cli",
            ]:
                if (
                    section_name in self.sot_data
                    and base_class_name in self.sot_data[section_name]
                ):
                    base_class_info = self.sot_data[section_name][base_class_name]
                    break

            if base_class_info:
                # éæ­¸ç²å–åŸºé¡çš„æ‰€æœ‰å­—æ®µ
                base_fields = self._get_all_fields(base_class_info, current_section)
                all_fields.update(base_fields)
            else:
                logger.warning(f"æ‰¾ä¸åˆ°åŸºé¡: {base_class_name}")

        # æ·»åŠ ç•¶å‰é¡çš„ç›´æ¥å­—æ®µ
        if "fields" in class_info:
            all_fields.update(class_info["fields"])

        # æ·»åŠ ç•¶å‰é¡çš„é¡å¤–å­—æ®µ
        if "additional_fields" in class_info:
            all_fields.update(class_info["additional_fields"])

        return all_fields

    def validate_schemas(self) -> bool:
        """é©—è­‰ Schema å®šç¾©çš„ä¸€è‡´æ€§"""
        logger.info("ğŸ” é–‹å§‹ Schema é©—è­‰...")

        errors = []

        # æª¢æŸ¥å¿…è¦çš„é ‚å±¤éµ
        required_keys = ["version", "metadata", "base_types", "generation_config"]
        for key in required_keys:
            if key not in self.sot_data:
                errors.append(f"ç¼ºå°‘å¿…è¦çš„é ‚å±¤éµ: {key}")  # type: ignore

        # æª¢æŸ¥ç‰ˆæœ¬æ ¼å¼
        version = self.sot_data.get("version", "")
        if not version or not version.replace(".", "").isdigit():
            errors.append(f"ç‰ˆæœ¬æ ¼å¼ç„¡æ•ˆ: {version}")  # type: ignore

        # æª¢æŸ¥é¡å‹å¼•ç”¨
        defined_types = set(self.sot_data.get("base_types", {}).keys())
        all_schemas = {}

        for category in ["messaging", "tasks", "findings"]:
            if category in self.sot_data:
                all_schemas.update(self.sot_data[category])
                defined_types.update(self.sot_data[category].keys())

        # æª¢æŸ¥é¡å‹å¼•ç”¨çš„æœ‰æ•ˆæ€§
        for schema_name, schema_info in all_schemas.items():
            for field_name, field_info in schema_info.get("fields", {}).items():
                field_type = field_info.get("type", "")
                # ç§»é™¤æ³›å‹åŒ…è£æª¢æŸ¥æ ¸å¿ƒé¡å‹
                core_type = (
                    field_type.replace("Optional[", "")
                    .replace("List[", "")
                    .replace("Dict[str, ", "")
                    .replace("]", "")
                    .replace(">", "")
                )
                if core_type in ["str", "int", "float", "bool", "datetime", "Any"]:
                    continue
                if core_type not in defined_types:
                    errors.append(f"åœ¨ {schema_name}.{field_name} ä¸­å¼•ç”¨äº†æœªå®šç¾©çš„é¡å‹: {core_type}")  # type: ignore

        if errors:
            logger.error("âŒ Schema é©—è­‰å¤±æ•—:")
            for error in errors:
                logger.error(f"  - {error}")
            return False

        logger.info("âœ… Schema é©—è­‰é€šé!")
        return True

    def generate_all(self, validate: bool = True) -> dict[str, list[str]]:
        """ç”Ÿæˆæ‰€æœ‰èªè¨€çš„ Schema

        Args:
            validate: æ˜¯å¦å…ˆé€²è¡Œé©—è­‰

        Returns:
            å„èªè¨€ç”Ÿæˆçš„æª”æ¡ˆåˆ—è¡¨
        """
        if validate and not self.validate_schemas():
            logger.error("âŒ Schema é©—è­‰å¤±æ•—ï¼Œåœæ­¢ç”Ÿæˆ")
            return {}

        results = {}

        logger.info("ğŸš€ é–‹å§‹ç”Ÿæˆæ‰€æœ‰èªè¨€ Schema...")

        # ç”Ÿæˆ Python
        try:
            results["python"] = self.generate_python_schemas()
            logger.info(f"âœ… Python Schema ç”Ÿæˆå®Œæˆ: {len(results['python'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Python Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["python"] = []

        # ç”Ÿæˆ Go
        try:
            results["go"] = self.generate_go_schemas()
            logger.info(f"âœ… Go Schema ç”Ÿæˆå®Œæˆ: {len(results['go'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Go Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["go"] = []

        # ç”Ÿæˆ Rust (ç°¡åŒ–ç‰ˆæœ¬)
        try:
            results["rust"] = self.generate_rust_schemas()
            logger.info(f"âœ… Rust Schema ç”Ÿæˆå®Œæˆ: {len(results['rust'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ Rust Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["rust"] = []

        # ç”Ÿæˆ TypeScript
        try:
            results["typescript"] = self.generate_typescript_schemas()
            logger.info(f"âœ… TypeScript Schema ç”Ÿæˆå®Œæˆ: {len(results['typescript'])} å€‹æª”æ¡ˆ")
        except Exception as e:
            logger.error(f"âŒ TypeScript Schema ç”Ÿæˆå¤±æ•—: {e}")
            results["typescript"] = []

        total_files = sum(len(files) for files in results.values())
        logger.info(f"ğŸ‰ æ‰€æœ‰èªè¨€ Schema ç”Ÿæˆå®Œæˆ! ç¸½è¨ˆ: {total_files} å€‹æª”æ¡ˆ")

        return results


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    parser = argparse.ArgumentParser(description="AIVA Schema ä»£ç¢¼ç”Ÿæˆå·¥å…·")
    parser.add_argument(
        "--lang",
        choices=["python", "go", "rust", "typescript", "all"],
        default="all",
        help="ç”Ÿæˆçš„èªè¨€",
    )
    parser.add_argument("--validate", action="store_true", help="åƒ…é€²è¡Œ Schema é©—è­‰")
    parser.add_argument("--output-dir", help="è‡ªè¨‚è¼¸å‡ºç›®éŒ„")
    parser.add_argument(
        "--sot-file",
        default="services/aiva_common/core_schema_sot.yaml",
        help="SOT æª”æ¡ˆè·¯å¾‘",
    )

    args = parser.parse_args()

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = SchemaCodeGenerator(args.sot_file)

    if args.validate:
        # åƒ…é©—è­‰
        success = generator.validate_schemas()
        sys.exit(0 if success else 1)

    # ç”Ÿæˆä»£ç¢¼
    if args.lang == "all":
        results = generator.generate_all()
    elif args.lang == "python":
        results = {"python": generator.generate_python_schemas(args.output_dir)}
    elif args.lang == "go":
        results = {"go": generator.generate_go_schemas(args.output_dir)}
    elif args.lang == "rust":
        results = {"rust": generator.generate_rust_schemas(args.output_dir)}
    elif args.lang == "typescript":
        results = {"typescript": generator.generate_typescript_schemas(args.output_dir)}

    # è¼¸å‡ºçµæœ
    success = all(len(files) > 0 for files in results.values())
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
