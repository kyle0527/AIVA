"""
AIVA å¢å¼·åŠŸèƒ½æ•´åˆç¤ºä¾‹

å±•ç¤ºå¦‚ä½•åœ¨å¯¦éš›æƒææµç¨‹ä¸­ä½¿ç”¨æ–°çš„è³‡ç”¢èˆ‡æ¼æ´ç”Ÿå‘½é€±æœŸç®¡ç†åŠŸèƒ½
"""

from __future__ import annotations

import asyncio
from typing import Any

from sqlalchemy import create_engine  # type: ignore[import-not-found]
from sqlalchemy.orm import sessionmaker  # type: ignore[import-not-found]

from services.aiva_common.schemas import FindingPayload
from services.aiva_common.utils import get_logger
from services.integration.aiva_integration.analysis.vuln_correlation_analyzer import (
    VulnerabilityCorrelationAnalyzer,
)
from services.integration.aiva_integration.reception.lifecycle_manager import (
    AssetVulnerabilityManager,
)
from services.integration.aiva_integration.reception.models_enhanced import Base

logger = get_logger(__name__)


class EnhancedScanProcessor:
    """
    å¢å¼·ç‰ˆæƒæè™•ç†å™¨

    æ•´åˆè³‡ç”¢ç®¡ç†ã€æ¼æ´ç”Ÿå‘½é€±æœŸã€ç›¸é—œæ€§åˆ†æç­‰åŠŸèƒ½
    """

    def __init__(self, database_url: str):
        """
        åˆå§‹åŒ–è™•ç†å™¨

        Args:
            database_url: è³‡æ–™åº«é€£æ¥ URL
        """
        self.engine = create_engine(database_url)
        self.SessionLocal = sessionmaker(bind=self.engine)

        # å‰µå»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        Base.metadata.create_all(bind=self.engine)

    async def process_scan_results(
        self,
        scan_id: str,
        target_info: dict[str, Any],
        findings: list[FindingPayload],
    ) -> dict[str, Any]:
        """
        è™•ç†æƒæçµæœ

        Args:
            scan_id: æƒæ ID
            target_info: ç›®æ¨™è³‡è¨Šï¼ˆåŒ…å«æ¥­å‹™ä¸Šä¸‹æ–‡ï¼‰
            findings: æƒæç™¼ç¾åˆ—è¡¨

        Returns:
            è™•ç†çµæœæ‘˜è¦
        """
        session = self.SessionLocal()
        try:
            # 1. è¨»å†Šæˆ–æ›´æ–°è³‡ç”¢
            logger.info(f"Processing scan {scan_id}: registering asset...")
            manager = AssetVulnerabilityManager(session)

            asset = manager.register_asset(
                asset_value=target_info.get("url") or target_info.get("value"),
                asset_type=target_info.get("type", "url"),
                name=target_info.get("name"),
                business_criticality=target_info.get(
                    "business_criticality", "medium"
                ),
                environment=target_info.get("environment", "development"),
                owner=target_info.get("owner"),
                tags=target_info.get("tags", []),
                technology_stack=target_info.get("technology_stack"),
            )

            logger.info(
                f"Asset registered: {asset.asset_id} ({asset.business_criticality} / {asset.environment})"  # type: ignore[attr-defined]
            )

            # 2. è™•ç†æ¯å€‹ Findingï¼Œé€²è¡Œæ¼æ´å»é‡å’Œç”Ÿå‘½é€±æœŸç®¡ç†
            logger.info(f"Processing {len(findings)} findings...")
            new_vulnerabilities = []
            updated_vulnerabilities = []

            for finding in findings:
                vulnerability, is_new = manager.process_finding(
                    finding, asset.asset_id  # type: ignore[attr-defined]
                )

                if is_new:
                    new_vulnerabilities.append(vulnerability)
                    logger.info(
                        f"New vulnerability: {vulnerability.vulnerability_id} "  # type: ignore[attr-defined]
                        f"({vulnerability.severity})"  # type: ignore[attr-defined]
                    )
                else:
                    updated_vulnerabilities.append(vulnerability)

            # 3. åŸ·è¡Œç›¸é—œæ€§åˆ†æ
            logger.info("Performing correlation analysis...")
            analyzer = VulnerabilityCorrelationAnalyzer()

            # è½‰æ›ç‚ºåˆ†æå™¨æ‰€éœ€çš„æ ¼å¼
            finding_dicts = [self._finding_to_dict(f) for f in findings]

            # åŸºç¤ç›¸é—œæ€§åˆ†æ
            correlation_result = analyzer.analyze_correlations(finding_dicts)

            # ç¨‹å¼ç¢¼å±¤é¢æ ¹å› åˆ†æ
            root_cause_result = analyzer.analyze_code_level_root_cause(finding_dicts)

            # SAST-DAST é—œè¯åˆ†æ
            sast_dast_result = analyzer.analyze_sast_dast_correlation(finding_dicts)

            # 4. æ ¹æ“šåˆ†æçµæœæ›´æ–°æ¼æ´ç‹€æ…‹å’Œæ¨™ç±¤
            self._apply_analysis_results(
                manager, correlation_result, root_cause_result, sast_dast_result
            )

            # 5. ç”Ÿæˆæ‘˜è¦å ±å‘Š
            summary = self._generate_summary(
                asset=asset,
                new_vulnerabilities=new_vulnerabilities,
                updated_vulnerabilities=updated_vulnerabilities,
                correlation_result=correlation_result,
                root_cause_result=root_cause_result,
                sast_dast_result=sast_dast_result,
            )

            logger.info(f"Scan processing completed: {scan_id}")
            return summary

        except Exception as e:
            logger.error(f"Error processing scan {scan_id}: {e}")
            session.rollback()
            raise
        finally:
            session.close()

    def _finding_to_dict(self, finding: FindingPayload) -> dict[str, Any]:
        """è½‰æ› FindingPayload ç‚ºå­—å…¸"""
        return {
            "finding_id": finding.finding_id,
            "vulnerability_type": finding.vulnerability.name.value,
            "severity": finding.vulnerability.severity.value,
            "confidence": finding.vulnerability.confidence.value,
            "location": {
                "url": str(finding.target.url),
                "parameter": finding.target.parameter,
                "method": finding.target.method,
            },
        }

    def _apply_analysis_results(
        self,
        manager: AssetVulnerabilityManager,
        correlation_result: dict[str, Any],
        root_cause_result: dict[str, Any],
        sast_dast_result: dict[str, Any],
    ) -> None:
        """
        æ ¹æ“šåˆ†æçµæœæ‡‰ç”¨æ¨™ç±¤å’Œæ›´æ–°ç‹€æ…‹

        Args:
            manager: è³‡ç”¢æ¼æ´ç®¡ç†å™¨
            correlation_result: ç›¸é—œæ€§åˆ†æçµæœ
            root_cause_result: æ ¹å› åˆ†æçµæœ
            sast_dast_result: SAST-DAST é—œè¯çµæœ
        """
        # æ¨™è¨˜æ”»æ“Šéˆä¸­çš„æ¼æ´
        if correlation_result.get("attack_chains"):
            for chain in correlation_result["attack_chains"]:
                for step in chain.get("matched_steps", []):
                    for finding in step.get("findings", []):
                        vuln_id = finding.get("finding_id") or finding.get(
                            "vulnerability_id"
                        )
                        if vuln_id:
                            manager.add_vulnerability_tag(vuln_id, "attack_chain")
                            manager.add_vulnerability_tag(
                                vuln_id, f"chain_{chain['pattern'][0]}"
                            )

        # æ¨™è¨˜æ ¹æœ¬åŸå› æ¼æ´
        if root_cause_result.get("root_causes"):
            for root_cause in root_cause_result["root_causes"]:
                for vuln_id in root_cause.get("vulnerability_ids", []):
                    manager.add_vulnerability_tag(vuln_id, "root_cause_derived")
                    manager.add_vulnerability_tag(
                        vuln_id, f"component_{root_cause['component_type']}"
                    )

        # æ¨™è¨˜å·²é©—è­‰çš„ SAST-DAST æµ
        if sast_dast_result.get("confirmed_flows"):
            for flow in sast_dast_result["confirmed_flows"]:
                sast_id = flow.get("sast_finding_id")
                dast_id = flow.get("dast_finding_id")

                if sast_id:
                    manager.add_vulnerability_tag(sast_id, "sast_dast_confirmed")
                    manager.add_vulnerability_tag(sast_id, "high_confidence")

                if dast_id:
                    manager.add_vulnerability_tag(dast_id, "sast_dast_confirmed")
                    manager.add_vulnerability_tag(dast_id, "high_confidence")

        # æ¨™è¨˜æœªç¢ºèªçš„ SAST ç™¼ç¾
        if sast_dast_result.get("unconfirmed_sast"):
            for unconfirmed in sast_dast_result["unconfirmed_sast"]:
                vuln_id = unconfirmed.get("finding_id")
                if vuln_id:
                    manager.add_vulnerability_tag(vuln_id, "sast_only")
                    manager.add_vulnerability_tag(vuln_id, "needs_verification")

    def _generate_summary(
        self,
        asset: Any,
        new_vulnerabilities: list[Any],
        updated_vulnerabilities: list[Any],
        correlation_result: dict[str, Any],
        root_cause_result: dict[str, Any],
        sast_dast_result: dict[str, Any],
    ) -> dict[str, Any]:
        """ç”Ÿæˆè™•ç†æ‘˜è¦"""
        return {
            "asset": {
                "asset_id": asset.asset_id,  # type: ignore[attr-defined]
                "name": asset.name,  # type: ignore[attr-defined]
                "type": asset.type,  # type: ignore[attr-defined]
                "business_criticality": asset.business_criticality,  # type: ignore[attr-defined]
                "environment": asset.environment,  # type: ignore[attr-defined]
            },
            "vulnerabilities": {
                "new": len(new_vulnerabilities),
                "updated": len(updated_vulnerabilities),
                "total": len(new_vulnerabilities) + len(updated_vulnerabilities),
                "by_severity": self._count_by_severity(
                    new_vulnerabilities + updated_vulnerabilities
                ),
            },
            "correlation_analysis": {
                "correlation_groups": len(correlation_result.get("correlation_groups", [])),
                "attack_chains": len(correlation_result.get("attack_chains", [])),
                "risk_amplification": correlation_result.get("risk_amplification", 1.0),
                "risk_level": correlation_result.get("summary", {}).get("risk_level", "unknown"),
            },
            "root_cause_analysis": {
                "root_causes": len(root_cause_result.get("root_causes", [])),
                "affected_vulnerabilities": len(
                    root_cause_result.get("derived_vulnerabilities", [])
                ),
                "fix_efficiency": root_cause_result.get("summary", {}).get(
                    "fix_efficiency", ""
                ),
            },
            "sast_dast_correlation": {
                "confirmed_flows": len(sast_dast_result.get("confirmed_flows", [])),
                "unconfirmed_sast": len(sast_dast_result.get("unconfirmed_sast", [])),
                "orphan_dast": len(sast_dast_result.get("orphan_dast", [])),
                "confirmation_rate": sast_dast_result.get("summary", {}).get(
                    "confirmation_rate", 0
                ),
            },
            "key_insights": self._generate_key_insights(
                correlation_result, root_cause_result, sast_dast_result
            ),
        }

    def _count_by_severity(self, vulnerabilities: list[Any]) -> dict[str, int]:
        """çµ±è¨ˆæ¼æ´åš´é‡ç¨‹åº¦åˆ†å¸ƒ"""
        counts = {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0, "INFO": 0}
        for vuln in vulnerabilities:
            severity = vuln.severity.upper()  # type: ignore[attr-defined]
            if severity in counts:
                counts[severity] += 1
        return counts

    def _generate_key_insights(
        self,
        correlation_result: dict[str, Any],
        root_cause_result: dict[str, Any],
        sast_dast_result: dict[str, Any],
    ) -> list[str]:
        """ç”Ÿæˆé—œéµæ´å¯Ÿ"""
        insights = []

        # æ”»æ“Šéˆæ´å¯Ÿ
        if correlation_result.get("attack_chains"):
            chain_count = len(correlation_result["attack_chains"])
            insights.append(
                f"ğŸ”— è­˜åˆ¥å‡º {chain_count} æ¢æ”»æ“Šéˆï¼Œæ”»æ“Šè€…å¯èƒ½é€éé€™äº›è·¯å¾‘é”æˆé€²éšæ”»æ“Šç›®æ¨™"
            )

        # æ ¹å› æ´å¯Ÿ
        if root_cause_result.get("root_causes"):
            root_count = len(root_cause_result["root_causes"])
            affected = len(root_cause_result.get("derived_vulnerabilities", []))
            insights.append(
                f"ğŸ¯ ç™¼ç¾ {root_count} å€‹å…±ç”¨å…ƒä»¶å•é¡Œï¼Œå½±éŸ¿ {affected} å€‹æ¼æ´ã€‚"
                f"å»ºè­°å„ªå…ˆä¿®å¾©é€™äº›æ ¹æœ¬åŸå› ä»¥æé«˜æ•ˆç‡"
            )

        # SAST-DAST é—œè¯æ´å¯Ÿ
        if sast_dast_result.get("confirmed_flows"):
            confirmed = len(sast_dast_result["confirmed_flows"])
            rate = sast_dast_result.get("summary", {}).get("confirmation_rate", 0)
            insights.append(
                f"âœ… {confirmed} å€‹ SAST ç™¼ç¾å·²è¢« DAST é©—è­‰ï¼ˆç¢ºèªç‡ {rate}%ï¼‰ï¼Œ"
                f"é€™äº›æ˜¯çœŸå¯¦å¯åˆ©ç”¨çš„æ¼æ´ï¼Œæ‡‰ç«‹å³è™•ç†"
            )

        # é¢¨éšªæ”¾å¤§æ´å¯Ÿ
        risk_amp = correlation_result.get("risk_amplification", 1.0)
        if risk_amp > 1.5:
            insights.append(
                f"âš ï¸ æ¼æ´ç›¸é—œæ€§å°è‡´é¢¨éšªæ”¾å¤§ {risk_amp}xï¼Œ"
                f"ç¶œåˆé¢¨éšªé é«˜æ–¼å–®å€‹æ¼æ´çš„ç¸½å’Œ"
            )

        return insights


# ============================================================================
# ä½¿ç”¨ç¯„ä¾‹
# ============================================================================


async def example_scan_workflow():
    """å®Œæ•´çš„æƒæå·¥ä½œæµç¨‹ç¤ºä¾‹"""
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = EnhancedScanProcessor(
        database_url="postgresql://user:password@localhost:5432/aiva_db"
    )

    # ç›®æ¨™è³‡è¨Šï¼ˆåŒ…å«æ¥­å‹™ä¸Šä¸‹æ–‡ï¼‰
    target_info = {
        "url": "https://api.example.com",
        "name": "Production API Server",
        "type": "url",
        "business_criticality": "critical",  # æ¥­å‹™é—œéµæ€§
        "environment": "production",  # ç’°å¢ƒ
        "owner": "api-team@example.com",
        "tags": ["api", "payment", "pci-dss"],
        "technology_stack": {
            "framework": "Django",
            "language": "Python 3.11",
            "database": "PostgreSQL",
        },
    }

    # æ¨¡æ“¬æƒæç™¼ç¾ï¼ˆå¯¦éš›æƒ…æ³æœƒå¾æƒæå¼•æ“ç²å–ï¼‰
    findings = []  # type: list[FindingPayload]
    # ... å¾æƒæå¼•æ“ç²å– findings

    # è™•ç†æƒæçµæœ
    result = await processor.process_scan_results(
        scan_id="scan_20251014_001", target_info=target_info, findings=findings
    )

    # è¼¸å‡ºæ‘˜è¦
    print("=" * 80)
    print("æƒæçµæœæ‘˜è¦")
    print("=" * 80)
    print(f"\nè³‡ç”¢: {result['asset']['name']}")
    print(
        f"æ¥­å‹™é‡è¦æ€§: {result['asset']['business_criticality']} | "
        f"ç’°å¢ƒ: {result['asset']['environment']}"
    )
    print(
        f"\næ¼æ´çµ±è¨ˆ: æ–°ç™¼ç¾ {result['vulnerabilities']['new']} å€‹, "
        f"æ›´æ–° {result['vulnerabilities']['updated']} å€‹"
    )
    print(f"åš´é‡ç¨‹åº¦åˆ†å¸ƒ: {result['vulnerabilities']['by_severity']}")

    print(f"\nç›¸é—œæ€§åˆ†æ:")
    print(f"  - ç›¸é—œæ€§çµ„åˆ: {result['correlation_analysis']['correlation_groups']}")
    print(f"  - æ”»æ“Šéˆ: {result['correlation_analysis']['attack_chains']}")
    print(f"  - é¢¨éšªæ”¾å¤§: {result['correlation_analysis']['risk_amplification']}x")

    print(f"\næ ¹å› åˆ†æ:")
    print(f"  - æ ¹æœ¬åŸå› : {result['root_cause_analysis']['root_causes']}")
    print(f"  - {result['root_cause_analysis']['fix_efficiency']}")

    print(f"\nSAST-DAST é—œè¯:")
    print(f"  - å·²é©—è­‰è³‡æ–™æµ: {result['sast_dast_correlation']['confirmed_flows']}")
    print(
        f"  - ç¢ºèªç‡: {result['sast_dast_correlation']['confirmation_rate']}%"
    )

    print("\né—œéµæ´å¯Ÿ:")
    for insight in result["key_insights"]:
        print(f"  {insight}")

    print("=" * 80)

    return result


async def example_vulnerability_management():
    """æ¼æ´ç”Ÿå‘½é€±æœŸç®¡ç†ç¤ºä¾‹"""
    from sqlalchemy import create_engine  # type: ignore[import-not-found]
    from sqlalchemy.orm import sessionmaker  # type: ignore[import-not-found]

    engine = create_engine("postgresql://user:password@localhost:5432/aiva_db")
    SessionLocal = sessionmaker(bind=engine)
    session = SessionLocal()

    manager = AssetVulnerabilityManager(session)

    # 1. æŸ¥è©¢ç‰¹å®šè³‡ç”¢çš„æ‰€æœ‰é–‹æ”¾æ¼æ´
    vulnerabilities = manager.get_asset_vulnerabilities(
        asset_id="asset_abc123", include_fixed=False
    )
    print(f"æ‰¾åˆ° {len(vulnerabilities)} å€‹é–‹æ”¾æ¼æ´")

    # 2. æ›´æ–°æ¼æ´ç‹€æ…‹
    for vuln in vulnerabilities[:3]:  # è™•ç†å‰ 3 å€‹
        manager.update_vulnerability_status(
            vulnerability_id=vuln.vulnerability_id,  # type: ignore[attr-defined]
            new_status="in_progress",
            changed_by="john.doe@example.com",
            comment="å·²æŒ‡æ´¾çµ¦é–‹ç™¼åœ˜éšŠ",
        )

    # 3. æŒ‡æ´¾æ¼æ´
    manager.assign_vulnerability(
        vulnerability_id=vulnerabilities[0].vulnerability_id,  # type: ignore[attr-defined]
        assigned_to="alice@example.com",
        changed_by="manager@example.com",
    )

    # 4. æŸ¥è©¢é€¾æœŸæ¼æ´
    overdue_vulns = manager.get_overdue_vulnerabilities()
    print(f"âš ï¸ æœ‰ {len(overdue_vulns)} å€‹æ¼æ´å·²é€¾æœŸ")

    # 5. è¨ˆç®— MTTR
    mttr_high = manager.calculate_mttr(severity="HIGH", days=30)
    print(f"é«˜å±æ¼æ´å¹³å‡ä¿®å¾©æ™‚é–“: {mttr_high['avg_hours']:.1f} å°æ™‚")

    session.close()


if __name__ == "__main__":
    # åŸ·è¡Œç¤ºä¾‹
    asyncio.run(example_scan_workflow())
    asyncio.run(example_vulnerability_management())
