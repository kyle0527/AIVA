#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIVA Docker åŸºç¤è¨­æ–½æ›´æ–°èˆ‡çµ„ç¹”å·¥å…·
æ ¹æ“š aiva_common æŒ‡å—å’Œåˆ†æå ±å‘Šï¼Œå° Docker åŸºç¤è¨­æ–½é€²è¡Œæ›´æ–°å’Œé‡çµ„
"""

import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

class DockerInfrastructureUpdater:
    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path).resolve()
        self.backup_dir = self.repo_path / "_backup_docker" / datetime.now().strftime("%Y%m%d_%H%M%S")
        self.update_log = []
        
        # åŸºæ–¼åˆ†æå ±å‘Šçš„ç¾ç‹€
        self.current_state = {
            "total_docker_files": 18,
            "complexity_score": 35,
            "root_level_files": 18,
            "docker_subdir_files": 0,
            "growth_prediction": "é«˜"
        }
        
        # åŸºæ–¼ AIVA æ¶æ§‹çš„çµ„ç¹”è¨ˆåŠƒ
        self.organization_plan = {
            "docker/": {
                "description": "Docker åŸºç¤è¨­æ–½çµ±ä¸€ç›®éŒ„",
                "subdirs": {
                    "core/": "æ ¸å¿ƒæœå‹™å®¹å™¨é…ç½®",
                    "components/": "åŠŸèƒ½çµ„ä»¶å®¹å™¨é…ç½®", 
                    "infrastructure/": "åŸºç¤è¨­æ–½æœå‹™é…ç½®",
                    "compose/": "Docker Compose é…ç½®æ–‡ä»¶",
                    "k8s/": "Kubernetes é…ç½®",
                    "helm/": "Helm Charts"
                }
            }
        }
    
    def log_update(self, operation: str, details: str, success: bool = True):
        """è¨˜éŒ„æ›´æ–°æ“ä½œ"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation,
            "details": details,
            "success": success
        }
        self.update_log.append(log_entry)
        status = "âœ…" if success else "âŒ"
        print(f"{status} {operation}: {details}")
    
    def create_backup(self):
        """å‰µå»ºç•¶å‰ Docker é…ç½®çš„å‚™ä»½"""
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        backup_files = []
        
        # å‚™ä»½æ ¹ç›®éŒ„çš„ Docker æ–‡ä»¶
        for pattern in ["Dockerfile*", "docker-compose*", "*.dockerfile"]:
            for file_path in self.repo_path.glob(pattern):
                if file_path.is_file():
                    backup_path = self.backup_dir / file_path.name
                    shutil.copy2(file_path, backup_path)
                    backup_files.append(str(file_path.relative_to(self.repo_path)))
        
        # å‚™ä»½ç¾æœ‰çš„ docker/ ç›®éŒ„
        docker_dir = self.repo_path / "docker"
        if docker_dir.exists():
            backup_docker_dir = self.backup_dir / "docker"
            shutil.copytree(docker_dir, backup_docker_dir)
            for file_path in docker_dir.rglob("*"):
                if file_path.is_file():
                    backup_files.append(str(file_path.relative_to(self.repo_path)))
        
        # å‚™ä»½ k8s/ å’Œ helm/ ç›®éŒ„
        for dir_name in ["k8s", "helm"]:
            source_dir = self.repo_path / dir_name
            if source_dir.exists():
                backup_target = self.backup_dir / dir_name
                shutil.copytree(source_dir, backup_target)
                for file_path in source_dir.rglob("*"):
                    if file_path.is_file():
                        backup_files.append(str(file_path.relative_to(self.repo_path)))
        
        self.log_update("å‰µå»ºå‚™ä»½", f"å‚™ä»½äº† {len(backup_files)} å€‹æ–‡ä»¶åˆ° {self.backup_dir}")
        return backup_files
    
    def analyze_current_docker_structure(self) -> Dict[str, Any]:
        """åˆ†æç•¶å‰ Docker çµæ§‹"""
        analysis = {
            "root_dockerfiles": [],
            "compose_files": [],
            "k8s_files": [],
            "helm_files": [],
            "docker_subdir_files": [],
            "service_mapping": {}
        }
        
        # æƒææ ¹ç›®éŒ„ Docker æ–‡ä»¶
        for file_path in self.repo_path.glob("Dockerfile*"):
            if file_path.is_file():
                analysis["root_dockerfiles"].append({
                    "name": file_path.name,
                    "path": str(file_path),
                    "type": self._classify_dockerfile(file_path.name)
                })
        
        # æƒæ compose æ–‡ä»¶
        for file_path in self.repo_path.glob("docker-compose*"):
            if file_path.is_file():
                analysis["compose_files"].append({
                    "name": file_path.name,
                    "path": str(file_path)
                })
        
        # æƒæ k8s ç›®éŒ„
        k8s_dir = self.repo_path / "k8s"
        if k8s_dir.exists():
            for file_path in k8s_dir.rglob("*.yaml"):
                if file_path.is_file():
                    analysis["k8s_files"].append({
                        "name": file_path.name,
                        "path": str(file_path)
                    })
        
        # æƒæ helm ç›®éŒ„
        helm_dir = self.repo_path / "helm"
        if helm_dir.exists():
            for file_path in helm_dir.rglob("*"):
                if file_path.is_file() and not file_path.name.startswith('.'):
                    analysis["helm_files"].append({
                        "name": file_path.name,
                        "path": str(file_path)
                    })
        
        # æƒæç¾æœ‰ docker å­ç›®éŒ„
        docker_dir = self.repo_path / "docker"
        if docker_dir.exists():
            for file_path in docker_dir.rglob("*"):
                if file_path.is_file():
                    analysis["docker_subdir_files"].append({
                        "name": file_path.name,
                        "path": str(file_path)
                    })
        
        # åŸºæ–¼ aiva_common æŒ‡å—åˆ†ææœå‹™æ˜ å°„
        analysis["service_mapping"] = self._analyze_service_mapping()
        
        return analysis
    
    def _classify_dockerfile(self, filename: str) -> str:
        """æ ¹æ“šæ–‡ä»¶ååˆ†é¡ Dockerfile"""
        name = filename.lower()
        if "core" in name:
            return "core_service"
        elif "component" in name:
            return "component_service"
        elif "patch" in name:
            return "patch_update"
        elif "minimal" in name:
            return "minimal_build"
        else:
            return "generic"
    
    def _analyze_service_mapping(self) -> Dict[str, Any]:
        """åŸºæ–¼ aiva_common æŒ‡å—åˆ†ææœå‹™æ˜ å°„"""
        services_dir = self.repo_path / "services"
        mapping = {
            "core_services": [],
            "feature_components": [],
            "infrastructure_services": [],
            "service_count": 0
        }
        
        if services_dir.exists():
            for service_dir in services_dir.iterdir():
                if service_dir.is_dir() and not service_dir.name.startswith('.'):
                    service_name = service_dir.name
                    mapping["service_count"] += 1
                    
                    if service_name in ["core", "aiva_common"]:
                        mapping["core_services"].append(service_name)
                    elif service_name == "features":
                        mapping["feature_components"].append(service_name)
                        # åˆ†æ features å­æœå‹™
                        features_dir = service_dir
                        if features_dir.exists():
                            for feature_dir in features_dir.iterdir():
                                if feature_dir.is_dir() and not feature_dir.name.startswith('.'):
                                    if feature_dir.name != "common":
                                        mapping["feature_components"].append(f"features/{feature_dir.name}")
                    elif service_name in ["scan", "integration"]:
                        mapping["infrastructure_services"].append(service_name)
        
        return mapping
    
    def create_new_docker_structure(self):
        """å‰µå»ºæ–°çš„ Docker ç›®éŒ„çµæ§‹"""
        new_docker_dir = self.repo_path / "docker"
        
        # å‰µå»ºä¸»ç›®éŒ„çµæ§‹
        for subdir, description in self.organization_plan["docker/"]["subdirs"].items():
            target_dir = new_docker_dir / subdir.rstrip('/')
            target_dir.mkdir(parents=True, exist_ok=True)
            self.log_update("å‰µå»ºç›®éŒ„", f"{target_dir}: {description}")
            
            # å‰µå»º README.md
            readme_content = f"""# {subdir.rstrip('/').title()} Docker é…ç½®

{description}

## æ–‡ä»¶èªªæ˜

æ­¤ç›®éŒ„åŒ…å« {description.lower()} çš„ç›¸é—œé…ç½®æ–‡ä»¶ã€‚

## ä½¿ç”¨æ–¹å¼

```bash
# å»ºæ§‹æ˜ åƒ
docker build -f {subdir}Dockerfile.xxx .

# ä½¿ç”¨ docker-compose
docker-compose -f {subdir}docker-compose.xxx.yml up
```

---
Created: {datetime.now().strftime('%Y-%m-%d')}
Last Modified: {datetime.now().strftime('%Y-%m-%d')}
"""
            readme_path = target_dir / "README.md"
            readme_path.write_text(readme_content, encoding='utf-8')
    
    def reorganize_docker_files(self):
        """é‡çµ„ Docker æ–‡ä»¶"""
        analysis = self.analyze_current_docker_structure()
        new_docker_dir = self.repo_path / "docker"
        
        # ç§»å‹• Dockerfile æ–‡ä»¶
        for dockerfile in analysis["root_dockerfiles"]:
            source_path = Path(dockerfile["path"])
            
            if dockerfile["type"] == "core_service":
                target_dir = new_docker_dir / "core"
            elif dockerfile["type"] == "component_service":
                target_dir = new_docker_dir / "components"
            elif dockerfile["type"] in ["patch_update", "minimal_build"]:
                target_dir = new_docker_dir / "core"  # æ ¸å¿ƒæœå‹™çš„è®Šé«”
            else:
                target_dir = new_docker_dir / "infrastructure"
            
            target_path = target_dir / source_path.name
            if source_path.exists():
                shutil.move(str(source_path), str(target_path))
                self.log_update("ç§»å‹•æ–‡ä»¶", f"{source_path.name} â†’ {target_path}")
        
        # ç§»å‹• docker-compose æ–‡ä»¶
        compose_dir = new_docker_dir / "compose"
        for compose_file in analysis["compose_files"]:
            source_path = Path(compose_file["path"])
            target_path = compose_dir / source_path.name
            if source_path.exists():
                shutil.move(str(source_path), str(target_path))
                self.log_update("ç§»å‹•æ–‡ä»¶", f"{source_path.name} â†’ {target_path}")
        
        # ç§»å‹• k8s æ–‡ä»¶
        if analysis["k8s_files"]:
            k8s_target_dir = new_docker_dir / "k8s"
            k8s_source_dir = self.repo_path / "k8s"
            if k8s_source_dir.exists():
                # å¦‚æœç›®æ¨™ç›®éŒ„å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤
                if k8s_target_dir.exists():
                    shutil.rmtree(k8s_target_dir)
                shutil.move(str(k8s_source_dir), str(k8s_target_dir))
                self.log_update("ç§»å‹•ç›®éŒ„", f"k8s/ â†’ docker/k8s/")
        
        # ç§»å‹• helm æ–‡ä»¶
        if analysis["helm_files"]:
            helm_target_dir = new_docker_dir / "helm"
            helm_source_dir = self.repo_path / "helm"
            if helm_source_dir.exists():
                # å¦‚æœç›®æ¨™ç›®éŒ„å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤
                if helm_target_dir.exists():
                    shutil.rmtree(helm_target_dir)
                shutil.move(str(helm_source_dir), str(helm_target_dir))
                self.log_update("ç§»å‹•ç›®éŒ„", f"helm/ â†’ docker/helm/")
        
        # åˆä½µç¾æœ‰ docker/ ç›®éŒ„å…§å®¹
        old_docker_dir = self.repo_path / "docker_old"
        current_docker_dir = self.repo_path / "docker"
        
        if analysis["docker_subdir_files"]:
            # æš«æ™‚é‡å‘½åç¾æœ‰ docker ç›®éŒ„
            if current_docker_dir.exists():
                current_docker_dir.rename(old_docker_dir)
                self.log_update("æš«å­˜ç›®éŒ„", "æš«æ™‚é‡å‘½åç¾æœ‰ docker/ ç‚º docker_old/")
            
            # é‡æ–°å‰µå»ºçµæ§‹
            self.create_new_docker_structure()
            
            # åˆä½µèˆŠæ–‡ä»¶
            if old_docker_dir.exists():
                for file_info in analysis["docker_subdir_files"]:
                    source_path = Path(file_info["path"].replace("docker/", "docker_old/"))
                    
                    # æ ¹æ“šæ–‡ä»¶é¡å‹æ±ºå®šç›®æ¨™ä½ç½®
                    if "compose" in file_info["name"]:
                        target_dir = new_docker_dir / "compose"
                    elif file_info["name"].endswith(('.yaml', '.yml')):
                        target_dir = new_docker_dir / "k8s"
                    else:
                        target_dir = new_docker_dir / "infrastructure"
                    
                    target_path = target_dir / file_info["name"]
                    if source_path.exists():
                        shutil.copy2(str(source_path), str(target_path))
                        self.log_update("åˆä½µæ–‡ä»¶", f"{source_path} â†’ {target_path}")
                
                # æ¸…ç†èˆŠç›®éŒ„
                shutil.rmtree(old_docker_dir)
                self.log_update("æ¸…ç†ç›®éŒ„", "ç§»é™¤ docker_old/ ç›®éŒ„")
    
    def update_documentation(self):
        """æ›´æ–°ç›¸é—œæ–‡æª”"""
        # æ›´æ–°ä¸» README
        self._update_main_readme()
        
        # å‰µå»º Docker ä½¿ç”¨æŒ‡å—
        self._create_docker_guide()
        
        # æ›´æ–° aiva_common ç›¸é—œæ–‡æª”
        self._update_aiva_common_references()
    
    def _update_main_readme(self):
        """æ›´æ–°ä¸» README ä¸­çš„ Docker èªªæ˜"""
        main_readme = self.repo_path / "README.md"
        if main_readme.exists():
            content = main_readme.read_text(encoding='utf-8')
            
            # æ·»åŠ  Docker çµæ§‹èªªæ˜
            docker_section = """
## ğŸ³ Docker åŸºç¤è¨­æ–½

AIVA æ¡ç”¨çµ±ä¸€çš„ Docker åŸºç¤è¨­æ–½ç®¡ç†ï¼Œæ‰€æœ‰å®¹å™¨åŒ–é…ç½®ä½æ–¼ `docker/` ç›®éŒ„ï¼š

```
docker/
â”œâ”€â”€ core/                    # æ ¸å¿ƒæœå‹™å®¹å™¨
â”‚   â”œâ”€â”€ Dockerfile.core      # æ ¸å¿ƒ AI æœå‹™
â”‚   â”œâ”€â”€ Dockerfile.core.minimal
â”‚   â””â”€â”€ Dockerfile.patch
â”œâ”€â”€ components/              # åŠŸèƒ½çµ„ä»¶å®¹å™¨
â”‚   â””â”€â”€ Dockerfile.component
â”œâ”€â”€ infrastructure/          # åŸºç¤è¨­æ–½æœå‹™
â”œâ”€â”€ compose/                 # Docker Compose é…ç½®
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ docker-compose.production.yml
â”œâ”€â”€ k8s/                     # Kubernetes é…ç½®
â”‚   â”œâ”€â”€ 00-namespace.yaml
â”‚   â”œâ”€â”€ 01-configmap.yaml
â”‚   â”œâ”€â”€ 02-storage.yaml
â”‚   â”œâ”€â”€ 10-core-deployment.yaml
â”‚   â””â”€â”€ 20-components-jobs.yaml
â””â”€â”€ helm/                    # Helm Charts
    â””â”€â”€ aiva/
```

### å¿«é€Ÿå•Ÿå‹•

```bash
# å•Ÿå‹•å®Œæ•´ç³»çµ±
docker-compose -f docker/compose/docker-compose.yml up -d

# åªå•Ÿå‹•æ ¸å¿ƒæœå‹™
docker-compose -f docker/compose/docker-compose.yml up -d aiva-core

# Kubernetes éƒ¨ç½²
kubectl apply -f docker/k8s/
```

"""
            
            # å¦‚æœæ²’æœ‰ Docker ç« ç¯€ï¼Œæ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾
            if "Docker åŸºç¤è¨­æ–½" not in content:
                content += docker_section
                main_readme.write_text(content, encoding='utf-8')
                self.log_update("æ›´æ–°æ–‡æª”", "ä¸» README.md æ·»åŠ  Docker ç« ç¯€")
    
    def _create_docker_guide(self):
        """å‰µå»ºè©³ç´°çš„ Docker ä½¿ç”¨æŒ‡å—"""
        guide_content = f"""---
Created: {datetime.now().strftime('%Y-%m-%d')}
Last Modified: {datetime.now().strftime('%Y-%m-%d')}
Document Type: Docker åŸºç¤è¨­æ–½æŒ‡å—
---

# AIVA Docker åŸºç¤è¨­æ–½ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—åŸºæ–¼ Docker åŸºç¤è¨­æ–½åˆ†æå ±å‘Šå’Œ aiva_common æ¨™æº–ç·¨å¯«ã€‚

## ğŸ“Š ç•¶å‰ç‹€æ…‹

- **Docker æ–‡ä»¶ç¸½æ•¸**: {self.current_state['total_docker_files']}
- **è¤‡é›œåº¦è©•åˆ†**: {self.current_state['complexity_score']}/100
- **å¢é•·é æ¸¬**: {self.current_state['growth_prediction']}
- **é‡çµ„ç‹€æ…‹**: âœ… å·²å®Œæˆ

## ğŸ—ï¸ æ¶æ§‹æ¦‚è¦½

AIVA æ¡ç”¨å¾®æœå‹™æ¶æ§‹ï¼ŒåŸºæ–¼ä»¥ä¸‹å®¹å™¨åŒ–ç­–ç•¥ï¼š

### æ ¸å¿ƒæœå‹™ (æ°¸é é‹è¡Œ)
- **aiva-core**: æ ¸å¿ƒ AI æœå‹™ï¼ŒåŒ…å«å°è©±åŠ©ç†ã€ç¶“é©—ç®¡ç†å™¨
- **åŸºç¤è¨­æ–½**: PostgreSQL, Redis, RabbitMQ, Neo4j

### åŠŸèƒ½çµ„ä»¶ (æŒ‰éœ€å•Ÿå‹•)
- **22å€‹åŠŸèƒ½çµ„ä»¶**: å„ç¨®æƒæå™¨ã€æ¸¬è©¦å·¥å…·ã€åˆ†æå™¨
- **å‹•æ…‹èª¿åº¦**: æ ¹æ“šä»»å‹™éœ€æ±‚å•Ÿå‹•ç›¸æ‡‰çµ„ä»¶

## ğŸ“ ç›®éŒ„çµæ§‹èªªæ˜

```
docker/
â”œâ”€â”€ core/                    # æ ¸å¿ƒæœå‹™å®¹å™¨é…ç½®
â”‚   â”œâ”€â”€ Dockerfile.core      # ä¸»è¦æ ¸å¿ƒæœå‹™
â”‚   â”œâ”€â”€ Dockerfile.core.minimal  # æœ€å°åŒ–ç‰ˆæœ¬
â”‚   â””â”€â”€ Dockerfile.patch     # å¢é‡æ›´æ–°ç‰ˆæœ¬
â”‚
â”œâ”€â”€ components/              # åŠŸèƒ½çµ„ä»¶å®¹å™¨é…ç½®
â”‚   â””â”€â”€ Dockerfile.component # é€šç”¨çµ„ä»¶å®¹å™¨
â”‚
â”œâ”€â”€ infrastructure/          # åŸºç¤è¨­æ–½æœå‹™é…ç½®
â”‚   â””â”€â”€ (æœªä¾†æ“´å±•ç”¨)
â”‚
â”œâ”€â”€ compose/                 # Docker Compose é…ç½®
â”‚   â”œâ”€â”€ docker-compose.yml  # ä¸»è¦é…ç½®
â”‚   â””â”€â”€ docker-compose.production.yml  # ç”Ÿç”¢ç’°å¢ƒé…ç½®
â”‚
â”œâ”€â”€ k8s/                     # Kubernetes éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ 00-namespace.yaml   # å‘½åç©ºé–“
â”‚   â”œâ”€â”€ 01-configmap.yaml   # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ 02-storage.yaml     # å­˜å„²é…ç½®
â”‚   â”œâ”€â”€ 10-core-deployment.yaml     # æ ¸å¿ƒæœå‹™éƒ¨ç½²
â”‚   â””â”€â”€ 20-components-jobs.yaml     # çµ„ä»¶ä»»å‹™é…ç½®
â”‚
â””â”€â”€ helm/                    # Helm Charts
    â””â”€â”€ aive/
        â”œâ”€â”€ Chart.yaml
        â””â”€â”€ values.yaml
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### é–‹ç™¼ç’°å¢ƒ

```bash
# å•Ÿå‹•å®Œæ•´é–‹ç™¼ç’°å¢ƒ
docker-compose -f docker/compose/docker-compose.yml up -d

# åªå•Ÿå‹•åŸºç¤è¨­æ–½
docker-compose -f docker/compose/docker-compose.yml up -d postgres redis rabbitmq neo4j

# å•Ÿå‹•æ ¸å¿ƒæœå‹™
docker-compose -f docker/compose/docker-compose.yml up -d aiva-core

# æŸ¥çœ‹æœå‹™ç‹€æ…‹
docker-compose -f docker/compose/docker-compose.yml ps
```

### ç”Ÿç”¢ç’°å¢ƒ

```bash
# ä½¿ç”¨ç”Ÿç”¢é…ç½®
docker-compose -f docker/compose/docker-compose.production.yml up -d

# Kubernetes éƒ¨ç½²
kubectl apply -f docker/k8s/

# Helm éƒ¨ç½²
helm install aiva docker/helm/aiva/
```

### å–®ç¨æ§‹å»ºæ˜ åƒ

```bash
# æ§‹å»ºæ ¸å¿ƒæœå‹™
docker build -f docker/core/Dockerfile.core -t aiva-core:latest .

# æ§‹å»ºåŠŸèƒ½çµ„ä»¶
docker build -f docker/components/Dockerfile.component -t aiva-component:latest .

# æ§‹å»ºæœ€å°åŒ–ç‰ˆæœ¬
docker build -f docker/core/Dockerfile.core.minimal -t aiva-core:minimal .
```

## ğŸ”§ é…ç½®èªªæ˜

### ç’°å¢ƒè®Šé‡

æ ¸å¿ƒæœå‹™æ”¯æ´ä»¥ä¸‹ç’°å¢ƒè®Šé‡é…ç½®ï¼š

```bash
# æ¨¡å¼é…ç½®
ENVIRONMENT=docker

# æ•¸æ“šåº«é…ç½® (ä½¿ç”¨å–®ä¸€ DATABASE_URL)
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aiva_db

# RabbitMQ é…ç½® (ä½¿ç”¨å–®ä¸€ RABBITMQ_URL)
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
```

### ç«¯å£æ˜ å°„

| æœå‹™ | å…§éƒ¨ç«¯å£ | å¤–éƒ¨ç«¯å£ | èªªæ˜ |
|------|---------|---------|------|
| AIVA Core | 8000 | 8000 | ä¸» API |
| AIVA Core | 8001 | 8001 | ç®¡ç† API |
| AIVA Core | 8002 | 8002 | WebSocket |
| PostgreSQL | 5432 | 5432 | æ•¸æ“šåº« |
| Redis | 6379 | 6379 | ç·©å­˜ |
| RabbitMQ | 5672 | 5672 | æ¶ˆæ¯éšŠåˆ— |
| RabbitMQ UI | 15672 | 15672 | ç®¡ç†ç•Œé¢ |
| Neo4j | 7687 | 7687 | åœ–æ•¸æ“šåº« |
| Neo4j UI | 7474 | 7474 | ç®¡ç†ç•Œé¢ |

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **å®¹å™¨å•Ÿå‹•å¤±æ•—**
   ```bash
   # æª¢æŸ¥æ—¥èªŒ
   docker-compose -f docker/compose/docker-compose.yml logs aiva-core
   
   # æª¢æŸ¥è³‡æºä½¿ç”¨
   docker stats
   ```

2. **æœå‹™é€£æ¥å•é¡Œ**
   ```bash
   # æª¢æŸ¥ç¶²çµ¡é€£é€šæ€§
   docker-compose -f docker/compose/docker-compose.yml exec aiva-core ping postgres
   
   # æª¢æŸ¥ç«¯å£
   docker-compose -f docker/compose/docker-compose.yml port aiva-core 8000
   ```

3. **æ•¸æ“šæŒä¹…åŒ–å•é¡Œ**
   ```bash
   # æª¢æŸ¥æ•¸æ“šå·
   docker volume ls
   docker volume inspect aiva-git_postgres-data
   ```

### æ€§èƒ½å„ªåŒ–

1. **è³‡æºé™åˆ¶**
   - æ ¸å¿ƒæœå‹™: 2GB RAM, 1 CPU
   - åŠŸèƒ½çµ„ä»¶: 1GB RAM, 0.5 CPU
   - åŸºç¤è¨­æ–½: æ ¹æ“šè² è¼‰èª¿æ•´

2. **ç¶²çµ¡å„ªåŒ–**
   - ä½¿ç”¨å…§éƒ¨ç¶²çµ¡é€šä¿¡
   - å•Ÿç”¨é€£æ¥æ± 
   - é…ç½®å¥åº·æª¢æŸ¥

## ğŸ“š ç›¸é—œæ–‡æª”

- [AIVA æ¶æ§‹æ–‡æª”](../reports/architecture/ARCHITECTURE_SUMMARY.md)
- [Docker åŸºç¤è¨­æ–½åˆ†æå ±å‘Š](../docker_infrastructure_analysis_20251030_113318.md)
- [aiva_common é–‹ç™¼æŒ‡å—](../services/aiva_common/README.md)

## ğŸ”„ ç‰ˆæœ¬è¨˜éŒ„

- **2025-10-30**: åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºæ–¼åŸºç¤è¨­æ–½åˆ†æå ±å‘Šå‰µå»º
- **æœªä¾†è¨ˆåŠƒ**: æ”¯æ´æ›´å¤šéƒ¨ç½²æ¨¡å¼ï¼Œå„ªåŒ–å®¹å™¨å¤§å°

---

*æœ€å¾Œæ›´æ–°: {datetime.now().isoformat()}*
"""
        
        guide_path = self.repo_path / "docker" / "DOCKER_GUIDE.md"
        guide_path.write_text(guide_content, encoding='utf-8')
        self.log_update("å‰µå»ºæ–‡æª”", f"Docker ä½¿ç”¨æŒ‡å—: {guide_path}")
    
    def _update_aiva_common_references(self):
        """æ›´æ–° aiva_common ä¸­çš„ Docker ç›¸é—œå¼•ç”¨"""
        # æ›´æ–° continuous_components_sot.json ä¸­çš„ Docker é…ç½®
        sot_file = self.repo_path / "services" / "aiva_common" / "continuous_components_sot.json"
        if sot_file.exists():
            try:
                with open(sot_file, 'r', encoding='utf-8') as f:
                    sot_data = json.load(f)
                
                # æ›´æ–° Docker æ•´åˆé…ç½®
                if "integration_points" in sot_data and "docker_integration" in sot_data["integration_points"]:
                    docker_config = sot_data["integration_points"]["docker_integration"]
                    docker_config.update({
                        "enabled": True,
                        "docker_socket": "/var/run/docker.sock",
                        "container_health_check": True,
                        "auto_container_restart": True,
                        "config_directory": "docker/",
                        "compose_files": {
                            "development": "docker/compose/docker-compose.yml",
                            "production": "docker/compose/docker-compose.production.yml"
                        },
                        "k8s_directory": "docker/k8s/",
                        "helm_chart": "docker/helm/aiva/"
                    })
                
                # ä¿å­˜æ›´æ–°
                with open(sot_file, 'w', encoding='utf-8') as f:
                    json.dump(sot_data, f, indent=2, ensure_ascii=False)
                
                self.log_update("æ›´æ–°é…ç½®", "aiva_common Docker æ•´åˆé…ç½®å·²æ›´æ–°")
                
            except Exception as e:
                self.log_update("æ›´æ–°é…ç½®", f"æ›´æ–° aiva_common é…ç½®å¤±æ•—: {e}", False)
    
    def validate_new_structure(self) -> Dict[str, Any]:
        """é©—è­‰æ–°çš„ç›®éŒ„çµæ§‹"""
        docker_dir = self.repo_path / "docker"
        validation = {
            "structure_exists": docker_dir.exists(),
            "subdirs_created": {},
            "files_moved": {},
            "documentation_created": {},
            "issues": []
        }
        
        # æª¢æŸ¥å­ç›®éŒ„
        for subdir in self.organization_plan["docker/"]["subdirs"].keys():
            subdir_path = docker_dir / subdir.rstrip('/')
            validation["subdirs_created"][subdir] = subdir_path.exists()
            
            if not subdir_path.exists():
                validation["issues"].append(f"ç¼ºå°‘ç›®éŒ„: {subdir}")
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æ­£ç¢ºç§»å‹•
        expected_files = {
            "core/": ["Dockerfile.core", "Dockerfile.core.minimal", "Dockerfile.patch"],
            "components/": ["Dockerfile.component"],
            "compose/": ["docker-compose.yml", "docker-compose.production.yml"],
            "k8s/": ["00-namespace.yaml", "01-configmap.yaml", "02-storage.yaml", 
                    "10-core-deployment.yaml", "20-components-jobs.yaml"],
            "helm/": ["aiva/Chart.yaml", "aiva/values.yaml"]
        }
        
        for subdir, files in expected_files.items():
            subdir_path = docker_dir / subdir.rstrip('/')
            validation["files_moved"][subdir] = []
            
            for file_name in files:
                file_path = subdir_path / file_name
                if file_path.exists():
                    validation["files_moved"][subdir].append(file_name)
                else:
                    validation["issues"].append(f"ç¼ºå°‘æ–‡ä»¶: {subdir}{file_name}")
        
        # æª¢æŸ¥æ–‡æª”
        docs_to_check = ["DOCKER_GUIDE.md", "README.md"]
        for doc in docs_to_check:
            doc_path = docker_dir / doc
            validation["documentation_created"][doc] = doc_path.exists()
            
            if not doc_path.exists():
                validation["issues"].append(f"ç¼ºå°‘æ–‡æª”: {doc}")
        
        return validation
    
    def generate_update_report(self) -> str:
        """ç”Ÿæˆæ›´æ–°å ±å‘Š"""
        validation = self.validate_new_structure()
        
        report_lines = [
            "# AIVA Docker åŸºç¤è¨­æ–½æ›´æ–°å ±å‘Š",
            "",
            f"**æ›´æ–°æ™‚é–“**: {datetime.now().isoformat()}",
            f"**æ›´æ–°è·¯å¾‘**: {self.repo_path}",
            "",
            "## ğŸ“Š æ›´æ–°æ¦‚è¦½",
            "",
            f"- **åŸå§‹ç‹€æ…‹**: {self.current_state['total_docker_files']} å€‹æ–‡ä»¶æ•£å¸ƒåœ¨æ ¹ç›®éŒ„",
            f"- **è¤‡é›œåº¦è©•åˆ†**: {self.current_state['complexity_score']}/100",
            f"- **æ›´æ–°æ“ä½œæ•¸**: {len(self.update_log)}",
            f"- **å‚™ä»½ä½ç½®**: {self.backup_dir}",
            "",
            "## ğŸ—ï¸ æ–°ç›®éŒ„çµæ§‹",
            "",
            "```",
            "docker/",
        ]
        
        # æ·»åŠ ç›®éŒ„çµæ§‹
        for subdir, description in self.organization_plan["docker/"]["subdirs"].items():
            status = "âœ…" if validation["subdirs_created"].get(subdir, False) else "âŒ"
            report_lines.append(f"â”œâ”€â”€ {subdir:<20} {status} {description}")
        
        report_lines.extend([
            "```",
            "",
            "## ğŸ“ æ–‡ä»¶ç§»å‹•çµæœ",
            ""
        ])
        
        # æ·»åŠ æ–‡ä»¶ç§»å‹•çµæœ
        for subdir, files in validation["files_moved"].items():
            if files:
                report_lines.append(f"### {subdir}")
                for file_name in files:
                    report_lines.append(f"- âœ… {file_name}")
                report_lines.append("")
        
        # æ·»åŠ æ“ä½œæ—¥èªŒ
        report_lines.extend([
            "## ğŸ“ æ›´æ–°æ“ä½œæ—¥èªŒ",
            ""
        ])
        
        for log_entry in self.update_log:
            status = "âœ…" if log_entry["success"] else "âŒ"
            timestamp = datetime.fromisoformat(log_entry["timestamp"]).strftime("%H:%M:%S")
            report_lines.append(f"- {status} **{timestamp}** {log_entry['operation']}: {log_entry['details']}")
        
        # æ·»åŠ é©—è­‰çµæœ
        report_lines.extend([
            "",
            "## ğŸ” é©—è­‰çµæœ",
            ""
        ])
        
        if validation["issues"]:
            report_lines.extend([
                "### âš ï¸ ç™¼ç¾çš„å•é¡Œ",
                ""
            ])
            for issue in validation["issues"]:
                report_lines.append(f"- âš ï¸ {issue}")
        else:
            report_lines.append("âœ… **æ‰€æœ‰é©—è­‰é€šéï¼Œç„¡ç™¼ç¾å•é¡Œ**")
        
        # æ·»åŠ å¾ŒçºŒå»ºè­°
        report_lines.extend([
            "",
            "## ğŸ’¡ å¾ŒçºŒå»ºè­°",
            "",
            "1. **æ¸¬è©¦æ–°çµæ§‹**",
            "   ```bash",
            "   # æ¸¬è©¦ Docker Compose",
            "   docker-compose -f docker/compose/docker-compose.yml config",
            "   ",
            "   # æ¸¬è©¦ Kubernetes é…ç½®",
            "   kubectl apply --dry-run=client -f docker/k8s/",
            "   ```",
            "",
            "2. **æ›´æ–° CI/CD ç®¡é“**",
            "   - æ›´æ–°æ§‹å»ºè…³æœ¬ä¸­çš„ Dockerfile è·¯å¾‘",
            "   - æ›´æ–°éƒ¨ç½²è…³æœ¬ä¸­çš„ docker-compose è·¯å¾‘",
            "",
            "3. **åœ˜éšŠé€šçŸ¥**",
            "   - é€šçŸ¥é–‹ç™¼åœ˜éšŠæ–°çš„ç›®éŒ„çµæ§‹",
            "   - æ›´æ–°é–‹ç™¼æ–‡æª”å’Œ README",
            "",
            "4. **æ¸…ç†å·¥ä½œ**",
            f"   - ç¢ºèªæ–°çµæ§‹æ­£å¸¸é‹è¡Œå¾Œï¼Œå¯åˆªé™¤å‚™ä»½: `{self.backup_dir}`",
            "",
            "## ğŸ“š ç›¸é—œæ–‡æª”",
            "",
            "- [Docker ä½¿ç”¨æŒ‡å—](docker/DOCKER_GUIDE.md)",
            "- [Docker åŸºç¤è¨­æ–½åˆ†æå ±å‘Š](docker_infrastructure_analysis_20251030_113318.md)",
            "- [aiva_common README](services/aiva_common/README.md)",
            "",
            f"---",
            f"*å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().isoformat()}*"
        ])
        
        return "\n".join(report_lines)
    
    def save_update_report(self, output_file: Optional[str] = None) -> str:
        """ä¿å­˜æ›´æ–°å ±å‘Š"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"docker_infrastructure_update_report_{timestamp}.md"
        
        output_path = self.repo_path / output_file
        
        # ç”Ÿæˆå ±å‘Šå…§å®¹
        report_content = self.generate_update_report()
        
        # æ·»åŠ æ™‚é–“æˆ³æ¨™é ­
        timestamped_content = f"""---
Created: {datetime.now().strftime("%Y-%m-%d")}
Last Modified: {datetime.now().strftime("%Y-%m-%d")}
Document Type: Docker Infrastructure Update Report
---

{report_content}
"""
        
        # ä¿å­˜å ±å‘Š
        output_path.write_text(timestamped_content, encoding='utf-8')
        
        return str(output_path)
    
    def run_full_update(self) -> str:
        """åŸ·è¡Œå®Œæ•´çš„ Docker åŸºç¤è¨­æ–½æ›´æ–°"""
        print("ğŸ”§ é–‹å§‹ Docker åŸºç¤è¨­æ–½æ›´æ–°...")
        
        try:
            # 1. å‰µå»ºå‚™ä»½
            print("ğŸ’¾ å‰µå»ºå‚™ä»½...")
            self.create_backup()
            
            # 2. åˆ†æç•¶å‰çµæ§‹
            print("ğŸ” åˆ†æç•¶å‰çµæ§‹...")
            analysis = self.analyze_current_docker_structure()
            print(f"   ç™¼ç¾ {len(analysis['root_dockerfiles'])} å€‹ Dockerfile")
            print(f"   ç™¼ç¾ {len(analysis['compose_files'])} å€‹ Compose æ–‡ä»¶")
            
            # 3. å‰µå»ºæ–°ç›®éŒ„çµæ§‹
            print("ğŸ—ï¸ å‰µå»ºæ–°ç›®éŒ„çµæ§‹...")
            self.create_new_docker_structure()
            
            # 4. é‡çµ„ Docker æ–‡ä»¶
            print("ğŸ“ é‡çµ„ Docker æ–‡ä»¶...")
            self.reorganize_docker_files()
            
            # 5. æ›´æ–°æ–‡æª”
            print("ğŸ“š æ›´æ–°ç›¸é—œæ–‡æª”...")
            self.update_documentation()
            
            # 6. é©—è­‰çµæœ
            print("ğŸ” é©—è­‰æ–°çµæ§‹...")
            validation = self.validate_new_structure()
            
            if validation["issues"]:
                print(f"âš ï¸ ç™¼ç¾ {len(validation['issues'])} å€‹å•é¡Œ")
                for issue in validation["issues"]:
                    print(f"   - {issue}")
            else:
                print("âœ… æ‰€æœ‰é©—è­‰é€šé")
            
            # 7. ç”Ÿæˆå ±å‘Š
            print("ğŸ“„ ç”Ÿæˆæ›´æ–°å ±å‘Š...")
            report_path = self.save_update_report()
            
            print(f"âœ… Docker åŸºç¤è¨­æ–½æ›´æ–°å®Œæˆï¼")
            print(f"   - å‚™ä»½ä½ç½®: {self.backup_dir}")
            print(f"   - å ±å‘Šä½ç½®: {report_path}")
            
            return report_path
            
        except Exception as e:
            self.log_update("æ›´æ–°å¤±æ•—", f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}", False)
            print(f"âŒ æ›´æ–°å¤±æ•—: {e}")
            raise

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AIVA Docker åŸºç¤è¨­æ–½æ›´æ–°å·¥å…·")
    parser.add_argument("--repo-path", default=".", help="å°ˆæ¡ˆè·¯å¾‘ (é è¨­: ç•¶å‰ç›®éŒ„)")
    parser.add_argument("--dry-run", action="store_true", help="åƒ…åˆ†æï¼Œä¸åŸ·è¡Œå¯¦éš›æ›´æ–°")
    parser.add_argument("--backup-only", action="store_true", help="åƒ…å‰µå»ºå‚™ä»½")
    
    args = parser.parse_args()
    
    # å‰µå»ºæ›´æ–°å™¨
    updater = DockerInfrastructureUpdater(args.repo_path)
    
    if args.backup_only:
        # åªå‰µå»ºå‚™ä»½
        backup_files = updater.create_backup()
        print(f"âœ… å‚™ä»½å®Œæˆ: {len(backup_files)} å€‹æ–‡ä»¶")
        print(f"   å‚™ä»½ä½ç½®: {updater.backup_dir}")
    elif args.dry_run:
        # åªåˆ†æä¸åŸ·è¡Œ
        print("ğŸ” åŸ·è¡Œåˆ†æï¼ˆä¹¾ç‡¥é‹è¡Œï¼‰...")
        analysis = updater.analyze_current_docker_structure()
        
        print(f"\nğŸ“Š åˆ†æçµæœ:")
        print(f"   - Dockerfile æ•¸é‡: {len(analysis['root_dockerfiles'])}")
        print(f"   - Compose æ–‡ä»¶æ•¸é‡: {len(analysis['compose_files'])}")
        print(f"   - K8s æ–‡ä»¶æ•¸é‡: {len(analysis['k8s_files'])}")
        print(f"   - Helm æ–‡ä»¶æ•¸é‡: {len(analysis['helm_files'])}")
        print(f"   - æœå‹™ç¸½æ•¸: {analysis['service_mapping']['service_count']}")
        
        print(f"\nğŸ’¡ å»ºè­°æ“ä½œ:")
        print(f"   - ç§»å‹• {len(analysis['root_dockerfiles'])} å€‹ Dockerfile åˆ°å°ˆé–€ç›®éŒ„")
        print(f"   - é‡çµ„ {len(analysis['compose_files'])} å€‹ Compose é…ç½®")
        print(f"   - æ•´åˆ K8s å’Œ Helm é…ç½®åˆ°çµ±ä¸€çµæ§‹")
        
        print(f"\nâ–¶ï¸ åŸ·è¡Œå¯¦éš›æ›´æ–°: python {__file__} --repo-path {args.repo_path}")
    else:
        # åŸ·è¡Œå®Œæ•´æ›´æ–°
        report_path = updater.run_full_update()
        print(f"\nğŸ“Š æ›´æ–°æ‘˜è¦:")
        print(f"   - æ“ä½œæ•¸é‡: {len(updater.update_log)}")
        print(f"   - å‚™ä»½ä½ç½®: {updater.backup_dir}")
        print(f"   - å ±å‘Šä½ç½®: {report_path}")

if __name__ == "__main__":
    main()