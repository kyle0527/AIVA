"""
å¢å¼·ç‰ˆé¢¨éšªè©•ä¼°å¼•æ“

æ•´åˆæ¥­å‹™ä¸Šä¸‹æ–‡ã€è³‡ç”¢åƒ¹å€¼ã€åˆè¦è¦æ±‚ç­‰å¤šç¶­åº¦å› ç´ é€²è¡Œé¢¨éšªè©•ä¼°
"""



from typing import Any

from services.aiva_common.utils import get_logger

logger = get_logger(__name__)


class EnhancedRiskAssessmentEngine:
    """
    å¢å¼·ç‰ˆé¢¨éšªè©•ä¼°å¼•æ“

    åŸºæ–¼æ¼æ´ã€ç’°å¢ƒã€æ¥­å‹™å½±éŸ¿ã€è³‡ç”¢åƒ¹å€¼ç­‰å¤šç¶­åº¦å› ç´ 
    é€²è¡Œç¶œåˆé¢¨éšªè©•ä¼°å’Œæ¥­å‹™é©…å‹•çš„å„ªå…ˆç´šæ’åºã€‚

    æ–°å¢åŠŸèƒ½ï¼š
    - æ¥­å‹™é‡è¦æ€§æ·±åº¦æ•´åˆ
    - è³‡æ–™æ•æ„Ÿåº¦è©•ä¼°
    - ç¶²è·¯æš´éœ²åº¦è€ƒé‡
    - åˆè¦é¢¨éšªè©•ä¼°
    - è²¡å‹™å½±éŸ¿ä¼°ç®—
    """

    def __init__(self) -> None:
        # åŸºç¤é¢¨éšªçŸ©é™£
        self._risk_matrix = {
            "critical": {"score": 10, "priority": 1},
            "high": {"score": 7, "priority": 2},
            "medium": {"score": 4, "priority": 3},
            "low": {"score": 1, "priority": 4},
        }

        # ç’°å¢ƒä¹˜æ•¸
        self._environment_multipliers = {
            "production": 2.0,
            "staging": 1.5,
            "development": 1.0,
            "testing": 0.8,
        }

        # æ¥­å‹™é‡è¦æ€§ä¹˜æ•¸
        self._business_criticality_multipliers = {
            "critical": 3.0,  # æ¥­å‹™é—œéµç³»çµ±
            "high": 2.0,  # é‡è¦æ¥­å‹™ç³»çµ±
            "medium": 1.0,  # ä¸€èˆ¬æ¥­å‹™ç³»çµ±
            "low": 0.5,  # éé—œéµç³»çµ±
        }

        # è³‡æ–™æ•æ„Ÿåº¦ä¹˜æ•¸
        self._data_sensitivity_multipliers = {
            "highly_sensitive": 2.5,  # é«˜åº¦æ•æ„Ÿï¼ˆä¿¡ç”¨å¡ã€å¥åº·è³‡æ–™ï¼‰
            "sensitive": 1.8,  # æ•æ„Ÿï¼ˆPIIï¼‰
            "internal": 1.2,  # å…§éƒ¨è³‡æ–™
            "public": 0.8,  # å…¬é–‹è³‡æ–™
        }

        # å¯åˆ©ç”¨æ€§è©•ä¼°ä¹˜æ•¸
        self._exploitability_multipliers = {
            "proven": 2.0,  # å·²æœ‰å…¬é–‹ exploit
            "high": 1.5,  # é«˜åº¦å¯åˆ©ç”¨
            "medium": 1.0,  # ä¸­ç­‰å¯åˆ©ç”¨æ€§
            "low": 0.7,  # ä½å¯åˆ©ç”¨æ€§
            "theoretical": 0.4,  # ç†è«–ä¸Šå¯åˆ©ç”¨
        }

        # è³‡ç”¢ç¶²è·¯æš´éœ²åº¦ä¹˜æ•¸
        self._exposure_multipliers = {
            "internet_facing": 2.0,  # ç›´æ¥æš´éœ²æ–¼äº’è¯ç¶²
            "dmz": 1.5,  # DMZ å€åŸŸ
            "internal_network": 1.0,  # å…§éƒ¨ç¶²è·¯
            "isolated": 0.6,  # éš”é›¢ç¶²è·¯
        }

        # åˆè¦è¦æ±‚æ¨™ç±¤æ¬Šé‡
        self._compliance_weights = {
            "pci-dss": 1.5,
            "hipaa": 1.5,
            "gdpr": 1.4,
            "sox": 1.3,
            "iso27001": 1.2,
        }

    def assess_risk(
        self, findings: list[dict[str, Any]], context: dict[str, Any]
    ) -> dict[str, Any]:
        """
        ç¶œåˆé¢¨éšªè©•ä¼°ï¼ˆå¢å¼·ç‰ˆï¼‰

        Args:
            findings: æ¼æ´ç™¼ç¾åˆ—è¡¨
            context: ç’°å¢ƒä¸Šä¸‹æ–‡è³‡è¨Šï¼Œæ”¯æ´ä»¥ä¸‹æ¬„ä½ï¼š
                - environment: ç’°å¢ƒé¡å‹
                - business_criticality: æ¥­å‹™é‡è¦æ€§
                - data_sensitivity: è³‡æ–™æ•æ„Ÿåº¦
                - asset_exposure: ç¶²è·¯æš´éœ²åº¦
                - compliance_tags: åˆè¦æ¨™ç±¤åˆ—è¡¨
                - asset_value: è³‡ç”¢ä¼°å€¼
                - user_base: ä½¿ç”¨è€…åŸºæ•¸

        Returns:
            é¢¨éšªè©•ä¼°çµæœ
        """
        if not findings:
            return {
                "overall_risk_score": 0,
                "risk_level": "none",
                "total_findings": 0,
                "priority_findings": [],
                "recommendations": ["ç„¡ç™¼ç¾å®‰å…¨æ¼æ´"],
            }

        # æå–ä¸Šä¸‹æ–‡è³‡è¨Š
        environment = context.get("environment", "development").lower()
        business_criticality = context.get("business_criticality", "medium").lower()
        data_sensitivity = context.get("data_sensitivity", "internal").lower()
        asset_exposure = context.get("asset_exposure", "internal_network").lower()
        compliance_tags = context.get("compliance_tags", [])
        asset_value = context.get("asset_value", 0)
        user_base = context.get("user_base", 0)

        # è¨ˆç®—ä¸Šä¸‹æ–‡ä¹˜æ•¸
        env_multiplier = self._environment_multipliers.get(environment, 1.0)
        business_multiplier = self._business_criticality_multipliers.get(
            business_criticality, 1.0
        )
        data_multiplier = self._data_sensitivity_multipliers.get(
            data_sensitivity, 1.0
        )
        exposure_multiplier = self._exposure_multipliers.get(asset_exposure, 1.0)

        # è¨ˆç®—åˆè¦ä¹˜æ•¸
        compliance_multiplier = 1.0
        for tag in compliance_tags:
            tag_lower = tag.lower()
            if tag_lower in self._compliance_weights:
                compliance_multiplier = max(
                    compliance_multiplier, self._compliance_weights[tag_lower]
                )

        # è¨ˆç®—ç¸½é«”ä¸Šä¸‹æ–‡ä¹˜æ•¸ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        context_multiplier = (
            env_multiplier * 0.3
            + business_multiplier * 0.25
            + data_multiplier * 0.2
            + exposure_multiplier * 0.15
            + compliance_multiplier * 0.1
        )

        logger.info(
            f"Context multipliers - Env: {env_multiplier}, Business: {business_multiplier}, "
            f"Data: {data_multiplier}, Exposure: {exposure_multiplier}, "
            f"Compliance: {compliance_multiplier}, Total: {context_multiplier:.2f}"
        )

        # è¨ˆç®—é¢¨éšªåˆ†æ•¸
        total_risk_score = 0.0
        business_risk_score = 0.0
        technical_risk_score = 0.0
        priority_findings = []
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}

        for finding in findings:
            severity = finding.get("severity", "low").lower()
            if severity not in self._risk_matrix:
                severity = "low"

            # åŸºç¤æŠ€è¡“é¢¨éšªåˆ†æ•¸
            base_score = self._risk_matrix[severity]["score"]
            technical_risk_score += base_score

            # å¯åˆ©ç”¨æ€§è©•ä¼°
            exploitability = finding.get("exploitability", "medium").lower()
            exploit_multiplier = self._exploitability_multipliers.get(
                exploitability, 1.0
            )

            # è¨ˆç®—èª¿æ•´å¾Œçš„æŠ€è¡“åˆ†æ•¸
            adjusted_tech_score = base_score * exploit_multiplier

            # è¨ˆç®—æ¥­å‹™é¢¨éšªåˆ†æ•¸
            adjusted_business_score = adjusted_tech_score * context_multiplier

            # é¡å¤–è€ƒæ…®ï¼šè³‡ç”¢åƒ¹å€¼æˆ–ä½¿ç”¨è€…åŸºæ•¸
            if asset_value > 0 or user_base > 0:
                impact_factor = self._calculate_business_impact_factor(
                    asset_value, user_base
                )
                adjusted_business_score *= impact_factor

            # è¨˜éŒ„è¨ˆç®—å¾Œçš„åˆ†æ•¸
            finding["calculated_technical_risk_score"] = round(adjusted_tech_score, 2)
            finding["calculated_business_risk_score"] = round(
                adjusted_business_score, 2
            )
            finding["context_multiplier"] = round(context_multiplier, 2)

            total_risk_score += adjusted_business_score
            business_risk_score += adjusted_business_score
            severity_counts[severity] += 1

            # æ”¶é›†é«˜å„ªå…ˆç´šç™¼ç¾
            if severity in ["critical", "high"] or adjusted_business_score >= 15:
                priority_findings.append(finding)

        # æŒ‰æ¥­å‹™é¢¨éšªåˆ†æ•¸æ’åº
        priority_findings.sort(
            key=lambda x: x.get("calculated_business_risk_score", 0), reverse=True
        )

        # ç¢ºå®šæ•´é«”é¢¨éšªç­‰ç´š
        avg_business_risk = business_risk_score / len(findings)
        overall_risk_level = self._determine_risk_level_enhanced(
            avg_business_risk, business_criticality, environment
        )

        # ç”Ÿæˆå¢å¼·çš„å»ºè­°
        recommendations = self._generate_enhanced_recommendations(
            severity_counts=severity_counts,
            overall_risk_level=overall_risk_level,
            business_criticality=business_criticality,
            environment=environment,
            compliance_tags=compliance_tags,
            priority_findings=priority_findings,
        )

        # è¨ˆç®—æ¥­å‹™å½±éŸ¿ä¼°ç®—
        business_impact = self._estimate_business_impact(
            severity_counts=severity_counts,
            asset_value=asset_value,
            user_base=user_base,
            business_criticality=business_criticality,
        )

        result = {
            "overall_risk_score": round(total_risk_score, 2),
            "average_risk_score": round(total_risk_score / len(findings), 2),
            "technical_risk_score": round(technical_risk_score, 2),
            "business_risk_score": round(business_risk_score, 2),
            "risk_level": overall_risk_level,
            "context": {
                "environment": environment,
                "environment_multiplier": env_multiplier,
                "business_criticality": business_criticality,
                "business_multiplier": business_multiplier,
                "data_sensitivity": data_sensitivity,
                "data_multiplier": data_multiplier,
                "asset_exposure": asset_exposure,
                "exposure_multiplier": exposure_multiplier,
                "compliance_tags": compliance_tags,
                "compliance_multiplier": compliance_multiplier,
                "total_context_multiplier": round(context_multiplier, 2),
            },
            "total_findings": len(findings),
            "severity_breakdown": severity_counts,
            "priority_findings": priority_findings[:10],
            "recommendations": recommendations,
            "business_impact": business_impact,
            "risk_trend": self._calculate_risk_trend(findings),
        }

        logger.info(
            f"Risk assessment completed: {len(findings)} findings, "
            f"business risk level: {overall_risk_level}, "
            f"business risk score: {business_risk_score:.2f}"
        )
        return result

    def _calculate_business_impact_factor(
        self, asset_value: float, user_base: int
    ) -> float:
        """
        è¨ˆç®—æ¥­å‹™å½±éŸ¿å› å­

        åŸºæ–¼è³‡ç”¢åƒ¹å€¼å’Œä½¿ç”¨è€…åŸºæ•¸è©•ä¼°æ½›åœ¨çš„æ¥­å‹™å½±éŸ¿
        """
        impact_factor = 1.0

        # è³‡ç”¢åƒ¹å€¼å½±éŸ¿
        if asset_value > 0:
            if asset_value >= 10_000_000:  # $10M+
                impact_factor += 0.5
            elif asset_value >= 1_000_000:  # $1M+
                impact_factor += 0.3
            elif asset_value >= 100_000:  # $100K+
                impact_factor += 0.2

        # ä½¿ç”¨è€…åŸºæ•¸å½±éŸ¿
        if user_base > 0:
            if user_base >= 1_000_000:  # 1M+ users
                impact_factor += 0.4
            elif user_base >= 100_000:  # 100K+ users
                impact_factor += 0.3
            elif user_base >= 10_000:  # 10K+ users
                impact_factor += 0.2

        return min(impact_factor, 2.5)  # ä¸Šé™ 2.5x

    def _determine_risk_level_enhanced(
        self, avg_score: float, business_criticality: str, environment: str
    ) -> str:
        """
        å¢å¼·ç‰ˆé¢¨éšªç­‰ç´šåˆ¤å®š

        è€ƒæ…®æ¥­å‹™é‡è¦æ€§å’Œç’°å¢ƒå› ç´ 
        """
        # åŸºç¤åˆ¤å®š
        if avg_score >= 15:
            base_level = "critical"
        elif avg_score >= 10:
            base_level = "high"
        elif avg_score >= 5:
            base_level = "medium"
        else:
            base_level = "low"

        # æ ¹æ“šæ¥­å‹™é‡è¦æ€§å’Œç’°å¢ƒæå‡é¢¨éšªç­‰ç´š
        if business_criticality == "critical" and environment == "production":
            # é—œéµæ¥­å‹™çš„ç”Ÿç”¢ç’°å¢ƒï¼Œæå‡ä¸€ç´š
            level_order = ["low", "medium", "high", "critical"]
            current_index = level_order.index(base_level)
            if current_index < len(level_order) - 1:
                return level_order[current_index + 1]

        return base_level

    def _generate_enhanced_recommendations(
        self,
        severity_counts: dict[str, int],
        overall_risk_level: str,
        business_criticality: str,
        environment: str,
        compliance_tags: list[str],
        priority_findings: list[dict[str, Any]],
    ) -> list[str]:
        """ç”Ÿæˆå¢å¼·çš„é¢¨éšªç·©è§£å»ºè­°"""
        recommendations = []

        # åš´é‡æ€§å»ºè­°
        if severity_counts["critical"] > 0:
            recommendations.append(
                f"ğŸš¨ ç«‹å³è™•ç† {severity_counts['critical']} å€‹é—œéµç´šåˆ¥æ¼æ´"
            )

        if severity_counts["high"] > 0:
            recommendations.append(f"âš ï¸ å„ªå…ˆè™•ç† {severity_counts['high']} å€‹é«˜é¢¨éšªæ¼æ´")

        # æ¥­å‹™èˆ‡ç’°å¢ƒç‰¹å®šå»ºè­°
        if business_criticality == "critical" and environment == "production":
            if overall_risk_level in ["critical", "high"]:
                recommendations.append(
                    "ğŸ’¼ æ¥­å‹™é—œéµç³»çµ±ç™¼ç¾é«˜é¢¨éšªæ¼æ´ï¼Œå»ºè­°å•Ÿå‹•ç·Šæ€¥éŸ¿æ‡‰ç¨‹åº"
                )
                recommendations.append("ğŸ”’ è€ƒæ…®æš«æ™‚ä¸‹ç·šå—å½±éŸ¿åŠŸèƒ½ç›´è‡³æ¼æ´ä¿®å¾©")

        # åˆè¦å»ºè­°
        if compliance_tags:
            compliance_str = ", ".join(compliance_tags)
            recommendations.append(
                f"ğŸ“‹ æ­¤è³‡ç”¢å— {compliance_str} åˆè¦è¦æ±‚ç´„æŸï¼Œå‹™å¿…åœ¨è¦å®šæ™‚é–“å…§ä¿®å¾©"
            )

        # è³‡æ–™æ•æ„Ÿåº¦å»ºè­°
        if len(priority_findings) > 0:
            top_vuln = priority_findings[0]
            recommendations.append(
                f"ğŸ¯ æœ€é«˜å„ªå…ˆç´šï¼š{top_vuln.get('vulnerability_type', 'æœªçŸ¥')} "
                f"(æ¥­å‹™é¢¨éšªåˆ†æ•¸: {top_vuln.get('calculated_business_risk_score', 0):.1f})"
            )

        # ä¸€èˆ¬å»ºè­°
        if overall_risk_level == "critical":
            recommendations.append("ğŸ“ å»ºè­°ç«‹å³é€šçŸ¥ç›¸é—œåˆ©ç›Šç›¸é—œè€…å’Œç®¡ç†å±¤")
            recommendations.append("ğŸ›¡ï¸ è€ƒæ…®å¯¦æ–½è‡¨æ™‚ç·©è§£æªæ–½ï¼ˆWAF è¦å‰‡ã€IP é™åˆ¶ç­‰ï¼‰")

        if not recommendations:
            recommendations.append("âœ… ç¹¼çºŒä¿æŒè‰¯å¥½çš„å®‰å…¨å¯¦è¸")

        return recommendations

    def _estimate_business_impact(
        self,
        severity_counts: dict[str, int],
        asset_value: float,
        user_base: int,
        business_criticality: str,
    ) -> dict[str, Any]:
        """ä¼°ç®—æ¥­å‹™å½±éŸ¿"""
        # æ½›åœ¨è²¡å‹™å½±éŸ¿ï¼ˆç°¡åŒ–ä¼°ç®—ï¼‰
        financial_impact = 0.0
        if asset_value > 0:
            # å‡è¨­æ¼æ´è¢«åˆ©ç”¨å¯èƒ½å°è‡´è³‡ç”¢åƒ¹å€¼çš„ä¸€å®šæ¯”ä¾‹æå¤±
            risk_percentage = (
                severity_counts["critical"] * 0.3
                + severity_counts["high"] * 0.15
                + severity_counts["medium"] * 0.05
            )
            financial_impact = asset_value * min(risk_percentage, 1.0)

        # å½±éŸ¿ç¯„åœ
        affected_users = 0
        if user_base > 0:
            # å‡è¨­æ¼æ´å¯èƒ½å½±éŸ¿çš„ä½¿ç”¨è€…æ¯”ä¾‹
            exposure_rate = (
                severity_counts["critical"] * 0.5
                + severity_counts["high"] * 0.3
                + severity_counts["medium"] * 0.1
            )
            affected_users = int(user_base * min(exposure_rate, 1.0))

        # æ¥­å‹™ä¸­æ–·é¢¨éšª
        disruption_risk = "low"
        if business_criticality == "critical":
            if severity_counts["critical"] > 0:
                disruption_risk = "high"
            elif severity_counts["high"] > 0:
                disruption_risk = "medium"

        return {
            "estimated_financial_impact": round(financial_impact, 2),
            "potentially_affected_users": affected_users,
            "business_disruption_risk": disruption_risk,
            "reputation_risk": self._assess_reputation_risk(
                severity_counts, business_criticality
            ),
        }

    def _assess_reputation_risk(
        self, severity_counts: dict[str, int], business_criticality: str
    ) -> str:
        """è©•ä¼°åè­½é¢¨éšª"""
        if business_criticality == "critical":
            if severity_counts["critical"] > 0:
                return "high"
            elif severity_counts["high"] > 0:
                return "medium"
        return "low"

    def _calculate_risk_trend(self, findings: list[dict[str, Any]]) -> dict[str, Any]:
        """è¨ˆç®—é¢¨éšªè¶¨å‹¢ï¼ˆéœ€è¦æ­·å²è³‡æ–™ï¼‰"""
        # ç°¡åŒ–ç‰ˆæœ¬ï¼šæª¢æŸ¥æ˜¯å¦æœ‰æ–°ç™¼ç¾çš„æ¼æ´
        new_findings = sum(
            1 for f in findings if f.get("status", "").lower() == "new"
        )
        total = len(findings)

        trend = "stable"
        if new_findings > total * 0.7:
            trend = "increasing"
        elif new_findings < total * 0.3:
            trend = "decreasing"

        return {
            "trend": trend,
            "new_findings": new_findings,
            "total_findings": total,
            "new_percentage": round((new_findings / total * 100) if total > 0 else 0, 1),
        }

    def compare_risk_trends(
        self, current_assessment: dict[str, Any], previous_assessment: dict[str, Any]
    ) -> dict[str, Any]:
        """æ¯”è¼ƒé¢¨éšªè¶¨å‹¢è®ŠåŒ–"""
        current_score = current_assessment.get("business_risk_score", 0)
        previous_score = previous_assessment.get("business_risk_score", 0)

        score_change = current_score - previous_score
        trend = "stable"
        if score_change > 5:
            trend = "increasing"
        elif score_change < -5:
            trend = "decreasing"

        return {
            "current_score": current_score,
            "previous_score": previous_score,
            "score_change": round(score_change, 2),
            "trend": trend,
            "improvement_percentage": (
                round(
                    (previous_score - current_score) / max(previous_score, 1) * 100, 1
                )
                if previous_score > 0
                else 0
            ),
        }
