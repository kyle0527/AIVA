"""
å¿«é€Ÿä¿®å¾©æ‰€æœ‰ schemas æ¨¡çµ„çš„å°å…¥å•é¡Œ
"""

import re
from pathlib import Path

# ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼Œå¾é …ç›®æ ¹ç›®éŒ„è¨ˆç®—
project_root = Path(__file__).parent.parent.parent
aiva_common = project_root / "services" / "aiva_common"

print("=" * 80)
print("ä¿®å¾©æ‰€æœ‰ schemas æ¨¡çµ„å°å…¥å•é¡Œ")
print("=" * 80)

# éœ€è¦ä¿®å¾©çš„æª”æ¡ˆå’Œå®ƒå€‘ç¼ºå°‘çš„å°å…¥
fixes = {
    "enhanced.py": {
        "missing_imports": [
            "HttpUrl",
            # å¾å…¶ä»–æ¨¡çµ„å°å…¥
            "Target", "FindingEvidence", "FindingImpact", "FindingRecommendation", 
            "SARIFResult", "SARIFLocation", "EnhancedVulnerability", 
            "RiskFactor", "CVSSv3Metrics", "TaskDependency"
        ],
        "from_imports": {
            ".base": ["RiskFactor", "TaskDependency"],
            ".findings": ["Target", "FindingEvidence", "FindingImpact", "FindingRecommendation"],
            ".references": ["SARIFResult", "SARIFLocation"],
            ".ai": ["EnhancedVulnerability", "CVSSv3Metrics"]
        }
    }
}

# æª¢æŸ¥å“ªäº›é¡åˆ¥å­˜åœ¨æ–¼å“ªå€‹æ¨¡çµ„
def find_class_in_modules(class_name, schemas_dir):
    for py_file in schemas_dir.glob("*.py"):
        if py_file.name == "__init__.py":
            continue
        try:
            content = py_file.read_text(encoding="utf-8")
            if re.search(rf'^class {class_name}\(', content, re.MULTILINE):
                return py_file.stem
        except:
            continue
    return None

schemas_dir = aiva_common / "schemas"

print("\nğŸ” æŸ¥æ‰¾ç¼ºå¤±é¡åˆ¥çš„ä½ç½®:")
all_missing = set()
for file_info in fixes.values():
    all_missing.update(file_info["missing_imports"])

class_locations = {}
for class_name in all_missing:
    if class_name == "HttpUrl":
        continue  # é€™æ˜¯ pydantic çš„
    location = find_class_in_modules(class_name, schemas_dir)
    if location:
        class_locations[class_name] = location
        print(f"   {class_name:25s} -> {location}.py")
    else:
        print(f"   {class_name:25s} -> âŒ æ‰¾ä¸åˆ°")

# ä¿®å¾© enhanced.py
print(f"\nğŸ”§ ä¿®å¾© enhanced.py...")
enhanced_file = schemas_dir / "enhanced.py"
content = enhanced_file.read_text(encoding="utf-8")

# æ‰¾åˆ°å°å…¥å€å¡Šä¸¦æ›¿æ›
import_section = """from pydantic import BaseModel, Field, field_validator

from ..enums import Confidence, ModuleName, Severity, TestStatus, VulnerabilityType"""

new_import_section = """from pydantic import BaseModel, Field, HttpUrl, field_validator

from ..enums import Confidence, ModuleName, Severity, TestStatus, VulnerabilityType
from .ai import CVSSv3Metrics, EnhancedVulnerability
from .base import RiskFactor, TaskDependency
from .findings import FindingEvidence, FindingImpact, FindingRecommendation, Target
from .references import SARIFLocation, SARIFResult"""

content = content.replace(import_section, new_import_section)
enhanced_file.write_text(content, encoding="utf-8")
print("   âœ… enhanced.py å°å…¥å·²ä¿®å¾©")

# æª¢æŸ¥å…¶ä»–å¯èƒ½æœ‰å•é¡Œçš„æª”æ¡ˆ
print(f"\nğŸ” æª¢æŸ¥å…¶ä»–æª”æ¡ˆçš„å°å…¥å•é¡Œ:")
problem_files = []

for py_file in schemas_dir.glob("*.py"):
    if py_file.name in ["__init__.py", "enhanced.py"]:
        continue
        
    try:
        content = py_file.read_text(encoding="utf-8")
        # æª¢æŸ¥æ˜¯å¦æœ‰ field_validator ä½†æ²’æœ‰å°å…¥
        if "field_validator" in content and "from pydantic import" in content:
            pydantic_import = re.search(r'from pydantic import ([^\\n]+)', content)
            if pydantic_import and "field_validator" not in pydantic_import.group(1):
                problem_files.append((py_file.name, "ç¼ºå°‘ field_validator"))
                
        # æª¢æŸ¥æ˜¯å¦æœ‰ HttpUrl ä½†æ²’æœ‰å°å…¥
        if "HttpUrl" in content and "from pydantic import" in content:
            pydantic_import = re.search(r'from pydantic import ([^\\n]+)', content)
            if pydantic_import and "HttpUrl" not in pydantic_import.group(1):
                problem_files.append((py_file.name, "ç¼ºå°‘ HttpUrl"))
                
    except Exception as e:
        print(f"   âš ï¸ æª¢æŸ¥ {py_file.name} æ™‚å‡ºéŒ¯: {e}")

for filename, issue in problem_files:
    print(f"   âš ï¸ {filename}: {issue}")

# å¿«é€Ÿä¿®å¾©å¸¸è¦‹å•é¡Œ
common_fixes = {
    "tasks.py": {
        "old": "from pydantic import BaseModel, Field, HttpUrl, field_validator",
        "new": "from pydantic import BaseModel, Field, HttpUrl, field_validator"
    },
    "findings.py": {
        "pattern": r'from pydantic import BaseModel, Field([^\\n]*)',
        "replacement": "from pydantic import BaseModel, Field, HttpUrl, field_validator"
    }
}

for filename, fix_info in common_fixes.items():
    file_path = schemas_dir / filename
    if file_path.exists():
        content = file_path.read_text(encoding="utf-8")
        
        if "pattern" in fix_info:
            content = re.sub(fix_info["pattern"], fix_info["replacement"], content)
        else:
            content = content.replace(fix_info["old"], fix_info["new"])
            
        file_path.write_text(content, encoding="utf-8")
        print(f"   âœ… {filename} å·²ä¿®å¾©")

print(f"\nâœ… æ‰€æœ‰å·²çŸ¥å•é¡Œå·²ä¿®å¾©")
print("=" * 80)