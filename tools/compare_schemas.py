"""
æ¯”å°èˆŠæª”æ¡ˆèˆ‡æ–° schemas/ è³‡æ–™å¤¾çš„å…§å®¹
"""

import re
from pathlib import Path

def extract_classes(content):
    """æå–æ‰€æœ‰é¡åˆ¥åç¨±"""
    pattern = r'^class\s+(\w+)\s*\('
    return set(re.findall(pattern, content, re.MULTILINE))

def compare_files(old_path, new_path, name):
    """æ¯”è¼ƒå…©å€‹æª”æ¡ˆçš„é¡åˆ¥"""
    old_file = Path(old_path)
    new_file = Path(new_path)
    
    if not old_file.exists():
        print(f"âŒ {old_path} ä¸å­˜åœ¨")
        return False
    
    if not new_file.exists():
        print(f"âŒ {new_path} ä¸å­˜åœ¨")
        return False
    
    old_content = old_file.read_text(encoding='utf-8')
    new_content = new_file.read_text(encoding='utf-8')
    
    old_classes = extract_classes(old_content)
    new_classes = extract_classes(new_content)
    
    print(f'\nğŸ“Š {name} åˆ†æ:')
    print(f'  èˆŠæª”æ¡ˆ ({old_path}):')
    print(f'    - é¡åˆ¥æ•¸é‡: {len(old_classes)}')
    
    print(f'  æ–°æª”æ¡ˆ ({new_path}):')
    print(f'    - é¡åˆ¥æ•¸é‡: {len(new_classes)}')
    
    only_in_old = old_classes - new_classes
    only_in_new = new_classes - old_classes
    common = old_classes & new_classes
    
    print(f'\n  ğŸ” æ¯”å°çµæœ:')
    print(f'    - å…±åŒé¡åˆ¥: {len(common)}')
    
    if only_in_old:
        print(f'    - âš ï¸  åƒ…åœ¨èˆŠæª”æ¡ˆ: {len(only_in_old)} å€‹')
        print(f'      {sorted(only_in_old)}')
        return False
    else:
        print(f'    - âœ… èˆŠæª”æ¡ˆçš„æ‰€æœ‰é¡åˆ¥å·²é·ç§»')
    
    if only_in_new:
        print(f'    - ğŸ“ æ–°å¢é¡åˆ¥: {len(only_in_new)} å€‹')
        
    return True

# ä¸»è¦æ¯”å°
print("=" * 60)
print("æª”æ¡ˆé·ç§»æ¯”å°å ±å‘Š")
print("=" * 60)

# æ¯”å° ai_schemas.py
ai_migrated = compare_files(
    'ai_schemas.py',
    'schemas/ai.py',
    'AI Schemas'
)

# æ¯”å° schemas.py (æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å…§å®¹éƒ½å·²æ‹†åˆ†)
print("\n" + "=" * 60)
print("schemas.py æ‹†åˆ†æª¢æŸ¥")
print("=" * 60)

schemas_content = Path('schemas.py').read_text(encoding='utf-8')
schemas_classes = extract_classes(schemas_content)

# æª¢æŸ¥æ–° schemas/ è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰é¡åˆ¥
new_schemas_dir = Path('schemas')
all_new_classes = set()

for py_file in new_schemas_dir.glob('*.py'):
    if py_file.name == '__init__.py':
        continue
    content = py_file.read_text(encoding='utf-8')
    classes = extract_classes(content)
    all_new_classes.update(classes)
    print(f'\n  ğŸ“„ {py_file.name}: {len(classes)} å€‹é¡åˆ¥')

print(f'\nğŸ“Š ç¸½è¨ˆ:')
print(f'  - åŸ schemas.py: {len(schemas_classes)} å€‹é¡åˆ¥')
print(f'  - æ–° schemas/: {len(all_new_classes)} å€‹é¡åˆ¥')

missing = schemas_classes - all_new_classes
if missing:
    print(f'\nâš ï¸  å°šæœªé·ç§»çš„é¡åˆ¥ ({len(missing)} å€‹):')
    for cls in sorted(missing):
        print(f'    - {cls}')
else:
    print(f'\nâœ… schemas.py çš„æ‰€æœ‰é¡åˆ¥å·²é·ç§»')

# å¯ä»¥åˆªé™¤çš„æª”æ¡ˆåˆ—è¡¨
print("\n" + "=" * 60)
print("å»ºè­°åˆªé™¤çš„æª”æ¡ˆ")
print("=" * 60)

can_delete = []

# å‚™ä»½æª”æ¡ˆ
backup_patterns = [
    '*backup*.py',
    '*old*.py',
    '*broken*.py',
    '*fixed*.py',
    '*compat*.py',
    '*.disabled',
]

for pattern in backup_patterns:
    for f in Path('.').glob(pattern):
        if f.is_file() and f.name != '__init__.py':
            can_delete.append(f)

if ai_migrated:
    can_delete.append(Path('ai_schemas.py'))

if not missing:  # å¦‚æœ schemas.py å·²å®Œå…¨é·ç§»
    can_delete.append(Path('schemas.py'))

print('\nå¯ä»¥å®‰å…¨åˆªé™¤çš„æª”æ¡ˆ:')
for f in sorted(can_delete):
    size = f.stat().st_size if f.exists() else 0
    print(f'  - {f.name} ({size:,} bytes)')

print(f'\nç¸½è¨ˆ: {len(can_delete)} å€‹æª”æ¡ˆå¯ä»¥åˆªé™¤')
