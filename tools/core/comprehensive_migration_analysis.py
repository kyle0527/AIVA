"""
å…¨é¢åˆ†æ AIVA Common é·ç§»å®Œæ•´æ€§
åŒ…æ‹¬ï¼šè©³ç´°å°æ¯”ã€ç¶²è·¯æœç´¢é©—è­‰ã€å®Œæ•´æ€§ç¢ºèª
"""

import re
import json
from pathlib import Path
from collections import defaultdict

def analyze_migration_completeness():
    """å…¨é¢åˆ†æé·ç§»å®Œæ•´æ€§"""
    
    project_root = Path(__file__).parent.parent.parent
    aiva_common = project_root / "services" / "aiva_common"
    
    print("=" * 100)
    print("ğŸ” AIVA COMMON é·ç§»å®Œæ•´æ€§å…¨é¢åˆ†æ")
    print("=" * 100)
    
    results = {
        "timestamp": "2025-10-16",
        "analysis": {},
        "migration_status": {},
        "file_structure": {},
        "validation": {}
    }
    
    # ========================================================================
    # 1. åˆ†æèˆŠæª”æ¡ˆå…§å®¹
    # ========================================================================
    print("\nğŸ“„ æ­¥é©Ÿ 1: åˆ†æèˆŠæª”æ¡ˆå…§å®¹")
    print("-" * 50)
    
    old_files = {
        "schemas.py": aiva_common / "schemas.py",
        "enums.py": aiva_common / "enums.py", 
        "ai_schemas.py": aiva_common / "ai_schemas.py"
    }
    
    old_data = {}
    for name, path in old_files.items():
        if path.exists():
            try:
                content = path.read_text(encoding='utf-8')
                classes = re.findall(r'^class (\w+)\(', content, re.MULTILINE)
                old_data[name] = {
                    "classes": sorted(set(classes)),
                    "size": path.stat().st_size,
                    "lines": len(content.split('\n'))
                }
                print(f"âœ… {name:15s}: {len(old_data[name]['classes']):3d} é¡åˆ¥, {old_data[name]['size']:>8,} bytes")
            except Exception as e:
                print(f"âŒ {name:15s}: è®€å–å¤±æ•— - {e}")
                old_data[name] = {"classes": [], "size": 0, "lines": 0}
        else:
            print(f"âš ï¸  {name:15s}: æª”æ¡ˆä¸å­˜åœ¨")
            old_data[name] = {"classes": [], "size": 0, "lines": 0}
    
    # åˆä½µæ‰€æœ‰èˆŠé¡åˆ¥
    all_old_schemas = set()
    all_old_enums = set()
    
    if old_data["schemas.py"]["classes"]:
        all_old_schemas.update(old_data["schemas.py"]["classes"])
    if old_data["ai_schemas.py"]["classes"]:
        all_old_schemas.update(old_data["ai_schemas.py"]["classes"])  
    if old_data["enums.py"]["classes"]:
        all_old_enums.update(old_data["enums.py"]["classes"])
    
    print(f"\nğŸ“Š èˆŠæª”æ¡ˆç¸½è¨ˆ:")
    print(f"   Schemas: {len(all_old_schemas)} å€‹é¡åˆ¥")
    print(f"   Enums: {len(all_old_enums)} å€‹é¡åˆ¥")
    
    results["analysis"]["old_files"] = {
        "schemas_count": len(all_old_schemas),
        "enums_count": len(all_old_enums),
        "schemas_list": sorted(all_old_schemas),
        "enums_list": sorted(all_old_enums)
    }
    
    # ========================================================================
    # 2. åˆ†ææ–°æ¨¡çµ„çµæ§‹
    # ========================================================================
    print("\nğŸ“ æ­¥é©Ÿ 2: åˆ†ææ–°æ¨¡çµ„çµæ§‹")
    print("-" * 50)
    
    new_structure = {}
    
    # åˆ†æ schemas/ è³‡æ–™å¤¾
    schemas_dir = aiva_common / "schemas"
    if schemas_dir.exists():
        schema_modules = {}
        total_schema_classes = set()
        
        for py_file in schemas_dir.glob("*.py"):
            if py_file.name == "__init__.py":
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                classes = re.findall(r'^class (\w+)\(', content, re.MULTILINE)
                schema_modules[py_file.stem] = {
                    "classes": sorted(set(classes)),
                    "size": py_file.stat().st_size,
                    "lines": len(content.split('\n'))
                }
                total_schema_classes.update(classes)
                print(f"   ğŸ“„ {py_file.name:20s}: {len(classes):3d} é¡åˆ¥, {py_file.stat().st_size:>8,} bytes")
            except Exception as e:
                print(f"   âŒ {py_file.name:20s}: è®€å–å¤±æ•— - {e}")
        
        new_structure["schemas"] = {
            "modules": schema_modules,
            "total_classes": sorted(total_schema_classes),
            "count": len(total_schema_classes)
        }
        print(f"   ğŸ“Š Schemas ç¸½è¨ˆ: {len(total_schema_classes)} å€‹é¡åˆ¥")
    
    # åˆ†æ enums/ è³‡æ–™å¤¾
    enums_dir = aiva_common / "enums"
    if enums_dir.exists():
        enum_modules = {}
        total_enum_classes = set()
        
        for py_file in enums_dir.glob("*.py"):
            if py_file.name == "__init__.py":
                continue
                
            try:
                content = py_file.read_text(encoding='utf-8')
                classes = re.findall(r'^class (\w+)\(', content, re.MULTILINE)
                enum_modules[py_file.stem] = {
                    "classes": sorted(set(classes)),
                    "size": py_file.stat().st_size,
                    "lines": len(content.split('\n'))
                }
                total_enum_classes.update(classes)
                print(f"   ğŸ“„ {py_file.name:20s}: {len(classes):3d} é¡åˆ¥, {py_file.stat().st_size:>8,} bytes")
            except Exception as e:
                print(f"   âŒ {py_file.name:20s}: è®€å–å¤±æ•— - {e}")
        
        new_structure["enums"] = {
            "modules": enum_modules,
            "total_classes": sorted(total_enum_classes),
            "count": len(total_enum_classes)
        }
        print(f"   ğŸ“Š Enums ç¸½è¨ˆ: {len(total_enum_classes)} å€‹é¡åˆ¥")
    
    results["file_structure"] = new_structure
    
    # ========================================================================
    # 3. å°æ¯”åˆ†æ - æª¢æŸ¥é·ç§»å®Œæ•´æ€§
    # ========================================================================
    print("\nğŸ”„ æ­¥é©Ÿ 3: é·ç§»å®Œæ•´æ€§å°æ¯”")
    print("-" * 50)
    
    # Schemas å°æ¯”
    if "schemas" in new_structure:
        new_schemas = set(new_structure["schemas"]["total_classes"])
        missing_schemas = all_old_schemas - new_schemas
        extra_schemas = new_schemas - all_old_schemas
        
        print(f"ğŸ“‹ Schemas å°æ¯”:")
        print(f"   èˆŠæª”æ¡ˆ: {len(all_old_schemas)} å€‹")
        print(f"   æ–°æ¨¡çµ„: {len(new_schemas)} å€‹")
        
        if missing_schemas:
            print(f"   âš ï¸  ç¼ºå¤±: {len(missing_schemas)} å€‹")
            for cls in sorted(missing_schemas)[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                print(f"      - {cls}")
            if len(missing_schemas) > 10:
                print(f"      ... é‚„æœ‰ {len(missing_schemas) - 10} å€‹")
        
        if extra_schemas:
            print(f"   â• æ–°å¢: {len(extra_schemas)} å€‹")
            for cls in sorted(extra_schemas)[:5]:
                print(f"      - {cls}")
        
        if not missing_schemas and not extra_schemas:
            print(f"   âœ… å®Œå…¨åŒ¹é…ï¼")
        
        results["migration_status"]["schemas"] = {
            "old_count": len(all_old_schemas),
            "new_count": len(new_schemas),
            "missing": sorted(missing_schemas),
            "extra": sorted(extra_schemas),
            "complete": len(missing_schemas) == 0
        }
    
    # Enums å°æ¯”
    if "enums" in new_structure:
        new_enums = set(new_structure["enums"]["total_classes"])
        missing_enums = all_old_enums - new_enums
        extra_enums = new_enums - all_old_enums
        
        print(f"\nğŸ“‹ Enums å°æ¯”:")
        print(f"   èˆŠæª”æ¡ˆ: {len(all_old_enums)} å€‹")
        print(f"   æ–°æ¨¡çµ„: {len(new_enums)} å€‹")
        
        if missing_enums:
            print(f"   âš ï¸  ç¼ºå¤±: {len(missing_enums)} å€‹")
            for cls in sorted(missing_enums):
                print(f"      - {cls}")
        
        if extra_enums:
            print(f"   â• æ–°å¢: {len(extra_enums)} å€‹")
            for cls in sorted(extra_enums):
                print(f"      - {cls}")
        
        if not missing_enums and not extra_enums:
            print(f"   âœ… å®Œå…¨åŒ¹é…ï¼")
        
        results["migration_status"]["enums"] = {
            "old_count": len(all_old_enums),
            "new_count": len(new_enums),
            "missing": sorted(missing_enums),
            "extra": sorted(extra_enums),
            "complete": len(missing_enums) == 0
        }
    
    # ========================================================================
    # 4. å¯¦éš›å°å…¥æ¸¬è©¦
    # ========================================================================
    print("\nğŸ§ª æ­¥é©Ÿ 4: å¯¦éš›å°å…¥æ¸¬è©¦")
    print("-" * 50)
    
    import sys
    sys.path.insert(0, str(project_root / "services"))
    
    import_tests = []
    
    # æ¸¬è©¦åŸºæœ¬æ¨¡çµ„å°å…¥
    try:
        from aiva_common import schemas, enums
        schema_exported = len([n for n in dir(schemas) if not n.startswith('_') and n[0].isupper()])
        enum_exported = len([n for n in dir(enums) if not n.startswith('_') and n[0].isupper()])
        
        import_tests.append({
            "test": "åŸºæœ¬æ¨¡çµ„å°å…¥",
            "status": "âœ… PASS",
            "detail": f"schemas: {schema_exported}, enums: {enum_exported}"
        })
        print(f"âœ… åŸºæœ¬æ¨¡çµ„å°å…¥æˆåŠŸ")
        print(f"   å°å‡º schemas: {schema_exported} å€‹")  
        print(f"   å°å‡º enums: {enum_exported} å€‹")
        
    except Exception as e:
        import_tests.append({
            "test": "åŸºæœ¬æ¨¡çµ„å°å…¥", 
            "status": "âŒ FAIL",
            "detail": str(e)
        })
        print(f"âŒ åŸºæœ¬æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    
    # æ¸¬è©¦å…·é«”é¡åˆ¥å°å…¥
    test_classes = [
        ("aiva_common.schemas", "ScanStartPayload"),
        ("aiva_common.schemas", "FunctionTaskPayload"),  
        ("aiva_common.schemas", "FindingPayload"),
        ("aiva_common.schemas", "MessageHeader"),
        ("aiva_common.enums", "ModuleName"),
        ("aiva_common.enums", "VulnerabilityType"),
        ("aiva_common.enums", "Severity"),
        ("aiva_common.enums", "Topic"),
    ]
    
    for module, class_name in test_classes:
        try:
            exec(f"from {module} import {class_name}")
            import_tests.append({
                "test": f"{module}.{class_name}",
                "status": "âœ… PASS", 
                "detail": "å°å…¥æˆåŠŸ"
            })
            print(f"âœ… {module}.{class_name}")
        except Exception as e:
            import_tests.append({
                "test": f"{module}.{class_name}",
                "status": "âŒ FAIL",
                "detail": str(e)
            })
            print(f"âŒ {module}.{class_name}: {e}")
    
    results["validation"]["import_tests"] = import_tests
    
    # ========================================================================
    # 5. æª”æ¡ˆå¤§å°å’Œæ•ˆç‡åˆ†æ
    # ========================================================================
    print("\nğŸ“Š æ­¥é©Ÿ 5: æª”æ¡ˆå¤§å°å’Œæ•ˆç‡åˆ†æ")
    print("-" * 50)
    
    old_total_size = sum(data["size"] for data in old_data.values())
    
    new_total_size = 0
    if schemas_dir.exists():
        new_total_size += sum(f.stat().st_size for f in schemas_dir.glob("*.py"))
    if enums_dir.exists():
        new_total_size += sum(f.stat().st_size for f in enums_dir.glob("*.py"))
    
    print(f"æª”æ¡ˆå¤§å°å°æ¯”:")
    print(f"   èˆŠæª”æ¡ˆç¸½å¤§å°: {old_total_size:>10,} bytes ({old_total_size/1024:.1f} KB)")
    print(f"   æ–°æª”æ¡ˆç¸½å¤§å°: {new_total_size:>10,} bytes ({new_total_size/1024:.1f} KB)")
    
    size_diff = new_total_size - old_total_size
    if size_diff > 0:
        print(f"   ğŸ“ˆ å¢åŠ : {size_diff:>10,} bytes ({size_diff/1024:.1f} KB)")
    elif size_diff < 0:
        print(f"   ğŸ“‰ æ¸›å°‘: {abs(size_diff):>10,} bytes ({abs(size_diff)/1024:.1f} KB)")
    else:
        print(f"   ğŸ“Š å¤§å°ç›¸åŒ")
    
    # ========================================================================
    # 6. ç¸½çµå ±å‘Š
    # ========================================================================
    print("\nğŸ¯ æ­¥é©Ÿ 6: é·ç§»å®Œæ•´æ€§ç¸½çµ")
    print("=" * 100)
    
    schemas_complete = results["migration_status"].get("schemas", {}).get("complete", False)
    enums_complete = results["migration_status"].get("enums", {}).get("complete", False)
    
    passed_tests = len([t for t in import_tests if "âœ…" in t["status"]])
    total_tests = len(import_tests)
    
    print(f"""
ğŸ” é·ç§»åˆ†æçµæœ:

ğŸ“„ Schemas é·ç§»:
   - èˆŠæª”æ¡ˆé¡åˆ¥æ•¸: {len(all_old_schemas)}
   - æ–°æ¨¡çµ„é¡åˆ¥æ•¸: {len(new_structure.get('schemas', {}).get('total_classes', []))}
   - é·ç§»ç‹€æ…‹: {'âœ… å®Œæ•´' if schemas_complete else 'âš ï¸ ä¸å®Œæ•´'}

ğŸ“„ Enums é·ç§»:  
   - èˆŠæª”æ¡ˆé¡åˆ¥æ•¸: {len(all_old_enums)}
   - æ–°æ¨¡çµ„é¡åˆ¥æ•¸: {len(new_structure.get('enums', {}).get('total_classes', []))}
   - é·ç§»ç‹€æ…‹: {'âœ… å®Œæ•´' if enums_complete else 'âš ï¸ ä¸å®Œæ•´'}

ğŸ§ª å°å…¥æ¸¬è©¦:
   - é€šé: {passed_tests}/{total_tests}
   - ç‹€æ…‹: {'âœ… å…¨éƒ¨é€šé' if passed_tests == total_tests else 'âš ï¸ éƒ¨åˆ†å¤±æ•—'}

ğŸ“Š æ•´é«”è©•ä¼°:
   - çµæ§‹å®Œæ•´æ€§: {'âœ… è‰¯å¥½' if schemas_complete and enums_complete else 'âš ï¸ éœ€è¦é—œæ³¨'}
   - åŠŸèƒ½å¯ç”¨æ€§: {'âœ… è‰¯å¥½' if passed_tests >= total_tests * 0.8 else 'âš ï¸ éœ€è¦ä¿®å¾©'}
   - å»ºè­°è¡Œå‹•: {'ğŸ‰ å¯ä»¥åˆªé™¤èˆŠæª”æ¡ˆ' if schemas_complete and enums_complete and passed_tests == total_tests else 'ğŸ”§ éœ€è¦é€²ä¸€æ­¥ä¿®å¾©'}
""")
    
    # å„²å­˜è©³ç´°å ±å‘Š
    report_file = project_root / "_out" / "migration_completeness_report.json"
    report_file.parent.mkdir(exist_ok=True)
    
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {report_file}")
    print("=" * 100)
    
    return {
        "schemas_complete": schemas_complete,
        "enums_complete": enums_complete, 
        "tests_passed": passed_tests == total_tests,
        "ready_for_cleanup": schemas_complete and enums_complete and passed_tests == total_tests
    }

if __name__ == "__main__":
    result = analyze_migration_completeness()