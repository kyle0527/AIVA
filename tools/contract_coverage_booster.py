#!/usr/bin/env python3
"""
AIVA åˆç´„è¦†è“‹ç‡æå‡å·¥å…·

è‡ªå‹•åŒ–å·¥å…·ï¼Œå¹«åŠ©è­˜åˆ¥ä¸¦æå‡ AIVA é …ç›®ä¸­æ¨™æº–åˆç´„çš„ä½¿ç”¨è¦†è“‹ç‡ã€‚
åŒ…å«åˆ†æã€å»ºè­°ã€è‡ªå‹•é‡æ§‹ç­‰åŠŸèƒ½ã€‚
"""

import ast
import json
import re
import sys
from collections import defaultdict, Counter
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Any
import argparse
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class ContractUsageAnalysis:
    """åˆç´„ä½¿ç”¨åˆ†æçµæœ"""
    total_files: int
    files_with_standard_contracts: int
    files_with_local_models: int
    standard_contract_coverage: float
    local_model_coverage: float
    most_used_contracts: List[Tuple[str, int]]
    local_model_candidates: List[Tuple[str, int]]
    module_usage: Dict[str, Dict[str, Any]]
    improvement_opportunities: List[Dict[str, Any]]


@dataclass
class RefactoringTask:
    """é‡æ§‹ä»»å‹™"""
    file_path: str
    task_type: str  # 'add_standard_import', 'replace_local_model', 'standardize_response'
    description: str
    old_code: Optional[str] = None
    new_code: Optional[str] = None
    confidence: float = 1.0  # 0.0-1.0 ç½®ä¿¡åº¦


class ContractCoverageAnalyzer:
    """åˆç´„è¦†è“‹ç‡åˆ†æå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = Path(project_root)
        self.exclude_patterns = [
            '__pycache__', '.git', 'venv', '.venv', 
            'node_modules', '.pytest_cache', 'build', 'dist'
        ]
        
        # æ¨™æº–åˆç´„æ¸…å–® (å¾ aiva_common.schemas)
        self.standard_contracts = [
            'FindingPayload', 'AivaMessage', 'AttackPlan', 'FunctionTelemetry',
            'ScanStartPayload', 'MessageHeader', 'Authentication', 'APIResponse',
            'ExecutionError', 'Target', 'Asset', 'Experience', 'Task', 'Scan'
        ]
        
        # å¸¸è¦‹æœ¬åœ°åˆç´„æ¨¡å¼
        self.local_model_patterns = [
            r'class (\w+)(?:Request|Response|Config|Model|Data|Payload)\(BaseModel\)',
            r'class (\w+)\(BaseModel\)',
        ]
        
        # APIéŸ¿æ‡‰æ¨¡å¼
        self.response_patterns = [
            r'return\s+{\s*["\']success["\']:\s*True',
            r'return\s+{\s*["\']success["\']:\s*False',
            r'return\s+(?:jsonify|Response)\(',
        ]
    
    def scan_python_files(self) -> List[Path]:
        """æƒææ‰€æœ‰ Python æ–‡ä»¶"""
        python_files = []
        
        for py_file in self.project_root.rglob('*.py'):
            # æ’é™¤ç‰¹å®šç›®éŒ„
            if any(pattern in str(py_file) for pattern in self.exclude_patterns):
                continue
            python_files.append(py_file)
        
        return python_files
    
    def analyze_file_contracts(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå–®å€‹æ–‡ä»¶çš„åˆç´„ä½¿ç”¨æƒ…æ³"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            analysis = {
                'has_standard_imports': False,
                'has_local_models': False,
                'standard_contracts': [],
                'local_models': [],
                'response_patterns': [],
                'import_lines': [],
                'api_endpoints': 0,
                'improvement_opportunities': []
            }
            
            # 1. åˆ†ææ¨™æº–åˆç´„å°å…¥
            import_patterns = [
                r'from services\.aiva_common\.schemas import ([^\\n]+)',
                r'from aiva_common\.schemas import ([^\\n]+)'
            ]
            
            for pattern in import_patterns:
                imports = re.findall(pattern, content)
                if imports:
                    analysis['has_standard_imports'] = True
                    analysis['import_lines'].extend(imports)
                    
                    for import_line in imports:
                        contracts = [c.strip() for c in import_line.replace('(', '').replace(')', '').split(',')]
                        analysis['standard_contracts'].extend([c for c in contracts if c.strip()])
            
            # 2. åˆ†ææœ¬åœ°æ¨¡å‹å®šç¾©
            for pattern in self.local_model_patterns:
                models = re.findall(pattern, content)
                if models:
                    analysis['has_local_models'] = True
                    analysis['local_models'].extend(models)
            
            # 3. åˆ†æéŸ¿æ‡‰æ¨¡å¼
            for pattern in self.response_patterns:
                matches = re.findall(pattern, content)
                analysis['response_patterns'].extend(matches)
            
            # 4. æª¢æŸ¥ API ç«¯é»æ•¸é‡
            api_decorators = re.findall(r'@app\.(get|post|put|delete|patch)', content)
            analysis['api_endpoints'] = len(api_decorators)
            
            # 5. è­˜åˆ¥æ”¹é€²æ©Ÿæœƒ
            analysis['improvement_opportunities'] = self._identify_improvements(file_path, content, analysis)
            
            return analysis
            
        except Exception as e:
            logger.warning(f"åˆ†ææ–‡ä»¶å¤±æ•— {file_path}: {e}")
            return {}
    
    def _identify_improvements(self, _file_path: Path, _content: str, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è­˜åˆ¥æ”¹é€²æ©Ÿæœƒ"""
        opportunities = []
        
        # 1. API ç«¯é»ä½†æ²’æœ‰ä½¿ç”¨æ¨™æº–éŸ¿æ‡‰æ ¼å¼
        if analysis['api_endpoints'] > 0 and not analysis['has_standard_imports']:
            opportunities.append({
                'type': 'add_standard_response',
                'description': 'API ç«¯é»å»ºè­°ä½¿ç”¨ APIResponse æ¨™æº–æ ¼å¼',
                'priority': 'high',
                'effort': 'medium'
            })
        
        # 2. æœ‰æœ¬åœ°æ¨¡å‹ä½†å¯èƒ½å¯ä»¥æ¨™æº–åŒ–
        if analysis['local_models']:
            for model in analysis['local_models']:
                if any(keyword in model.lower() for keyword in ['response', 'request', 'payload', 'message']):
                    opportunities.append({
                        'type': 'standardize_local_model',
                        'description': f'æœ¬åœ°æ¨¡å‹ {model} å¯èƒ½å¯ä»¥ä½¿ç”¨æ¨™æº–åˆç´„',
                        'model_name': model,
                        'priority': 'medium',
                        'effort': 'high'
                    })
        
        # 3. ä½¿ç”¨èˆŠå¼éŸ¿æ‡‰æ ¼å¼
        if analysis['response_patterns'] and 'APIResponse' not in analysis['standard_contracts']:
            opportunities.append({
                'type': 'upgrade_response_format',
                'description': 'éŸ¿æ‡‰æ ¼å¼å¯ä»¥å‡ç´šç‚º APIResponse æ¨™æº–',
                'priority': 'medium',
                'effort': 'low'
            })
        
        return opportunities
    
    def run_full_analysis(self) -> ContractUsageAnalysis:
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        logger.info("é–‹å§‹åˆç´„è¦†è“‹ç‡å…¨é¢åˆ†æ...")
        
        python_files = self.scan_python_files()
        total_files = len(python_files)
        
        # çµ±è¨ˆæ•¸æ“š
        files_with_standard_contracts = 0
        files_with_local_models = 0
        contract_usage = Counter()
        local_model_usage = Counter()
        module_usage = defaultdict(dict)
        all_opportunities = []
        
        logger.info(f"æƒæ {total_files} å€‹ Python æ–‡ä»¶...")
        
        for file_path in python_files:
            analysis = self.analyze_file_contracts(file_path)
            
            if not analysis:
                continue
            
            # çµ±è¨ˆæ¨™æº–åˆç´„ä½¿ç”¨
            if analysis['has_standard_imports']:
                files_with_standard_contracts += 1
                for contract in analysis['standard_contracts']:
                    contract_usage[contract.strip()] += 1
            
            # çµ±è¨ˆæœ¬åœ°æ¨¡å‹
            if analysis['has_local_models']:
                files_with_local_models += 1
                for model in analysis['local_models']:
                    local_model_usage[model] += 1
            
            # æ¨¡çµ„çµ±è¨ˆ
            module_name = self._get_module_name(file_path)
            module_usage[module_name] = {
                'files': module_usage[module_name].get('files', 0) + 1,
                'standard_contracts': len(analysis['standard_contracts']),
                'local_models': len(analysis['local_models']),
                'api_endpoints': analysis['api_endpoints']
            }
            
            # æ”¶é›†æ”¹é€²æ©Ÿæœƒ
            for opp in analysis['improvement_opportunities']:
                opp['file_path'] = str(file_path)
                all_opportunities.append(opp)
        
        # è¨ˆç®—è¦†è“‹ç‡
        standard_coverage = (files_with_standard_contracts / total_files * 100) if total_files > 0 else 0
        local_coverage = (files_with_local_models / total_files * 100) if total_files > 0 else 0
        
        return ContractUsageAnalysis(
            total_files=total_files,
            files_with_standard_contracts=files_with_standard_contracts,
            files_with_local_models=files_with_local_models,
            standard_contract_coverage=standard_coverage,
            local_model_coverage=local_coverage,
            most_used_contracts=contract_usage.most_common(10),
            local_model_candidates=local_model_usage.most_common(10),
            module_usage=dict(module_usage),
            improvement_opportunities=all_opportunities
        )
    
    def _get_module_name(self, file_path: Path) -> str:
        """ç²å–æ¨¡çµ„åç¨±"""
        relative_path = file_path.relative_to(self.project_root)
        parts = relative_path.parts
        
        if len(parts) > 1:
            return parts[0]
        else:
            return parts[0] if parts else 'root'
    
    def generate_improvement_plan(self, analysis: ContractUsageAnalysis) -> Dict[str, Any]:
        """ç”Ÿæˆæ”¹é€²è¨ˆåŠƒ"""
        plan = {
            'current_status': {
                'coverage_rate': analysis.standard_contract_coverage,
                'status': self._get_coverage_status(analysis.standard_contract_coverage)
            },
            'quick_wins': [],
            'medium_term_goals': [],
            'long_term_objectives': [],
            'priority_modules': [],
            'automation_opportunities': []
        }
        
        # æ ¹æ“šè¦†è“‹ç‡ç”Ÿæˆå»ºè­°
        if analysis.standard_contract_coverage < 10:
            plan['quick_wins'].extend([
                'åœ¨ API æ¨¡çµ„ä¸­æ¨å»£ APIResponse æ¨™æº–æ ¼å¼',
                'å‰µå»ºåˆç´„ä½¿ç”¨ç¯„æœ¬å’Œå¿«é€Ÿé–‹å§‹æŒ‡å—',
                'åœ¨æ–°åŠŸèƒ½é–‹ç™¼ä¸­å¼·åˆ¶ä½¿ç”¨æ¨™æº–åˆç´„'
            ])
        elif analysis.standard_contract_coverage < 20:
            plan['quick_wins'].extend([
                'é‡æ§‹ç¾æœ‰ API ç«¯é»ä½¿ç”¨æ¨™æº–éŸ¿æ‡‰æ ¼å¼',
                'æ¨™æº–åŒ–éŒ¯èª¤è™•ç†ä½¿ç”¨ ExecutionError',
                'çµ±ä¸€è¨Šæ¯æ ¼å¼ä½¿ç”¨ AivaMessage'
            ])
        else:
            plan['quick_wins'].extend([
                'å„ªåŒ–é«˜é »ä½¿ç”¨çš„æœ¬åœ°åˆç´„',
                'å»ºç«‹è‡ªå‹•åŒ–é·ç§»å·¥å…·',
                'å®Œå–„æ€§èƒ½ç›£æ§æ©Ÿåˆ¶'
            ])
        
        # ä¸­æœŸç›®æ¨™
        plan['medium_term_goals'] = [
            'é”æˆ 25%+ æ¨™æº–åˆç´„è¦†è“‹ç‡',
            'æ¸…ç†å’Œæ¨™æº–åŒ–æœ¬åœ°åˆç´„å®šç¾©',
            'å»ºç«‹ CI/CD è¦†è“‹ç‡æª¢æŸ¥',
            'å®Œå–„é–‹ç™¼è€…åŸ¹è¨“é«”ç³»'
        ]
        
        # é•·æœŸç›®æ¨™
        plan['long_term_objectives'] = [
            'å¯¦ç¾ 35%+ æ¨™æº–åˆç´„è¦†è“‹ç‡',
            'å»ºç«‹æ™ºèƒ½åˆç´„æ¨è–¦ç³»çµ±',
            'å¯¦ç¾è·¨èªè¨€åˆç´„åŒæ­¥',
            'å®Œå–„åˆç´„ç‰ˆæœ¬ç®¡ç†é«”ç³»'
        ]
        
        # å„ªå…ˆæ¨¡çµ„
        priority_modules = []
        for module, stats in analysis.module_usage.items():
            if stats.get('api_endpoints', 0) > 0 and stats.get('standard_contracts', 0) == 0:
                priority_modules.append({
                    'module': module,
                    'reason': 'API æ¨¡çµ„ç¼ºä¹æ¨™æº–åˆç´„',
                    'api_endpoints': stats.get('api_endpoints', 0)
                })
        
        plan['priority_modules'] = sorted(priority_modules, 
                                        key=lambda x: x['api_endpoints'], 
                                        reverse=True)[:5]
        
        return plan
    
    def _get_coverage_status(self, coverage: float) -> str:
        """ç²å–è¦†è“‹ç‡ç‹€æ…‹"""
        if coverage >= 30:
            return 'excellent'
        elif coverage >= 20:
            return 'good'
        elif coverage >= 10:
            return 'fair'
        else:
            return 'needs_improvement'
    
    def generate_refactoring_tasks(self, analysis: ContractUsageAnalysis) -> List[RefactoringTask]:
        """ç”Ÿæˆé‡æ§‹ä»»å‹™"""
        tasks = []
        
        for opportunity in analysis.improvement_opportunities:
            if opportunity['type'] == 'add_standard_response':
                task = RefactoringTask(
                    file_path=opportunity['file_path'],
                    task_type='add_standard_import',
                    description='æ·»åŠ  APIResponse æ¨™æº–å°å…¥',
                    new_code='from services.aiva_common.schemas import APIResponse',
                    confidence=0.9
                )
                tasks.append(task)
            
            elif opportunity['type'] == 'upgrade_response_format':
                task = RefactoringTask(
                    file_path=opportunity['file_path'],
                    task_type='standardize_response',
                    description='å‡ç´šéŸ¿æ‡‰æ ¼å¼ç‚º APIResponse æ¨™æº–',
                    confidence=0.7
                )
                tasks.append(task)
        
        return tasks
    
    def export_analysis_report(self, analysis: ContractUsageAnalysis, output_path: Path):
        """å°å‡ºåˆ†æå ±å‘Š"""
        improvement_plan = self.generate_improvement_plan(analysis)
        refactoring_tasks = self.generate_refactoring_tasks(analysis)
        
        report = {
            'analysis_summary': asdict(analysis),
            'improvement_plan': improvement_plan,
            'refactoring_tasks': [asdict(task) for task in refactoring_tasks],
            'generated_at': str(Path().cwd()),
            'recommendations': self._generate_recommendations(analysis)
        }
        
        # å°å‡º JSON
        json_output = output_path.with_suffix('.json')
        with open(json_output, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # å°å‡º Markdown
        md_output = output_path.with_suffix('.md')
        with open(md_output, 'w', encoding='utf-8') as f:
            f.write(self._generate_markdown_report(analysis, improvement_plan))
        
        logger.info(f"å ±å‘Šå·²å°å‡º: {json_output}, {md_output}")
    
    def _generate_recommendations(self, analysis: ContractUsageAnalysis) -> List[str]:
        """ç”Ÿæˆå…·é«”å»ºè­°"""
        recommendations = []
        
        if analysis.standard_contract_coverage < 15:
            recommendations.extend([
                'ç«‹å³åœ¨ API æ¨¡çµ„ä¸­æ¨å»£ APIResponse æ¨™æº–',
                'å‰µå»ºåˆç´„ä½¿ç”¨æª¢æŸ¥æ¸…å–®',
                'å»ºç«‹é–‹ç™¼è€…åˆç´„åŸ¹è¨“è¨ˆåŠƒ'
            ])
        
        if analysis.local_model_candidates:
            top_local = analysis.local_model_candidates[0]
            recommendations.append(
                f'è€ƒæ…®å°‡é«˜é »æœ¬åœ°åˆç´„ "{top_local[0]}" (ä½¿ç”¨{top_local[1]}æ¬¡) æ¨™æº–åŒ–'
            )
        
        return recommendations
    
    def _generate_markdown_report(self, analysis: ContractUsageAnalysis, plan: Dict[str, Any]) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼å ±å‘Š"""
        status_emoji = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¡', 
            'fair': 'ğŸŸ ',
            'needs_improvement': 'ğŸ”´'
        }
        
        status = plan['current_status']['status']
        emoji = status_emoji.get(status, 'â“')
        
        report = f"""# AIVA åˆç´„è¦†è“‹ç‡åˆ†æå ±å‘Š

## ğŸ“Š ç•¶å‰ç‹€æ…‹

{emoji} **è¦†è“‹ç‡**: {analysis.standard_contract_coverage:.1f}% ({analysis.files_with_standard_contracts}/{analysis.total_files} æ–‡ä»¶)  
ğŸ“ˆ **ç‹€æ…‹**: {status.replace('_', ' ').title()}  
ğŸ“‚ **æœ¬åœ°æ¨¡å‹**: {analysis.local_model_coverage:.1f}% ({analysis.files_with_local_models} æ–‡ä»¶)

## ğŸ”¥ æœ€å¸¸ç”¨æ¨™æº–åˆç´„

| æ’å | åˆç´„åç¨± | ä½¿ç”¨æ¬¡æ•¸ |
|------|----------|----------|
"""
        
        for i, (contract, count) in enumerate(analysis.most_used_contracts[:5], 1):
            report += f"| {i} | `{contract}` | {count} |\n"
        
        report += """
## ğŸ  æœ¬åœ°åˆç´„å€™é¸ (æ¨™æº–åŒ–æ©Ÿæœƒ)

| æ’å | åˆç´„åç¨± | ä½¿ç”¨æ¬¡æ•¸ |
|------|----------|----------|
"""
        
        for i, (contract, count) in enumerate(analysis.local_model_candidates[:5], 1):
            report += f"| {i} | `{contract}` | {count} |\n"
        
        report += """
## ğŸ¯ ç«‹å³è¡Œå‹•é …

"""
        for item in plan['quick_wins']:
            report += f"- {item}\n"
        
        report += """
## ğŸ“… ä¸­æœŸç›®æ¨™

"""
        for item in plan['medium_term_goals']:
            report += f"- {item}\n"
        
        report += """
## ğŸš€ é•·æœŸè¦åŠƒ

"""
        for item in plan['long_term_objectives']:
            report += f"- {item}\n"
        
        if plan['priority_modules']:
            report += """
## ğŸ¯ å„ªå…ˆè™•ç†æ¨¡çµ„

"""
            for module in plan['priority_modules']:
                report += f"- **{module['module']}**: {module['reason']} ({module['api_endpoints']} API ç«¯é»)\n"
        
        report += """
---
**ç”Ÿæˆå·¥å…·**: AIVA åˆç´„è¦†è“‹ç‡åˆ†æå™¨  
**å»ºè­°**: å®šæœŸé‹è¡Œæ­¤åˆ†æä»¥è¿½è¹¤æ”¹é€²é€²åº¦
"""
        
        return report


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="AIVA åˆç´„è¦†è“‹ç‡æå‡å·¥å…·")
    parser.add_argument("--project-root", default=".", help="é …ç›®æ ¹ç›®éŒ„è·¯å¾‘")
    parser.add_argument("--output", default="reports/contract_coverage_analysis", help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--quick-check", action="store_true", help="å¿«é€Ÿæª¢æŸ¥æ¨¡å¼")
    parser.add_argument("--generate-tasks", action="store_true", help="ç”Ÿæˆé‡æ§‹ä»»å‹™")
    
    args = parser.parse_args()
    
    # å‰µå»ºåˆ†æå™¨
    analyzer = ContractCoverageAnalyzer(Path(args.project_root))
    
    if args.quick_check:
        # å¿«é€Ÿæª¢æŸ¥æ¨¡å¼
        python_files = analyzer.scan_python_files()
        total_files = len(python_files)
        
        files_with_contracts = 0
        for file_path in python_files[:100]:  # åƒ…æª¢æŸ¥å‰100å€‹æ–‡ä»¶
            analysis = analyzer.analyze_file_contracts(file_path)
            if analysis.get('has_standard_imports'):
                files_with_contracts += 1
        
        coverage = (files_with_contracts / min(100, total_files)) * 100
        print(f"ğŸ“Š å¿«é€Ÿæª¢æŸ¥çµæœ: è¦†è“‹ç‡ç´„ {coverage:.1f}%")
        return
    
    # å®Œæ•´åˆ†æ
    analysis = analyzer.run_full_analysis()
    
    # é¡¯ç¤ºçµæœ
    print(f"""
ğŸ“Š AIVA åˆç´„è¦†è“‹ç‡åˆ†æçµæœ
{'=' * 40}

ğŸ“ˆ æ¨™æº–åˆç´„è¦†è“‹ç‡: {analysis.standard_contract_coverage:.1f}%
ğŸ“‚ æœ¬åœ°æ¨¡å‹è¦†è“‹ç‡: {analysis.local_model_coverage:.1f}%
ğŸ“ ç¸½æ–‡ä»¶æ•¸: {analysis.total_files}
âœ… ä½¿ç”¨æ¨™æº–åˆç´„: {analysis.files_with_standard_contracts} æ–‡ä»¶
ğŸ  åŒ…å«æœ¬åœ°æ¨¡å‹: {analysis.files_with_local_models} æ–‡ä»¶

ğŸ”¥ æœ€å¸¸ç”¨æ¨™æº–åˆç´„:
""")
    
    for i, (contract, count) in enumerate(analysis.most_used_contracts[:5], 1):
        print(f"  {i}. {contract:<20} - {count:3d}æ¬¡")
    
    print(f"""
ğŸ’¡ æ”¹é€²æ©Ÿæœƒ: {len(analysis.improvement_opportunities)} å€‹
""")
    
    # å°å‡ºå ±å‘Š
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    analyzer.export_analysis_report(analysis, output_path)
    
    if args.generate_tasks:
        tasks = analyzer.generate_refactoring_tasks(analysis)
        print(f"\nğŸ”§ ç”Ÿæˆ {len(tasks)} å€‹é‡æ§‹ä»»å‹™")
        
        for i, task in enumerate(tasks[:10], 1):
            print(f"  {i}. {task.description} ({task.confidence:.1%} ç½®ä¿¡åº¦)")


if __name__ == "__main__":
    main()