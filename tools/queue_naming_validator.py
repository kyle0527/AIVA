#!/usr/bin/env python3
"""
AIVA éšŠåˆ—å‘½åä¸€è‡´æ€§é©—è­‰å·¥å…·

æ­¤å·¥å…·æƒææ‰€æœ‰ worker ä»£ç¢¼ï¼Œé©—è­‰éšŠåˆ—å‘½åæ˜¯å¦ç¬¦åˆçµ±ä¸€æ¨™æº–ã€‚

æ¨™æº–:
- çµæœéšŠåˆ—: findings.new
- ä»»å‹™éšŠåˆ—: tasks.{module}.{function}
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Set
from dataclasses import dataclass

@dataclass
class QueueUsage:
    """éšŠåˆ—ä½¿ç”¨æƒ…æ³"""
    file_path: str
    line_number: int
    queue_name: str
    queue_type: str  # 'task' or 'result'
    language: str
    context: str

class QueueValidator:
    """éšŠåˆ—å‘½åé©—è­‰å™¨"""
    
    def __init__(self, workspace_root: str):
        self.workspace_root = Path(workspace_root)
        self.queue_usages: List[QueueUsage] = []
        self.expected_result_queue = "findings.new"
        
    def scan_workers(self) -> None:
        """æƒææ‰€æœ‰ worker ç›®éŒ„"""
        print("ğŸ” æƒæ AIVA workers...")
        
        # æƒæç›®éŒ„
        scan_dirs = [
            "services/scan",
            "services/features",
        ]
        
        for scan_dir in scan_dirs:
            dir_path = self.workspace_root / scan_dir
            if dir_path.exists():
                self._scan_directory(dir_path)
                
        print(f"âœ… æƒæå®Œæˆï¼Œæ‰¾åˆ° {len(self.queue_usages)} å€‹éšŠåˆ—ä½¿ç”¨")
    
    def _scan_directory(self, directory: Path) -> None:
        """éæ­¸æƒæç›®éŒ„"""
        for file_path in directory.rglob("*"):
            if file_path.is_file():
                self._scan_file(file_path)
    
    def _scan_file(self, file_path: Path) -> None:
        """æƒæå–®å€‹æª”æ¡ˆ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡æƒææ¨¡å¼
            if file_path.suffix == '.py':
                self._scan_python(file_path, content)
            elif file_path.suffix == '.rs':
                self._scan_rust(file_path, content)
            elif file_path.suffix == '.go':
                self._scan_go(file_path, content)
            elif file_path.suffix in ['.ts', '.js']:
                self._scan_typescript(file_path, content)
                
        except Exception as e:
            # å¿½ç•¥äºŒé€²åˆ¶æª”æ¡ˆæˆ–ç„¡æ³•è®€å–çš„æª”æ¡ˆ
            pass
    
    def _scan_python(self, file_path: Path, content: str) -> None:
        """æƒæ Python æª”æ¡ˆä¸­çš„éšŠåˆ—ä½¿ç”¨"""
        patterns = [
            (r'queue_name\s*=\s*["\']([^"\']+)["\']', 'unknown'),
            (r'result.*queue.*=\s*["\']([^"\']+)["\']', 'result'),
            (r'task.*queue.*=\s*["\']([^"\']+)["\']', 'task'),
            (r'["\']([^"\']*(?:findings|results)[^"\']*)["\']', 'result'),
            (r'["\']([^"\']*tasks\.[^"\']*)["\']', 'task'),
        ]
        
        self._apply_patterns(file_path, content, patterns, 'python')
    
    def _scan_rust(self, file_path: Path, content: str) -> None:
        """æƒæ Rust æª”æ¡ˆä¸­çš„éšŠåˆ—ä½¿ç”¨"""
        patterns = [
            (r'const\s+\w*QUEUE\s*:\s*&str\s*=\s*"([^"]+)"', 'unknown'),
            (r'const\s+RESULT_QUEUE\s*:\s*&str\s*=\s*"([^"]+)"', 'result'),
            (r'const\s+FINDING_QUEUE\s*:\s*&str\s*=\s*"([^"]+)"', 'result'),
            (r'const\s+TASK_QUEUE\s*:\s*&str\s*=\s*"([^"]+)"', 'task'),
            (r'"([^"]*(?:findings|results)[^"]*)"', 'result'),
            (r'"([^"]*tasks\.[^"]*)"', 'task'),
        ]
        
        self._apply_patterns(file_path, content, patterns, 'rust')
    
    def _scan_go(self, file_path: Path, content: str) -> None:
        """æƒæ Go æª”æ¡ˆä¸­çš„éšŠåˆ—ä½¿ç”¨"""
        patterns = [
            (r'queueName\s*:=\s*"([^"]+)"', 'unknown'),
            (r'resultQueue\s*:=\s*"([^"]+)"', 'result'),
            (r'taskQueue\s*:=\s*"([^"]+)"', 'task'),
            (r'"([^"]*(?:findings|results)[^"]*)"', 'result'),
            (r'"([^"]*tasks\.[^"]*)"', 'task'),
        ]
        
        self._apply_patterns(file_path, content, patterns, 'go')
    
    def _scan_typescript(self, file_path: Path, content: str) -> None:
        """æƒæ TypeScript/JavaScript æª”æ¡ˆä¸­çš„éšŠåˆ—ä½¿ç”¨"""
        patterns = [
            (r'const\s+\w*QUEUE\s*=\s*["\']([^"\']+)["\']', 'unknown'),
            (r'const\s+RESULT_QUEUE\s*=\s*["\']([^"\']+)["\']', 'result'),
            (r'const\s+TASK_QUEUE\s*=\s*["\']([^"\']+)["\']', 'task'),
            (r'resultQueue\s*=\s*["\']([^"\']+)["\']', 'result'),
            (r'["\']([^"\']*(?:findings|results)[^"\']*)["\']', 'result'),
            (r'["\']([^"\']*tasks\.[^"\']*)["\']', 'task'),
        ]
        
        self._apply_patterns(file_path, content, patterns, 'typescript')
    
    def _apply_patterns(self, file_path: Path, content: str, patterns: List[Tuple[str, str]], language: str) -> None:
        """æ‡‰ç”¨æ­£å‰‡è¡¨é”å¼æ¨¡å¼"""
        lines = content.split('\n')
        
        for pattern, queue_type in patterns:
            for match in re.finditer(pattern, content, re.IGNORECASE):
                queue_name = match.group(1)
                
                # è·³éæ˜é¡¯ä¸æ˜¯éšŠåˆ—åçš„åŒ¹é…
                if self._is_valid_queue_name(queue_name):
                    line_number = content[:match.start()].count('\n') + 1
                    context = lines[line_number - 1].strip() if line_number <= len(lines) else ""
                    
                    self.queue_usages.append(QueueUsage(
                        file_path=str(file_path.relative_to(self.workspace_root)),
                        line_number=line_number,
                        queue_name=queue_name,
                        queue_type=queue_type,
                        language=language,
                        context=context
                    ))
    
    def _is_valid_queue_name(self, queue_name: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„éšŠåˆ—å"""
        if not queue_name or len(queue_name) < 3:
            return False
            
        # è·³éæ˜é¡¯ä¸æ˜¯éšŠåˆ—åçš„å­—ä¸²
        invalid_patterns = [
            r'^[A-Z_]+$',  # å…¨å¤§å¯«å¸¸é‡
            r'^\w+$',      # å–®å€‹å–®è©
            r'^/.*',       # è·¯å¾‘
            r'^https?://', # URL
        ]
        
        for pattern in invalid_patterns:
            if re.match(pattern, queue_name):
                return False
        
        return True
    
    def validate_naming(self) -> Dict[str, List[QueueUsage]]:
        """é©—è­‰éšŠåˆ—å‘½åä¸€è‡´æ€§"""
        print("\nğŸ“‹ é©—è­‰éšŠåˆ—å‘½åä¸€è‡´æ€§...")
        
        issues = {
            'incorrect_result_queues': [],
            'non_standard_task_queues': [],
            'duplicate_queues': [],
            'compliant_queues': []
        }
        
        # æŒ‰éšŠåˆ—ååˆ†çµ„
        queue_groups = {}
        for usage in self.queue_usages:
            if usage.queue_name not in queue_groups:
                queue_groups[usage.queue_name] = []
            queue_groups[usage.queue_name].append(usage)
        
        for queue_name, usages in queue_groups.items():
            result_usages = [u for u in usages if u.queue_type == 'result']
            task_usages = [u for u in usages if u.queue_type == 'task']
            
            # æª¢æŸ¥çµæœéšŠåˆ—
            if result_usages:
                if queue_name != self.expected_result_queue:
                    issues['incorrect_result_queues'].extend(result_usages)
                else:
                    issues['compliant_queues'].extend(result_usages)
            
            # æª¢æŸ¥ä»»å‹™éšŠåˆ—
            if task_usages:
                if not queue_name.startswith('tasks.'):
                    issues['non_standard_task_queues'].extend(task_usages)
                else:
                    issues['compliant_queues'].extend(task_usages)
            
            # æª¢æŸ¥é‡è¤‡ä½¿ç”¨
            if len(usages) > 1:
                issues['duplicate_queues'].extend(usages)
        
        return issues
    
    def generate_report(self, issues: Dict[str, List[QueueUsage]]) -> str:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        report = []
        report.append("# AIVA éšŠåˆ—å‘½åä¸€è‡´æ€§å ±å‘Š")
        report.append("=" * 50)
        report.append("")
        
        # çµ±è¨ˆä¿¡æ¯
        total_usages = len(self.queue_usages)
        compliant_count = len(issues['compliant_queues'])
        issue_count = total_usages - compliant_count
        
        report.append(f"ğŸ“Š **çµ±è¨ˆä¿¡æ¯**")
        report.append(f"- ç¸½éšŠåˆ—ä½¿ç”¨æ•¸: {total_usages}")
        report.append(f"- ç¬¦åˆæ¨™æº–: {compliant_count}")
        report.append(f"- éœ€è¦ä¿®å¾©: {issue_count}")
        report.append(f"- åˆè¦ç‡: {compliant_count/total_usages*100:.1f}%" if total_usages > 0 else "- åˆè¦ç‡: N/A")
        report.append("")
        
        # å•é¡Œè©³æƒ…
        if issues['incorrect_result_queues']:
            report.append("âŒ **ä¸æ­£ç¢ºçš„çµæœéšŠåˆ—**")
            report.append(f"æ¨™æº–çµæœéšŠåˆ—æ‡‰ç‚º: `{self.expected_result_queue}`")
            report.append("")
            for usage in issues['incorrect_result_queues']:
                report.append(f"- ğŸ“ `{usage.file_path}:{usage.line_number}`")
                report.append(f"  - éšŠåˆ—å: `{usage.queue_name}` âŒ")
                report.append(f"  - èªè¨€: {usage.language}")
                report.append(f"  - ä¸Šä¸‹æ–‡: `{usage.context}`")
                report.append("")
        
        if issues['non_standard_task_queues']:
            report.append("âŒ **ä¸ç¬¦åˆæ¨™æº–çš„ä»»å‹™éšŠåˆ—**")
            report.append("ä»»å‹™éšŠåˆ—æ‡‰éµå¾ªæ ¼å¼: `tasks.{module}.{function}`")
            report.append("")
            for usage in issues['non_standard_task_queues']:
                report.append(f"- ğŸ“ `{usage.file_path}:{usage.line_number}`")
                report.append(f"  - éšŠåˆ—å: `{usage.queue_name}` âŒ")
                report.append(f"  - èªè¨€: {usage.language}")
                report.append(f"  - ä¸Šä¸‹æ–‡: `{usage.context}`")
                report.append("")
        
        # åˆè¦éšŠåˆ—
        if issues['compliant_queues']:
            report.append("âœ… **ç¬¦åˆæ¨™æº–çš„éšŠåˆ—**")
            report.append("")
            
            # æŒ‰éšŠåˆ—ååˆ†çµ„é¡¯ç¤º
            compliant_groups = {}
            for usage in issues['compliant_queues']:
                if usage.queue_name not in compliant_groups:
                    compliant_groups[usage.queue_name] = []
                compliant_groups[usage.queue_name].append(usage)
            
            for queue_name, usages in compliant_groups.items():
                report.append(f"**éšŠåˆ—: `{queue_name}`**")
                for usage in usages:
                    report.append(f"- ğŸ“ `{usage.file_path}:{usage.line_number}` ({usage.language})")
                report.append("")
        
        # ä¿®å¾©å»ºè­°
        report.append("ğŸ”§ **ä¿®å¾©å»ºè­°**")
        report.append("")
        
        if issues['incorrect_result_queues']:
            report.append("1. **çµæœéšŠåˆ—çµ±ä¸€åŒ–**:")
            unique_files = set(u.file_path for u in issues['incorrect_result_queues'])
            for file_path in unique_files:
                file_usages = [u for u in issues['incorrect_result_queues'] if u.file_path == file_path]
                old_queues = set(u.queue_name for u in file_usages)
                report.append(f"   - `{file_path}`: {', '.join(old_queues)} â†’ `{self.expected_result_queue}`")
            report.append("")
        
        if issues['non_standard_task_queues']:
            report.append("2. **ä»»å‹™éšŠåˆ—æ¨™æº–åŒ–**:")
            for usage in issues['non_standard_task_queues']:
                suggested = self._suggest_task_queue_name(usage)
                report.append(f"   - `{usage.file_path}`: `{usage.queue_name}` â†’ `{suggested}`")
            report.append("")
        
        report.append("3. **ç’°å¢ƒè®Šæ•¸æ”¯æ´**:")
        report.append("   - æ‰€æœ‰ workers æ‡‰æ”¯æ´ `AIVA_RESULT_QUEUE` å’Œ `AIVA_TASK_QUEUE` ç’°å¢ƒè®Šæ•¸")
        report.append("   - é è¨­å€¼æ‡‰ç¬¦åˆå‘½åæ¨™æº–")
        report.append("")
        
        return "\n".join(report)
    
    def _suggest_task_queue_name(self, usage: QueueUsage) -> str:
        """å»ºè­°ä»»å‹™éšŠåˆ—åç¨±"""
        # ç°¡å–®çš„å»ºè­°é‚è¼¯
        if 'authn' in usage.file_path:
            return 'tasks.function.authn'
        elif 'ssrf' in usage.file_path:
            return 'tasks.function.ssrf'
        elif 'sast' in usage.file_path:
            return 'tasks.function.sast'
        elif 'cspm' in usage.file_path:
            return 'tasks.function.cspm'
        elif 'scan' in usage.file_path:
            return 'tasks.scan.dynamic'
        else:
            return 'tasks.unknown.function'

def main():
    """ä¸»ç¨‹åº"""
    workspace_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    print("ğŸš€ AIVA éšŠåˆ—å‘½åä¸€è‡´æ€§é©—è­‰å·¥å…·")
    print("=" * 50)
    print(f"å·¥ä½œå€: {workspace_root}")
    print()
    
    validator = QueueValidator(workspace_root)
    validator.scan_workers()
    issues = validator.validate_naming()
    report = validator.generate_report(issues)
    
    # è¼¸å‡ºå ±å‘Š
    print(report)
    
    # ä¿å­˜å ±å‘Šåˆ°æª”æ¡ˆ
    report_path = os.path.join(workspace_root, "reports", "queue_naming_validation.md")
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ å®Œæ•´å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    # è¿”å›é€€å‡ºä»£ç¢¼
    total_issues = sum(len(issues[key]) for key in issues if key != 'compliant_queues')
    if total_issues > 0:
        print(f"\nâŒ ç™¼ç¾ {total_issues} å€‹éœ€è¦ä¿®å¾©çš„å•é¡Œ")
        return 1
    else:
        print("\nâœ… æ‰€æœ‰éšŠåˆ—å‘½åéƒ½ç¬¦åˆæ¨™æº–ï¼")
        return 0

if __name__ == "__main__":
    exit(main())