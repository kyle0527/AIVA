"""
ğŸ¤– æ”»æ“Šæ¨¡å¼è¨“ç·´å™¨ - Attack Pattern Trainer
ä½¿ç”¨çœŸå¯¦æ”»æ“Šæ•¸æ“šè¨“ç·´ AI æ¨¡å‹è­˜åˆ¥å®‰å…¨å¨è„…

åŠŸèƒ½:
1. åŸºæ–¼çœŸå¯¦ OWASP æ”»æ“Šæ—¥èªŒè¨“ç·´æ¨¡å‹
2. å­¸ç¿’ 8 ç¨®ä¸»è¦æ”»æ“Šæ¨¡å¼
3. å¯¦æ™‚å¨è„…æª¢æ¸¬å’Œåˆ†é¡
4. ç”Ÿæˆé˜²ç¦¦å»ºè­°
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)


class AttackPatternTrainer:
    """æ”»æ“Šæ¨¡å¼è¨“ç·´å™¨"""
    
    # æ”»æ“Šé¡å‹åˆ° ID çš„æ˜ å°„
    ATTACK_TYPES = {
        'SQL Injection': 0,
        'XSS Attack': 1,
        'Authentication Bypass': 2,
        'Path Traversal': 3,
        'File Upload Attack': 4,
        'Error-Based Attack': 5,
        'Parameter Pollution': 6,
        'Blocked Activity': 7
    }
    
    def __init__(self):
        """åˆå§‹åŒ–è¨“ç·´å™¨"""
        self.training_data = None
        self.model_weights = None
        self.attack_vectors = []
        self.labels = []
        self.training_history = []
        
    def load_training_data(self, data_file: str = "_out/attack_training_data.json") -> bool:
        """è¼‰å…¥è¨“ç·´æ•¸æ“š"""
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                self.training_data = json.load(f)
            
            logger.info(f"âœ“ è¼‰å…¥è¨“ç·´æ•¸æ“š: {data_file}")
            logger.info(f"  - æ”»æ“Šé¡å‹: {self.training_data['metadata']['attack_types']}")
            logger.info(f"  - ç¸½æ”»æ“Šæ•¸: {self.training_data['metadata']['total_attacks']}")
            logger.info(f"  - æˆåŠŸç‡: {self.training_data['metadata']['success_rate']:.2f}%")
            
            return True
        except Exception as e:
            logger.error(f"âœ— è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def prepare_features(self) -> np.ndarray:
        """æº–å‚™ç‰¹å¾µå‘é‡"""
        logger.info("ğŸ”§ æº–å‚™ç‰¹å¾µå‘é‡...")
        
        # ç‚ºæ¯ç¨®æ”»æ“Šé¡å‹å‰µå»ºç‰¹å¾µå‘é‡
        for attack_type, type_id in self.ATTACK_TYPES.items():
            if attack_type in self.training_data['attack_patterns']:
                pattern_data = self.training_data['attack_patterns'][attack_type]
                
                # ç‰¹å¾µ: [é »ç‡, æ•¸é‡æ­¸ä¸€åŒ–, æ¨£æœ¬æ•¸é‡, é¡å‹ID]
                features = [
                    pattern_data['frequency'],
                    pattern_data['count'] / self.training_data['metadata']['total_attacks'],
                    len(pattern_data['samples']) / 10.0,  # æ­¸ä¸€åŒ–åˆ° 0-1
                    type_id / len(self.ATTACK_TYPES)
                ]
                
                self.attack_vectors.append(features)
                self.labels.append(type_id)
        
        logger.info(f"âœ“ æº–å‚™äº† {len(self.attack_vectors)} å€‹ç‰¹å¾µå‘é‡")
        return np.array(self.attack_vectors)
    
    def train_model(self, epochs: int = 100, learning_rate: float = 0.01) -> Dict:
        """è¨“ç·´ç°¡å–®çš„æ”»æ“Šæª¢æ¸¬æ¨¡å‹"""
        logger.info(f"ğŸ“ é–‹å§‹è¨“ç·´æ¨¡å‹ (epochs={epochs}, lr={learning_rate})...")
        
        features = np.array(self.attack_vectors)
        labels = np.array(self.labels)
        
        # åˆå§‹åŒ–æ¬Šé‡ (ç°¡å–®ç·šæ€§æ¨¡å‹)
        n_features = features.shape[1]
        self.model_weights = np.random.randn(n_features, len(self.ATTACK_TYPES)) * 0.01
        bias = np.zeros(len(self.ATTACK_TYPES))
        
        # è¨“ç·´å¾ªç’°
        for epoch in range(epochs):
            # å‰å‘å‚³æ’­
            logits = np.dot(features, self.model_weights) + bias
            predictions = self._softmax(logits)
            
            # è¨ˆç®—æå¤± (äº¤å‰ç†µ)
            loss = -np.mean(np.log(predictions[range(len(labels)), labels] + 1e-10))
            
            # è¨ˆç®—æº–ç¢ºç‡
            pred_labels = np.argmax(predictions, axis=1)
            accuracy = np.mean(pred_labels == labels)
            
            # è¨˜éŒ„è¨“ç·´æ­·å²
            if epoch % 10 == 0:
                self.training_history.append({
                    'epoch': epoch,
                    'loss': float(loss),
                    'accuracy': float(accuracy)
                })
                logger.info(f"  Epoch {epoch:3d} | Loss: {loss:.4f} | Acc: {accuracy:.2%}")
            
            # ç°¡å–®æ¢¯åº¦ä¸‹é™ (å¯¦éš›æ‡‰ä½¿ç”¨åå‘å‚³æ’­)
            grad = (predictions - self._one_hot(labels, len(self.ATTACK_TYPES))) / len(labels)
            self.model_weights -= learning_rate * np.dot(features.T, grad)
            bias -= learning_rate * np.sum(grad, axis=0)
        
        logger.info("âœ“ è¨“ç·´å®Œæˆ!")
        
        return {
            'final_loss': float(loss),
            'final_accuracy': float(accuracy),
            'epochs': epochs,
            'training_samples': len(labels)
        }
    
    def predict_attack_type(self, features: List[float]) -> Tuple[str, float]:
        """é æ¸¬æ”»æ“Šé¡å‹"""
        if self.model_weights is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´!")
        
        features_array = np.array(features).reshape(1, -1)
        logits = np.dot(features_array, self.model_weights)
        predictions = self._softmax(logits)[0]
        
        predicted_id = np.argmax(predictions)
        confidence = predictions[predicted_id]
        
        # æ‰¾åˆ°å°æ‡‰çš„æ”»æ“Šé¡å‹
        attack_type = list(self.ATTACK_TYPES.keys())[
            list(self.ATTACK_TYPES.values()).index(predicted_id)
        ]
        
        return attack_type, float(confidence)
    
    def save_model(self, output_file: str = "_out/attack_detection_model.json"):
        """ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'metadata': {
                'trained_at': datetime.now().isoformat(),
                'attack_types': self.ATTACK_TYPES,
                'training_samples': len(self.attack_vectors)
            },
            'weights': self.model_weights.tolist() if self.model_weights is not None else None,
            'training_history': self.training_history,
            'attack_vectors': self.attack_vectors,
            'labels': self.labels
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(model_data, f, indent=2)
        
        logger.info(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {output_file}")
        return str(output_path)
    
    def generate_defense_recommendations(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆé˜²ç¦¦å»ºè­°"""
        recommendations = {}
        
        if not self.training_data:
            return recommendations
        
        for attack_type, pattern_data in self.training_data['attack_patterns'].items():
            count = pattern_data['count']
            
            if attack_type == 'SQL Injection':
                recommendations[attack_type] = [
                    "ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ (Prepared Statements)",
                    "å¯¦æ–½ ORM (Object-Relational Mapping)",
                    "å•Ÿç”¨ SQL æ³¨å…¥ WAF è¦å‰‡",
                    f"å„ªå…ˆç´š: {'é«˜' if count > 50 else 'ä¸­'} (æª¢æ¸¬åˆ° {count} æ¬¡)"
                ]
            elif attack_type == 'XSS Attack':
                recommendations[attack_type] = [
                    "å¯¦æ–½ Content Security Policy (CSP)",
                    "è¼¸å‡ºç·¨ç¢¼æ‰€æœ‰ç”¨æˆ¶è¼¸å…¥",
                    "ä½¿ç”¨ HTTPOnly å’Œ Secure cookies",
                    f"å„ªå…ˆç´š: {'é«˜' if count > 30 else 'ä¸­'} (æª¢æ¸¬åˆ° {count} æ¬¡)"
                ]
            elif attack_type == 'Authentication Bypass':
                recommendations[attack_type] = [
                    "å¼·åˆ¶æ‰€æœ‰ç«¯é»é€²è¡Œèº«ä»½é©—è­‰",
                    "å¯¦æ–½ JWT token é©—è­‰",
                    "å•Ÿç”¨å¤šå› ç´ é©—è­‰ (MFA)",
                    "å¯¦æ–½é€Ÿç‡é™åˆ¶",
                    f"å„ªå…ˆç´š: {'é«˜' if count > 100 else 'ä¸­'} (æª¢æ¸¬åˆ° {count} æ¬¡)"
                ]
            elif attack_type == 'Path Traversal':
                recommendations[attack_type] = [
                    "é©—è­‰å’Œæ¸…ç†æ‰€æœ‰æ–‡ä»¶è·¯å¾‘",
                    "ä½¿ç”¨ç™½åå–®é™åˆ¶å¯è¨ªå•è·¯å¾‘",
                    "å¯¦æ–½ chroot ç’°å¢ƒ",
                    f"å„ªå…ˆç´š: {'é«˜' if count > 20 else 'ä¸­'} (æª¢æ¸¬åˆ° {count} æ¬¡)"
                ]
            elif attack_type == 'File Upload Attack':
                recommendations[attack_type] = [
                    "é©—è­‰æ–‡ä»¶é¡å‹å’Œæ“´å±•å",
                    "æƒæä¸Šå‚³æ–‡ä»¶çš„æƒ¡æ„å…§å®¹",
                    "é™åˆ¶æ–‡ä»¶å¤§å°",
                    "éš”é›¢ä¸Šå‚³æ–‡ä»¶å­˜å„²",
                    f"å„ªå…ˆç´š: {'é«˜' if count > 10 else 'ä½'} (æª¢æ¸¬åˆ° {count} æ¬¡)"
                ]
        
        return recommendations
    
    @staticmethod
    def _softmax(x: np.ndarray) -> np.ndarray:
        """Softmax æ¿€æ´»å‡½æ•¸"""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)
    
    @staticmethod
    def _one_hot(labels: np.ndarray, num_classes: int) -> np.ndarray:
        """One-hot ç·¨ç¢¼"""
        one_hot = np.zeros((len(labels), num_classes))
        one_hot[range(len(labels)), labels] = 1
        return one_hot


def main():
    """ä¸»ç¨‹åº"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ğŸ¤– æ”»æ“Šæ¨¡å¼è¨“ç·´å™¨')
    parser.add_argument('--data', '-d',
                       default='_out/attack_training_data.json',
                       help='è¨“ç·´æ•¸æ“šæ–‡ä»¶')
    parser.add_argument('--epochs', '-e', type=int, default=100,
                       help='è¨“ç·´è¼ªæ•¸ (é è¨­: 100)')
    parser.add_argument('--learning-rate', '-lr', type=float, default=0.01,
                       help='å­¸ç¿’ç‡ (é è¨­: 0.01)')
    parser.add_argument('--output', '-o',
                       default='_out/attack_detection_model.json',
                       help='æ¨¡å‹è¼¸å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸ¤– æ”»æ“Šæ¨¡å¼è¨“ç·´å™¨ - Attack Pattern Trainer")
    print("=" * 70)
    print()
    
    # åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = AttackPatternTrainer()
    
    # è¼‰å…¥æ•¸æ“š
    print("ğŸ“¥ è¼‰å…¥è¨“ç·´æ•¸æ“š...\n")
    if not trainer.load_training_data(args.data):
        print("âŒ ç„¡æ³•è¼‰å…¥è¨“ç·´æ•¸æ“š")
        return
    
    # æº–å‚™ç‰¹å¾µ
    print("\nğŸ”§ æº–å‚™ç‰¹å¾µå‘é‡...\n")
    trainer.prepare_features()
    
    # è¨“ç·´æ¨¡å‹
    print(f"\nğŸ“ è¨“ç·´æ¨¡å‹ (epochs={args.epochs})...\n")
    results = trainer.train_model(epochs=args.epochs, learning_rate=args.learning_rate)
    
    print(f"\nâœ“ è¨“ç·´çµæœ:")
    print(f"  - æœ€çµ‚æå¤±: {results['final_loss']:.4f}")
    print(f"  - æœ€çµ‚æº–ç¢ºç‡: {results['final_accuracy']:.2%}")
    print(f"  - è¨“ç·´æ¨£æœ¬: {results['training_samples']}")
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹...\n")
    model_file = trainer.save_model(args.output)
    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜è‡³: {model_file}")
    
    # ç”Ÿæˆé˜²ç¦¦å»ºè­°
    print(f"\nğŸ’¡ ç”Ÿæˆé˜²ç¦¦å»ºè­°...\n")
    recommendations = trainer.generate_defense_recommendations()
    
    print("=" * 70)
    print("ğŸ›¡ï¸ é˜²ç¦¦å»ºè­°")
    print("=" * 70)
    
    for attack_type, recs in recommendations.items():
        print(f"\nã€{attack_type}ã€‘")
        for rec in recs:
            print(f"  â€¢ {rec}")
    
    print("\n" + "=" * 70)
    print("âœ“ è¨“ç·´å®Œæˆ!")
    print("=" * 70)


if __name__ == "__main__":
    main()
