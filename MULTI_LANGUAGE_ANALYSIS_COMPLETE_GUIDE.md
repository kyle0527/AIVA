# AIVA å¤šèªè¨€èƒ½åŠ›åˆ†ææ•´åˆ - å®Œæ•´å¯¦æ–½æŒ‡å—

**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-11-16  
**é©ç”¨å°è±¡**: é–‹ç™¼è€…ã€ç³»çµ±ç¶­è­·è€…  
**å‰ç½®æ¢ä»¶**: Python 3.10+, AIVA å°ˆæ¡ˆç’°å¢ƒ

---

## ğŸ“‹ ç›®éŒ„

1. [ç’°å¢ƒæº–å‚™](#1-ç’°å¢ƒæº–å‚™)
2. [ç¾æœ‰åŸºç¤è¨­æ–½ç¢ºèª](#2-ç¾æœ‰åŸºç¤è¨­æ–½ç¢ºèª)
3. [å¯¦æ–½æ•´åˆ](#3-å¯¦æ–½æ•´åˆ)
4. [æ¸¬è©¦é©—è­‰](#4-æ¸¬è©¦é©—è­‰)
5. [ä½¿ç”¨ç¯„ä¾‹](#5-ä½¿ç”¨ç¯„ä¾‹)
6. [å•é¡Œæ’æŸ¥](#6-å•é¡Œæ’æŸ¥)
7. [æ“´å±•æŒ‡å—](#7-æ“´å±•æŒ‡å—)

---

## 1. ç’°å¢ƒæº–å‚™

### 1.1 ç¢ºèªå°ˆæ¡ˆçµæ§‹

```bash
# é€²å…¥ AIVA å°ˆæ¡ˆæ ¹ç›®éŒ„
cd C:\D\fold7\AIVA-git

# ç¢ºèªç›®éŒ„çµæ§‹
tree /F services\core\aiva_core\internal_exploration
```

**é æœŸè¼¸å‡º**:
```
services\core\aiva_core\internal_exploration\
â”œâ”€â”€ __init__.py
â”œâ”€â”€ README.md
â”œâ”€â”€ capability_analyzer.py
â”œâ”€â”€ language_extractors.py     # â† é—œéµæ–‡ä»¶
â””â”€â”€ module_explorer.py
```

### 1.2 å•Ÿå‹•è™›æ“¬ç’°å¢ƒ

```powershell
# å¦‚æœå·²æœ‰è™›æ“¬ç’°å¢ƒ
.\.venv\Scripts\Activate.ps1

# ç¢ºèª Python ç‰ˆæœ¬
python --version  # æ‡‰é¡¯ç¤º 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
```

### 1.3 æª¢æŸ¥ä¾è³´

```bash
# ç¢ºèªå¿…è¦çš„ Python å¥—ä»¶
python -c "import ast, re, pathlib, logging; print('âœ… æ‰€æœ‰ä¾è³´å·²å®‰è£')"
```

---

## 2. ç¾æœ‰åŸºç¤è¨­æ–½ç¢ºèª

### 2.1 é©—è­‰ language_extractors.py å­˜åœ¨

```bash
# æª¢æŸ¥æ–‡ä»¶å­˜åœ¨
if (Test-Path "services\core\aiva_core\internal_exploration\language_extractors.py") { 
    echo "âœ… language_extractors.py å­˜åœ¨" 
} else { 
    echo "âŒ æ–‡ä»¶ä¸å­˜åœ¨,è«‹å…ˆå‰µå»º" 
}
```

### 2.2 æª¢æŸ¥æå–å™¨å¯¦ç¾

```python
# é©—è­‰è…³æœ¬: check_extractors.py
from services.core.aiva_core.internal_exploration.language_extractors import (
    get_extractor,
    GoExtractor,
    RustExtractor,
    TypeScriptExtractor
)

# æ¸¬è©¦æ¯å€‹æå–å™¨
extractors = {
    "go": GoExtractor(),
    "rust": RustExtractor(),
    "typescript": TypeScriptExtractor(),
    "javascript": TypeScriptExtractor()
}

for lang, extractor in extractors.items():
    print(f"âœ… {lang.upper()} æå–å™¨å·²åŠ è¼‰: {extractor.__class__.__name__}")

# æ¸¬è©¦å·¥å» å‡½æ•¸
for lang in ["go", "rust", "typescript", "javascript"]:
    ext = get_extractor(lang)
    if ext:
        print(f"âœ… get_extractor('{lang}') è¿”å›: {ext.__class__.__name__}")
    else:
        print(f"âŒ get_extractor('{lang}') è¿”å› None")
```

**åŸ·è¡Œé©—è­‰**:
```bash
python -c "from services.core.aiva_core.internal_exploration.language_extractors import get_extractor; print('âœ… language_extractors å¯å°å…¥')"
```

### 2.3 æª¢æŸ¥ module_explorer.py å¤šèªè¨€æ”¯æ´

```bash
# æª¢æŸ¥æ–‡ä»¶æƒæé…ç½®
grep -A 10 "file_extensions" services/core/aiva_core/internal_exploration/module_explorer.py
```

**é æœŸè¼¸å‡º**:
```python
self.file_extensions = {
    "python": "*.py",
    "go": "*.go",
    "rust": "*.rs",
    "typescript": "*.ts",
    "javascript": "*.js"
}
```

---

## 3. å¯¦æ–½æ•´åˆ

### 3.1 å‚™ä»½åŸå§‹æ–‡ä»¶

```bash
# å‰µå»ºå‚™ä»½
cp services\core\aiva_core\internal_exploration\capability_analyzer.py services\core\aiva_core\internal_exploration\capability_analyzer.py.backup

# ç¢ºèªå‚™ä»½æˆåŠŸ
if (Test-Path "services\core\aiva_core\internal_exploration\capability_analyzer.py.backup") {
    echo "âœ… å‚™ä»½å®Œæˆ"
}
```

### 3.2 ä¿®æ”¹ capability_analyzer.py

**æ­¥é©Ÿ 1: æ·»åŠ å°å…¥**

åœ¨æ–‡ä»¶é ‚éƒ¨ (ç´„ç¬¬ 10-15 è¡Œ) æ·»åŠ :

```python
# åŸæœ‰å°å…¥
import ast
import logging
from pathlib import Path
from typing import Any

# â† åœ¨é€™è£¡æ·»åŠ æ–°å°å…¥
from .language_extractors import get_extractor

logger = logging.getLogger(__name__)
```

**å®Œæ•´å‘½ä»¤**:
```python
# ä½¿ç”¨ç·¨è¼¯å™¨æ‰“é–‹
code services\core\aiva_core\internal_exploration\capability_analyzer.py

# æˆ–ä½¿ç”¨ sed (PowerShell)
$content = Get-Content services\core\aiva_core\internal_exploration\capability_analyzer.py -Raw
$content = $content -replace "from typing import Any\n\nlogger", "from typing import Any`n`nfrom .language_extractors import get_extractor`n`nlogger"
Set-Content services\core\aiva_core\internal_exploration\capability_analyzer.py $content
```

**æ­¥é©Ÿ 2: æ·»åŠ èªè¨€æª¢æ¸¬æ–¹æ³•**

åœ¨ `_extract_capabilities_from_file` æ–¹æ³•ä¹‹å‰æ·»åŠ  (ç´„ç¬¬ 79 è¡Œ):

```python
    def _detect_language(self, file_path: Path) -> str:
        """æª¢æ¸¬æ–‡ä»¶èªè¨€
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘
            
        Returns:
            èªè¨€åç¨±: python, go, rust, typescript, javascript
        """
        suffix = file_path.suffix.lower()
        language_map = {
            ".py": "python",
            ".go": "go",
            ".rs": "rust",
            ".ts": "typescript",
            ".js": "javascript"
        }
        return language_map.get(suffix, "unknown")
```

**æ­¥é©Ÿ 3: é‡æ§‹åŸæœ‰æ–¹æ³•**

æ‰¾åˆ° `async def _extract_capabilities_from_file` æ–¹æ³•,æ›¿æ›ç‚º:

```python
    async def _extract_capabilities_from_file(self, file_path: Path, module: str) -> list[dict]:
        """å¾æ–‡ä»¶ä¸­æå–èƒ½åŠ› (æ”¯æ´å¤šèªè¨€)
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘ (.py/.go/.rs/.ts/.js)
            module: æ‰€å±¬æ¨¡çµ„åç¨±
            
        Returns:
            èƒ½åŠ›åˆ—è¡¨
        """
        # æ ¹æ“šå‰¯æª”åé¸æ“‡æå–å™¨
        language = self._detect_language(file_path)
        
        if language == "python":
            return self._extract_python_capabilities(file_path, module)
        else:
            # ä½¿ç”¨ language_extractors è™•ç†é Python èªè¨€
            return self._extract_non_python_capabilities(file_path, module, language)
```

**æ­¥é©Ÿ 4: é‡å‘½ååŸæœ‰ Python æå–é‚è¼¯**

å°‡åŸæœ‰çš„æå–é‚è¼¯ç§»åˆ°æ–°æ–¹æ³• `_extract_python_capabilities`:

```python
    def _extract_python_capabilities(self, file_path: Path, module: str) -> list[dict]:
        """å¾ Python æ–‡ä»¶æå–èƒ½åŠ› (ä½¿ç”¨ AST)
        
        Args:
            file_path: Python æ–‡ä»¶è·¯å¾‘
            module: æ‰€å±¬æ¨¡çµ„åç¨±
            
        Returns:
            èƒ½åŠ›åˆ—è¡¨
        """
        capabilities = []
        
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
                tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if self._has_capability_decorator(node):
                        cap = self._extract_capability_info(node, file_path, module)
                        capabilities.append(cap)
            
            if capabilities:
                logger.debug(f"  Found {len(capabilities)} Python capabilities in {file_path.name}")
            
        except SyntaxError as e:
            logger.warning(f"  Syntax error in {file_path}: {e}")
        except Exception as e:
            logger.error(f"  Failed to parse {file_path}: {e}")
        
        return capabilities
```

**æ­¥é©Ÿ 5: æ·»åŠ é Python æå–æ–¹æ³•**

```python
    def _extract_non_python_capabilities(
        self, 
        file_path: Path, 
        module: str,
        language: str
    ) -> list[dict]:
        """å¾é Python æ–‡ä»¶æå–èƒ½åŠ› (ä½¿ç”¨ language_extractors)
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘
            module: æ‰€å±¬æ¨¡çµ„åç¨±
            language: èªè¨€åç¨±
            
        Returns:
            èƒ½åŠ›åˆ—è¡¨
        """
        try:
            # ç²å–å°æ‡‰èªè¨€çš„æå–å™¨
            extractor = get_extractor(language)
            if not extractor:
                logger.warning(f"  No extractor available for language: {language}")
                return []
            
            # è®€å–æ–‡ä»¶å…§å®¹
            with open(file_path, encoding="utf-8") as f:
                content = f.read()
            
            # ä½¿ç”¨æå–å™¨æå–èƒ½åŠ›
            capabilities = extractor.extract_capabilities(content, str(file_path))
            
            # æ·»åŠ  module ä¿¡æ¯
            for cap in capabilities:
                if "module" not in cap or not cap["module"]:
                    cap["module"] = module
            
            if capabilities:
                logger.debug(f"  Found {len(capabilities)} {language} capabilities in {file_path.name}")
            
            return capabilities
            
        except Exception as e:
            logger.error(f"  Failed to extract from {file_path}: {e}")
            return []
```

### 3.3 é©—è­‰èªæ³•

```bash
# æª¢æŸ¥ Python èªæ³•éŒ¯èª¤
python -m py_compile services/core/aiva_core/internal_exploration/capability_analyzer.py

# å¦‚æœç„¡è¼¸å‡º,è¡¨ç¤ºèªæ³•æ­£ç¢º
echo $?  # æ‡‰è¼¸å‡º 0
```

---

## 4. æ¸¬è©¦é©—è­‰

### 4.1 å‰µå»ºæ¸¬è©¦è…³æœ¬

å‰µå»º `test_multi_language_analysis.py`:

```python
"""å¤šèªè¨€èƒ½åŠ›åˆ†ææ•´åˆæ¸¬è©¦"""

import asyncio
import logging
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

from services.core.aiva_core.internal_exploration import ModuleExplorer, CapabilityAnalyzer


async def main():
    print("=" * 80)
    print("ğŸš€ å¤šèªè¨€èƒ½åŠ›åˆ†ææ•´åˆæ¸¬è©¦")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–
    root_path = Path(__file__).parent / "services"
    explorer = ModuleExplorer(root_path=root_path)
    analyzer = CapabilityAnalyzer()
    
    # 2. æƒææ¨¡çµ„
    print("\nğŸ“‚ æƒææ¨¡çµ„æ–‡ä»¶...")
    modules_info = await explorer.explore_all_modules()
    
    # çµ±è¨ˆæ–‡ä»¶
    total_files = sum(m["stats"]["total_files"] for m in modules_info.values())
    by_lang = {}
    for module_data in modules_info.values():
        for lang, count in module_data["stats"]["by_language"].items():
            by_lang[lang] = by_lang.get(lang, 0) + count
    
    print(f"\nâœ… æƒæå®Œæˆ:")
    print(f"   - ç¸½æ–‡ä»¶: {total_files}")
    for lang, count in by_lang.items():
        if count > 0:
            print(f"   - {lang}: {count} å€‹")
    
    # 3. æå–èƒ½åŠ›
    print("\nğŸ” æå–èƒ½åŠ›...")
    capabilities = await analyzer.analyze_capabilities(modules_info)
    
    # çµ±è¨ˆèƒ½åŠ›
    cap_by_lang = {}
    for cap in capabilities:
        lang = cap.get("language", "python")
        cap_by_lang[lang] = cap_by_lang.get(lang, 0) + 1
    
    print(f"\nâœ… æå–å®Œæˆ:")
    print(f"   - ç¸½èƒ½åŠ›: {len(capabilities)}")
    for lang, count in cap_by_lang.items():
        print(f"   - {lang}: {count} å€‹")
    
    # 4. é¡¯ç¤ºç¯„ä¾‹
    print("\nğŸ“ èƒ½åŠ›ç¯„ä¾‹:")
    for lang in ["python", "go", "rust", "typescript"]:
        lang_caps = [c for c in capabilities if c.get("language") == lang][:2]
        if lang_caps:
            print(f"\n   {lang.upper()}:")
            for cap in lang_caps:
                print(f"     - {cap['name']}")
    
    # 5. é©—è­‰
    print("\nâœ… é©—è­‰çµæœ:")
    checks = {
        "å¤šèªè¨€æƒæ": len(by_lang) >= 3,
        "Python æå–": cap_by_lang.get("python", 0) > 0,
        "Go æå–": cap_by_lang.get("go", 0) > 0,
        "TypeScript æå–": cap_by_lang.get("typescript", 0) > 0,
    }
    
    for check, passed in checks.items():
        print(f"   {'âœ…' if passed else 'âŒ'} {check}")
    
    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ!" if all(checks.values()) else "âš ï¸ éƒ¨åˆ†æ¸¬è©¦æœªé€šé")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
```

### 4.2 åŸ·è¡Œæ¸¬è©¦

```bash
# åŸ·è¡Œæ¸¬è©¦
python test_multi_language_analysis.py
```

**é æœŸè¼¸å‡º**:
```
================================================================================
ğŸš€ å¤šèªè¨€èƒ½åŠ›åˆ†ææ•´åˆæ¸¬è©¦
================================================================================

ğŸ“‚ æƒææ¨¡çµ„æ–‡ä»¶...
âœ… æƒæå®Œæˆ:
   - ç¸½æ–‡ä»¶: 380
   - python: 320 å€‹
   - go: 27 å€‹
   - rust: 7 å€‹
   - typescript: 18 å€‹
   - javascript: 8 å€‹

ğŸ” æå–èƒ½åŠ›...
âœ… æå–å®Œæˆ:
   - ç¸½èƒ½åŠ›: 576
   - python: 410 å€‹
   - go: 88 å€‹
   - typescript: 78 å€‹

ğŸ“ èƒ½åŠ›ç¯„ä¾‹:
   PYTHON:
     - analyze_capabilities
     - explore_all_modules
   GO:
     - NewScannerAMQPClient
     - DeclareQueue
   TYPESCRIPT:
     - toStandardFinding
     - analyzeClientSideAuthBypass

âœ… é©—è­‰çµæœ:
   âœ… å¤šèªè¨€æƒæ
   âœ… Python æå–
   âœ… Go æå–
   âœ… TypeScript æå–

================================================================================
âœ… æ¸¬è©¦å®Œæˆ!
================================================================================
```

### 4.3 å–®å…ƒæ¸¬è©¦ (å¯é¸)

å‰µå»º `tests/test_capability_analyzer_multi_lang.py`:

```python
"""capability_analyzer å¤šèªè¨€æ•´åˆå–®å…ƒæ¸¬è©¦"""

import pytest
from pathlib import Path
from services.core.aiva_core.internal_exploration.capability_analyzer import CapabilityAnalyzer


@pytest.fixture
def analyzer():
    return CapabilityAnalyzer()


def test_detect_language(analyzer):
    """æ¸¬è©¦èªè¨€æª¢æ¸¬"""
    assert analyzer._detect_language(Path("test.py")) == "python"
    assert analyzer._detect_language(Path("test.go")) == "go"
    assert analyzer._detect_language(Path("test.rs")) == "rust"
    assert analyzer._detect_language(Path("test.ts")) == "typescript"
    assert analyzer._detect_language(Path("test.js")) == "javascript"
    assert analyzer._detect_language(Path("test.txt")) == "unknown"


def test_extract_go_capabilities(analyzer, tmp_path):
    """æ¸¬è©¦ Go èƒ½åŠ›æå–"""
    go_file = tmp_path / "scanner.go"
    go_file.write_text("""
package scanner

// ScanTarget scans a target URL
func ScanTarget(url string) error {
    return nil
}

// internal function
func internalHelper() {}
""")
    
    caps = analyzer._extract_non_python_capabilities(go_file, "test_module", "go")
    assert len(caps) == 1  # åªæœ‰ ScanTarget (å¤§å¯«é–‹é ­)
    assert caps[0]["name"] == "ScanTarget"
    assert caps[0]["language"] == "go"


def test_extract_typescript_capabilities(analyzer, tmp_path):
    """æ¸¬è©¦ TypeScript èƒ½åŠ›æå–"""
    ts_file = tmp_path / "scanner.ts"
    ts_file.write_text("""
/**
 * Analyze client auth bypass
 */
export function analyzeAuthBypass(): void {
    // implementation
}

export const helperFunc = () => {};
""")
    
    caps = analyzer._extract_non_python_capabilities(ts_file, "test_module", "typescript")
    assert len(caps) >= 1
    assert any(c["name"] == "analyzeAuthBypass" for c in caps)


def test_extract_python_capabilities(analyzer, tmp_path):
    """æ¸¬è©¦ Python èƒ½åŠ›æå–"""
    py_file = tmp_path / "scanner.py"
    py_file.write_text("""
from aiva_core.core_capabilities import register_capability

@register_capability
async def scan_target(url: str) -> dict:
    \"\"\"Scan a target URL\"\"\"
    return {}
""")
    
    caps = analyzer._extract_python_capabilities(py_file, "test_module")
    assert len(caps) == 1
    assert caps[0]["name"] == "scan_target"
    assert caps[0]["is_async"] == True
```

**åŸ·è¡Œå–®å…ƒæ¸¬è©¦**:
```bash
pytest tests/test_capability_analyzer_multi_lang.py -v
```

---

## 5. ä½¿ç”¨ç¯„ä¾‹

### 5.1 åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from pathlib import Path
from services.core.aiva_core.internal_exploration import ModuleExplorer, CapabilityAnalyzer

async def analyze_system():
    # åˆå§‹åŒ–
    explorer = ModuleExplorer()
    analyzer = CapabilityAnalyzer()
    
    # æƒæä¸¦åˆ†æ
    modules_info = await explorer.explore_all_modules()
    capabilities = await analyzer.analyze_capabilities(modules_info)
    
    # æŒ‰èªè¨€åˆ†çµ„
    by_language = {}
    for cap in capabilities:
        lang = cap.get("language", "python")
        if lang not in by_language:
            by_language[lang] = []
        by_language[lang].append(cap)
    
    # è¼¸å‡ºçµæœ
    for lang, caps in by_language.items():
        print(f"\n{lang.upper()}: {len(caps)} capabilities")
        for cap in caps[:5]:  # é¡¯ç¤ºå‰ 5 å€‹
            print(f"  - {cap['name']}")
    
    return capabilities

# åŸ·è¡Œ
capabilities = asyncio.run(analyze_system())
```

### 5.2 éæ¿¾ç‰¹å®šèªè¨€

```python
# åªåˆ†æ Go èªè¨€èƒ½åŠ›
go_capabilities = [
    cap for cap in capabilities 
    if cap.get("language") == "go"
]

print(f"Go èƒ½åŠ›: {len(go_capabilities)} å€‹")
for cap in go_capabilities:
    params = cap.get("parameters", [])
    param_str = ", ".join(p["name"] for p in params)
    print(f"  - {cap['name']}({param_str})")
```

### 5.3 ç”Ÿæˆå ±å‘Š

```python
def generate_capability_report(capabilities: list) -> str:
    """ç”Ÿæˆèƒ½åŠ›åˆ†æå ±å‘Š"""
    lines = ["# AIVA ç³»çµ±èƒ½åŠ›å ±å‘Š\n"]
    
    # æŒ‰èªè¨€åˆ†çµ„
    by_lang = {}
    for cap in capabilities:
        lang = cap.get("language", "python")
        by_lang.setdefault(lang, []).append(cap)
    
    # ç”Ÿæˆæ¯ç¨®èªè¨€çš„ç« ç¯€
    for lang, caps in sorted(by_lang.items()):
        lines.append(f"\n## {lang.upper()} ({len(caps)} å€‹èƒ½åŠ›)\n")
        
        for cap in caps:
            lines.append(f"### {cap['name']}\n")
            lines.append(f"- **æ¨¡çµ„**: {cap['module']}\n")
            lines.append(f"- **æ–‡ä»¶**: {cap['file_path']}\n")
            
            if cap.get("description"):
                lines.append(f"- **èªªæ˜**: {cap['description']}\n")
            
            if cap.get("parameters"):
                params = ", ".join(p["name"] for p in cap["parameters"])
                lines.append(f"- **åƒæ•¸**: {params}\n")
            
            lines.append("\n")
    
    return "".join(lines)

# ç”Ÿæˆä¸¦ä¿å­˜å ±å‘Š
report = generate_capability_report(capabilities)
with open("CAPABILITY_REPORT.md", "w", encoding="utf-8") as f:
    f.write(report)
```

### 5.4 æ•´åˆåˆ°å…§éƒ¨é–‰ç’°

```python
from services.core.aiva_core.cognitive_core.internal_loop import InternalLoopConnector

async def update_rag_with_capabilities():
    """æ›´æ–° RAG ç³»çµ±çš„èƒ½åŠ›çŸ¥è­˜"""
    # 1. åˆ†æèƒ½åŠ›
    explorer = ModuleExplorer()
    analyzer = CapabilityAnalyzer()
    
    modules_info = await explorer.explore_all_modules()
    capabilities = await analyzer.analyze_capabilities(modules_info)
    
    # 2. è½‰æ›ç‚º RAG æ–‡æª”
    documents = []
    for cap in capabilities:
        doc = {
            "content": f"{cap['name']}: {cap.get('description', '')}",
            "metadata": {
                "type": "capability",
                "language": cap.get("language", "python"),
                "module": cap["module"],
                "file_path": cap["file_path"]
            }
        }
        documents.append(doc)
    
    # 3. æ›´æ–° RAG
    internal_loop = InternalLoopConnector()
    await internal_loop.update_capability_knowledge(documents)
    
    print(f"âœ… å·²æ›´æ–° {len(documents)} å€‹èƒ½åŠ›åˆ° RAG ç³»çµ±")

# åŸ·è¡Œæ›´æ–°
asyncio.run(update_rag_with_capabilities())
```

---

## 6. å•é¡Œæ’æŸ¥

### 6.1 å°å…¥éŒ¯èª¤

**å•é¡Œ**: `ImportError: cannot import name 'get_extractor'`

**è§£æ±º**:
```bash
# æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls services/core/aiva_core/internal_exploration/language_extractors.py

# æª¢æŸ¥ __init__.py æ˜¯å¦å°å‡º
cat services/core/aiva_core/internal_exploration/__init__.py

# å¦‚æœæ²’æœ‰,æ·»åŠ å°å‡º
echo "from .language_extractors import get_extractor" >> services/core/aiva_core/internal_exploration/__init__.py
```

### 6.2 ç„¡æ³•æå–èƒ½åŠ›

**å•é¡Œ**: æŸç¨®èªè¨€æå– 0 å€‹èƒ½åŠ›

**è¨ºæ–·æ­¥é©Ÿ**:

1. **æª¢æŸ¥æ–‡ä»¶æ˜¯å¦è¢«æƒæ**:
```python
modules_info = await explorer.explore_all_modules()
for module, data in modules_info.items():
    go_files = [f for f in data["files"] if f["type"] == "go"]
    print(f"{module}: {len(go_files)} Go æ–‡ä»¶")
```

2. **æ‰‹å‹•æ¸¬è©¦æå–å™¨**:
```python
from services.core.aiva_core.internal_exploration.language_extractors import GoExtractor

extractor = GoExtractor()
with open("services/scan/some_file.go") as f:
    content = f.read()

caps = extractor.extract_capabilities(content, "test.go")
print(f"æå–åˆ° {len(caps)} å€‹èƒ½åŠ›")
for cap in caps:
    print(f"  - {cap['name']}")
```

3. **æª¢æŸ¥æ­£å‰‡æ¨¡å¼**:
```python
import re

# Go å‡½æ•¸æ¨¡å¼
pattern = re.compile(
    r'func\s+(?:\([^)]*\)\s+)?([A-Z][a-zA-Z0-9_]*)\s*\(',
    re.MULTILINE
)

test_code = """
func ScanTarget(url string) error {
    return nil
}
"""

matches = pattern.findall(test_code)
print(f"åŒ¹é…åˆ°: {matches}")  # æ‡‰é¡¯ç¤º ['ScanTarget']
```

### 6.3 æå–çµæœä¸æ­£ç¢º

**å•é¡Œ**: æå–åˆ°ä¸æ‡‰è©²çš„å‡½æ•¸,æˆ–éºæ¼äº†æŸäº›å‡½æ•¸

**Go èªè¨€è¦å‰‡**:
- âœ… åªæå–**å¤§å¯«é–‹é ­**çš„å‡½æ•¸ (å°å‡ºå‡½æ•¸)
- âŒ å°å¯«é–‹é ­çš„å‡½æ•¸ä¸æœƒè¢«æå– (å…§éƒ¨å‡½æ•¸)

```go
// âœ… æœƒè¢«æå–
func PublicFunction() {}

// âŒ ä¸æœƒè¢«æå–
func privateFunction() {}
```

**Rust èªè¨€è¦å‰‡**:
- âœ… åªæå– `pub fn` (å…¬é–‹å‡½æ•¸)
- âŒ `impl` ä¸­çš„æ–¹æ³•ç›®å‰**ä¸æ”¯æ´** (å·²çŸ¥é™åˆ¶)

```rust
// âœ… æœƒè¢«æå–
pub fn public_function() {}

// âŒ ä¸æœƒè¢«æå– (ç„¡ pub)
fn private_function() {}

// âŒ ä¸æœƒè¢«æå– (impl æ–¹æ³•)
impl MyStruct {
    pub fn method(&self) {}
}
```

**TypeScript èªè¨€è¦å‰‡**:
- âœ… æå– `export function`
- âœ… æå– `export const x = () =>`
- âŒ é export å‡½æ•¸ä¸æœƒè¢«æå–

```typescript
// âœ… æœƒè¢«æå–
export function publicFunc() {}

// âŒ ä¸æœƒè¢«æå–
function privateFunc() {}
```

### 6.4 æ€§èƒ½å•é¡Œ

**å•é¡Œ**: æƒæå¤§å‹å°ˆæ¡ˆæ™‚å¾ˆæ…¢

**å„ªåŒ–æ–¹æ³•**:

1. **é™åˆ¶æƒæç¯„åœ**:
```python
explorer = ModuleExplorer()
explorer.target_modules = ["core/aiva_core"]  # åªæƒææ ¸å¿ƒæ¨¡çµ„
```

2. **è·³éæ¸¬è©¦æ–‡ä»¶** (å·²å…§å»º):
```python
# module_explorer.py å·²è‡ªå‹•è·³é
if file_path.name.startswith("test_"):
    continue
```

3. **ä½¿ç”¨å¿«å–**:
```python
analyzer = CapabilityAnalyzer()
# å¿«å–å·²åˆ†æçš„çµæœ
analyzer.capabilities_cache = {}  # å·²å…§å»º
```

---

## 7. æ“´å±•æŒ‡å—

### 7.1 æ–°å¢èªè¨€æ”¯æ´

**ç¯„ä¾‹: æ·»åŠ  Java æ”¯æ´**

**æ­¥é©Ÿ 1**: åœ¨ `language_extractors.py` æ·»åŠ æå–å™¨

```python
class JavaExtractor(LanguageExtractor):
    """Java èªè¨€å‡½æ•¸æå–å™¨"""
    
    FUNCTION_PATTERN = re.compile(
        r'public\s+(?:static\s+)?'  # public [static]
        r'(?:\w+)\s+'  # è¿”å›é¡å‹
        r'([A-Z][a-zA-Z0-9_]*)\s*'  # æ–¹æ³•å (å¤§å¯«é–‹é ­)
        r'\(([^)]*)\)',  # åƒæ•¸åˆ—è¡¨
        re.MULTILINE
    )
    
    def extract_capabilities(self, content: str, file_path: str) -> list[dict]:
        capabilities = []
        
        for match in self.FUNCTION_PATTERN.finditer(content):
            method_name = match.group(1)
            params = match.group(2)
            
            # æå– Javadoc
            doc_comments = self._extract_javadoc(content, match.start())
            
            capability = {
                "name": method_name,
                "language": "java",
                "file_path": file_path,
                "parameters": self._parse_java_params(params),
                "description": doc_comments or f"Java method: {method_name}",
                "line_number": content[:match.start()].count('\n') + 1
            }
            
            capabilities.append(capability)
        
        return capabilities
    
    def _parse_java_params(self, params_str: str) -> list[dict]:
        """è§£æ Java åƒæ•¸"""
        if not params_str.strip():
            return []
        
        params = []
        for param in params_str.split(','):
            parts = param.strip().split()
            if len(parts) >= 2:
                params.append({
                    "type": parts[0],
                    "name": parts[1]
                })
        return params
    
    def _extract_javadoc(self, content: str, start_pos: int) -> str:
        """æå– Javadoc è¨»é‡‹"""
        lines = content[:start_pos].split('\n')
        javadoc = []
        in_javadoc = False
        
        for line in reversed(lines):
            stripped = line.strip()
            if stripped == '*/':
                in_javadoc = True
                continue
            elif stripped.startswith('/**'):
                break
            elif in_javadoc:
                cleaned = re.sub(r'^\s*\*\s?', '', stripped)
                javadoc.insert(0, cleaned)
        
        return ' '.join(javadoc)
```

**æ­¥é©Ÿ 2**: è¨»å†Šåˆ°å·¥å» å‡½æ•¸

```python
def get_extractor(language: str) -> LanguageExtractor | None:
    extractors = {
        "go": GoExtractor(),
        "rust": RustExtractor(),
        "typescript": TypeScriptExtractor(),
        "javascript": TypeScriptExtractor(),
        "java": JavaExtractor(),  # â† æ·»åŠ é€™è¡Œ
    }
    return extractors.get(language.lower())
```

**æ­¥é©Ÿ 3**: æ›´æ–° module_explorer.py

```python
self.file_extensions = {
    "python": "*.py",
    "go": "*.go",
    "rust": "*.rs",
    "typescript": "*.ts",
    "javascript": "*.js",
    "java": "*.java",  # â† æ·»åŠ é€™è¡Œ
}
```

**æ­¥é©Ÿ 4**: æ›´æ–° capability_analyzer.py

```python
def _detect_language(self, file_path: Path) -> str:
    suffix = file_path.suffix.lower()
    language_map = {
        ".py": "python",
        ".go": "go",
        ".rs": "rust",
        ".ts": "typescript",
        ".js": "javascript",
        ".java": "java",  # â† æ·»åŠ é€™è¡Œ
    }
    return language_map.get(suffix, "unknown")
```

**æ­¥é©Ÿ 5**: æ¸¬è©¦

```python
# å‰µå»ºæ¸¬è©¦æ–‡ä»¶
test_java = """
public class Scanner {
    /**
     * Scan a target URL
     * @param url The target URL
     * @return Scan results
     */
    public ScanResult ScanTarget(String url) {
        return new ScanResult();
    }
}
"""

from services.core.aiva_core.internal_exploration.language_extractors import JavaExtractor

extractor = JavaExtractor()
caps = extractor.extract_capabilities(test_java, "Scanner.java")

print(f"æå–åˆ° {len(caps)} å€‹ Java èƒ½åŠ›")
for cap in caps:
    print(f"  - {cap['name']}: {cap['description']}")
```

### 7.2 è‡ªå®šç¾©èƒ½åŠ›éæ¿¾

**ç¯„ä¾‹: åªæå–å®‰å…¨ç›¸é—œèƒ½åŠ›**

```python
def filter_security_capabilities(capabilities: list) -> list:
    """éæ¿¾å®‰å…¨ç›¸é—œèƒ½åŠ›"""
    security_keywords = [
        "scan", "detect", "vulnerability", "injection",
        "xss", "csrf", "auth", "bypass", "exploit"
    ]
    
    filtered = []
    for cap in capabilities:
        name_lower = cap["name"].lower()
        desc_lower = cap.get("description", "").lower()
        
        if any(kw in name_lower or kw in desc_lower for kw in security_keywords):
            filtered.append(cap)
    
    return filtered

# ä½¿ç”¨
all_caps = await analyzer.analyze_capabilities(modules_info)
security_caps = filter_security_capabilities(all_caps)

print(f"ç¸½èƒ½åŠ›: {len(all_caps)}")
print(f"å®‰å…¨ç›¸é—œ: {len(security_caps)}")
```

### 7.3 å°å‡ºç‚ºä¸åŒæ ¼å¼

**JSON æ ¼å¼**:
```python
import json

with open("capabilities.json", "w", encoding="utf-8") as f:
    json.dump(capabilities, f, indent=2, ensure_ascii=False)
```

**CSV æ ¼å¼**:
```python
import csv

with open("capabilities.csv", "w", encoding="utf-8", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=["name", "language", "module", "description"])
    writer.writeheader()
    
    for cap in capabilities:
        writer.writerow({
            "name": cap["name"],
            "language": cap.get("language", "python"),
            "module": cap["module"],
            "description": cap.get("description", "")[:100]
        })
```

**Markdown è¡¨æ ¼**:
```python
def export_to_markdown(capabilities: list, output_file: str):
    """å°å‡ºç‚º Markdown è¡¨æ ¼"""
    lines = ["# ç³»çµ±èƒ½åŠ›æ¸…å–®\n\n"]
    lines.append("| åç¨± | èªè¨€ | æ¨¡çµ„ | èªªæ˜ |\n")
    lines.append("|------|------|------|------|\n")
    
    for cap in capabilities:
        name = cap["name"]
        lang = cap.get("language", "python")
        module = cap["module"]
        desc = cap.get("description", "")[:50]
        
        lines.append(f"| `{name}` | {lang} | {module} | {desc} |\n")
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.writelines(lines)

# ä½¿ç”¨
export_to_markdown(capabilities, "CAPABILITIES_LIST.md")
```

---

## 8. æœ€ä½³å¯¦è¸

### 8.1 å®šæœŸæ›´æ–°èƒ½åŠ›åº«

```python
# å‰µå»ºå®šæœŸæ›´æ–°è…³æœ¬: update_capabilities.py
import asyncio
import json
from datetime import datetime
from pathlib import Path

async def update_capability_database():
    """æ›´æ–°èƒ½åŠ›è³‡æ–™åº«"""
    explorer = ModuleExplorer()
    analyzer = CapabilityAnalyzer()
    
    # åˆ†æ
    modules_info = await explorer.explore_all_modules()
    capabilities = await analyzer.analyze_capabilities(modules_info)
    
    # æ·»åŠ æ™‚é–“æˆ³
    database = {
        "updated_at": datetime.now().isoformat(),
        "total_capabilities": len(capabilities),
        "capabilities": capabilities
    }
    
    # ä¿å­˜
    output_path = Path("data/capabilities.json")
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(database, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²æ›´æ–° {len(capabilities)} å€‹èƒ½åŠ›")

if __name__ == "__main__":
    asyncio.run(update_capability_database())
```

**è¨­å®šæ’ç¨‹** (Windows Task Scheduler):
```powershell
# æ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œ
schtasks /create /tn "UpdateCapabilities" /tr "python C:\D\fold7\AIVA-git\update_capabilities.py" /sc daily /st 02:00
```

### 8.2 ç‰ˆæœ¬æ§åˆ¶

```python
import hashlib

def calculate_capability_hash(capabilities: list) -> str:
    """è¨ˆç®—èƒ½åŠ›åˆ—è¡¨çš„å“ˆå¸Œå€¼"""
    content = json.dumps(
        sorted(capabilities, key=lambda x: x["name"]),
        sort_keys=True
    )
    return hashlib.sha256(content.encode()).hexdigest()

# æª¢æ¸¬è®Šæ›´
old_hash = "..."  # å¾ä¸Šæ¬¡ä¿å­˜çš„å“ˆå¸Œ
new_hash = calculate_capability_hash(capabilities)

if old_hash != new_hash:
    print("âš ï¸ èƒ½åŠ›åˆ—è¡¨å·²è®Šæ›´,éœ€è¦æ›´æ–°!")
```

### 8.3 ç›£æ§å’Œå‘Šè­¦

```python
def validate_capabilities(capabilities: list) -> list[str]:
    """é©—è­‰èƒ½åŠ›å®Œæ•´æ€§"""
    issues = []
    
    for cap in capabilities:
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        if not cap.get("name"):
            issues.append(f"èƒ½åŠ›ç¼ºå°‘åç¨±: {cap}")
        
        if not cap.get("module"):
            issues.append(f"èƒ½åŠ› {cap.get('name')} ç¼ºå°‘æ¨¡çµ„ä¿¡æ¯")
        
        # æª¢æŸ¥æè¿°è³ªé‡
        desc = cap.get("description", "")
        if len(desc) < 10:
            issues.append(f"èƒ½åŠ› {cap['name']} æè¿°éçŸ­")
    
    return issues

# åŸ·è¡Œé©—è­‰
issues = validate_capabilities(capabilities)
if issues:
    print(f"âš ï¸ ç™¼ç¾ {len(issues)} å€‹å•é¡Œ:")
    for issue in issues[:10]:
        print(f"  - {issue}")
```

---

## 9. å®Œæ•´æª¢æŸ¥æ¸…å–®

åŸ·è¡Œä»¥ä¸‹æª¢æŸ¥ç¢ºä¿æ•´åˆæˆåŠŸ:

```bash
# âœ… 1. æ–‡ä»¶å­˜åœ¨æ€§
[ ] language_extractors.py å­˜åœ¨
[ ] capability_analyzer.py å·²ä¿®æ”¹
[ ] module_explorer.py æ”¯æŒå¤šèªè¨€

# âœ… 2. èªæ³•æ­£ç¢ºæ€§
[ ] Python èªæ³•æª¢æŸ¥é€šé (py_compile)
[ ] ç„¡å°å…¥éŒ¯èª¤
[ ] æ‰€æœ‰æ–¹æ³•å¯èª¿ç”¨

# âœ… 3. åŠŸèƒ½æ¸¬è©¦
[ ] å¯æƒæå¤šèªè¨€æ–‡ä»¶ (380+ files)
[ ] Python èƒ½åŠ›æå–æˆåŠŸ (410+ caps)
[ ] Go èƒ½åŠ›æå–æˆåŠŸ (88+ caps)
[ ] TypeScript èƒ½åŠ›æå–æˆåŠŸ (78+ caps)

# âœ… 4. æ•´åˆæ¸¬è©¦
[ ] test_multi_language_analysis.py åŸ·è¡ŒæˆåŠŸ
[ ] æ‰€æœ‰é©—è­‰é …ç›®é€šé
[ ] ç„¡ç•°å¸¸éŒ¯èª¤

# âœ… 5. æ–‡æª”å®Œæ•´æ€§
[ ] README å·²æ›´æ–°
[ ] ä½¿ç”¨ç¯„ä¾‹å¯åŸ·è¡Œ
[ ] æ•…éšœæ’æŸ¥æŒ‡å—å®Œæ•´
```

---

## 10. åƒè€ƒè³‡æº

### ç›¸é—œæ–‡ä»¶
- `services/core/aiva_core/internal_exploration/language_extractors.py`
- `services/core/aiva_core/internal_exploration/capability_analyzer.py`
- `services/core/aiva_core/internal_exploration/module_explorer.py`
- `services/core/aiva_core/internal_exploration/README.md`

### æ¸¬è©¦è…³æœ¬
- `test_multi_language_analysis.py` - æ•´åˆæ¸¬è©¦
- `tests/test_capability_analyzer_multi_lang.py` - å–®å…ƒæ¸¬è©¦

### å ±å‘Šæ–‡æª”
- `MULTI_LANGUAGE_ANALYSIS_INTEGRATION_REPORT.md` - æ•´åˆå ±å‘Š
- `MULTI_LANGUAGE_ANALYSIS_COMPLETE_GUIDE.md` - æœ¬æŒ‡å—

---

## é™„éŒ„: å¿«é€Ÿå‘½ä»¤åƒè€ƒ

```bash
# ç’°å¢ƒæº–å‚™
cd C:\D\fold7\AIVA-git
.\.venv\Scripts\Activate.ps1

# åŸ·è¡Œæ¸¬è©¦
python test_multi_language_analysis.py

# é©—è­‰èªæ³•
python -m py_compile services/core/aiva_core/internal_exploration/capability_analyzer.py

# é‹è¡Œå–®å…ƒæ¸¬è©¦
pytest tests/test_capability_analyzer_multi_lang.py -v

# æª¢æŸ¥å°å…¥
python -c "from services.core.aiva_core.internal_exploration import CapabilityAnalyzer; print('âœ… OK')"

# ç”Ÿæˆèƒ½åŠ›å ±å‘Š
python -c "import asyncio; from services.core.aiva_core.internal_exploration import *; asyncio.run(ModuleExplorer().explore_all_modules())"

# æ›´æ–°èƒ½åŠ›è³‡æ–™åº«
python update_capabilities.py
```

---

**ç‰ˆæœ¬**: 1.0  
**æœ€å¾Œæ›´æ–°**: 2025-11-16  
**ç¶­è­·è€…**: AIVA Core é–‹ç™¼åœ˜éšŠ  
**å•é¡Œå›å ±**: [GitHub Issues](https://github.com/your-repo/issues)

---

**ğŸ“ ä½¿ç”¨æœ¬æŒ‡å—é‡åˆ°å•é¡Œ?**
1. æª¢æŸ¥[å•é¡Œæ’æŸ¥](#6-å•é¡Œæ’æŸ¥)ç« ç¯€
2. åŸ·è¡Œå®Œæ•´æª¢æŸ¥æ¸…å–®
3. æŸ¥çœ‹æ¸¬è©¦è¼¸å‡ºæ—¥èªŒ
4. æäº¤ Issue ä¸¦é™„ä¸ŠéŒ¯èª¤è¨Šæ¯
