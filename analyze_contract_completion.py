#!/usr/bin/env python3
"""
AIVA æ•¸æ“šåˆç´„å®Œæˆåº¦ç¶œåˆåˆ†æå·¥å…·
åˆ†æç³»çµ±ä¸­åˆç´„çš„å®Œæˆåº¦ã€è¦†è“‹ç‡ã€æ•¸æ“šå¡«å……ç‡
"""

import sqlite3
import os
import json
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime

def analyze_database_metrics():
    """åˆ†æè³‡æ–™åº«ä¸­çš„åˆç´„æŒ‡æ¨™"""
    db_path = "logs/contract_metrics.db"
    metrics = {
        'database_exists': os.path.exists(db_path),
        'total_records': 0,
        'latest_metrics': None,
        'alert_count': 0,
        'coverage_rate': 0.0,
        'health_status': 'unknown'
    }
    
    if not metrics['database_exists']:
        return metrics
    
    try:
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        
        # æª¢æŸ¥ contract_metrics è¡¨æ ¼
        cur.execute("SELECT COUNT(*) FROM contract_metrics")
        metrics['total_records'] = cur.fetchone()[0]
        
        # ç²å–æœ€æ–°æŒ‡æ¨™
        if metrics['total_records'] > 0:
            cur.execute("""
                SELECT usage_coverage, health_status, total_contracts, used_contracts
                FROM contract_metrics 
                ORDER BY timestamp DESC 
                LIMIT 1
            """)
            result = cur.fetchone()
            if result:
                metrics['coverage_rate'] = result[0] or 0.0
                metrics['health_status'] = result[1] or 'unknown'
                metrics['latest_metrics'] = {
                    'total_contracts': result[2],
                    'used_contracts': result[3]
                }
        
        # æª¢æŸ¥è­¦å ±æ•¸é‡
        cur.execute("SELECT COUNT(*) FROM alerts WHERE resolved = 0")
        metrics['alert_count'] = cur.fetchone()[0]
        
        conn.close()
        
    except Exception as e:
        print(f"è³‡æ–™åº«åˆ†æéŒ¯èª¤: {e}")
    
    return metrics

def analyze_schema_definitions():
    """åˆ†æ schema å®šç¾©å®Œæˆåº¦"""
    schema_path = Path("services/aiva_common/schemas")
    schema_stats = {
        'total_files': 0,
        'valid_schemas': 0,
        'exported_schemas': 0,
        'categories': {}
    }
    
    if not schema_path.exists():
        return schema_stats
    
    # çµ±è¨ˆ schema æª”æ¡ˆ
    schema_files = list(schema_path.glob("*.py"))
    schema_stats['total_files'] = len([f for f in schema_files if f.name != '__init__.py'])
    
    # åˆ†æ __init__.py çš„å°å‡º
    init_file = schema_path / "__init__.py"
    if init_file.exists():
        try:
            content = init_file.read_text(encoding='utf-8')
            # è¨ˆç®— __all__ ä¸­çš„é …ç›®
            if "__all__" in content:
                # ç°¡å–®è¨ˆç®—ï¼Œå¯¦éš›å¯èƒ½éœ€è¦æ›´è¤‡é›œçš„è§£æ
                lines = [line.strip().strip('",\'') for line in content.split('\n')]
                exported_count = len([line for line in lines if line and not line.startswith(('#', '__all__', '[', ']'))])
                schema_stats['exported_schemas'] = exported_count
        except Exception as e:
            print(f"__init__.py åˆ†æéŒ¯èª¤: {e}")
    
    # åˆ†æåˆ†é¡
    for category_dir in schema_path.iterdir():
        if category_dir.is_dir():
            py_files = list(category_dir.glob("*.py"))
            schema_stats['categories'][category_dir.name] = len(py_files)
    
    return schema_stats

def analyze_usage_patterns():
    """åˆ†æä½¿ç”¨æ¨¡å¼"""
    modules_path = Path("services")
    usage_stats = {
        'modules_scanned': 0,
        'files_with_imports': 0,
        'import_patterns': {},
        'coverage_by_module': {}
    }
    
    if not modules_path.exists():
        return usage_stats
    
    # æƒæä¸»è¦æ¨¡çµ„
    main_modules = ['features', 'core', 'scan', 'integration']
    
    for module_name in main_modules:
        module_stats = _analyze_single_module(modules_path / module_name)
        if module_stats:
            usage_stats['modules_scanned'] += 1
            usage_stats['coverage_by_module'][module_name] = module_stats
    
    return usage_stats

def _analyze_single_module(module_path):
    """åˆ†æå–®ä¸€æ¨¡çµ„çš„ä½¿ç”¨æ¨¡å¼ï¼Œé™ä½èªçŸ¥è¤‡é›œåº¦"""
    if not module_path.exists():
        return None
        
    py_files = list(module_path.rglob("*.py"))
    files_with_schema_imports = _count_schema_imports(py_files)
    
    return {
        'total_files': len(py_files),
        'files_with_imports': files_with_schema_imports,
        'import_rate': files_with_schema_imports / len(py_files) * 100 if py_files else 0
    }

def _count_schema_imports(py_files):
    """çµ±è¨ˆåŒ…å« schema å°å…¥çš„æª”æ¡ˆæ•¸é‡"""
    count = 0
    for py_file in py_files:
        try:
            content = py_file.read_text(encoding='utf-8')
            if "aiva_common.schemas" in content:
                count += 1
        except Exception:
            continue
    return count

def calculate_completion_percentage(db_metrics, schema_stats, usage_stats):
    """è¨ˆç®—æ•´é«”å®Œæˆåº¦ç™¾åˆ†æ¯”"""
    scores = {}
    
    # 1. è³‡æ–™åº«å¥åº·åº¦ (25%)
    if db_metrics['database_exists'] and db_metrics['total_records'] > 0:
        db_score = min(db_metrics['coverage_rate'] * 100, 100)
    else:
        db_score = 0
    scores['database_health'] = db_score
    
    # 2. Schema å®šç¾©å®Œæˆåº¦ (25%)
    if schema_stats['total_files'] > 0:
        definition_score = min((schema_stats['exported_schemas'] / max(schema_stats['total_files'], 1)) * 100, 100)
    else:
        definition_score = 0
    scores['schema_definitions'] = definition_score
    
    # 3. ä½¿ç”¨è¦†è“‹ç‡ (25%)
    total_import_rate = 0
    if usage_stats['coverage_by_module']:
        rates = [module['import_rate'] for module in usage_stats['coverage_by_module'].values()]
        total_import_rate = sum(rates) / len(rates) if rates else 0
    scores['usage_coverage'] = total_import_rate
    
    # 4. ç³»çµ±æ•´åˆåº¦ (25%)
    integration_score = 0
    if usage_stats['modules_scanned'] > 0:
        modules_with_imports = sum(1 for module in usage_stats['coverage_by_module'].values() 
                                 if module['files_with_imports'] > 0)
        integration_score = (modules_with_imports / usage_stats['modules_scanned']) * 100
    scores['system_integration'] = integration_score
    
    # è¨ˆç®—ç¸½åˆ†
    weights = {'database_health': 0.25, 'schema_definitions': 0.25, 
               'usage_coverage': 0.25, 'system_integration': 0.25}
    
    total_score = sum(scores[key] * weights[key] for key in scores)
    
    return total_score, scores

def print_completion_report():
    """æ‰“å°å®Œæ•´çš„å®Œæˆåº¦å ±å‘Š"""
    print("ğŸ¯ AIVA æ•¸æ“šåˆç´„å®Œæˆåº¦ç¶œåˆåˆ†æ")
    print("=" * 80)
    
    # åˆ†æå„é …æŒ‡æ¨™
    print("\nğŸ“Š æ•¸æ“šæ”¶é›†ä¸­...")
    db_metrics = analyze_database_metrics()
    schema_stats = analyze_schema_definitions()
    usage_stats = analyze_usage_patterns()
    
    # è¨ˆç®—å®Œæˆåº¦
    completion_rate, detailed_scores = calculate_completion_percentage(
        db_metrics, schema_stats, usage_stats
    )
    
    # æ‰“å°ä¸»è¦çµæœ
    print(f"\nğŸ† æ•´é«”æ•¸æ“šåˆç´„å®Œæˆåº¦: {completion_rate:.1f}%")
    
    # è©³ç´°åˆ†æ
    print("\nğŸ“‹ è©³ç´°åˆ†æ:")
    print(f"  ğŸ’¾ è³‡æ–™åº«å¥åº·åº¦: {detailed_scores['database_health']:.1f}% (æ¬Šé‡25%)")
    print(f"     - è³‡æ–™åº«å­˜åœ¨: {'âœ…' if db_metrics['database_exists'] else 'âŒ'}")
    print(f"     - è¨˜éŒ„æ•¸é‡: {db_metrics['total_records']}")
    print(f"     - è¦†è“‹ç‡: {db_metrics['coverage_rate']:.1f}%")
    print(f"     - å¥åº·ç‹€æ…‹: {db_metrics['health_status']}")
    print(f"     - æœªè§£æ±ºè­¦å ±: {db_metrics['alert_count']}")
    
    print(f"\n  ğŸ“š Schemaå®šç¾©å®Œæˆåº¦: {detailed_scores['schema_definitions']:.1f}% (æ¬Šé‡25%)")
    print(f"     - Schemaæª”æ¡ˆç¸½æ•¸: {schema_stats['total_files']}")
    print(f"     - å·²å°å‡ºSchema: {schema_stats['exported_schemas']}")
    print(f"     - åˆ†é¡æ•¸é‡: {len(schema_stats['categories'])}")
    
    print(f"\n  ğŸ”— ä½¿ç”¨è¦†è“‹ç‡: {detailed_scores['usage_coverage']:.1f}% (æ¬Šé‡25%)")
    for module_name, stats in usage_stats['coverage_by_module'].items():
        print(f"     - {module_name}: {stats['import_rate']:.1f}% ({stats['files_with_imports']}/{stats['total_files']})")
    
    print(f"\n  ğŸŒ ç³»çµ±æ•´åˆåº¦: {detailed_scores['system_integration']:.1f}% (æ¬Šé‡25%)")
    print(f"     - å·²æƒææ¨¡çµ„: {usage_stats['modules_scanned']}")
    modules_with_usage = sum(1 for stats in usage_stats['coverage_by_module'].values() 
                           if stats['files_with_imports'] > 0)
    print(f"     - æœ‰ä½¿ç”¨åˆç´„çš„æ¨¡çµ„: {modules_with_usage}")
    
    # å¥åº·åº¦è©•ä¼°
    print("\nğŸ¥ å¥åº·åº¦è©•ä¼°:")
    if completion_rate >= 80:
        print("  âœ… å„ªç§€: æ•¸æ“šåˆç´„ç³»çµ±å®Œæˆåº¦å¾ˆé«˜")
    elif completion_rate >= 60:
        print("  âš ï¸ è‰¯å¥½: ç³»çµ±åŸºæœ¬å®Œå–„ï¼Œæœ‰æ”¹é€²ç©ºé–“")
    elif completion_rate >= 40:
        print("  ğŸ”¶ ä¸­ç­‰: éœ€è¦æŒçºŒæ”¹é€²")
    else:
        print("  ğŸ”´ éœ€è¦é‡é»é—œæ³¨: å®Œæˆåº¦åä½ï¼Œå»ºè­°å„ªå…ˆæ”¹å–„")
    
    # æ”¹é€²å»ºè­°
    print("\nğŸ’¡ æ”¹é€²å»ºè­°:")
    if detailed_scores['database_health'] < 50:
        print("  1. ğŸ”§ å„ªå…ˆä¿®å¾©è³‡æ–™åº«è¨˜éŒ„å’Œç›£æ§ç³»çµ±")
    if detailed_scores['usage_coverage'] < 60:
        print("  2. ğŸ“ˆ å¢åŠ å„æ¨¡çµ„å°é€šç”¨åˆç´„çš„ä½¿ç”¨")
    if detailed_scores['system_integration'] < 70:
        print("  3. ğŸ”— åŠ å¼·æ¨¡çµ„é–“çš„åˆç´„æ•´åˆ")
    
    return completion_rate

if __name__ == "__main__":
    completion_rate = print_completion_report()
    print(f"\nğŸ“ ç¸½çµ: AIVA æ•¸æ“šåˆç´„å®Œæˆåº¦ç‚º {completion_rate:.1f}%")