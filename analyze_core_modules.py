#!/usr/bin/env python3
"""
AIVA æ ¸å¿ƒæ¨¡çµ„ä»£ç¢¼åˆ†æå·¥å…·
åˆ†æä»£ç¢¼è¤‡é›œåº¦ã€çµæ§‹å’Œå“è³ªæŒ‡æ¨™
"""

import ast
from collections import defaultdict
import json
from pathlib import Path


def analyze_python_file(filepath):
    """åˆ†æå–®å€‹ Python æª”æ¡ˆ"""
    try:
        with open(filepath, encoding='utf-8') as f:
            content = f.read()

        tree = ast.parse(content)

        # çµ±è¨ˆåŸºæœ¬æŒ‡æ¨™
        classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
        functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
        imports = [node for node in ast.walk(tree) if isinstance(node, (ast.Import, ast.ImportFrom))]

        # è¨ˆç®—è¤‡é›œåº¦æŒ‡æ¨™
        async_functions = [node for node in ast.walk(tree) if isinstance(node, ast.AsyncFunctionDef)]
        decorators = [node for node in ast.walk(tree) if hasattr(node, 'decorator_list') and node.decorator_list]

        # è¨ˆç®—è¡Œæ•¸
        lines = content.split('\n')
        code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
        comment_lines = [line for line in lines if line.strip().startswith('#')]

        # åˆ†æå°å…¥ä¾è³´
        import_modules = []
        for imp in imports:
            if isinstance(imp, ast.Import):
                import_modules.extend([alias.name for alias in imp.names])
            elif isinstance(imp, ast.ImportFrom):
                module = imp.module or ''
                import_modules.append(module)

        # è¨ˆç®—å‡½æ•¸å¹³å‡é•·åº¦
        function_lengths = []
        for func in functions + async_functions:
            if hasattr(func, 'lineno') and hasattr(func, 'end_lineno'):
                length = func.end_lineno - func.lineno + 1
                function_lengths.append(length)

        avg_function_length = sum(function_lengths) / len(function_lengths) if function_lengths else 0

        return {
            'file': str(filepath.relative_to(Path('c:/AMD/AIVA'))),
            'total_lines': len(lines),
            'code_lines': len(code_lines),
            'comment_lines': len(comment_lines),
            'classes': len(classes),
            'functions': len(functions),
            'async_functions': len(async_functions),
            'imports': len(imports),
            'decorators': len(decorators),
            'avg_function_length': round(avg_function_length, 1),
            'max_function_length': max(function_lengths) if function_lengths else 0,
            'class_names': [cls.name for cls in classes],
            'function_names': [func.name for func in functions[:5]],
            'import_modules': list(set(import_modules)),
            'complexity_score': _calculate_complexity_score(classes, functions, avg_function_length, len(imports))
        }
    except Exception as e:
        return {'file': str(filepath), 'error': str(e)}

def _calculate_complexity_score(classes, functions, avg_func_len, imports):
    """è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸ (0-100, è¶Šé«˜è¶Šè¤‡é›œ)"""
    score = 0
    score += len(classes) * 5  # æ¯å€‹é¡åˆ¥ +5 åˆ†
    score += len(functions) * 2  # æ¯å€‹å‡½æ•¸ +2 åˆ†
    score += max(0, (avg_func_len - 20) * 1)  # è¶…é20è¡Œçš„å‡½æ•¸é¡å¤–è¨ˆåˆ†
    score += imports * 1  # æ¯å€‹å°å…¥ +1 åˆ†
    return min(100, score)

def analyze_core_modules():
    """åˆ†æ AIVA æ ¸å¿ƒæ¨¡çµ„"""
    core_path = Path('c:/AMD/AIVA/services/core/aiva_core')
    results = []

    for py_file in core_path.rglob('*.py'):
        if '__pycache__' not in str(py_file) and '.backup' not in str(py_file):
            result = analyze_python_file(py_file)
            if 'error' not in result:
                results.append(result)

    return results

def generate_analysis_report(results):
    """ç”Ÿæˆåˆ†æå ±å‘Š"""
    print('=' * 80)
    print('AIVA æ ¸å¿ƒæ¨¡çµ„ä»£ç¢¼åˆ†æå ±å‘Š')
    print('=' * 80)
    print(f'ç¸½è¨ˆåˆ†ææª”æ¡ˆ: {len(results)} å€‹')
    print()

    # æŒ‰ä»£ç¢¼è¡Œæ•¸æ’åº
    results_by_size = sorted(results, key=lambda x: x['code_lines'], reverse=True)

    print('ğŸ” æŒ‰ä»£ç¢¼è¦æ¨¡æ’åº (å‰10å€‹æœ€å¤§æ–‡ä»¶):')
    print('-' * 80)
    for i, result in enumerate(results_by_size[:10]):
        complexity = int(result.get("complexity_score", 0))
        print(f'{i+1:2d}. {result["file"]:45s} | ä»£ç¢¼: {result["code_lines"]:4d} è¡Œ | è¤‡é›œåº¦: {complexity:3d}')

    print('\nğŸ§  AI ç›¸é—œæ ¸å¿ƒæ¨¡çµ„åˆ†æ:')
    print('-' * 80)
    ai_files = [r for r in results if 'ai_' in r['file'] or 'bio_neuron' in r['file'] or 'nlg_' in r['file']]
    for result in sorted(ai_files, key=lambda x: x['code_lines'], reverse=True):
        print(f'ğŸ“ {result["file"]}')
        print(f'   ä»£ç¢¼è¡Œæ•¸: {result["code_lines"]}, é¡åˆ¥: {result["classes"]}, å‡½æ•¸: {result["functions"]}')
        if result['class_names']:
            print(f'   ä¸»è¦é¡åˆ¥: {", ".join(result["class_names"][:3])}')
        print()

    print('âš¡ æ€§èƒ½é—œéµæ¨¡çµ„åˆ†æ:')
    print('-' * 80)
    performance_files = [r for r in results if any(keyword in r['file'] for keyword in
                        ['optimized', 'parallel', 'execution', 'task_', 'cache'])]
    for result in sorted(performance_files, key=lambda x: x['code_lines'], reverse=True):
        print(f'ğŸ“ {result["file"]}')
        print(f'   ä»£ç¢¼è¡Œæ•¸: {result["code_lines"]}, ç•°æ­¥å‡½æ•¸: {result["async_functions"]}, è¤‡é›œåº¦: {result.get("complexity_score", 0)}')
        print()

    # è¤‡é›œåº¦åˆ†æ
    print('ğŸ“Š è¤‡é›œåº¦çµ±è¨ˆ:')
    print('-' * 80)
    complexity_scores = [r.get('complexity_score', 0) for r in results]
    high_complexity = [r for r in results if r.get('complexity_score', 0) > 50]

    print(f'å¹³å‡è¤‡é›œåº¦: {sum(complexity_scores)/len(complexity_scores):.1f}')
    print(f'é«˜è¤‡é›œåº¦æ–‡ä»¶ (>50): {len(high_complexity)} å€‹')

    if high_complexity:
        print('\nğŸš¨ éœ€è¦é‡æ§‹çš„é«˜è¤‡é›œåº¦æ–‡ä»¶:')
        for result in sorted(high_complexity, key=lambda x: x.get('complexity_score', 0), reverse=True):
            complexity = int(result.get("complexity_score", 0))
            max_func_len = int(result["max_function_length"])
            print(f'   {result["file"]:40s} | è¤‡é›œåº¦: {complexity:3d} | æœ€é•·å‡½æ•¸: {max_func_len:3d} è¡Œ')# ä¾è³´åˆ†æ
    print('\nğŸ”— ä¾è³´é—œä¿‚åˆ†æ:')
    print('-' * 80)
    all_imports = defaultdict(int)
    for result in results:
        for module in result.get('import_modules', []):
            if module and not module.startswith('.'):
                all_imports[module] += 1

    common_imports = sorted(all_imports.items(), key=lambda x: x[1], reverse=True)[:10]
    print('æœ€å¸¸ç”¨çš„å¤–éƒ¨ä¾è³´:')
    for module, count in common_imports:
        print(f'   {module:30s}: {count:2d} æ¬¡')

    return results

if __name__ == '__main__':
    # ä¿®å¾© _calculate_complexity_score å‡½æ•¸
    def _calculate_complexity_score(classes, functions, avg_func_len, imports):
        """è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸ (0-100, è¶Šé«˜è¶Šè¤‡é›œ)"""
        score = 0
        score += len(classes) * 5  # æ¯å€‹é¡åˆ¥ +5 åˆ†
        score += len(functions) * 2  # æ¯å€‹å‡½æ•¸ +2 åˆ†
        score += max(0, (avg_func_len - 20) * 1)  # è¶…é20è¡Œçš„å‡½æ•¸é¡å¤–è¨ˆåˆ†
        score += imports * 1  # æ¯å€‹å°å…¥ +1 åˆ†
        return min(100, score)

    # é‡æ–°å®šç¾© analyze_python_file ä»¥åŒ…å«ä¿®å¾©çš„å‡½æ•¸
    def analyze_python_file(filepath):
        """åˆ†æå–®å€‹ Python æª”æ¡ˆ"""
        try:
            with open(filepath, encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            # çµ±è¨ˆåŸºæœ¬æŒ‡æ¨™
            classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
            functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
            imports = [node for node in ast.walk(tree) if isinstance(node, (ast.Import, ast.ImportFrom))]

            # è¨ˆç®—è¤‡é›œåº¦æŒ‡æ¨™
            async_functions = [node for node in ast.walk(tree) if isinstance(node, ast.AsyncFunctionDef)]
            decorators = [node for node in ast.walk(tree) if hasattr(node, 'decorator_list') and node.decorator_list]

            # è¨ˆç®—è¡Œæ•¸
            lines = content.split('\n')
            code_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
            comment_lines = [line for line in lines if line.strip().startswith('#')]

            # åˆ†æå°å…¥ä¾è³´
            import_modules = []
            for imp in imports:
                if isinstance(imp, ast.Import):
                    import_modules.extend([alias.name for alias in imp.names])
                elif isinstance(imp, ast.ImportFrom):
                    module = imp.module or ''
                    import_modules.append(module)

            # è¨ˆç®—å‡½æ•¸å¹³å‡é•·åº¦
            function_lengths = []
            for func in functions + async_functions:
                if hasattr(func, 'lineno') and hasattr(func, 'end_lineno'):
                    length = func.end_lineno - func.lineno + 1
                    function_lengths.append(length)

            avg_function_length = sum(function_lengths) / len(function_lengths) if function_lengths else 0

            return {
                'file': str(filepath.relative_to(Path('c:/AMD/AIVA'))),
                'total_lines': len(lines),
                'code_lines': len(code_lines),
                'comment_lines': len(comment_lines),
                'classes': len(classes),
                'functions': len(functions),
                'async_functions': len(async_functions),
                'imports': len(imports),
                'decorators': len(decorators),
                'avg_function_length': round(avg_function_length, 1),
                'max_function_length': max(function_lengths) if function_lengths else 0,
                'class_names': [cls.name for cls in classes],
                'function_names': [func.name for func in functions[:5]],
                'import_modules': list(set(import_modules)),
                'complexity_score': _calculate_complexity_score(classes, functions, avg_function_length, len(imports))
            }
        except Exception as e:
            return {'file': str(filepath), 'error': str(e)}

    results = analyze_core_modules()
    generate_analysis_report(results)

    # å„²å­˜è©³ç´°çµæœåˆ° JSON
    with open('c:/AMD/AIVA/_out/core_module_analysis_detailed.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print('\nğŸ“ è©³ç´°åˆ†æçµæœå·²å„²å­˜åˆ°: _out/core_module_analysis_detailed.json')
