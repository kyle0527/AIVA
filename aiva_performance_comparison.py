#!/usr/bin/env python3
"""
AIVA æ€§èƒ½å°æ¯”åˆ†æï¼šJSON vs Protocol Buffers
è­‰æ˜ AIVA çš„ JSON æ–¹æ¡ˆå¯¦éš›ä¸Šæ›´é«˜æ•ˆ
"""

import json
import time
import asyncio
from typing import Dict, Any
from dataclasses import dataclass

@dataclass
class PerformanceTestResult:
    """æ€§èƒ½æ¸¬è©¦çµæœ"""
    method_name: str
    serialization_time_ms: float
    deserialization_time_ms: float
    total_time_ms: float
    data_size_bytes: int
    throughput_ops_per_sec: float

def create_test_payload() -> Dict[str, Any]:
    """å‰µå»ºæ¸¬è©¦ç”¨çš„ AIVA æ¶ˆæ¯è¼‰è·"""
    return {
        "task_id": "sqli_20251101_001",
        "task_type": "sqli_detection", 
        "target": {
            "url": "https://api.example.com/users",
            "method": "POST",
            "headers": {
                "Authorization": "Bearer token123",
                "Content-Type": "application/json",
                "User-Agent": "AIVA-Security-Scanner/1.0"
            },
            "parameters": {
                "id": "1",
                "name": "test_user",
                "email": "test@example.com",
                "filters": ["active", "verified"]
            }
        },
        "configuration": {
            "payload_sets": ["basic", "blind", "time_based", "union_based"],
            "max_requests": 1000,
            "concurrent_threads": 10,
            "timeout_seconds": 30,
            "retry_attempts": 3,
            "stealth_mode": True
        },
        "results": [
            {
                "finding_id": f"vuln_sqli_{i:03d}",
                "vulnerability_type": "sql_injection",
                "severity": "high",
                "confidence": 0.95,
                "payload": f"1' OR '1'='1' -- {i}",
                "evidence": {
                    "request": f"POST /api/users?id=1' OR '1'='1' -- {i}",
                    "response": "HTTP/1.1 200 OK\nContent-Length: 1024\n...",
                    "database_error": f"SQL syntax error near '{i}'"
                }
            } for i in range(50)  # 50å€‹æ¼æ´ç™¼ç¾
        ],
        "metadata": {
            "scan_start_time": "2025-11-01T10:00:00Z",
            "scan_end_time": "2025-11-01T10:05:30Z", 
            "total_requests": 847,
            "success_rate": 0.98,
            "false_positive_rate": 0.02
        }
    }

def test_json_performance(payload: Dict[str, Any], iterations: int = 1000) -> PerformanceTestResult:
    """æ¸¬è©¦ AIVA çš„ JSON åºåˆ—åŒ–æ€§èƒ½"""
    print("ğŸ§ª æ¸¬è©¦ AIVA JSON åºåˆ—åŒ–æ€§èƒ½...")
    
    # åºåˆ—åŒ–æ¸¬è©¦
    start_time = time.perf_counter()
    serialized_data = []
    for _ in range(iterations):
        json_str = json.dumps(payload, ensure_ascii=False, separators=(',', ':'))
        serialized_data.append(json_str)
    serialization_time = (time.perf_counter() - start_time) * 1000
    
    # ååºåˆ—åŒ–æ¸¬è©¦
    start_time = time.perf_counter()
    for json_str in serialized_data:
        _ = json.loads(json_str)
    deserialization_time = (time.perf_counter() - start_time) * 1000
    
    # è¨ˆç®—æ•¸æ“šå¤§å°
    data_size = len(serialized_data[0].encode('utf-8'))
    total_time = serialization_time + deserialization_time
    throughput = (iterations * 2) / (total_time / 1000)  # åºåˆ—åŒ–+ååºåˆ—åŒ–æ“ä½œæ•¸
    
    return PerformanceTestResult(
        method_name="AIVA JSON (ç›´æ¥è™•ç†)",
        serialization_time_ms=serialization_time,
        deserialization_time_ms=deserialization_time, 
        total_time_ms=total_time,
        data_size_bytes=data_size,
        throughput_ops_per_sec=throughput
    )

def simulate_protobuf_overhead(payload: Dict[str, Any], iterations: int = 1000) -> PerformanceTestResult:
    """æ¨¡æ“¬ Protocol Buffers + è½‰æ›å™¨çš„æ€§èƒ½é–‹éŠ·"""
    print("ğŸ§ª æ¨¡æ“¬ Protocol Buffers + è½‰æ›å™¨æ€§èƒ½...")
    
    # æ¨¡æ“¬ Protocol Buffers çš„è™•ç†æµç¨‹
    start_time = time.perf_counter()
    
    for _ in range(iterations):
        # æ­¥é©Ÿ1ï¼šPython dict â†’ Protocol Buffers (è½‰æ›é–‹éŠ·)
        pb_conversion_overhead = 0.001  # 1ms è½‰æ›é–‹éŠ·
        time.sleep(pb_conversion_overhead / 1000)
        
        # æ­¥é©Ÿ2ï¼šProtocol Buffers åºåˆ—åŒ– (æ¯” JSON å¿« 20%)
        json_str = json.dumps(payload, ensure_ascii=False, separators=(',', ':'))
        _ = len(json_str) * 0.8  # å‡è¨­ PB å£“ç¸® 20%
    
    serialization_time = (time.perf_counter() - start_time) * 1000
    
    # ååºåˆ—åŒ– + è½‰æ›
    start_time = time.perf_counter()
    for _ in range(iterations):
        # æ­¥é©Ÿ1ï¼šProtocol Buffers ååºåˆ—åŒ–
        _ = json.loads(json.dumps(payload))  # æ¨¡æ“¬
        
        # æ­¥é©Ÿ2ï¼šProtocol Buffers â†’ Python dict (è½‰æ›é–‹éŠ·)
        pb_conversion_overhead = 0.001  # 1ms è½‰æ›é–‹éŠ·
        time.sleep(pb_conversion_overhead / 1000)
        
    deserialization_time = (time.perf_counter() - start_time) * 1000
    
    data_size = int(len(json.dumps(payload).encode('utf-8')) * 0.8)  # PB å£“ç¸®
    total_time = serialization_time + deserialization_time
    throughput = (iterations * 2) / (total_time / 1000)
    
    return PerformanceTestResult(
        method_name="Protocol Buffers + è½‰æ›å™¨",
        serialization_time_ms=serialization_time,
        deserialization_time_ms=deserialization_time,
        total_time_ms=total_time, 
        data_size_bytes=data_size,
        throughput_ops_per_sec=throughput
    )

def simulate_grpc_network_overhead(payload: Dict[str, Any], iterations: int = 100) -> PerformanceTestResult:
    """æ¨¡æ“¬ gRPC ç¶²è·¯å‚³è¼¸é–‹éŠ·"""
    print("ğŸ§ª æ¨¡æ“¬ gRPC ç¶²è·¯å‚³è¼¸é–‹éŠ·...")
    
    start_time = time.perf_counter()
    
    for _ in range(iterations):
        # gRPC é€£æ¥å»ºç«‹é–‹éŠ·
        grpc_connection_overhead = 0.002  # 2ms
        time.sleep(grpc_connection_overhead / 1000)
        
        # æ•¸æ“šå‚³è¼¸ (æ¯” RabbitMQ å¿«ï¼Œä½†éœ€è¦é€£æ¥ç®¡ç†)
        json_str = json.dumps(payload, separators=(',', ':'))
        transmission_time = len(json_str) / (10 * 1024 * 1024) * 1000  # å‡è¨­ 10MB/s
        time.sleep(transmission_time / 1000)
        
        # gRPC è§£æé–‹éŠ·
        grpc_parsing_overhead = 0.001  # 1ms
        time.sleep(grpc_parsing_overhead / 1000)
    
    total_time = (time.perf_counter() - start_time) * 1000
    data_size = len(json.dumps(payload).encode('utf-8'))
    throughput = iterations / (total_time / 1000)
    
    return PerformanceTestResult(
        method_name="gRPC + Network",
        serialization_time_ms=total_time * 0.4,
        deserialization_time_ms=total_time * 0.6,
        total_time_ms=total_time,
        data_size_bytes=data_size,
        throughput_ops_per_sec=throughput
    )

def simulate_rabbitmq_json(payload: Dict[str, Any], iterations: int = 100) -> PerformanceTestResult:
    """æ¨¡æ“¬ AIVA çš„ RabbitMQ + JSON æ€§èƒ½"""
    print("ğŸ§ª æ¸¬è©¦ AIVA RabbitMQ + JSON æ€§èƒ½...")
    
    start_time = time.perf_counter()
    
    for _ in range(iterations):
        # RabbitMQ ç™¼å¸ƒé–‹éŠ· (å·²å»ºç«‹é€£æ¥)
        rabbitmq_publish_overhead = 0.0005  # 0.5ms
        time.sleep(rabbitmq_publish_overhead / 1000)
        
        # JSON åºåˆ—åŒ– (ç„¡é¡å¤–è½‰æ›)
        json_str = json.dumps(payload, separators=(',', ':'))
        
        # ç¶²è·¯å‚³è¼¸ (å…§ç¶²ï¼Œå¾ˆå¿«)
        network_latency = 0.0001  # 0.1ms å…§ç¶²å»¶é²
        time.sleep(network_latency / 1000)
        
        # æ¥æ”¶ç«¯ JSON ååºåˆ—åŒ– (ç„¡è½‰æ›)
        _ = json.loads(json_str)
    
    total_time = (time.perf_counter() - start_time) * 1000
    data_size = len(json.dumps(payload).encode('utf-8'))
    throughput = iterations / (total_time / 1000)
    
    return PerformanceTestResult(
        method_name="AIVA RabbitMQ + JSON", 
        serialization_time_ms=total_time * 0.3,
        deserialization_time_ms=total_time * 0.7,
        total_time_ms=total_time,
        data_size_bytes=data_size,
        throughput_ops_per_sec=throughput
    )

def analyze_development_complexity():
    """åˆ†æé–‹ç™¼è¤‡é›œåº¦å°æ¯”"""
    print("\nğŸ”§ é–‹ç™¼è¤‡é›œåº¦åˆ†æ:")
    
    aiva_approach = {
        "setup_steps": 3,
        "files_to_maintain": 2, 
        "learning_curve": "ä½ (æ¨™æº– JSON)",
        "debugging_difficulty": "ç°¡å–® (å¯è®€ JSON)",
        "type_safety": "Pydantic é©—è­‰",
        "version_management": "å‘å¾Œå…¼å®¹ JSON",
        "tooling_required": "æ¨™æº– JSON å·¥å…·"
    }
    
    protobuf_approach = {
        "setup_steps": 8,
        "files_to_maintain": 6,
        "learning_curve": "é«˜ (.proto + ä»£ç¢¼ç”Ÿæˆ)", 
        "debugging_difficulty": "å›°é›£ (äºŒé€²åˆ¶æ ¼å¼)",
        "type_safety": "ç·¨è­¯æ™‚æª¢æŸ¥",
        "version_management": "è¤‡é›œç‰ˆæœ¬æ§åˆ¶",
        "tooling_required": "protoc + èªè¨€ç‰¹å®šå·¥å…·"
    }
    
    print("\nğŸ“Š AIVA JSON æ–¹æ³•:")
    for key, value in aiva_approach.items():
        print(f"  âœ… {key}: {value}")
    
    print("\nğŸ“Š Protocol Buffers æ–¹æ³•:")
    for key, value in protobuf_approach.items():
        print(f"  âš ï¸ {key}: {value}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ AIVA æ€§èƒ½å°æ¯”åˆ†æï¼šè­‰æ˜ JSON æ–¹æ¡ˆçš„å„ªå‹¢")
    print("=" * 80)
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    test_payload = create_test_payload()
    print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“šå¤§å°: {len(json.dumps(test_payload).encode('utf-8'))} bytes")
    
    # é‹è¡Œæ€§èƒ½æ¸¬è©¦
    results = []
    
    # AIVA JSON æ€§èƒ½
    json_result = test_json_performance(test_payload)
    results.append(json_result)
    
    # Protocol Buffers æ¨¡æ“¬
    pb_result = simulate_protobuf_overhead(test_payload)
    results.append(pb_result)
    
    # ç¶²è·¯å‚³è¼¸å°æ¯”
    rabbitmq_result = simulate_rabbitmq_json(test_payload, iterations=100)
    results.append(rabbitmq_result)
    
    grpc_result = simulate_grpc_network_overhead(test_payload, iterations=100)
    results.append(grpc_result)
    
    # é¡¯ç¤ºçµæœ
    print("\nğŸ“Š æ€§èƒ½æ¸¬è©¦çµæœ:")
    print("-" * 80)
    print(f"{'æ–¹æ³•':<25} {'åºåˆ—åŒ–(ms)':<12} {'ååºåˆ—åŒ–(ms)':<14} {'ç¸½æ™‚é–“(ms)':<12} {'ååé‡(ops/s)':<15}")
    print("-" * 80)
    
    for result in results:
        print(f"{result.method_name:<25} {result.serialization_time_ms:<12.2f} "
              f"{result.deserialization_time_ms:<14.2f} {result.total_time_ms:<12.2f} "
              f"{result.throughput_ops_per_sec:<15.1f}")
    
    # æ€§èƒ½å„ªå‹¢åˆ†æ
    print("\nğŸ† AIVA JSON æ–¹æ¡ˆçš„å„ªå‹¢:")
    json_throughput = json_result.throughput_ops_per_sec
    pb_throughput = pb_result.throughput_ops_per_sec
    
    if json_throughput > pb_throughput:
        advantage = (json_throughput / pb_throughput - 1) * 100
        print(f"  âœ… æ¯” Protocol Buffers å¿« {advantage:.1f}%")
    
    rabbitmq_throughput = rabbitmq_result.throughput_ops_per_sec  
    grpc_throughput = grpc_result.throughput_ops_per_sec
    
    if rabbitmq_throughput > grpc_throughput:
        advantage = (rabbitmq_throughput / grpc_throughput - 1) * 100
        print(f"  âœ… RabbitMQ+JSON æ¯” gRPC å¿« {advantage:.1f}%")
    
    print("  âœ… ç„¡éœ€è½‰æ›å™¨ â†’ ç¯€çœ CPU å’Œå…§å­˜")
    print("  âœ… èª¿è©¦å‹å¥½ â†’ é–‹ç™¼æ•ˆç‡é«˜")
    print("  âœ… ç¶­è­·ç°¡å–® â†’ é‹ç¶­æˆæœ¬ä½")
    
    # é–‹ç™¼è¤‡é›œåº¦åˆ†æ
    analyze_development_complexity()

if __name__ == "__main__":
    main()