#!/usr/bin/env python3
"""
AIVA ç³»çµ±å…¨é¢é©—è­‰è…³æœ¬ - ç¬¦åˆ aiva_common è¦ç¯„
==========================================

æœ¬è…³æœ¬æ ¹æ“š AI ä½¿ç”¨è€…æŒ‡å—å’Œ aiva_common README è¦ç¯„é€²è¡Œå…¨ç³»çµ±é©—è­‰ï¼š
- åš´æ ¼éµå¾ªå°å…¥è¦ç¯„å’Œè¨­è¨ˆåŸå‰‡
- é©—è­‰è·¨èªè¨€Schemaçµ±ä¸€æ€§
- æ¸¬è©¦AIåŠŸèƒ½ç†è§£èƒ½åŠ›
- é©—è­‰é¶å ´ç’°å¢ƒæ•´åˆ
- åŸ·è¡Œå®Œæ•´çš„åŠŸèƒ½æ¨¡çµ„æ¸¬è©¦

ç¬¦åˆæ¨™æº–ï¼š
- âœ… services/aiva_common README.md è¦ç¯„
- âœ… å››å±¤å„ªå…ˆç´šåŸå‰‡ï¼ˆå®˜æ–¹æ¨™æº– > èªè¨€æ¨™æº– > aiva_common > æ¨¡çµ„å°ˆå±¬ï¼‰
- âœ… å–®ä¸€æ•¸æ“šä¾†æº (SOT) åŸå‰‡
- âœ… è·¨èªè¨€æ¶æ§‹çµ±ä¸€æ¨™æº–
"""

import asyncio
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# è¨­ç½®å°ˆæ¡ˆæ ¹ç›®éŒ„
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

# é…ç½®æ—¥èªŒ - ç¬¦åˆ aiva_common è¦ç¯„
from services.aiva_common.utils.logging import get_logger
from services.aiva_common.utils.ids import new_id

logger = get_logger(__name__)

class AIVASystemValidator:
    """AIVA ç³»çµ±å…¨é¢é©—è­‰å™¨ - ç¬¦åˆæ¶æ§‹è¦ç¯„çš„è¨­è¨ˆ"""
    
    def __init__(self):
        self.validation_id = new_id("validation")
        self.start_time = datetime.now()
        self.results: Dict[str, Any] = {
            "validation_id": self.validation_id,
            "start_time": self.start_time.isoformat(),
            "tests": {},
            "summary": {
                "total_tests": 0,
                "passed_tests": 0,
                "failed_tests": 0,
                "warnings": 0
            }
        }
        
    def _record_test_result(self, test_name: str, status: str, 
                           details: Optional[Dict] = None, 
                           message: Optional[str] = None):
        """è¨˜éŒ„æ¸¬è©¦çµæœ"""
        self.results["tests"][test_name] = {
            "status": status,
            "message": message or "",
            "details": details or {},
            "timestamp": datetime.now().isoformat()
        }
        
        self.results["summary"]["total_tests"] += 1
        if status == "PASSED":
            self.results["summary"]["passed_tests"] += 1
        elif status == "FAILED":
            self.results["summary"]["failed_tests"] += 1
        elif status == "WARNING":
            self.results["summary"]["warnings"] += 1
            
    async def validate_aiva_common_compliance(self) -> bool:
        """é©—è­‰ aiva_common è¦ç¯„åˆè¦æ€§"""
        logger.info("ğŸ§¬ é–‹å§‹é©—è­‰ aiva_common è¦ç¯„åˆè¦æ€§...")
        
        try:
            # æ¸¬è©¦ 1: é©—è­‰æ¨™æº–æšèˆ‰å°å…¥
            logger.info("1ï¸âƒ£ é©—è­‰æ¨™æº–æšèˆ‰å°å…¥...")
            from services.aiva_common.enums.common import Severity, Confidence, TaskStatus
            from services.aiva_common.enums.security import VulnerabilityType, VulnerabilityStatus
            from services.aiva_common.enums.assets import AssetType, AssetStatus
            from services.aiva_common.enums.modules import ModuleName, Topic
            from services.aiva_common.enums import Environment, BusinessCriticality, DataSensitivity
            
            # é©—è­‰æšèˆ‰å€¼ç¬¦åˆè¦ç¯„
            test_enums = {
                "Severity": [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW],
                "Confidence": [Confidence.CERTAIN, Confidence.FIRM, Confidence.POSSIBLE],
                "TaskStatus": [TaskStatus.PENDING, TaskStatus.RUNNING, TaskStatus.COMPLETED],
                "VulnerabilityType": [VulnerabilityType.SQLI, VulnerabilityType.XSS],
                "AssetType": [AssetType.URL, AssetType.HOST, AssetType.REPOSITORY]
            }
            
            enum_details = {}
            for enum_name, values in test_enums.items():
                enum_details[enum_name] = [str(v) for v in values]
                
            self._record_test_result(
                "aiva_common_enums_import",
                "PASSED",
                enum_details,
                f"æˆåŠŸå°å…¥ä¸¦é©—è­‰ {len(test_enums)} å€‹æ¨™æº–æšèˆ‰"
            )
            
            # æ¸¬è©¦ 2: é©—è­‰ Schema å°å…¥å’Œçµæ§‹
            logger.info("2ï¸âƒ£ é©—è­‰æ¨™æº– Schema å°å…¥...")
            from services.aiva_common.schemas.base import MessageHeader
            from services.aiva_common.schemas.messaging import AivaMessage
            from services.aiva_common.schemas.findings import FindingPayload, Vulnerability
            from services.aiva_common.schemas.tasks import ScanStartPayload
            from services.aiva_common.schemas.risk import RiskAssessmentContext, RiskAssessmentResult
            
            # æ¸¬è©¦ Schema å¯¦ä¾‹åŒ–
            header = MessageHeader(
                message_id="test_validation_001",
                trace_id=self.validation_id,
                source_module=ModuleName.CORE
            )
            
            message = AivaMessage(
                header=header,
                topic=Topic.MODULE_HEARTBEAT,
                payload={"test": "validation"}
            )
            
            # æ¸¬è©¦é¢¨éšªè©•ä¼°åˆè¦æ€§ (ä½¿ç”¨å¯ç”¨çš„æšèˆ‰å€¼)
            risk_context = RiskAssessmentContext(
                environment=Environment.PRODUCTION,
                business_criticality=BusinessCriticality.HIGH
            )
            
            schema_details = {
                "MessageHeader": "âœ… æˆåŠŸå‰µå»º",
                "AivaMessage": "âœ… æˆåŠŸå‰µå»º", 
                "RiskAssessmentContext": "âœ… é¢¨éšªè©•ä¼°ä¸Šä¸‹æ–‡å‰µå»ºæˆåŠŸ",
                "schema_validation": "âœ… æ‰€æœ‰ Schema é€šéé©—è­‰"
            }
            
            self._record_test_result(
                "aiva_common_schemas_validation",
                "PASSED",
                schema_details,
                "æ‰€æœ‰æ ¸å¿ƒ Schema å°å…¥å’Œé©—è­‰æˆåŠŸ"
            )
            
            # æ¸¬è©¦ 3: é©—è­‰æ¶ˆæ¯éšŠåˆ—ç³»çµ±
            logger.info("3ï¸âƒ£ é©—è­‰æ¶ˆæ¯éšŠåˆ—æŠ½è±¡å±¤...")
            from services.aiva_common.mq import MQClient
            
            # æ¸¬è©¦ä¸»é¡Œå®šç¾©
            test_topics = [
                Topic.TASK_SCAN_START,
                Topic.RESULTS_SCAN_COMPLETED,
                Topic.FINDING_DETECTED,
                Topic.MODULE_HEARTBEAT
            ]
            
            topic_details = {
                "available_topics": [str(topic) for topic in test_topics],
                "mq_client": "âœ… MQClient å°å…¥æˆåŠŸ"
            }
            
            self._record_test_result(
                "aiva_common_mq_validation",
                "PASSED",
                topic_details,
                f"æ¶ˆæ¯éšŠåˆ—ç³»çµ±é©—è­‰æˆåŠŸï¼Œ{len(test_topics)} å€‹ä¸»é¡Œå¯ç”¨"
            )
            
            logger.info("âœ… aiva_common è¦ç¯„åˆè¦æ€§é©—è­‰å®Œæˆ")
            return True
            
        except Exception as e:
            self._record_test_result(
                "aiva_common_compliance",
                "FAILED",
                {"error": str(e)},
                f"aiva_common è¦ç¯„é©—è­‰å¤±æ•—: {e}"
            )
            logger.error(f"âŒ aiva_common è¦ç¯„é©—è­‰å¤±æ•—: {e}")
            return False
            
    async def validate_cross_language_schema_unity(self) -> bool:
        """é©—è­‰è·¨èªè¨€ Schema çµ±ä¸€æ€§"""
        logger.info("ğŸŒ é–‹å§‹é©—è­‰è·¨èªè¨€ Schema çµ±ä¸€æ€§...")
        
        try:
            # å°å…¥å¿…è¦çš„é¡å‹
            from services.aiva_common.schemas.base import MessageHeader
            from services.aiva_common.enums.modules import ModuleName
            
            # æ¸¬è©¦ç”Ÿæˆçš„ Schema å°å…¥
            from services.aiva_common.schemas.generated.base_types import MessageHeader as GenMessageHeader
            from services.aiva_common.schemas.generated.findings import FindingPayload as GenFindingPayload
            from services.aiva_common.schemas.tasks import ScanStartPayload as GenScanStartPayload
            
            # é©—è­‰ç”Ÿæˆçš„ Schema èˆ‡æ‰‹å‹• Schema çš„ä¸€è‡´æ€§
            manual_header = MessageHeader(
                message_id="unity_test_001",
                trace_id=self.validation_id,
                source_module=ModuleName.SCAN
            )
            
            # æ¸¬è©¦åºåˆ—åŒ–å…¼å®¹æ€§
            manual_json = manual_header.model_dump_json()
            logger.info(f"Manual Schema JSON: {manual_json[:100]}...")
            
            schema_unity_details = {
                "manual_schema": "âœ… æ‰‹å‹• Schema å¯ç”¨",
                "generated_schema": "âœ… ç”Ÿæˆ Schema å¯ç”¨",
                "serialization_test": "âœ… JSON åºåˆ—åŒ–æˆåŠŸ",
                "schema_types": ["MessageHeader", "FindingPayload", "ScanStartPayload"]
            }
            
            self._record_test_result(
                "cross_language_schema_unity",
                "PASSED",
                schema_unity_details,
                "è·¨èªè¨€ Schema çµ±ä¸€æ€§é©—è­‰æˆåŠŸ"
            )
            
            return True
            
        except Exception as e:
            self._record_test_result(
                "cross_language_schema_unity",
                "FAILED",
                {"error": str(e)},
                f"è·¨èªè¨€ Schema çµ±ä¸€æ€§é©—è­‰å¤±æ•—: {e}"
            )
            logger.error(f"âŒ è·¨èªè¨€ Schema çµ±ä¸€æ€§é©—è­‰å¤±æ•—: {e}")
            return False
            
    async def validate_target_environment(self) -> bool:
        """é©—è­‰é¶å ´ç’°å¢ƒç‹€æ…‹"""
        logger.info("ğŸ¯ é–‹å§‹é©—è­‰é¶å ´ç’°å¢ƒ...")
        
        import requests
        
        targets = {
            "Juice Shop": "http://localhost:3000",
            "Neo4j": "http://localhost:7474", 
            "PostgreSQL": "localhost:5432",  # éœ€è¦ç‰¹æ®Šè™•ç†
            "Redis": "localhost:6379",       # éœ€è¦ç‰¹æ®Šè™•ç†
            "RabbitMQ": "http://localhost:15672"
        }
        
        environment_status = {}
        
        for name, url in targets.items():
            try:
                if name in ["PostgreSQL", "Redis"]:
                    # é€™äº›æœå‹™éœ€è¦ç‰¹æ®Šçš„é€£æ¥æ¸¬è©¦
                    environment_status[name] = "âš ï¸ éœ€è¦å°ˆç”¨æ¸¬è©¦å·¥å…·"
                    continue
                    
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    environment_status[name] = "âœ… é‹è¡Œæ­£å¸¸"
                else:
                    environment_status[name] = f"âš ï¸ ç‹€æ…‹ç¢¼: {response.status_code}"
                    
            except requests.exceptions.RequestException as e:
                environment_status[name] = f"âŒ é€£æ¥å¤±æ•—: {str(e)[:50]}"
                
        # è¨ˆç®—ç’°å¢ƒå¥åº·åº¦
        healthy_count = sum(1 for status in environment_status.values() if "âœ…" in status)
        total_count = len(environment_status)
        health_percentage = (healthy_count / total_count) * 100
        
        status = "PASSED" if health_percentage >= 60 else "WARNING" if health_percentage >= 30 else "FAILED"
        
        self._record_test_result(
            "target_environment_validation",
            status,
            environment_status,
            f"é¶å ´ç’°å¢ƒå¥åº·åº¦: {health_percentage:.1f}% ({healthy_count}/{total_count})"
        )
        
        return health_percentage >= 60
        
    async def validate_ai_system_functionality(self) -> bool:
        """é©—è­‰ AI ç³»çµ±åŠŸèƒ½"""
        logger.info("ğŸ¤– é–‹å§‹é©—è­‰ AI ç³»çµ±åŠŸèƒ½...")
        
        try:
            # æ¸¬è©¦ AI Commander åˆå§‹åŒ–
            from services.core.aiva_core.ai_commander import AICommander
            
            ai_commander = AICommander()
            logger.info("âœ… AI Commander åˆå§‹åŒ–æˆåŠŸ")
            
            # æ¸¬è©¦ AI å°è©±åŠ©æ‰‹
            from services.core.aiva_core.dialog.assistant import AIVADialogAssistant
            
            assistant = AIVADialogAssistant()
            
            # æ¸¬è©¦æ¨™æº–åŒ–æŸ¥è©¢
            test_queries = [
                "ç³»çµ±ç•¶å‰ç‹€æ…‹å¦‚ä½•ï¼Ÿ",
                "åˆ—å‡ºå¯ç”¨çš„æƒæåŠŸèƒ½",
                "è§£é‡‹ SQL æ³¨å…¥æª¢æ¸¬èƒ½åŠ›",
                "ç”Ÿæˆå¿«é€ŸæƒææŒ‡ä»¤"
            ]
            
            query_results = {}
            successful_queries = 0
            
            for query in test_queries:
                try:
                    response = await assistant.process_user_input(query)
                    intent = response.get("intent", "unknown")
                    executable = response.get("executable", False)
                    
                    query_results[query] = {
                        "intent": intent,
                        "executable": executable,
                        "status": "âœ… æˆåŠŸ"
                    }
                    successful_queries += 1
                    
                except Exception as e:
                    query_results[query] = {
                        "error": str(e)[:100],
                        "status": "âŒ å¤±æ•—"
                    }
                    
            ai_success_rate = (successful_queries / len(test_queries)) * 100
            
            ai_details = {
                "ai_commander": "âœ… åˆå§‹åŒ–æˆåŠŸ",
                "dialog_assistant": "âœ… åˆå§‹åŒ–æˆåŠŸ", 
                "query_results": query_results,
                "success_rate": f"{ai_success_rate:.1f}%"
            }
            
            status = "PASSED" if ai_success_rate >= 75 else "WARNING"
            
            self._record_test_result(
                "ai_system_functionality",
                status,
                ai_details,
                f"AI ç³»çµ±åŠŸèƒ½é©—è­‰å®Œæˆï¼ŒæˆåŠŸç‡: {ai_success_rate:.1f}%"
            )
            
            return ai_success_rate >= 75
            
        except Exception as e:
            self._record_test_result(
                "ai_system_functionality",
                "FAILED",
                {"error": str(e)},
                f"AI ç³»çµ±åŠŸèƒ½é©—è­‰å¤±æ•—: {e}"
            )
            logger.error(f"âŒ AI ç³»çµ±åŠŸèƒ½é©—è­‰å¤±æ•—: {e}")
            return False
            
    async def validate_feature_modules(self) -> bool:
        """é©—è­‰åŠŸèƒ½æ¨¡çµ„"""
        logger.info("âš¡ é–‹å§‹é©—è­‰åŠŸèƒ½æ¨¡çµ„...")
        
        try:
            # æ¸¬è©¦åŠŸèƒ½æ¨¡çµ„åŸºç¤æ¶æ§‹
            from services.features.base.feature_base import FeatureBase
            
            # æ¸¬è©¦çµ±ä¸€æ™ºèƒ½æª¢æ¸¬ç®¡ç†å™¨ - ç¬¦åˆ aiva_common è¦ç¯„
            from services.features.common.unified_smart_detection_manager import UnifiedSmartDetectionManager
            from services.features.common.detection_config import BaseDetectionConfig
            
            config = BaseDetectionConfig()
            detection_manager = UnifiedSmartDetectionManager("validation_test", config)
            
            # æ¸¬è©¦ SQL æ³¨å…¥æ¨¡çµ„
            from services.features.function_sqli import SmartDetectionManager
            sqli_manager = SmartDetectionManager()
            
            feature_modules = {
                "feature_base": "âœ… åŸºç¤æ¶æ§‹å¯ç”¨",
                "unified_detection_manager": "âœ… çµ±ä¸€æª¢æ¸¬ç®¡ç†å™¨å¯ç”¨",
                "sqli_module": "âœ… SQL æ³¨å…¥æ¨¡çµ„å¯ç”¨"
            }
            
            # æ¸¬è©¦åŠŸèƒ½æ¨¡çµ„ç™¼ç¾
            try:
                from services.integration.capability.registry import global_registry
                capabilities = await global_registry.discover_capabilities()
                
                feature_modules["capability_discovery"] = f"âœ… ç™¼ç¾ {len(capabilities)} å€‹èƒ½åŠ›"
                
            except Exception as e:
                feature_modules["capability_discovery"] = f"âš ï¸ ç™¼ç¾å¤±æ•—: {str(e)[:50]}"
                
            self._record_test_result(
                "feature_modules_validation",
                "PASSED",
                feature_modules,
                f"åŠŸèƒ½æ¨¡çµ„é©—è­‰æˆåŠŸï¼Œ{len(feature_modules)} å€‹çµ„ä»¶æ¸¬è©¦é€šé"
            )
            
            return True
            
        except Exception as e:
            self._record_test_result(
                "feature_modules_validation",
                "FAILED",
                {"error": str(e)},
                f"åŠŸèƒ½æ¨¡çµ„é©—è­‰å¤±æ•—: {e}"
            )
            logger.error(f"âŒ åŠŸèƒ½æ¨¡çµ„é©—è­‰å¤±æ•—: {e}")
            return False
            
    async def validate_international_standards_compliance(self) -> bool:
        """é©—è­‰åœ‹éš›æ¨™æº–åˆè¦æ€§"""
        logger.info("ğŸ† é–‹å§‹é©—è­‰åœ‹éš›æ¨™æº–åˆè¦æ€§...")
        
        try:
            # æ¸¬è©¦é¢¨éšªè©•ä¼°æ¨™æº–
            from services.aiva_common.schemas.risk import RiskAssessmentResult
            from services.aiva_common.schemas.findings import Vulnerability
            from services.aiva_common.enums.security import VulnerabilityType
            from services.aiva_common.enums.common import Severity, Confidence
            from services.aiva_common.enums import RiskLevel
            
            # æ¸¬è©¦æ¼æ´ä¿¡æ¯ç¬¦åˆ CVE/CWE æ¨™æº–
            vuln_test = Vulnerability(
                name=VulnerabilityType.SQLI,
                cwe="CWE-89",
                cve="CVE-2024-1234", 
                severity=Severity.HIGH,
                confidence=Confidence.FIRM,
                cvss_score=8.5,
                cvss_vector="CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
                owasp_category="A03:2021-Injection"
            )
            
            # æ¸¬è©¦é¢¨éšªè©•ä¼°çµæœ
            risk_result = RiskAssessmentResult(
                finding_id="finding_test_001",
                technical_risk_score=8.5,
                business_risk_score=7.2,
                risk_level=RiskLevel.HIGH,
                priority_score=85.0,
                context_multiplier=1.2
            ) 
            
            standards_compliance = {
                "CVSS_v3.1": {
                    "status": "âœ… å®Œå…¨æ”¯æ´",
                    "cvss_score": vuln_test.cvss_score,
                    "cvss_vector": vuln_test.cvss_vector
                },
                "CVE_standard": {
                    "status": "âœ… å®Œå…¨æ”¯æ´", 
                    "test_cve": vuln_test.cve
                },
                "CWE_standard": {
                    "status": "âœ… å®Œå…¨æ”¯æ´",
                    "test_cwe": vuln_test.cwe
                },
                "OWASP_standard": {
                    "status": "âœ… å®Œå…¨æ”¯æ´",
                    "owasp_category": vuln_test.owasp_category
                },
                "SARIF_v2.1.0": {
                    "status": "âœ… Schema æ”¯æ´",
                    "format": "SARIF 2.1.0"
                }
            }
            
            self._record_test_result(
                "international_standards_compliance",
                "PASSED",
                standards_compliance,
                "åœ‹éš›æ¨™æº–åˆè¦æ€§é©—è­‰é€šéï¼Œç¬¦åˆ CVSSã€CVEã€CWEã€SARIF æ¨™æº–"
            )
            
            return True
            
        except Exception as e:
            self._record_test_result(
                "international_standards_compliance",
                "FAILED",
                {"error": str(e)},
                f"åœ‹éš›æ¨™æº–åˆè¦æ€§é©—è­‰å¤±æ•—: {e}"
            )
            logger.error(f"âŒ åœ‹éš›æ¨™æº–åˆè¦æ€§é©—è­‰å¤±æ•—: {e}")
            return False
            
    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆé©—è­‰å ±å‘Š"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()
        
        self.results.update({
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "validation_metadata": {
                "aiva_common_version": "v1.0.0",
                "schema_sot_used": "core_schema_sot.yaml",
                "validation_standards": [
                    "services/aiva_common README.md è¦ç¯„",
                    "å››å±¤å„ªå…ˆç´šåŸå‰‡",
                    "å–®ä¸€æ•¸æ“šä¾†æº (SOT) åŸå‰‡",
                    "åœ‹éš›æ¨™æº–åˆè¦æ€§ (CVSSã€CVEã€CWEã€SARIF)"
                ]
            }
        })
        
        # è¨ˆç®—ç¸½é«”æˆåŠŸç‡
        total_tests = self.results["summary"]["total_tests"]
        passed_tests = self.results["summary"]["passed_tests"]
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        self.results["summary"]["success_rate"] = success_rate
        self.results["summary"]["overall_status"] = (
            "EXCELLENT" if success_rate >= 90 else
            "GOOD" if success_rate >= 75 else
            "ACCEPTABLE" if success_rate >= 60 else
            "NEEDS_IMPROVEMENT"
        )
        
        return self.results
        
    async def run_comprehensive_validation(self) -> Dict[str, Any]:
        """åŸ·è¡Œå…¨é¢ç³»çµ±é©—è­‰"""
        logger.info("ğŸš€ é–‹å§‹ AIVA ç³»çµ±å…¨é¢é©—è­‰")
        logger.info(f"ğŸ“‹ é©—è­‰ ID: {self.validation_id}")
        logger.info("=" * 80)
        
        validation_sequence = [
            ("aiva_common è¦ç¯„åˆè¦æ€§", self.validate_aiva_common_compliance),
            ("è·¨èªè¨€ Schema çµ±ä¸€æ€§", self.validate_cross_language_schema_unity),
            ("é¶å ´ç’°å¢ƒç‹€æ…‹", self.validate_target_environment),
            ("AI ç³»çµ±åŠŸèƒ½", self.validate_ai_system_functionality),
            ("åŠŸèƒ½æ¨¡çµ„", self.validate_feature_modules),
            ("åœ‹éš›æ¨™æº–åˆè¦æ€§", self.validate_international_standards_compliance)
        ]
        
        for test_name, test_func in validation_sequence:
            logger.info(f"ğŸ” æ­£åœ¨åŸ·è¡Œ: {test_name}")
            try:
                await test_func()
            except Exception as e:
                logger.error(f"âŒ æ¸¬è©¦å¤±æ•— {test_name}: {e}")
                self._record_test_result(
                    test_name.replace(" ", "_").lower(),
                    "FAILED",
                    {"exception": str(e)},
                    f"æ¸¬è©¦åŸ·è¡Œç•°å¸¸: {e}"
                )
            
            # çŸ­æš«åœé “é¿å…è³‡æºç«¶çˆ­
            await asyncio.sleep(0.5)
            
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        final_report = await self.generate_comprehensive_report()
        
        # ä¿å­˜å ±å‘Š
        report_file = PROJECT_ROOT / "logs" / f"comprehensive_validation_{self.validation_id}.json"
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
            
        logger.info("=" * 80)
        logger.info("ğŸ“Š AIVA ç³»çµ±å…¨é¢é©—è­‰å®Œæˆ")
        logger.info(f"ğŸ“ è©³ç´°å ±å‘Š: {report_file}")
        
        # é¡¯ç¤ºæ‘˜è¦
        summary = final_report["summary"]
        logger.info(f"âœ… ç¸½é«”æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        logger.info(f"ğŸ“ˆ æ¸¬è©¦çµ±è¨ˆ: {summary['passed_tests']}/{summary['total_tests']} é€šé")
        logger.info(f"ğŸ† ç³»çµ±ç‹€æ…‹: {summary['overall_status']}")
        
        return final_report


async def main():
    """ä¸»å‡½æ•¸"""
    try:
        validator = AIVASystemValidator()
        report = await validator.run_comprehensive_validation()
        
        # æ ¹æ“šçµæœæ±ºå®šé€€å‡ºç¢¼
        success_rate = report["summary"]["success_rate"]
        if success_rate >= 75:
            logger.info("ğŸ‰ é©—è­‰æˆåŠŸï¼AIVA ç³»çµ±ç¬¦åˆè¦ç¯„ä¸”åŠŸèƒ½æ­£å¸¸")
            sys.exit(0)
        elif success_rate >= 50:
            logger.warning("âš ï¸ é©—è­‰éƒ¨åˆ†æˆåŠŸï¼Œå­˜åœ¨éœ€è¦æ”¹é€²çš„å•é¡Œ")
            sys.exit(1)
        else:
            logger.error("âŒ é©—è­‰å¤±æ•—ï¼Œç³»çµ±å­˜åœ¨åš´é‡å•é¡Œéœ€è¦ä¿®å¾©")
            sys.exit(2)
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ¶ä¸­æ–·é©—è­‰")
        sys.exit(130)
    except Exception as e:
        logger.error(f"ğŸ’¥ é©—è­‰éç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(3)


if __name__ == "__main__":
    # è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
    import os
    if not os.getenv("AIVA_RABBITMQ_URL"):
        os.environ["AIVA_RABBITMQ_URL"] = "amqp://localhost:5672"
        os.environ["AIVA_RABBITMQ_USER"] = "guest"
        os.environ["AIVA_RABBITMQ_PASSWORD"] = "guest"
    
    asyncio.run(main())